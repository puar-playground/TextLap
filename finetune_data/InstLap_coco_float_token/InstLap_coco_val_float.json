[
  {
    "id": "coco_000000000285",
    "conversations": [
      {
        "from": "human",
        "value": "The bear's head is in the center of the image, facing forward."
      },
      {
        "from": "gpt",
        "value": "bear: [0.047, 0.109, 0.953, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000000285_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bears head is in the center of the image, facing forward.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.047, 0.109, 0.953, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000000285_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the brown bear's head is in the center of the image, facing forward."
      },
      {
        "from": "gpt",
        "value": "brown bear: [0.047, 0.109, 0.953, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000000285_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the brown bears head is in the center of the image, facing forward.\nObjects: [brown bear]"
      },
      {
        "from": "gpt",
        "value": "brown bear: [0.047, 0.109, 0.953, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000000285_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.047, 0.109, 0.953, 0.984]\nGiven the above layout, shift the bear upwards by 0.047."
      },
      {
        "from": "gpt",
        "value": "bear: [0.047, 0.062, 0.953, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000000632",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is at the center of the image, and the potted plant is on the windowsill to the right of the bed."
      },
      {
        "from": "gpt",
        "value": "bed: [0.008, 0.539, 0.625, 0.859]\npotted plant: [0.539, 0.453, 0.664, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000000632_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is at the center of the image, and the potted plant is on the windowsill to the right of the bed.\nObjects: [bed, potted plant]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.008, 0.539, 0.625, 0.859]\npotted plant: [0.539, 0.453, 0.664, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000000724",
    "conversations": [
      {
        "from": "human",
        "value": "A stop sign is located to the right of the image against a background of trees and sky."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.359, 0.141, 0.633, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000000724_key",
    "conversations": [
      {
        "from": "human",
        "value": "A stop sign is located to the right of the image against a background of trees and sky.\nObjects: [stop sign]"
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.359, 0.141, 0.633, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000000724_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red traffic signal is located to the right of the image against a background of trees and sky."
      },
      {
        "from": "gpt",
        "value": "red traffic signal: [0.359, 0.141, 0.633, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000000724_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red traffic signal is located to the right of the image against a background of trees and sky.\nObjects: [red traffic signal]"
      },
      {
        "from": "gpt",
        "value": "red traffic signal: [0.359, 0.141, 0.633, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000000724_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: stop sign: [0.359, 0.141, 0.633, 0.445]\nGiven the above layout, shift the stop sign downwards by 0.078."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.359, 0.219, 0.633, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000000785",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skiing, with each ski positioned parallel under each foot."
      },
      {
        "from": "gpt",
        "value": "person: [0.438, 0.234, 0.773, 0.773]\nskis: [0.320, 0.727, 0.953, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000000785_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skiing, with each ski positioned parallel under each foot.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.438, 0.234, 0.773, 0.773]\nskis: [0.320, 0.727, 0.953, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000000785_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young skier is skiing, with each ski positioned parallel under each foot."
      },
      {
        "from": "gpt",
        "value": "young skier: [0.438, 0.234, 0.773, 0.773]\nred and white skis: [0.320, 0.727, 0.953, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000000785_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young skier is skiing, with each ski positioned parallel under each foot.\nObjects: [young skier, red and white skis]"
      },
      {
        "from": "gpt",
        "value": "young skier: [0.438, 0.234, 0.773, 0.773]\nred and white skis: [0.320, 0.727, 0.953, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000000785_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.438, 0.234, 0.773, 0.773]\nskis: [0.320, 0.727, 0.953, 0.789]\nGiven the above layout, shift the skis to the left by 0.234."
      },
      {
        "from": "gpt",
        "value": "person: [0.438, 0.234, 0.773, 0.773]\nskis: [0.086, 0.727, 0.719, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000000802",
    "conversations": [
      {
        "from": "human",
        "value": "A refrigerator is to the right of an oven in a kitchen."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.547, 0.289, 0.805, 0.836]\noven: [0.219, 0.445, 0.414, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000000802_key",
    "conversations": [
      {
        "from": "human",
        "value": "A refrigerator is to the right of an oven in a kitchen.\nObjects: [refrigerator, oven]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.547, 0.289, 0.805, 0.836]\noven: [0.219, 0.445, 0.414, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000000802_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a stainless steel refrigerator is to the right of an small electric oven in a kitchen."
      },
      {
        "from": "gpt",
        "value": "stainless steel refrigerator: [0.547, 0.289, 0.805, 0.836]\nsmall electric oven: [0.219, 0.445, 0.414, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000000802_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a stainless steel refrigerator is to the right of an small electric oven in a kitchen.\nObjects: [stainless steel refrigerator, small electric oven]"
      },
      {
        "from": "gpt",
        "value": "stainless steel refrigerator: [0.547, 0.289, 0.805, 0.836]\nsmall electric oven: [0.219, 0.445, 0.414, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000000802_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: refrigerator: [0.547, 0.289, 0.805, 0.836]\noven: [0.219, 0.445, 0.414, 0.805]\nGiven the above layout, shift the refrigerator upwards by 0.055."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.547, 0.234, 0.805, 0.781]\noven: [0.219, 0.445, 0.414, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000001425",
    "conversations": [
      {
        "from": "human",
        "value": "A sandwich in the foreground on a plate, with a bowl to the right in the background."
      },
      {
        "from": "gpt",
        "value": "sandwich: [0.102, 0.383, 0.680, 0.727]\nbowl: [0.758, 0.383, 0.992, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000001425_key",
    "conversations": [
      {
        "from": "human",
        "value": "A sandwich in the foreground on a plate, with a bowl to the right in the background.\nObjects: [sandwich, bowl]"
      },
      {
        "from": "gpt",
        "value": "sandwich: [0.102, 0.383, 0.680, 0.727]\nbowl: [0.758, 0.383, 0.992, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000001425_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a ham and cheese sandwich in the foreground on a plate, with a blue ceramic bowl to the right in the background."
      },
      {
        "from": "gpt",
        "value": "ham and cheese sandwich: [0.102, 0.383, 0.680, 0.727]\nblue ceramic bowl: [0.758, 0.383, 0.992, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000001425_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a ham and cheese sandwich in the foreground on a plate, with a blue ceramic bowl to the right in the background.\nObjects: [ham and cheese sandwich, blue ceramic bowl]"
      },
      {
        "from": "gpt",
        "value": "ham and cheese sandwich: [0.102, 0.383, 0.680, 0.727]\nblue ceramic bowl: [0.758, 0.383, 0.992, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000001425_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sandwich: [0.102, 0.383, 0.680, 0.727]\nbowl: [0.758, 0.383, 0.992, 0.695]\nGiven the above layout, shift the sandwich upwards by 0.352."
      },
      {
        "from": "gpt",
        "value": "sandwich: [0.102, 0.031, 0.680, 0.375]\nbowl: [0.758, 0.383, 0.992, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000001503",
    "conversations": [
      {
        "from": "human",
        "value": "A laptop is on the left, a keyboard is in the center, and a TV is on the right."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.000, 0.430, 0.391, 0.852]\ntv: [0.391, 0.156, 0.734, 0.438]\nkeyboard: [0.500, 0.594, 0.977, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000001503_key",
    "conversations": [
      {
        "from": "human",
        "value": "A laptop is on the left, a keyboard is in the center, and a TV is on the right.\nObjects: [laptop, tv, keyboard]"
      },
      {
        "from": "gpt",
        "value": "laptop: [0.000, 0.430, 0.391, 0.852]\ntv: [0.391, 0.156, 0.734, 0.438]\nkeyboard: [0.500, 0.594, 0.977, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000001503_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek MacBook Pro is on the left, a wireless mechanical keyboard is in the center, and a large plasma screen is on the right."
      },
      {
        "from": "gpt",
        "value": "sleek MacBook Pro: [0.000, 0.430, 0.391, 0.852]\nlarge plasma screen: [0.391, 0.156, 0.734, 0.438]\nwireless mechanical keyboard: [0.500, 0.594, 0.977, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000001503_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek MacBook Pro is on the left, a wireless mechanical keyboard is in the center, and a large plasma screen is on the right.\nObjects: [sleek MacBook Pro, large plasma screen, wireless mechanical keyboard]"
      },
      {
        "from": "gpt",
        "value": "sleek MacBook Pro: [0.000, 0.430, 0.391, 0.852]\nlarge plasma screen: [0.391, 0.156, 0.734, 0.438]\nwireless mechanical keyboard: [0.500, 0.594, 0.977, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000001503_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: laptop: [0.000, 0.430, 0.391, 0.852]\ntv: [0.391, 0.156, 0.734, 0.438]\nkeyboard: [0.500, 0.594, 0.977, 0.734]\nGiven the above layout, shift the tv upwards by 0.102."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.000, 0.430, 0.391, 0.852]\ntv: [0.391, 0.055, 0.734, 0.336]\nkeyboard: [0.500, 0.594, 0.977, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000001584",
    "conversations": [
      {
        "from": "human",
        "value": "A red double-decker bus in the center of the image."
      },
      {
        "from": "gpt",
        "value": "bus: [0.203, 0.148, 0.852, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000001584_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red double-decker bus in the center of the image.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.203, 0.148, 0.852, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000001584_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red double-decker classic London double-decker bus in the center of the image."
      },
      {
        "from": "gpt",
        "value": "classic London double-decker bus: [0.203, 0.148, 0.852, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000001584_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red double-decker classic London double-decker bus in the center of the image.\nObjects: [classic London double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "classic London double-decker bus: [0.203, 0.148, 0.852, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000001584_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.203, 0.148, 0.852, 0.867]\nGiven the above layout, shift the bus to the left by 0.164."
      },
      {
        "from": "gpt",
        "value": "bus: [0.039, 0.148, 0.688, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000001675",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is lying on top of a keyboard."
      },
      {
        "from": "gpt",
        "value": "cat: [0.000, 0.148, 0.992, 0.602]\nkeyboard: [0.094, 0.695, 0.883, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000001675_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is lying on top of a keyboard.\nObjects: [cat, keyboard]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.000, 0.148, 0.992, 0.602]\nkeyboard: [0.094, 0.695, 0.883, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000001675_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a small ginger kitten is lying on top of a standard office keyboard."
      },
      {
        "from": "gpt",
        "value": "small ginger kitten: [0.000, 0.148, 0.992, 0.602]\nstandard office keyboard: [0.094, 0.695, 0.883, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000001675_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a small ginger kitten is lying on top of a standard office keyboard.\nObjects: [small ginger kitten, standard office keyboard]"
      },
      {
        "from": "gpt",
        "value": "small ginger kitten: [0.000, 0.148, 0.992, 0.602]\nstandard office keyboard: [0.094, 0.695, 0.883, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000001675_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.000, 0.148, 0.992, 0.602]\nkeyboard: [0.094, 0.695, 0.883, 0.859]\nGiven the above layout, shift the cat upwards by 0.125."
      },
      {
        "from": "gpt",
        "value": "cat: [0.000, 0.023, 0.992, 0.477]\nkeyboard: [0.094, 0.695, 0.883, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000002431",
    "conversations": [
      {
        "from": "human",
        "value": "A wine glass is to the right of two cups on a dining table."
      },
      {
        "from": "gpt",
        "value": "dining table: [0.148, 0.008, 0.852, 0.969]\nwine glass: [0.617, 0.000, 0.805, 0.328]\ncup: [0.305, 0.609, 0.508, 0.883]\ncup: [0.695, 0.641, 0.852, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000002431_key",
    "conversations": [
      {
        "from": "human",
        "value": "A wine glass is to the right of two cups on a dining table.\nObjects: [dining table, wine glass, cup, cup]"
      },
      {
        "from": "gpt",
        "value": "dining table: [0.148, 0.008, 0.852, 0.969]\nwine glass: [0.617, 0.000, 0.805, 0.328]\ncup: [0.305, 0.609, 0.508, 0.883]\ncup: [0.695, 0.641, 0.852, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000003553",
    "conversations": [
      {
        "from": "human",
        "value": "A person's foot on top of a skateboard."
      },
      {
        "from": "gpt",
        "value": "person: [0.234, 0.164, 0.648, 0.641]\nskateboard: [0.289, 0.570, 0.570, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000003553_key",
    "conversations": [
      {
        "from": "human",
        "value": "A persons foot on top of a skateboard.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.234, 0.164, 0.648, 0.641]\nskateboard: [0.289, 0.570, 0.570, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000003553_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager's foot on top of a multicolored skateboard."
      },
      {
        "from": "gpt",
        "value": "teenager: [0.234, 0.164, 0.648, 0.641]\nmulticolored skateboard: [0.289, 0.570, 0.570, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000003553_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenagers foot on top of a multicolored skateboard.\nObjects: [teenager, multicolored skateboard]"
      },
      {
        "from": "gpt",
        "value": "teenager: [0.234, 0.164, 0.648, 0.641]\nmulticolored skateboard: [0.289, 0.570, 0.570, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000003553_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.234, 0.164, 0.648, 0.641]\nskateboard: [0.289, 0.570, 0.570, 0.742]\nGiven the above layout, shift the person to the right by 0.094."
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.164, 0.742, 0.641]\nskateboard: [0.289, 0.570, 0.570, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000003661",
    "conversations": [
      {
        "from": "human",
        "value": "A bunch of bananas is in the foreground, with a cup to the right in the background."
      },
      {
        "from": "gpt",
        "value": "banana: [0.094, 0.195, 0.859, 0.742]\ncup: [0.883, 0.227, 0.992, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000003661_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bunch of bananas is in the foreground, with a cup to the right in the background.\nObjects: [banana, cup]"
      },
      {
        "from": "gpt",
        "value": "banana: [0.094, 0.195, 0.859, 0.742]\ncup: [0.883, 0.227, 0.992, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000003661_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a bunch of ripe bunch of bananass is in the foreground, with a ceramic coffee mug to the right in the background."
      },
      {
        "from": "gpt",
        "value": "ripe bunch of bananas: [0.094, 0.195, 0.859, 0.742]\nceramic coffee mug: [0.883, 0.227, 0.992, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000003661_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a bunch of ripe bunch of bananass is in the foreground, with a ceramic coffee mug to the right in the background.\nObjects: [ripe bunch of bananas, ceramic coffee mug]"
      },
      {
        "from": "gpt",
        "value": "ripe bunch of bananas: [0.094, 0.195, 0.859, 0.742]\nceramic coffee mug: [0.883, 0.227, 0.992, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000003661_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: banana: [0.094, 0.195, 0.859, 0.742]\ncup: [0.883, 0.227, 0.992, 0.570]\nGiven the above layout, shift the banana downwards by 0.195."
      },
      {
        "from": "gpt",
        "value": "banana: [0.094, 0.391, 0.859, 0.938]\ncup: [0.883, 0.227, 0.992, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000004765",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a surfboard at the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.203, 0.656, 0.625]\nsurfboard: [0.414, 0.547, 0.875, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000004765_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a surfboard at the center of the image.\nObjects: [person, surfboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.203, 0.656, 0.625]\nsurfboard: [0.414, 0.547, 0.875, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000004765_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a professional surfer is standing on a red and white striped surfboard at the center of the image."
      },
      {
        "from": "gpt",
        "value": "professional surfer: [0.344, 0.203, 0.656, 0.625]\nred and white striped surfboard: [0.414, 0.547, 0.875, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000004765_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a professional surfer is standing on a red and white striped surfboard at the center of the image.\nObjects: [professional surfer, red and white striped surfboard]"
      },
      {
        "from": "gpt",
        "value": "professional surfer: [0.344, 0.203, 0.656, 0.625]\nred and white striped surfboard: [0.414, 0.547, 0.875, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000004765_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.344, 0.203, 0.656, 0.625]\nsurfboard: [0.414, 0.547, 0.875, 0.688]\nGiven the above layout, shift the person to the left by 0.078."
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.203, 0.578, 0.625]\nsurfboard: [0.414, 0.547, 0.875, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000005037",
    "conversations": [
      {
        "from": "human",
        "value": "There is no person visible in the image; only a bus is shown on the left side."
      },
      {
        "from": "gpt",
        "value": "bus: [0.156, 0.195, 0.891, 0.742]\nperson: [0.969, 0.500, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000005037_key",
    "conversations": [
      {
        "from": "human",
        "value": "There is no person visible in the image; only a bus is shown on the left side.\nObjects: [bus, person]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.156, 0.195, 0.891, 0.742]\nperson: [0.969, 0.500, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000005037_aug",
    "conversations": [
      {
        "from": "human",
        "value": "there is no unseen individual visible in the image; only a city bus is shown on the left side."
      },
      {
        "from": "gpt",
        "value": "city bus: [0.156, 0.195, 0.891, 0.742]\nunseen individual: [0.969, 0.500, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000005037_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "there is no unseen individual visible in the image; only a city bus is shown on the left side.\nObjects: [city bus, unseen individual]"
      },
      {
        "from": "gpt",
        "value": "city bus: [0.156, 0.195, 0.891, 0.742]\nunseen individual: [0.969, 0.500, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000005037_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.156, 0.195, 0.891, 0.742]\nperson: [0.969, 0.500, 0.992, 0.727]\nGiven the above layout, shift the bus downwards by 0.180."
      },
      {
        "from": "gpt",
        "value": "bus: [0.156, 0.375, 0.891, 0.922]\nperson: [0.969, 0.500, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000023781",
    "conversations": [
      {
        "from": "human",
        "value": "The broccoli is located at the top right corner of the image."
      },
      {
        "from": "gpt",
        "value": "broccoli: [0.117, 0.352, 0.500, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000023781_key",
    "conversations": [
      {
        "from": "human",
        "value": "The broccoli is located at the top right corner of the image.\nObjects: [broccoli]"
      },
      {
        "from": "gpt",
        "value": "broccoli: [0.117, 0.352, 0.500, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000023781_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the bunch of spinach is located at the top right corner of the image."
      },
      {
        "from": "gpt",
        "value": "bunch of spinach: [0.117, 0.352, 0.500, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000023781_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the bunch of spinach is located at the top right corner of the image.\nObjects: [bunch of spinach]"
      },
      {
        "from": "gpt",
        "value": "bunch of spinach: [0.117, 0.352, 0.500, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000023781_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: broccoli: [0.117, 0.352, 0.500, 0.562]\nGiven the above layout, shift the broccoli to the right by 0.367."
      },
      {
        "from": "gpt",
        "value": "broccoli: [0.484, 0.352, 0.867, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000025139",
    "conversations": [
      {
        "from": "human",
        "value": "A zebra in the foreground on the left facing away and another zebra in the background on the right facing towards the camera."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.000, 0.172, 0.680, 0.820]\nzebra: [0.625, 0.219, 0.906, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000025139_key",
    "conversations": [
      {
        "from": "human",
        "value": "A zebra in the foreground on the left facing away and another zebra in the background on the right facing towards the camera.\nObjects: [zebra, zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.000, 0.172, 0.680, 0.820]\nzebra: [0.625, 0.219, 0.906, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000025181",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the right side of the tracks, parallel to the platform."
      },
      {
        "from": "gpt",
        "value": "train: [0.555, 0.383, 0.992, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000025181_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the right side of the tracks, parallel to the platform.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.555, 0.383, 0.992, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000025181_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker commuter train is on the right side of the tracks, parallel to the platform."
      },
      {
        "from": "gpt",
        "value": "double-decker commuter train: [0.555, 0.383, 0.992, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000025181_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker commuter train is on the right side of the tracks, parallel to the platform.\nObjects: [double-decker commuter train]"
      },
      {
        "from": "gpt",
        "value": "double-decker commuter train: [0.555, 0.383, 0.992, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000025181_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.555, 0.383, 0.992, 0.633]\nGiven the above layout, shift the train to the left by 0.148."
      },
      {
        "from": "gpt",
        "value": "train: [0.406, 0.383, 0.844, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000025228",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on a surfboard in the water."
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.398, 0.703, 0.805]\nsurfboard: [0.227, 0.719, 0.812, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000025228_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on a surfboard in the water.\nObjects: [person, surfboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.398, 0.703, 0.805]\nsurfboard: [0.227, 0.719, 0.812, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000025228_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a middle-aged man is sitting on a a red and white striped surfboard in the water."
      },
      {
        "from": "gpt",
        "value": "a middle-aged man: [0.266, 0.398, 0.703, 0.805]\na red and white striped surfboard: [0.227, 0.719, 0.812, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000025228_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a middle-aged man is sitting on a a red and white striped surfboard in the water.\nObjects: [a middle-aged man, a red and white striped surfboard]"
      },
      {
        "from": "gpt",
        "value": "a middle-aged man: [0.266, 0.398, 0.703, 0.805]\na red and white striped surfboard: [0.227, 0.719, 0.812, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000025228_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.266, 0.398, 0.703, 0.805]\nsurfboard: [0.227, 0.719, 0.812, 0.828]\nGiven the above layout, shift the person upwards by 0.297."
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.102, 0.703, 0.508]\nsurfboard: [0.227, 0.719, 0.812, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000025424",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center swinging a tennis racket over their head towards the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.375, 0.656, 0.992]\ntennis racket: [0.617, 0.195, 0.805, 0.422]"
      }
    ]
  },
  {
    "id": "coco_000000025424_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center swinging a tennis racket over their head towards the right.\nObjects: [person, tennis racket]"
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.375, 0.656, 0.992]\ntennis racket: [0.617, 0.195, 0.805, 0.422]"
      }
    ]
  },
  {
    "id": "coco_000000025424_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a professional tennis player is at the center swinging a white and blue tennis racket over their head towards the right."
      },
      {
        "from": "gpt",
        "value": "professional tennis player: [0.367, 0.375, 0.656, 0.992]\nwhite and blue tennis racket: [0.617, 0.195, 0.805, 0.422]"
      }
    ]
  },
  {
    "id": "coco_000000025424_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a professional tennis player is at the center swinging a white and blue tennis racket over their head towards the right.\nObjects: [professional tennis player, white and blue tennis racket]"
      },
      {
        "from": "gpt",
        "value": "professional tennis player: [0.367, 0.375, 0.656, 0.992]\nwhite and blue tennis racket: [0.617, 0.195, 0.805, 0.422]"
      }
    ]
  },
  {
    "id": "coco_000000025424_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.367, 0.375, 0.656, 0.992]\ntennis racket: [0.617, 0.195, 0.805, 0.422]\nGiven the above layout, shift the person to the left by 0.289."
      },
      {
        "from": "gpt",
        "value": "person: [0.078, 0.375, 0.367, 0.992]\ntennis racket: [0.617, 0.195, 0.805, 0.422]"
      }
    ]
  },
  {
    "id": "coco_000000026926",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is at the center of the image."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.367, 0.039, 0.766, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000026926_key",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is at the center of the image.\nObjects: [fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.367, 0.039, 0.766, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000026926_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red fire hydrant is at the center of the image."
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.367, 0.039, 0.766, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000026926_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red fire hydrant is at the center of the image.\nObjects: [red fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.367, 0.039, 0.766, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000026926_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: fire hydrant: [0.367, 0.039, 0.766, 0.992]\nGiven the above layout, shift the fire hydrant to the left by 0.102."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.266, 0.039, 0.664, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000027768",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is positioned on the right side of the image with the front facing towards the left."
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.273, 0.930, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000027768_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is positioned on the right side of the image with the front facing towards the left.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.273, 0.930, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000027768_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker red bus is positioned on the right side of the image with the front facing towards the left."
      },
      {
        "from": "gpt",
        "value": "double-decker red bus: [0.000, 0.273, 0.930, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000027768_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker red bus is positioned on the right side of the image with the front facing towards the left.\nObjects: [double-decker red bus]"
      },
      {
        "from": "gpt",
        "value": "double-decker red bus: [0.000, 0.273, 0.930, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000027768_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.000, 0.273, 0.930, 0.977]\nGiven the above layout, shift the bus upwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.250, 0.930, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000027982",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is located on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.078, 0.352, 0.312, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000027982_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is located on the left side of the image.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.078, 0.352, 0.312, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000027982_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the modern porcelain toilet is located on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "modern porcelain toilet: [0.078, 0.352, 0.312, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000027982_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the modern porcelain toilet is located on the left side of the image.\nObjects: [modern porcelain toilet]"
      },
      {
        "from": "gpt",
        "value": "modern porcelain toilet: [0.078, 0.352, 0.312, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000027982_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.078, 0.352, 0.312, 0.805]\nGiven the above layout, shift the toilet to the right by 0.648."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.727, 0.352, 0.961, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000028452",
    "conversations": [
      {
        "from": "human",
        "value": "An open refrigerator is in the center of the image, with its door swung open to the right side."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.125, 0.062, 0.867, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000028452_key",
    "conversations": [
      {
        "from": "human",
        "value": "An open refrigerator is in the center of the image, with its door swung open to the right side.\nObjects: [refrigerator]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.125, 0.062, 0.867, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000028452_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an open double-door stainless steel fridge is in the center of the image, with its door swung open to the right side."
      },
      {
        "from": "gpt",
        "value": "double-door stainless steel fridge: [0.125, 0.062, 0.867, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000028452_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an open double-door stainless steel fridge is in the center of the image, with its door swung open to the right side.\nObjects: [double-door stainless steel fridge]"
      },
      {
        "from": "gpt",
        "value": "double-door stainless steel fridge: [0.125, 0.062, 0.867, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000028452_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: refrigerator: [0.125, 0.062, 0.867, 0.984]\nGiven the above layout, shift the refrigerator to the left by 0.078."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.047, 0.062, 0.789, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000029393",
    "conversations": [
      {
        "from": "human",
        "value": "The dog is standing on a wooden structure in the center of the image, with plants in the background."
      },
      {
        "from": "gpt",
        "value": "dog: [0.336, 0.438, 0.727, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000029393_key",
    "conversations": [
      {
        "from": "human",
        "value": "The dog is standing on a wooden structure in the center of the image, with plants in the background.\nObjects: [dog]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.336, 0.438, 0.727, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000029393_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the fluffy golden retriever is standing on a wooden structure in the center of the image, with plants in the background."
      },
      {
        "from": "gpt",
        "value": "fluffy golden retriever: [0.336, 0.438, 0.727, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000029393_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the fluffy golden retriever is standing on a wooden structure in the center of the image, with plants in the background.\nObjects: [fluffy golden retriever]"
      },
      {
        "from": "gpt",
        "value": "fluffy golden retriever: [0.336, 0.438, 0.727, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000029393_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.336, 0.438, 0.727, 0.805]\nGiven the above layout, shift the dog upwards by 0.180."
      },
      {
        "from": "gpt",
        "value": "dog: [0.336, 0.258, 0.727, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000030494",
    "conversations": [
      {
        "from": "human",
        "value": "A black and white dog is positioned in the center-left of the image near a tree."
      },
      {
        "from": "gpt",
        "value": "dog: [0.164, 0.172, 0.445, 0.469]"
      }
    ]
  },
  {
    "id": "coco_000000030494_key",
    "conversations": [
      {
        "from": "human",
        "value": "A black and white dog is positioned in the center-left of the image near a tree.\nObjects: [dog]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.164, 0.172, 0.445, 0.469]"
      }
    ]
  },
  {
    "id": "coco_000000030494_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a black and white Dalmatian puppy is positioned in the center-left of the image near a tree."
      },
      {
        "from": "gpt",
        "value": "Dalmatian puppy: [0.164, 0.172, 0.445, 0.469]"
      }
    ]
  },
  {
    "id": "coco_000000030494_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a black and white Dalmatian puppy is positioned in the center-left of the image near a tree.\nObjects: [Dalmatian puppy]"
      },
      {
        "from": "gpt",
        "value": "Dalmatian puppy: [0.164, 0.172, 0.445, 0.469]"
      }
    ]
  },
  {
    "id": "coco_000000030494_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.164, 0.172, 0.445, 0.469]\nGiven the above layout, shift the dog to the right by 0.359."
      },
      {
        "from": "gpt",
        "value": "dog: [0.523, 0.172, 0.805, 0.469]"
      }
    ]
  },
  {
    "id": "coco_000000054164",
    "conversations": [
      {
        "from": "human",
        "value": "A person is surfing on a wave to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.281, 0.328, 0.516, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000054164_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is surfing on a wave to the right side of the image.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.281, 0.328, 0.516, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000054164_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a professional surfer is surfing on a wave to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "professional surfer: [0.281, 0.328, 0.516, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000054164_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a professional surfer is surfing on a wave to the right side of the image.\nObjects: [professional surfer]"
      },
      {
        "from": "gpt",
        "value": "professional surfer: [0.281, 0.328, 0.516, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000054164_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.281, 0.328, 0.516, 0.695]\nGiven the above layout, shift the person to the right by 0.328."
      },
      {
        "from": "gpt",
        "value": "person: [0.609, 0.328, 0.844, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000054931",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the foreground to the right, holding a rope with a horse in the background to the left."
      },
      {
        "from": "gpt",
        "value": "person: [0.469, 0.242, 0.758, 0.969]\nhorse: [0.164, 0.133, 0.398, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000054931_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the foreground to the right, holding a rope with a horse in the background to the left.\nObjects: [person, horse]"
      },
      {
        "from": "gpt",
        "value": "person: [0.469, 0.242, 0.758, 0.969]\nhorse: [0.164, 0.133, 0.398, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000054931_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a cowboy is standing in the foreground to the right, holding a rope with a brown horse in the background to the left."
      },
      {
        "from": "gpt",
        "value": "cowboy: [0.469, 0.242, 0.758, 0.969]\nbrown horse: [0.164, 0.133, 0.398, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000054931_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a cowboy is standing in the foreground to the right, holding a rope with a brown horse in the background to the left.\nObjects: [cowboy, brown horse]"
      },
      {
        "from": "gpt",
        "value": "cowboy: [0.469, 0.242, 0.758, 0.969]\nbrown horse: [0.164, 0.133, 0.398, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000054931_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.469, 0.242, 0.758, 0.969]\nhorse: [0.164, 0.133, 0.398, 0.438]\nGiven the above layout, shift the person to the right by 0.094."
      },
      {
        "from": "gpt",
        "value": "person: [0.562, 0.242, 0.852, 0.969]\nhorse: [0.164, 0.133, 0.398, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000055072",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe stands in the center of the image, facing left."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.078, 0.234, 0.797, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000055072_key",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe stands in the center of the image, facing left.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.078, 0.234, 0.797, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000055072_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall brown giraffe stands in the center of the image, facing left."
      },
      {
        "from": "gpt",
        "value": "tall brown giraffe: [0.078, 0.234, 0.797, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000055072_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall brown giraffe stands in the center of the image, facing left.\nObjects: [tall brown giraffe]"
      },
      {
        "from": "gpt",
        "value": "tall brown giraffe: [0.078, 0.234, 0.797, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000055072_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.078, 0.234, 0.797, 0.828]\nGiven the above layout, shift the giraffe upwards by 0.055."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.078, 0.180, 0.797, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000056545",
    "conversations": [
      {
        "from": "human",
        "value": "The bird is perched on a branch at the center of the image, facing slightly to the right."
      },
      {
        "from": "gpt",
        "value": "bird: [0.312, 0.047, 0.672, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000056545_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bird is perched on a branch at the center of the image, facing slightly to the right.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.312, 0.047, 0.672, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000056545_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the small mockingbird is perched on a branch at the center of the image, facing slightly to the right."
      },
      {
        "from": "gpt",
        "value": "small mockingbird: [0.312, 0.047, 0.672, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000056545_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the small mockingbird is perched on a branch at the center of the image, facing slightly to the right.\nObjects: [small mockingbird]"
      },
      {
        "from": "gpt",
        "value": "small mockingbird: [0.312, 0.047, 0.672, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000056545_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.312, 0.047, 0.672, 0.977]\nGiven the above layout, shift the bird to the right by 0.320."
      },
      {
        "from": "gpt",
        "value": "bird: [0.633, 0.047, 0.992, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000057244",
    "conversations": [
      {
        "from": "human",
        "value": "The rusty body of a train with a cylindrical boiler is centered in the image, with trees in the background."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.172, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000057244_key",
    "conversations": [
      {
        "from": "human",
        "value": "The rusty body of a train with a cylindrical boiler is centered in the image, with trees in the background.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.172, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000057244_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the rusty body of a vintage red steam locomotive with a cylindrical boiler is centered in the image, with trees in the background."
      },
      {
        "from": "gpt",
        "value": "vintage red steam locomotive: [0.000, 0.172, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000057244_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the rusty body of a vintage red steam locomotive with a cylindrical boiler is centered in the image, with trees in the background.\nObjects: [vintage red steam locomotive]"
      },
      {
        "from": "gpt",
        "value": "vintage red steam locomotive: [0.000, 0.172, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000057244_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.172, 0.992, 0.680]\nGiven the above layout, shift the train downwards by 0.109."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.281, 0.992, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000059044",
    "conversations": [
      {
        "from": "human",
        "value": "Four people standing in a line from left to right, with the second person partially obscured by the first person."
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.164, 0.523, 0.820]\nperson: [0.000, 0.250, 0.234, 0.656]\nperson: [0.508, 0.289, 0.648, 0.797]\nperson: [0.672, 0.273, 0.797, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000059044_key",
    "conversations": [
      {
        "from": "human",
        "value": "Four people standing in a line from left to right, with the second person partially obscured by the first person.\nObjects: [person, person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.164, 0.523, 0.820]\nperson: [0.000, 0.250, 0.234, 0.656]\nperson: [0.508, 0.289, 0.648, 0.797]\nperson: [0.672, 0.273, 0.797, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000059920",
    "conversations": [
      {
        "from": "human",
        "value": "There is one toilet in the center of the image and another toilet directly behind it."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.523, 0.492, 0.828, 0.984]\ntoilet: [0.164, 0.648, 0.375, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000059920_key",
    "conversations": [
      {
        "from": "human",
        "value": "There is one toilet in the center of the image and another toilet directly behind it.\nObjects: [toilet, toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.523, 0.492, 0.828, 0.984]\ntoilet: [0.164, 0.648, 0.375, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000060090",
    "conversations": [
      {
        "from": "human",
        "value": "A train is approaching on the tracks to the right of the platform."
      },
      {
        "from": "gpt",
        "value": "train: [0.352, 0.320, 0.766, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000060090_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is approaching on the tracks to the right of the platform.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.352, 0.320, 0.766, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000060090_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a high speed train is approaching on the tracks to the right of the platform."
      },
      {
        "from": "gpt",
        "value": "high speed train: [0.352, 0.320, 0.766, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000060090_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a high speed train is approaching on the tracks to the right of the platform.\nObjects: [high speed train]"
      },
      {
        "from": "gpt",
        "value": "high speed train: [0.352, 0.320, 0.766, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000060090_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.352, 0.320, 0.766, 0.695]\nGiven the above layout, shift the train to the left by 0.336."
      },
      {
        "from": "gpt",
        "value": "train: [0.016, 0.320, 0.430, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000061268",
    "conversations": [
      {
        "from": "human",
        "value": "A train is passing from left to right under an overpass."
      },
      {
        "from": "gpt",
        "value": "train: [0.250, 0.391, 0.789, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000061268_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is passing from left to right under an overpass.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.250, 0.391, 0.789, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000061268_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a diesel locomotive is passing from left to right under an overpass."
      },
      {
        "from": "gpt",
        "value": "diesel locomotive: [0.250, 0.391, 0.789, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000061268_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a diesel locomotive is passing from left to right under an overpass.\nObjects: [diesel locomotive]"
      },
      {
        "from": "gpt",
        "value": "diesel locomotive: [0.250, 0.391, 0.789, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000061268_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.250, 0.391, 0.789, 0.664]\nGiven the above layout, shift the train upwards by 0.203."
      },
      {
        "from": "gpt",
        "value": "train: [0.250, 0.188, 0.789, 0.461]"
      }
    ]
  },
  {
    "id": "coco_000000061747",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on skis."
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.086, 0.680, 0.852]\nskis: [0.164, 0.727, 0.773, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000061747_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on skis.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.086, 0.680, 0.852]\nskis: [0.164, 0.727, 0.773, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000061747_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a young man in a winter jacket is standing on professional skis.."
      },
      {
        "from": "gpt",
        "value": "a young man in a winter jacket: [0.352, 0.086, 0.680, 0.852]\nprofessional skis.: [0.164, 0.727, 0.773, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000061747_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a young man in a winter jacket is standing on professional skis..\nObjects: [a young man in a winter jacket, professional skis.]"
      },
      {
        "from": "gpt",
        "value": "a young man in a winter jacket: [0.352, 0.086, 0.680, 0.852]\nprofessional skis.: [0.164, 0.727, 0.773, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000061747_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.352, 0.086, 0.680, 0.852]\nskis: [0.164, 0.727, 0.773, 0.938]\nGiven the above layout, shift the skis to the right by 0.078."
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.086, 0.680, 0.852]\nskis: [0.242, 0.727, 0.852, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000062692",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the right on a tennis court, with a racket in hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.438, 0.625, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000062692_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the right on a tennis court, with a racket in hand.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.438, 0.625, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000062692_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tennis player is standing to the right on a tennis court, with a racket in hand."
      },
      {
        "from": "gpt",
        "value": "tennis player: [0.328, 0.438, 0.625, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000062692_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tennis player is standing to the right on a tennis court, with a racket in hand.\nObjects: [tennis player]"
      },
      {
        "from": "gpt",
        "value": "tennis player: [0.328, 0.438, 0.625, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000062692_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.328, 0.438, 0.625, 0.852]\nGiven the above layout, shift the person upwards by 0.047."
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.391, 0.625, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000063047",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center of the image, wearing a red shirt and holding a snack with both hands."
      },
      {
        "from": "gpt",
        "value": "person: [0.094, 0.398, 0.602, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000063047_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center of the image, wearing a red shirt and holding a snack with both hands.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.094, 0.398, 0.602, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000063047_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a man in red polo shirt is standing in the center of the image, wearing a red shirt and holding a snack with both hands."
      },
      {
        "from": "gpt",
        "value": "man in red polo shirt: [0.094, 0.398, 0.602, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000063047_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a man in red polo shirt is standing in the center of the image, wearing a red shirt and holding a snack with both hands.\nObjects: [man in red polo shirt]"
      },
      {
        "from": "gpt",
        "value": "man in red polo shirt: [0.094, 0.398, 0.602, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000063047_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.094, 0.398, 0.602, 0.922]\nGiven the above layout, shift the person upwards by 0.102."
      },
      {
        "from": "gpt",
        "value": "person: [0.094, 0.297, 0.602, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000063602",
    "conversations": [
      {
        "from": "human",
        "value": "The laptop is open and located in the center of the table."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.352, 0.430, 0.602, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000063602_key",
    "conversations": [
      {
        "from": "human",
        "value": "The laptop is open and located in the center of the table.\nObjects: [laptop]"
      },
      {
        "from": "gpt",
        "value": "laptop: [0.352, 0.430, 0.602, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000063602_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the silver MacBook Pro is open and located in the center of the table."
      },
      {
        "from": "gpt",
        "value": "silver MacBook Pro: [0.352, 0.430, 0.602, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000063602_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the silver MacBook Pro is open and located in the center of the table.\nObjects: [silver MacBook Pro]"
      },
      {
        "from": "gpt",
        "value": "silver MacBook Pro: [0.352, 0.430, 0.602, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000063602_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: laptop: [0.352, 0.430, 0.602, 0.742]\nGiven the above layout, shift the laptop upwards by 0.406."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.352, 0.023, 0.602, 0.336]"
      }
    ]
  },
  {
    "id": "coco_000000064462",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing with skis on their feet on a snowy slope."
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.125, 0.648, 0.758]\nskis: [0.406, 0.703, 0.656, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000064462_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing with skis on their feet on a snowy slope.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.125, 0.648, 0.758]\nskis: [0.406, 0.703, 0.656, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000064462_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a an adventurous skier is standing with a pair of shiny red skis on their feet on a snowy slope."
      },
      {
        "from": "gpt",
        "value": "an adventurous skier: [0.344, 0.125, 0.648, 0.758]\na pair of shiny red skis: [0.406, 0.703, 0.656, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000064462_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a an adventurous skier is standing with a pair of shiny red skis on their feet on a snowy slope.\nObjects: [an adventurous skier, a pair of shiny red skis]"
      },
      {
        "from": "gpt",
        "value": "an adventurous skier: [0.344, 0.125, 0.648, 0.758]\na pair of shiny red skis: [0.406, 0.703, 0.656, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000064462_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.344, 0.125, 0.648, 0.758]\nskis: [0.406, 0.703, 0.656, 0.875]\nGiven the above layout, shift the person to the left by 0.125."
      },
      {
        "from": "gpt",
        "value": "person: [0.219, 0.125, 0.523, 0.758]\nskis: [0.406, 0.703, 0.656, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000088345",
    "conversations": [
      {
        "from": "human",
        "value": "The person is in the center of the image, with a clock on the wall to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.227, 0.477, 0.648, 0.828]\nclock: [0.758, 0.516, 0.969, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000088345_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is in the center of the image, with a clock on the wall to the right.\nObjects: [person, clock]"
      },
      {
        "from": "gpt",
        "value": "person: [0.227, 0.477, 0.648, 0.828]\nclock: [0.758, 0.516, 0.969, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000088345_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the middle-aged man with glasses is in the center of the image, with a antique wall clock on the wall to the right."
      },
      {
        "from": "gpt",
        "value": "middle-aged man with glasses: [0.227, 0.477, 0.648, 0.828]\nantique wall clock: [0.758, 0.516, 0.969, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000088345_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the middle-aged man with glasses is in the center of the image, with a antique wall clock on the wall to the right.\nObjects: [middle-aged man with glasses, antique wall clock]"
      },
      {
        "from": "gpt",
        "value": "middle-aged man with glasses: [0.227, 0.477, 0.648, 0.828]\nantique wall clock: [0.758, 0.516, 0.969, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000088345_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.227, 0.477, 0.648, 0.828]\nclock: [0.758, 0.516, 0.969, 0.727]\nGiven the above layout, shift the person upwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "person: [0.227, 0.406, 0.648, 0.758]\nclock: [0.758, 0.516, 0.969, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000088432",
    "conversations": [
      {
        "from": "human",
        "value": "A fire hydrant is in the foreground on the right, and a truck is parked in the background on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "truck: [0.133, 0.414, 0.594, 0.617]\nfire hydrant: [0.328, 0.695, 0.469, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000088432_key",
    "conversations": [
      {
        "from": "human",
        "value": "A fire hydrant is in the foreground on the right, and a truck is parked in the background on the left side of the image.\nObjects: [truck, fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.133, 0.414, 0.594, 0.617]\nfire hydrant: [0.328, 0.695, 0.469, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000088432_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red and white striped fire hydrant is in the foreground on the right, and a large blue delivery truck is parked in the background on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "large blue delivery truck: [0.133, 0.414, 0.594, 0.617]\nred and white striped fire hydrant: [0.328, 0.695, 0.469, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000088432_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red and white striped fire hydrant is in the foreground on the right, and a large blue delivery truck is parked in the background on the left side of the image.\nObjects: [large blue delivery truck, red and white striped fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "large blue delivery truck: [0.133, 0.414, 0.594, 0.617]\nred and white striped fire hydrant: [0.328, 0.695, 0.469, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000088432_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.133, 0.414, 0.594, 0.617]\nfire hydrant: [0.328, 0.695, 0.469, 0.938]\nGiven the above layout, shift the truck upwards by 0.297."
      },
      {
        "from": "gpt",
        "value": "truck: [0.133, 0.117, 0.594, 0.320]\nfire hydrant: [0.328, 0.695, 0.469, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000088462",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is on the left, angled towards the right side of the image on a street."
      },
      {
        "from": "gpt",
        "value": "bus: [0.461, 0.273, 0.992, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000088462_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is on the left, angled towards the right side of the image on a street.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.461, 0.273, 0.992, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000088462_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker bus is on the left, angled towards the right side of the image on a street."
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.461, 0.273, 0.992, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000088462_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker bus is on the left, angled towards the right side of the image on a street.\nObjects: [double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.461, 0.273, 0.992, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000088462_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.461, 0.273, 0.992, 0.617]\nGiven the above layout, shift the bus to the left by 0.375."
      },
      {
        "from": "gpt",
        "value": "bus: [0.086, 0.273, 0.617, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000088848",
    "conversations": [
      {
        "from": "human",
        "value": "The image is divided into four sections. On the top left, there is a yellow and red fire hydrant. On the top right, there's a yellow and blue fire hydrant. On the bottom left, there's a person standing. On the bottom right, there's a group of people with a boat in the background."
      },
      {
        "from": "gpt",
        "value": "boat: [0.500, 0.609, 0.914, 0.867]\nfire hydrant: [0.203, 0.047, 0.383, 0.391]\nperson: [0.227, 0.562, 0.359, 0.969]\nfire hydrant: [0.633, 0.195, 0.766, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000088848_key",
    "conversations": [
      {
        "from": "human",
        "value": "The image is divided into four sections. On the top left, there is a yellow and red fire hydrant. On the top right, theres a yellow and blue fire hydrant. On the bottom left, theres a person standing. On the bottom right, theres a group of people with a boat in the background.\nObjects: [boat, fire hydrant, person, fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.500, 0.609, 0.914, 0.867]\nfire hydrant: [0.203, 0.047, 0.383, 0.391]\nperson: [0.227, 0.562, 0.359, 0.969]\nfire hydrant: [0.633, 0.195, 0.766, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000089078",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a snowboard."
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.023, 0.695, 0.914]\nsnowboard: [0.398, 0.859, 0.664, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000089078_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a snowboard.\nObjects: [person, snowboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.023, 0.695, 0.914]\nsnowboard: [0.398, 0.859, 0.664, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000089078_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a adventurous red and white red and white snowboarder is standing on a red and white snowboard."
      },
      {
        "from": "gpt",
        "value": "adventurous red and white snowboarder: [0.352, 0.023, 0.695, 0.914]\nred and white snowboard: [0.398, 0.859, 0.664, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000089078_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a adventurous red and white red and white snowboarder is standing on a red and white snowboard.\nObjects: [adventurous red and white snowboarder, red and white snowboard]"
      },
      {
        "from": "gpt",
        "value": "adventurous red and white snowboarder: [0.352, 0.023, 0.695, 0.914]\nred and white snowboard: [0.398, 0.859, 0.664, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000089078_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.352, 0.023, 0.695, 0.914]\nsnowboard: [0.398, 0.859, 0.664, 0.922]\nGiven the above layout, shift the person to the left by 0.242."
      },
      {
        "from": "gpt",
        "value": "person: [0.109, 0.023, 0.453, 0.914]\nsnowboard: [0.398, 0.859, 0.664, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000089271",
    "conversations": [
      {
        "from": "human",
        "value": "A cat wearing a hat is at the center of the image, with its paws resting in front."
      },
      {
        "from": "gpt",
        "value": "cat: [0.000, 0.352, 0.961, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000089271_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat wearing a hat is at the center of the image, with its paws resting in front.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.000, 0.352, 0.961, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000089271_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a black kitten with a bow tie wearing a hat is at the center of the image, with its paws resting in front."
      },
      {
        "from": "gpt",
        "value": "black kitten with a bow tie: [0.000, 0.352, 0.961, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000089271_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a black kitten with a bow tie wearing a hat is at the center of the image, with its paws resting in front.\nObjects: [black kitten with a bow tie]"
      },
      {
        "from": "gpt",
        "value": "black kitten with a bow tie: [0.000, 0.352, 0.961, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000089271_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.000, 0.352, 0.961, 0.891]\nGiven the above layout, shift the cat upwards by 0.016."
      },
      {
        "from": "gpt",
        "value": "cat: [0.000, 0.336, 0.961, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000089296",
    "conversations": [
      {
        "from": "human",
        "value": "One person is holding a baseball bat in the center, while another person is standing behind a protective net to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.328, 0.680, 0.828]\nperson: [0.836, 0.164, 0.992, 0.562]\nbaseball bat: [0.539, 0.219, 0.617, 0.375]"
      }
    ]
  },
  {
    "id": "coco_000000089296_key",
    "conversations": [
      {
        "from": "human",
        "value": "One person is holding a baseball bat in the center, while another person is standing behind a protective net to the right.\nObjects: [person, person, baseball bat]"
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.328, 0.680, 0.828]\nperson: [0.836, 0.164, 0.992, 0.562]\nbaseball bat: [0.539, 0.219, 0.617, 0.375]"
      }
    ]
  },
  {
    "id": "coco_000000089670",
    "conversations": [
      {
        "from": "human",
        "value": "The image does not contain a bottle; only a cake is placed at the center of the image."
      },
      {
        "from": "gpt",
        "value": "cake: [0.195, 0.344, 0.805, 0.719]\nbottle: [0.875, 0.438, 0.906, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000089670_key",
    "conversations": [
      {
        "from": "human",
        "value": "The image does not contain a bottle; only a cake is placed at the center of the image.\nObjects: [cake, bottle]"
      },
      {
        "from": "gpt",
        "value": "cake: [0.195, 0.344, 0.805, 0.719]\nbottle: [0.875, 0.438, 0.906, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000089761",
    "conversations": [
      {
        "from": "human",
        "value": "A toilet is positioned in front of a tree trunk."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.336, 0.492, 0.734, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000089761_key",
    "conversations": [
      {
        "from": "human",
        "value": "A toilet is positioned in front of a tree trunk.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.336, 0.492, 0.734, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000089761_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a ceramic throne is positioned in front of a tree trunk."
      },
      {
        "from": "gpt",
        "value": "ceramic throne: [0.336, 0.492, 0.734, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000089761_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a ceramic throne is positioned in front of a tree trunk.\nObjects: [ceramic throne]"
      },
      {
        "from": "gpt",
        "value": "ceramic throne: [0.336, 0.492, 0.734, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000089761_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.336, 0.492, 0.734, 0.977]\nGiven the above layout, shift the toilet upwards by 0.328."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.336, 0.164, 0.734, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000090062",
    "conversations": [
      {
        "from": "human",
        "value": "A cow standing on the left side of the image in front of a wooden structure."
      },
      {
        "from": "gpt",
        "value": "cow: [0.094, 0.359, 0.648, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000090062_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cow standing on the left side of the image in front of a wooden structure.\nObjects: [cow]"
      },
      {
        "from": "gpt",
        "value": "cow: [0.094, 0.359, 0.648, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000090062_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a grazing buffalo standing on the left side of the image in front of a wooden structure."
      },
      {
        "from": "gpt",
        "value": "grazing buffalo: [0.094, 0.359, 0.648, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000090062_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a grazing buffalo standing on the left side of the image in front of a wooden structure.\nObjects: [grazing buffalo]"
      },
      {
        "from": "gpt",
        "value": "grazing buffalo: [0.094, 0.359, 0.648, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000090062_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cow: [0.094, 0.359, 0.648, 0.781]\nGiven the above layout, shift the cow upwards by 0.312."
      },
      {
        "from": "gpt",
        "value": "cow: [0.094, 0.047, 0.648, 0.469]"
      }
    ]
  },
  {
    "id": "coco_000000090155",
    "conversations": [
      {
        "from": "human",
        "value": "A train is traveling to the right, on railway tracks that extend towards the horizon on the right side of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.102, 0.430, 0.812, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000090155_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is traveling to the right, on railway tracks that extend towards the horizon on the right side of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.102, 0.430, 0.812, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000090155_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a old-fashioned steam locomotive is traveling to the right, on railway tracks that extend towards the horizon on the right side of the image."
      },
      {
        "from": "gpt",
        "value": "old-fashioned steam locomotive: [0.102, 0.430, 0.812, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000090155_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a old-fashioned steam locomotive is traveling to the right, on railway tracks that extend towards the horizon on the right side of the image.\nObjects: [old-fashioned steam locomotive]"
      },
      {
        "from": "gpt",
        "value": "old-fashioned steam locomotive: [0.102, 0.430, 0.812, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000090155_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.102, 0.430, 0.812, 0.672]\nGiven the above layout, shift the train upwards by 0.078."
      },
      {
        "from": "gpt",
        "value": "train: [0.102, 0.352, 0.812, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000090284",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center, playing tennis with a stretched posture aiming to the right side."
      },
      {
        "from": "gpt",
        "value": "person: [0.102, 0.219, 0.906, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000090284_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center, playing tennis with a stretched posture aiming to the right side.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.102, 0.219, 0.906, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000090284_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall athlete is at the center, playing tennis with a stretched posture aiming to the right side."
      },
      {
        "from": "gpt",
        "value": "tall athlete: [0.102, 0.219, 0.906, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000090284_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall athlete is at the center, playing tennis with a stretched posture aiming to the right side.\nObjects: [tall athlete]"
      },
      {
        "from": "gpt",
        "value": "tall athlete: [0.102, 0.219, 0.906, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000090284_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.102, 0.219, 0.906, 0.875]\nGiven the above layout, shift the person upwards by 0.047."
      },
      {
        "from": "gpt",
        "value": "person: [0.102, 0.172, 0.906, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000090631",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying towards the right in the center of the image against a blue sky with a faint trail of smoke behind it."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.273, 0.375, 0.711, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000090631_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying towards the right in the center of the image against a blue sky with a faint trail of smoke behind it.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.273, 0.375, 0.711, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000090631_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an white passenger jet is flying towards the right in the center of the image against a blue sky with a faint trail of smoke behind it."
      },
      {
        "from": "gpt",
        "value": "white passenger jet: [0.273, 0.375, 0.711, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000090631_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an white passenger jet is flying towards the right in the center of the image against a blue sky with a faint trail of smoke behind it.\nObjects: [white passenger jet]"
      },
      {
        "from": "gpt",
        "value": "white passenger jet: [0.273, 0.375, 0.711, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000090631_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.273, 0.375, 0.711, 0.547]\nGiven the above layout, shift the airplane downwards by 0.438."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.273, 0.812, 0.711, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000091921",
    "conversations": [
      {
        "from": "human",
        "value": "One zebra is lying down on the ground to the left, while another zebra is standing to the right."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.484, 0.469, 0.930, 0.773]\nzebra: [0.109, 0.586, 0.359, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000091921_key",
    "conversations": [
      {
        "from": "human",
        "value": "One zebra is lying down on the ground to the left, while another zebra is standing to the right.\nObjects: [zebra, zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.484, 0.469, 0.930, 0.773]\nzebra: [0.109, 0.586, 0.359, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000110972",
    "conversations": [
      {
        "from": "human",
        "value": "A bear at the center of the image, facing downwards towards the ground."
      },
      {
        "from": "gpt",
        "value": "bear: [0.133, 0.133, 0.789, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000110972_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bear at the center of the image, facing downwards towards the ground.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.133, 0.133, 0.789, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000110972_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a grizzly bear at the center of the image, facing downwards towards the ground."
      },
      {
        "from": "gpt",
        "value": "grizzly bear: [0.133, 0.133, 0.789, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000110972_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a grizzly bear at the center of the image, facing downwards towards the ground.\nObjects: [grizzly bear]"
      },
      {
        "from": "gpt",
        "value": "grizzly bear: [0.133, 0.133, 0.789, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000110972_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.133, 0.133, 0.789, 0.789]\nGiven the above layout, shift the bear to the right by 0.148."
      },
      {
        "from": "gpt",
        "value": "bear: [0.281, 0.133, 0.938, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000112110",
    "conversations": [
      {
        "from": "human",
        "value": "A person is stepping over a suitcase on the ground."
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.125, 0.672, 0.586]\nsuitcase: [0.336, 0.562, 0.594, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000112110_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is stepping over a suitcase on the ground.\nObjects: [person, suitcase]"
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.125, 0.672, 0.586]\nsuitcase: [0.336, 0.562, 0.594, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000112110_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a man in a business suit is stepping over a large navy blue luggage on the ground."
      },
      {
        "from": "gpt",
        "value": "a man in a business suit: [0.328, 0.125, 0.672, 0.586]\nlarge navy blue luggage: [0.336, 0.562, 0.594, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000112110_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a man in a business suit is stepping over a large navy blue luggage on the ground.\nObjects: [a man in a business suit, large navy blue luggage]"
      },
      {
        "from": "gpt",
        "value": "a man in a business suit: [0.328, 0.125, 0.672, 0.586]\nlarge navy blue luggage: [0.336, 0.562, 0.594, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000112110_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.328, 0.125, 0.672, 0.586]\nsuitcase: [0.336, 0.562, 0.594, 0.688]\nGiven the above layout, shift the person to the left by 0.266."
      },
      {
        "from": "gpt",
        "value": "person: [0.062, 0.125, 0.406, 0.586]\nsuitcase: [0.336, 0.562, 0.594, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000112634",
    "conversations": [
      {
        "from": "human",
        "value": "One giraffe in the foreground facing left, and another giraffe partially visible in the background to the right."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.008, 0.188, 0.891, 0.836]\ngiraffe: [0.898, 0.453, 0.992, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000112634_key",
    "conversations": [
      {
        "from": "human",
        "value": "One giraffe in the foreground facing left, and another giraffe partially visible in the background to the right.\nObjects: [giraffe, giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.008, 0.188, 0.891, 0.836]\ngiraffe: [0.898, 0.453, 0.992, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000115118",
    "conversations": [
      {
        "from": "human",
        "value": "A train with multicolored containers is situated on the left side of the railway tracks, moving towards the right of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.125, 0.297, 0.781, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000115118_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train with multicolored containers is situated on the left side of the railway tracks, moving towards the right of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.125, 0.297, 0.781, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000115118_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a freight train with vividly colored boxes with multicolored containers is situated on the left side of the railway tracks, moving towards the right of the image."
      },
      {
        "from": "gpt",
        "value": "freight train with vividly colored boxes: [0.125, 0.297, 0.781, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000115118_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a freight train with vividly colored boxes with multicolored containers is situated on the left side of the railway tracks, moving towards the right of the image.\nObjects: [freight train with vividly colored boxes]"
      },
      {
        "from": "gpt",
        "value": "freight train with vividly colored boxes: [0.125, 0.297, 0.781, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000115118_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.125, 0.297, 0.781, 0.695]\nGiven the above layout, shift the train upwards by 0.242."
      },
      {
        "from": "gpt",
        "value": "train: [0.125, 0.055, 0.781, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000117197",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on a ledge to the right of a black bollard."
      },
      {
        "from": "gpt",
        "value": "person: [0.500, 0.312, 0.836, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000117197_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on a ledge to the right of a black bollard.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.500, 0.312, 0.836, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000117197_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a woman in a red coat is sitting on a ledge to the right of a black bollard."
      },
      {
        "from": "gpt",
        "value": "a woman in a red coat: [0.500, 0.312, 0.836, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000117197_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a woman in a red coat is sitting on a ledge to the right of a black bollard.\nObjects: [a woman in a red coat]"
      },
      {
        "from": "gpt",
        "value": "a woman in a red coat: [0.500, 0.312, 0.836, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000117197_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.500, 0.312, 0.836, 0.672]\nGiven the above layout, shift the person to the left by 0.305."
      },
      {
        "from": "gpt",
        "value": "person: [0.195, 0.312, 0.531, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000117719",
    "conversations": [
      {
        "from": "human",
        "value": "A person to the right side, partially obscured by a bar counter in the foreground."
      },
      {
        "from": "gpt",
        "value": "person: [0.641, 0.414, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000117719_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person to the right side, partially obscured by a bar counter in the foreground.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.641, 0.414, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000117719_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in a red dress to the right side, partially obscured by a bar counter in the foreground."
      },
      {
        "from": "gpt",
        "value": "woman in a red dress: [0.641, 0.414, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000117719_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in a red dress to the right side, partially obscured by a bar counter in the foreground.\nObjects: [woman in a red dress]"
      },
      {
        "from": "gpt",
        "value": "woman in a red dress: [0.641, 0.414, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000117719_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.641, 0.414, 0.992, 0.828]\nGiven the above layout, shift the person to the left by 0.625."
      },
      {
        "from": "gpt",
        "value": "person: [0.016, 0.414, 0.367, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000117744",
    "conversations": [
      {
        "from": "human",
        "value": "There is a person standing with a tennis racket held in front at the lower body level."
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.047, 0.586, 0.648]\ntennis racket: [0.406, 0.562, 0.578, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000117744_key",
    "conversations": [
      {
        "from": "human",
        "value": "There is a person standing with a tennis racket held in front at the lower body level.\nObjects: [person, tennis racket]"
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.047, 0.586, 0.648]\ntennis racket: [0.406, 0.562, 0.578, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000117744_aug",
    "conversations": [
      {
        "from": "human",
        "value": "there is a middle-aged woman standing with a professional tennis racket held in front at the lower body level."
      },
      {
        "from": "gpt",
        "value": "middle-aged woman: [0.344, 0.047, 0.586, 0.648]\nprofessional tennis racket: [0.406, 0.562, 0.578, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000117744_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "there is a middle-aged woman standing with a professional tennis racket held in front at the lower body level.\nObjects: [middle-aged woman, professional tennis racket]"
      },
      {
        "from": "gpt",
        "value": "middle-aged woman: [0.344, 0.047, 0.586, 0.648]\nprofessional tennis racket: [0.406, 0.562, 0.578, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000117744_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.344, 0.047, 0.586, 0.648]\ntennis racket: [0.406, 0.562, 0.578, 0.812]\nGiven the above layout, shift the person to the right by 0.234."
      },
      {
        "from": "gpt",
        "value": "person: [0.578, 0.047, 0.820, 0.648]\ntennis racket: [0.406, 0.562, 0.578, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000117914",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is located on the left side of the image and the sink is on the right side, against the wall."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.180, 0.555, 0.523, 0.992]\nsink: [0.430, 0.844, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000117914_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is located on the left side of the image and the sink is on the right side, against the wall.\nObjects: [toilet, sink]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.180, 0.555, 0.523, 0.992]\nsink: [0.430, 0.844, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000117914_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the ceramic toilet is located on the left side of the image and the stainless steel sink is on the right side, against the wall."
      },
      {
        "from": "gpt",
        "value": "ceramic toilet: [0.180, 0.555, 0.523, 0.992]\nstainless steel sink: [0.430, 0.844, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000117914_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the ceramic toilet is located on the left side of the image and the stainless steel sink is on the right side, against the wall.\nObjects: [ceramic toilet, stainless steel sink]"
      },
      {
        "from": "gpt",
        "value": "ceramic toilet: [0.180, 0.555, 0.523, 0.992]\nstainless steel sink: [0.430, 0.844, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000117914_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.180, 0.555, 0.523, 0.992]\nsink: [0.430, 0.844, 0.828, 0.992]\nGiven the above layout, shift the toilet upwards by 0.359."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.180, 0.195, 0.523, 0.633]\nsink: [0.430, 0.844, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000118209",
    "conversations": [
      {
        "from": "human",
        "value": "Two horses side by side behind a fence, with the left horse slightly in front of the right horse."
      },
      {
        "from": "gpt",
        "value": "horse: [0.016, 0.234, 0.562, 0.828]\nhorse: [0.602, 0.188, 0.930, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000118209_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two horses side by side behind a fence, with the left horse slightly in front of the right horse.\nObjects: [horse, horse]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.016, 0.234, 0.562, 0.828]\nhorse: [0.602, 0.188, 0.930, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000118594",
    "conversations": [
      {
        "from": "human",
        "value": "A brown and white cow with long horns to the left, facing and grazing towards another cow partially visible on the right."
      },
      {
        "from": "gpt",
        "value": "cow: [0.055, 0.156, 0.922, 0.648]\ncow: [0.805, 0.133, 0.992, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000118594_key",
    "conversations": [
      {
        "from": "human",
        "value": "A brown and white cow with long horns to the left, facing and grazing towards another cow partially visible on the right.\nObjects: [cow, cow]"
      },
      {
        "from": "gpt",
        "value": "cow: [0.055, 0.156, 0.922, 0.648]\ncow: [0.805, 0.133, 0.992, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000118921",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center of the image, cross-country skiing on a snowy path."
      },
      {
        "from": "gpt",
        "value": "person: [0.477, 0.367, 0.734, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000118921_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center of the image, cross-country skiing on a snowy path.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.477, 0.367, 0.734, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000118921_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a adult wearing a red skiing suit is at the center of the image, cross-country skiing on a snowy path."
      },
      {
        "from": "gpt",
        "value": "adult wearing a red skiing suit: [0.477, 0.367, 0.734, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000118921_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a adult wearing a red skiing suit is at the center of the image, cross-country skiing on a snowy path.\nObjects: [adult wearing a red skiing suit]"
      },
      {
        "from": "gpt",
        "value": "adult wearing a red skiing suit: [0.477, 0.367, 0.734, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000118921_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.477, 0.367, 0.734, 0.719]\nGiven the above layout, shift the person to the left by 0.266."
      },
      {
        "from": "gpt",
        "value": "person: [0.211, 0.367, 0.469, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000119677",
    "conversations": [
      {
        "from": "human",
        "value": "A piece of cake is at the center with a fork to the right of it."
      },
      {
        "from": "gpt",
        "value": "cake: [0.305, 0.188, 0.586, 0.531]\nfork: [0.594, 0.492, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000119677_key",
    "conversations": [
      {
        "from": "human",
        "value": "A piece of cake is at the center with a fork to the right of it.\nObjects: [cake, fork]"
      },
      {
        "from": "gpt",
        "value": "cake: [0.305, 0.188, 0.586, 0.531]\nfork: [0.594, 0.492, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000119677_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a piece of creamy cheesecake is at the center with a golden fork to the right of it."
      },
      {
        "from": "gpt",
        "value": "creamy cheesecake: [0.305, 0.188, 0.586, 0.531]\ngolden fork: [0.594, 0.492, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000119677_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a piece of creamy cheesecake is at the center with a golden fork to the right of it.\nObjects: [creamy cheesecake, golden fork]"
      },
      {
        "from": "gpt",
        "value": "creamy cheesecake: [0.305, 0.188, 0.586, 0.531]\ngolden fork: [0.594, 0.492, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000119677_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cake: [0.305, 0.188, 0.586, 0.531]\nfork: [0.594, 0.492, 0.992, 0.680]\nGiven the above layout, shift the fork downwards by 0.102."
      },
      {
        "from": "gpt",
        "value": "cake: [0.305, 0.188, 0.586, 0.531]\nfork: [0.594, 0.594, 0.992, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000119911",
    "conversations": [
      {
        "from": "human",
        "value": "A person at the center riding a skateboard on the street."
      },
      {
        "from": "gpt",
        "value": "person: [0.430, 0.320, 0.656, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000119911_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person at the center riding a skateboard on the street.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.430, 0.320, 0.656, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000119911_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage skater boy at the center riding a skateboard on the street."
      },
      {
        "from": "gpt",
        "value": "teenage skater boy: [0.430, 0.320, 0.656, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000119911_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage skater boy at the center riding a skateboard on the street.\nObjects: [teenage skater boy]"
      },
      {
        "from": "gpt",
        "value": "teenage skater boy: [0.430, 0.320, 0.656, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000119911_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.430, 0.320, 0.656, 0.688]\nGiven the above layout, shift the person to the left by 0.117."
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.320, 0.539, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000119995",
    "conversations": [
      {
        "from": "human",
        "value": "One person is in the foreground swinging a tennis racket to the right, while another person is standing in the background to the left."
      },
      {
        "from": "gpt",
        "value": "person: [0.109, 0.023, 0.539, 0.961]\nperson: [0.695, 0.062, 0.930, 0.469]\ntennis racket: [0.539, 0.430, 0.883, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000119995_key",
    "conversations": [
      {
        "from": "human",
        "value": "One person is in the foreground swinging a tennis racket to the right, while another person is standing in the background to the left.\nObjects: [person, person, tennis racket]"
      },
      {
        "from": "gpt",
        "value": "person: [0.109, 0.023, 0.539, 0.961]\nperson: [0.695, 0.062, 0.930, 0.469]\ntennis racket: [0.539, 0.430, 0.883, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000128654",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in mid-air on the right side, reaching out towards the left."
      },
      {
        "from": "gpt",
        "value": "person: [0.141, 0.180, 0.945, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000128654_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in mid-air on the right side, reaching out towards the left.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.141, 0.180, 0.945, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000128654_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a athletic basketball player is in mid-air on the right side, reaching out towards the left."
      },
      {
        "from": "gpt",
        "value": "athletic basketball player: [0.141, 0.180, 0.945, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000128654_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a athletic basketball player is in mid-air on the right side, reaching out towards the left.\nObjects: [athletic basketball player]"
      },
      {
        "from": "gpt",
        "value": "athletic basketball player: [0.141, 0.180, 0.945, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000128654_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.141, 0.180, 0.945, 0.859]\nGiven the above layout, shift the person upwards by 0.062."
      },
      {
        "from": "gpt",
        "value": "person: [0.141, 0.117, 0.945, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000129135",
    "conversations": [
      {
        "from": "human",
        "value": "A bench is in the foreground at the bottom center, and a train is in the background on the tracks above the bench."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.375, 0.992, 0.664]\nbench: [0.469, 0.695, 0.844, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000129135_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bench is in the foreground at the bottom center, and a train is in the background on the tracks above the bench.\nObjects: [train, bench]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.375, 0.992, 0.664]\nbench: [0.469, 0.695, 0.844, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000129135_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a wooden park bench is in the foreground at the bottom center, and a steam locomotive is in the background on the tracks above the wooden park bench."
      },
      {
        "from": "gpt",
        "value": "steam locomotive: [0.000, 0.375, 0.992, 0.664]\nwooden park bench: [0.469, 0.695, 0.844, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000129135_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a wooden park bench is in the foreground at the bottom center, and a steam locomotive is in the background on the tracks above the wooden park bench.\nObjects: [steam locomotive, wooden park bench]"
      },
      {
        "from": "gpt",
        "value": "steam locomotive: [0.000, 0.375, 0.992, 0.664]\nwooden park bench: [0.469, 0.695, 0.844, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000129135_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.375, 0.992, 0.664]\nbench: [0.469, 0.695, 0.844, 0.844]\nGiven the above layout, shift the train upwards by 0.250."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.125, 0.992, 0.414]\nbench: [0.469, 0.695, 0.844, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000130566",
    "conversations": [
      {
        "from": "human",
        "value": "A train on the tracks, moving towards the right of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.031, 0.344, 0.898, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000130566_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train on the tracks, moving towards the right of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.031, 0.344, 0.898, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000130566_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a green commuter train on the tracks, moving towards the right of the image."
      },
      {
        "from": "gpt",
        "value": "green commuter train: [0.031, 0.344, 0.898, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000130566_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a green commuter train on the tracks, moving towards the right of the image.\nObjects: [green commuter train]"
      },
      {
        "from": "gpt",
        "value": "green commuter train: [0.031, 0.344, 0.898, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000130566_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.031, 0.344, 0.898, 0.656]\nGiven the above layout, shift the train upwards by 0.062."
      },
      {
        "from": "gpt",
        "value": "train: [0.031, 0.281, 0.898, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000131273",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is sitting on the front passenger seat of a car, facing towards the left."
      },
      {
        "from": "gpt",
        "value": "dog: [0.312, 0.000, 0.867, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000131273_key",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is sitting on the front passenger seat of a car, facing towards the left.\nObjects: [dog]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.312, 0.000, 0.867, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000131273_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a Dalmatian puppy is sitting on the front passenger seat of a car, facing towards the left."
      },
      {
        "from": "gpt",
        "value": "Dalmatian puppy: [0.312, 0.000, 0.867, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000131273_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a Dalmatian puppy is sitting on the front passenger seat of a car, facing towards the left.\nObjects: [Dalmatian puppy]"
      },
      {
        "from": "gpt",
        "value": "Dalmatian puppy: [0.312, 0.000, 0.867, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000131273_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.312, 0.000, 0.867, 0.922]\nGiven the above layout, shift the dog to the left by 0.164."
      },
      {
        "from": "gpt",
        "value": "dog: [0.148, 0.000, 0.703, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000131379",
    "conversations": [
      {
        "from": "human",
        "value": "The image is a close-up of a cake with a golden-brown crust, filling the frame. There are visible pink swirls within the cake."
      },
      {
        "from": "gpt",
        "value": "cake: [0.000, 0.133, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000131379_key",
    "conversations": [
      {
        "from": "human",
        "value": "The image is a close-up of a cake with a golden-brown crust, filling the frame. There are visible pink swirls within the cake.\nObjects: [cake]"
      },
      {
        "from": "gpt",
        "value": "cake: [0.000, 0.133, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000131379_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the image is a close-up of a strawberry cheesecake with golden-brown crust with a golden-brown crust, filling the frame. there are visible pink swirls within the strawberry cheesecake with golden-brown crust."
      },
      {
        "from": "gpt",
        "value": "strawberry cheesecake with golden-brown crust: [0.000, 0.133, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000131379_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the image is a close-up of a strawberry cheesecake with golden-brown crust with a golden-brown crust, filling the frame. there are visible pink swirls within the strawberry cheesecake with golden-brown crust.\nObjects: [strawberry cheesecake with golden-brown crust]"
      },
      {
        "from": "gpt",
        "value": "strawberry cheesecake with golden-brown crust: [0.000, 0.133, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000131379_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cake: [0.000, 0.133, 0.992, 0.859]\nGiven the above layout, shift the cake upwards by 0.078."
      },
      {
        "from": "gpt",
        "value": "cake: [0.000, 0.055, 0.992, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000132622",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is at the center of the image, facing forward."
      },
      {
        "from": "gpt",
        "value": "bear: [0.016, 0.102, 0.883, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000132622_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is at the center of the image, facing forward.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.016, 0.102, 0.883, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000132622_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the large grizzly bear is at the center of the image, facing forward."
      },
      {
        "from": "gpt",
        "value": "large grizzly bear: [0.016, 0.102, 0.883, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000132622_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the large grizzly bear is at the center of the image, facing forward.\nObjects: [large grizzly bear]"
      },
      {
        "from": "gpt",
        "value": "large grizzly bear: [0.016, 0.102, 0.883, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000132622_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.016, 0.102, 0.883, 0.891]\nGiven the above layout, shift the bear to the right by 0.055."
      },
      {
        "from": "gpt",
        "value": "bear: [0.070, 0.102, 0.938, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000132703",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the air above a skateboard, which is positioned on a metal railing."
      },
      {
        "from": "gpt",
        "value": "person: [0.305, 0.227, 0.625, 0.492]\nskateboard: [0.312, 0.477, 0.594, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000132703_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the air above a skateboard, which is positioned on a metal railing.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.305, 0.227, 0.625, 0.492]\nskateboard: [0.312, 0.477, 0.594, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000132703_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young graffiti-covered graffiti-covered skateboarder is in the air above a graffiti-covered skateboard, which is positioned on a metal railing."
      },
      {
        "from": "gpt",
        "value": "young graffiti-covered skateboarder: [0.305, 0.227, 0.625, 0.492]\ngraffiti-covered skateboard: [0.312, 0.477, 0.594, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000132703_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young graffiti-covered graffiti-covered skateboarder is in the air above a graffiti-covered skateboard, which is positioned on a metal railing.\nObjects: [young graffiti-covered skateboarder, graffiti-covered skateboard]"
      },
      {
        "from": "gpt",
        "value": "young graffiti-covered skateboarder: [0.305, 0.227, 0.625, 0.492]\ngraffiti-covered skateboard: [0.312, 0.477, 0.594, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000132703_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.305, 0.227, 0.625, 0.492]\nskateboard: [0.312, 0.477, 0.594, 0.562]\nGiven the above layout, shift the skateboard downwards by 0.109."
      },
      {
        "from": "gpt",
        "value": "person: [0.305, 0.227, 0.625, 0.492]\nskateboard: [0.312, 0.586, 0.594, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000132931",
    "conversations": [
      {
        "from": "human",
        "value": "A person in a blue uniform standing to the left and a person in a red and white uniform standing to the right on a baseball field."
      },
      {
        "from": "gpt",
        "value": "person: [0.492, 0.266, 0.695, 0.719]\nperson: [0.266, 0.320, 0.391, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000132931_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in a blue uniform standing to the left and a person in a red and white uniform standing to the right on a baseball field.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.492, 0.266, 0.695, 0.719]\nperson: [0.266, 0.320, 0.391, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000133000",
    "conversations": [
      {
        "from": "human",
        "value": "The train is in the center of the image, moving on elevated tracks."
      },
      {
        "from": "gpt",
        "value": "train: [0.109, 0.438, 0.930, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000133000_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is in the center of the image, moving on elevated tracks.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.109, 0.438, 0.930, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000133000_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker express train is in the center of the image, moving on elevated tracks."
      },
      {
        "from": "gpt",
        "value": "double-decker express train: [0.109, 0.438, 0.930, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000133000_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker express train is in the center of the image, moving on elevated tracks.\nObjects: [double-decker express train]"
      },
      {
        "from": "gpt",
        "value": "double-decker express train: [0.109, 0.438, 0.930, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000133000_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.109, 0.438, 0.930, 0.797]\nGiven the above layout, shift the train upwards by 0.227."
      },
      {
        "from": "gpt",
        "value": "train: [0.109, 0.211, 0.930, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000133244",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the foreground preparing to hit a tennis ball, with another person seated on a chair at the back near the edge of the tennis court."
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.383, 0.500, 0.703]\nchair: [0.648, 0.367, 0.750, 0.508]\nperson: [0.844, 0.422, 0.938, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000133244_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the foreground preparing to hit a tennis ball, with another person seated on a chair at the back near the edge of the tennis court.\nObjects: [person, chair, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.383, 0.500, 0.703]\nchair: [0.648, 0.367, 0.750, 0.508]\nperson: [0.844, 0.422, 0.938, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000133631",
    "conversations": [
      {
        "from": "human",
        "value": "The elephant is at the center of the image facing left."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.312, 0.078, 0.828, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000133631_key",
    "conversations": [
      {
        "from": "human",
        "value": "The elephant is at the center of the image facing left.\nObjects: [elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.312, 0.078, 0.828, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000133631_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the large rhinoceros is at the center of the image facing left."
      },
      {
        "from": "gpt",
        "value": "large rhinoceros: [0.312, 0.078, 0.828, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000133631_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the large rhinoceros is at the center of the image facing left.\nObjects: [large rhinoceros]"
      },
      {
        "from": "gpt",
        "value": "large rhinoceros: [0.312, 0.078, 0.828, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000133631_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: elephant: [0.312, 0.078, 0.828, 0.945]\nGiven the above layout, shift the elephant to the left by 0.023."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.289, 0.078, 0.805, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000134689",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe standing in the center, facing forward with its back to the camera."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.227, 0.117, 0.742, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000134689_key",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe standing in the center, facing forward with its back to the camera.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.227, 0.117, 0.742, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000134689_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a long-necked brown giraffe standing in the center, facing forward with its back to the camera."
      },
      {
        "from": "gpt",
        "value": "long-necked brown giraffe: [0.227, 0.117, 0.742, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000134689_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a long-necked brown giraffe standing in the center, facing forward with its back to the camera.\nObjects: [long-necked brown giraffe]"
      },
      {
        "from": "gpt",
        "value": "long-necked brown giraffe: [0.227, 0.117, 0.742, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000134689_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.227, 0.117, 0.742, 0.898]\nGiven the above layout, shift the giraffe to the right by 0.094."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.320, 0.117, 0.836, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000153797",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center, pitching a baseball from the mound."
      },
      {
        "from": "gpt",
        "value": "person: [0.641, 0.312, 0.867, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000153797_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center, pitching a baseball from the mound.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.641, 0.312, 0.867, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000153797_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall baseball player is at the center, pitching a baseball from the mound."
      },
      {
        "from": "gpt",
        "value": "tall baseball player: [0.641, 0.312, 0.867, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000153797_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall baseball player is at the center, pitching a baseball from the mound.\nObjects: [tall baseball player]"
      },
      {
        "from": "gpt",
        "value": "tall baseball player: [0.641, 0.312, 0.867, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000153797_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.641, 0.312, 0.867, 0.750]\nGiven the above layout, shift the person to the left by 0.219."
      },
      {
        "from": "gpt",
        "value": "person: [0.422, 0.312, 0.648, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000154213",
    "conversations": [
      {
        "from": "human",
        "value": "The scissors are to the right of the pie in the baking dish."
      },
      {
        "from": "gpt",
        "value": "scissors: [0.766, 0.367, 0.992, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000154213_key",
    "conversations": [
      {
        "from": "human",
        "value": "The scissors are to the right of the pie in the baking dish.\nObjects: [scissors]"
      },
      {
        "from": "gpt",
        "value": "scissors: [0.766, 0.367, 0.992, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000154213_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the steel crafting shears are to the right of the pie in the baking dish."
      },
      {
        "from": "gpt",
        "value": "steel crafting shears: [0.766, 0.367, 0.992, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000154213_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the steel crafting shears are to the right of the pie in the baking dish.\nObjects: [steel crafting shears]"
      },
      {
        "from": "gpt",
        "value": "steel crafting shears: [0.766, 0.367, 0.992, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000154213_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: scissors: [0.766, 0.367, 0.992, 0.789]\nGiven the above layout, shift the scissors to the left by 0.688."
      },
      {
        "from": "gpt",
        "value": "scissors: [0.078, 0.367, 0.305, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000154718",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in front of a toilet."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.188, 0.086, 0.711, 0.734]\nperson: [0.195, 0.648, 0.852, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000154718_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in front of a toilet.\nObjects: [toilet, person]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.188, 0.086, 0.711, 0.734]\nperson: [0.195, 0.648, 0.852, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000154718_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man in a suit is standing in front of a porcelain bathroom fixture."
      },
      {
        "from": "gpt",
        "value": "porcelain bathroom fixture: [0.188, 0.086, 0.711, 0.734]\ntall man in a suit: [0.195, 0.648, 0.852, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000154718_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man in a suit is standing in front of a porcelain bathroom fixture.\nObjects: [porcelain bathroom fixture, tall man in a suit]"
      },
      {
        "from": "gpt",
        "value": "porcelain bathroom fixture: [0.188, 0.086, 0.711, 0.734]\ntall man in a suit: [0.195, 0.648, 0.852, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000154718_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.188, 0.086, 0.711, 0.734]\nperson: [0.195, 0.648, 0.852, 0.984]\nGiven the above layout, shift the toilet to the left by 0.055."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.133, 0.086, 0.656, 0.734]\nperson: [0.195, 0.648, 0.852, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000155179",
    "conversations": [
      {
        "from": "human",
        "value": "A cake is at the center on top of a dining table."
      },
      {
        "from": "gpt",
        "value": "cake: [0.016, 0.133, 0.984, 0.758]\ndining table: [0.000, 0.734, 0.992, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000155179_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cake is at the center on top of a dining table.\nObjects: [cake, dining table]"
      },
      {
        "from": "gpt",
        "value": "cake: [0.016, 0.133, 0.984, 0.758]\ndining table: [0.000, 0.734, 0.992, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000155179_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a chocolate mousse cake is at the center on top of a ornate oak dining table."
      },
      {
        "from": "gpt",
        "value": "chocolate mousse cake: [0.016, 0.133, 0.984, 0.758]\nornate oak dining table: [0.000, 0.734, 0.992, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000155179_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a chocolate mousse cake is at the center on top of a ornate oak dining table.\nObjects: [chocolate mousse cake, ornate oak dining table]"
      },
      {
        "from": "gpt",
        "value": "chocolate mousse cake: [0.016, 0.133, 0.984, 0.758]\nornate oak dining table: [0.000, 0.734, 0.992, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000155179_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cake: [0.016, 0.133, 0.984, 0.758]\ndining table: [0.000, 0.734, 0.992, 0.844]\nGiven the above layout, shift the dining table downwards by 0.062."
      },
      {
        "from": "gpt",
        "value": "cake: [0.016, 0.133, 0.984, 0.758]\ndining table: [0.000, 0.797, 0.992, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000157124",
    "conversations": [
      {
        "from": "human",
        "value": "The sink is at the center of a white countertop with cabinets below it."
      },
      {
        "from": "gpt",
        "value": "sink: [0.008, 0.367, 0.586, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000157124_key",
    "conversations": [
      {
        "from": "human",
        "value": "The sink is at the center of a white countertop with cabinets below it.\nObjects: [sink]"
      },
      {
        "from": "gpt",
        "value": "sink: [0.008, 0.367, 0.586, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000157124_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the modern stainless steel sink is at the center of a white countertop with cabinets below it."
      },
      {
        "from": "gpt",
        "value": "modern stainless steel sink: [0.008, 0.367, 0.586, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000157124_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the modern stainless steel sink is at the center of a white countertop with cabinets below it.\nObjects: [modern stainless steel sink]"
      },
      {
        "from": "gpt",
        "value": "modern stainless steel sink: [0.008, 0.367, 0.586, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000157124_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sink: [0.008, 0.367, 0.586, 0.641]\nGiven the above layout, shift the sink to the right by 0.125."
      },
      {
        "from": "gpt",
        "value": "sink: [0.133, 0.367, 0.711, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000157138",
    "conversations": [
      {
        "from": "human",
        "value": "A piece of cake is on a plate, with a fork to the right of it."
      },
      {
        "from": "gpt",
        "value": "cake: [0.148, 0.203, 0.539, 0.578]\nfork: [0.344, 0.531, 0.969, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000157138_key",
    "conversations": [
      {
        "from": "human",
        "value": "A piece of cake is on a plate, with a fork to the right of it.\nObjects: [cake, fork]"
      },
      {
        "from": "gpt",
        "value": "cake: [0.148, 0.203, 0.539, 0.578]\nfork: [0.344, 0.531, 0.969, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000157138_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a piece of chocolate pastry is on a plate, with a stainless-steel fork to the right of it."
      },
      {
        "from": "gpt",
        "value": "chocolate pastry: [0.148, 0.203, 0.539, 0.578]\nstainless-steel fork: [0.344, 0.531, 0.969, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000157138_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a piece of chocolate pastry is on a plate, with a stainless-steel fork to the right of it.\nObjects: [chocolate pastry, stainless-steel fork]"
      },
      {
        "from": "gpt",
        "value": "chocolate pastry: [0.148, 0.203, 0.539, 0.578]\nstainless-steel fork: [0.344, 0.531, 0.969, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000157138_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cake: [0.148, 0.203, 0.539, 0.578]\nfork: [0.344, 0.531, 0.969, 0.742]\nGiven the above layout, shift the fork downwards by 0.195."
      },
      {
        "from": "gpt",
        "value": "cake: [0.148, 0.203, 0.539, 0.578]\nfork: [0.344, 0.727, 0.969, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000159458",
    "conversations": [
      {
        "from": "human",
        "value": "A bed is at the center of the image, and a chair is partially visible to the right of the bed."
      },
      {
        "from": "gpt",
        "value": "bed: [0.172, 0.375, 0.805, 0.844]\nchair: [0.812, 0.508, 0.992, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000159458_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bed is at the center of the image, and a chair is partially visible to the right of the bed.\nObjects: [bed, chair]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.172, 0.375, 0.805, 0.844]\nchair: [0.812, 0.508, 0.992, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000159684",
    "conversations": [
      {
        "from": "human",
        "value": "A train is at the center of the image, facing the right side."
      },
      {
        "from": "gpt",
        "value": "train: [0.117, 0.414, 0.992, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000159684_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is at the center of the image, facing the right side.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.117, 0.414, 0.992, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000159684_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a magnificently detailed model train is at the center of the image, facing the right side."
      },
      {
        "from": "gpt",
        "value": "magnificently detailed model train: [0.117, 0.414, 0.992, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000159684_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a magnificently detailed model train is at the center of the image, facing the right side.\nObjects: [magnificently detailed model train]"
      },
      {
        "from": "gpt",
        "value": "magnificently detailed model train: [0.117, 0.414, 0.992, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000159684_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.117, 0.414, 0.992, 0.750]\nGiven the above layout, shift the train upwards by 0.055."
      },
      {
        "from": "gpt",
        "value": "train: [0.117, 0.359, 0.992, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000160556",
    "conversations": [
      {
        "from": "human",
        "value": "A microwave is in the foreground on the left, a TV is in the background on the upper right, and a person is seated to the right of the microwave facing the TV."
      },
      {
        "from": "gpt",
        "value": "microwave: [0.000, 0.328, 0.539, 0.750]\nperson: [0.703, 0.281, 0.992, 0.820]\ntv: [0.430, 0.375, 0.625, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000160556_key",
    "conversations": [
      {
        "from": "human",
        "value": "A microwave is in the foreground on the left, a TV is in the background on the upper right, and a person is seated to the right of the microwave facing the TV.\nObjects: [microwave, person, tv]"
      },
      {
        "from": "gpt",
        "value": "microwave: [0.000, 0.328, 0.539, 0.750]\nperson: [0.703, 0.281, 0.992, 0.820]\ntv: [0.430, 0.375, 0.625, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000160556_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a stainless steel microwave is in the foreground on the left, a flat screen TV is in the background on the upper right, and a blonde woman is seated to the right of the stainless steel microwave facing the flat screen TV."
      },
      {
        "from": "gpt",
        "value": "stainless steel microwave: [0.000, 0.328, 0.539, 0.750]\nblonde woman: [0.703, 0.281, 0.992, 0.820]\nflat screen TV: [0.430, 0.375, 0.625, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000160556_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a stainless steel microwave is in the foreground on the left, a flat screen TV is in the background on the upper right, and a blonde woman is seated to the right of the stainless steel microwave facing the flat screen TV.\nObjects: [stainless steel microwave, blonde woman, flat screen TV]"
      },
      {
        "from": "gpt",
        "value": "stainless steel microwave: [0.000, 0.328, 0.539, 0.750]\nblonde woman: [0.703, 0.281, 0.992, 0.820]\nflat screen TV: [0.430, 0.375, 0.625, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000160556_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: microwave: [0.000, 0.328, 0.539, 0.750]\nperson: [0.703, 0.281, 0.992, 0.820]\ntv: [0.430, 0.375, 0.625, 0.570]\nGiven the above layout, shift the person upwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "microwave: [0.000, 0.328, 0.539, 0.750]\nperson: [0.703, 0.258, 0.992, 0.797]\ntv: [0.430, 0.375, 0.625, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000160666",
    "conversations": [
      {
        "from": "human",
        "value": "The toothbrush is to the right of the toothpaste, oriented diagonally with the bristles pointing to the top right corner."
      },
      {
        "from": "gpt",
        "value": "toothbrush: [0.000, 0.500, 0.883, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000160666_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toothbrush is to the right of the toothpaste, oriented diagonally with the bristles pointing to the top right corner.\nObjects: [toothbrush]"
      },
      {
        "from": "gpt",
        "value": "toothbrush: [0.000, 0.500, 0.883, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000160666_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the blue electric toothbrush is to the right of the toothpaste, oriented diagonally with the bristles pointing to the top right corner."
      },
      {
        "from": "gpt",
        "value": "blue electric toothbrush: [0.000, 0.500, 0.883, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000160666_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the blue electric toothbrush is to the right of the toothpaste, oriented diagonally with the bristles pointing to the top right corner.\nObjects: [blue electric toothbrush]"
      },
      {
        "from": "gpt",
        "value": "blue electric toothbrush: [0.000, 0.500, 0.883, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000160666_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toothbrush: [0.000, 0.500, 0.883, 0.766]\nGiven the above layout, shift the toothbrush upwards by 0.477."
      },
      {
        "from": "gpt",
        "value": "toothbrush: [0.000, 0.023, 0.883, 0.289]"
      }
    ]
  },
  {
    "id": "coco_000000160772",
    "conversations": [
      {
        "from": "human",
        "value": "The boat is in the water towards the right side of the image, behind a wave."
      },
      {
        "from": "gpt",
        "value": "boat: [0.133, 0.305, 0.867, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000160772_key",
    "conversations": [
      {
        "from": "human",
        "value": "The boat is in the water towards the right side of the image, behind a wave.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.133, 0.305, 0.867, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000160772_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the luxury yacht is in the water towards the right side of the image, behind a wave."
      },
      {
        "from": "gpt",
        "value": "luxury yacht: [0.133, 0.305, 0.867, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000160772_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the luxury yacht is in the water towards the right side of the image, behind a wave.\nObjects: [luxury yacht]"
      },
      {
        "from": "gpt",
        "value": "luxury yacht: [0.133, 0.305, 0.867, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000160772_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.133, 0.305, 0.867, 0.516]\nGiven the above layout, shift the boat downwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "boat: [0.133, 0.328, 0.867, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000161008",
    "conversations": [
      {
        "from": "human",
        "value": "The scissors are open and placed diagonally on top of a wooden box."
      },
      {
        "from": "gpt",
        "value": "scissors: [0.133, 0.125, 0.891, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000161008_key",
    "conversations": [
      {
        "from": "human",
        "value": "The scissors are open and placed diagonally on top of a wooden box.\nObjects: [scissors]"
      },
      {
        "from": "gpt",
        "value": "scissors: [0.133, 0.125, 0.891, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000161008_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the silver shears are open and placed diagonally on top of a wooden box."
      },
      {
        "from": "gpt",
        "value": "silver shears: [0.133, 0.125, 0.891, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000161008_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the silver shears are open and placed diagonally on top of a wooden box.\nObjects: [silver shears]"
      },
      {
        "from": "gpt",
        "value": "silver shears: [0.133, 0.125, 0.891, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000161008_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: scissors: [0.133, 0.125, 0.891, 0.859]\nGiven the above layout, shift the scissors to the left by 0.117."
      },
      {
        "from": "gpt",
        "value": "scissors: [0.016, 0.125, 0.773, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000161781",
    "conversations": [
      {
        "from": "human",
        "value": "A person at the center wearing skis."
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.195, 0.727, 0.727]\nskis: [0.227, 0.688, 0.781, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000161781_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person at the center wearing skis.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.195, 0.727, 0.727]\nskis: [0.227, 0.688, 0.781, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000161781_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a young ski enthusiast at the center wearing red racing skis."
      },
      {
        "from": "gpt",
        "value": "a young ski enthusiast: [0.406, 0.195, 0.727, 0.727]\nred racing skis: [0.227, 0.688, 0.781, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000161781_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a young ski enthusiast at the center wearing red racing skis.\nObjects: [a young ski enthusiast, red racing skis]"
      },
      {
        "from": "gpt",
        "value": "a young ski enthusiast: [0.406, 0.195, 0.727, 0.727]\nred racing skis: [0.227, 0.688, 0.781, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000161781_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.406, 0.195, 0.727, 0.727]\nskis: [0.227, 0.688, 0.781, 0.758]\nGiven the above layout, shift the skis downwards by 0.148."
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.195, 0.727, 0.727]\nskis: [0.227, 0.836, 0.781, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000161820",
    "conversations": [
      {
        "from": "human",
        "value": "A bunch of green bananas is at the center of the image, with individual bananas hanging vertically."
      },
      {
        "from": "gpt",
        "value": "banana: [0.281, 0.000, 0.828, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000161820_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bunch of green bananas is at the center of the image, with individual bananas hanging vertically.\nObjects: [banana]"
      },
      {
        "from": "gpt",
        "value": "banana: [0.281, 0.000, 0.828, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000161820_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a bunch of green ripe yellow bananass is at the center of the image, with individual ripe yellow bananass hanging vertically."
      },
      {
        "from": "gpt",
        "value": "ripe yellow bananas: [0.281, 0.000, 0.828, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000161820_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a bunch of green ripe yellow bananass is at the center of the image, with individual ripe yellow bananass hanging vertically.\nObjects: [ripe yellow bananas]"
      },
      {
        "from": "gpt",
        "value": "ripe yellow bananas: [0.281, 0.000, 0.828, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000161820_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: banana: [0.281, 0.000, 0.828, 0.984]\nGiven the above layout, shift the banana to the left by 0.234."
      },
      {
        "from": "gpt",
        "value": "banana: [0.047, 0.000, 0.594, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000176778",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is partially seen to the right of a toilet."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.188, 0.328, 0.633, 0.844]\ncat: [0.578, 0.617, 0.688, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000176778_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is partially seen to the right of a toilet.\nObjects: [toilet, cat]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.188, 0.328, 0.633, 0.844]\ncat: [0.578, 0.617, 0.688, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000176778_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a cat is partially seen to the right of a toilet."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.188, 0.328, 0.633, 0.844]\ncat: [0.578, 0.617, 0.688, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000176778_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a cat is partially seen to the right of a toilet.\nObjects: [toilet, cat]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.188, 0.328, 0.633, 0.844]\ncat: [0.578, 0.617, 0.688, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000176778_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.188, 0.328, 0.633, 0.844]\ncat: [0.578, 0.617, 0.688, 0.992]\nGiven the above layout, shift the toilet upwards by 0.234."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.188, 0.094, 0.633, 0.609]\ncat: [0.578, 0.617, 0.688, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000177383",
    "conversations": [
      {
        "from": "human",
        "value": "A train is positioned in the center of the image, facing forward with train tracks below it."
      },
      {
        "from": "gpt",
        "value": "train: [0.180, 0.102, 0.766, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000177383_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is positioned in the center of the image, facing forward with train tracks below it.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.180, 0.102, 0.766, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000177383_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a steam locomotive is positioned in the center of the image, facing forward with steam locomotive tracks below it."
      },
      {
        "from": "gpt",
        "value": "steam locomotive: [0.180, 0.102, 0.766, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000177383_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a steam locomotive is positioned in the center of the image, facing forward with steam locomotive tracks below it.\nObjects: [steam locomotive]"
      },
      {
        "from": "gpt",
        "value": "steam locomotive: [0.180, 0.102, 0.766, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000177383_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.180, 0.102, 0.766, 0.750]\nGiven the above layout, shift the train downwards by 0.188."
      },
      {
        "from": "gpt",
        "value": "train: [0.180, 0.289, 0.766, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000177935",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is at the center with a stovetop above and towel handles on its door."
      },
      {
        "from": "gpt",
        "value": "oven: [0.125, 0.406, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000177935_key",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is at the center with a stovetop above and towel handles on its door.\nObjects: [oven]"
      },
      {
        "from": "gpt",
        "value": "oven: [0.125, 0.406, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000177935_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red microwave is at the center with a stovetop above and towel handles on its door."
      },
      {
        "from": "gpt",
        "value": "red microwave: [0.125, 0.406, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000177935_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red microwave is at the center with a stovetop above and towel handles on its door.\nObjects: [red microwave]"
      },
      {
        "from": "gpt",
        "value": "red microwave: [0.125, 0.406, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000177935_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: oven: [0.125, 0.406, 0.828, 0.992]\nGiven the above layout, shift the oven upwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "oven: [0.125, 0.383, 0.828, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000179214",
    "conversations": [
      {
        "from": "human",
        "value": "The pizza is on top of a blue bin."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.164, 0.305, 0.688, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000179214_key",
    "conversations": [
      {
        "from": "human",
        "value": "The pizza is on top of a blue bin.\nObjects: [pizza]"
      },
      {
        "from": "gpt",
        "value": "pizza: [0.164, 0.305, 0.688, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000179214_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the pepperoni pizza is on top of a blue bin."
      },
      {
        "from": "gpt",
        "value": "pepperoni pizza: [0.164, 0.305, 0.688, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000179214_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the pepperoni pizza is on top of a blue bin.\nObjects: [pepperoni pizza]"
      },
      {
        "from": "gpt",
        "value": "pepperoni pizza: [0.164, 0.305, 0.688, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000179214_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: pizza: [0.164, 0.305, 0.688, 0.734]\nGiven the above layout, shift the pizza upwards by 0.031."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.164, 0.273, 0.688, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000179487",
    "conversations": [
      {
        "from": "human",
        "value": "A person is crouching in the foreground on the right, another person stands in the background at the center, and a third person is on the far right in the background."
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.352, 0.680, 0.906]\nperson: [0.617, 0.180, 0.734, 0.625]\nperson: [0.805, 0.305, 0.891, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000179487_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is crouching in the foreground on the right, another person stands in the background at the center, and a third person is on the far right in the background.\nObjects: [person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.352, 0.680, 0.906]\nperson: [0.617, 0.180, 0.734, 0.625]\nperson: [0.805, 0.305, 0.891, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000180135",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing holding a skateboard to their right side."
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.008, 0.664, 0.914]\nskateboard: [0.164, 0.695, 0.641, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000180135_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing holding a skateboard to their right side.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.008, 0.664, 0.914]\nskateboard: [0.164, 0.695, 0.641, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000180135_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager carrying a backpack is standing holding a vintage wooden skateboard to their right side."
      },
      {
        "from": "gpt",
        "value": "teenager carrying a backpack: [0.164, 0.008, 0.664, 0.914]\nvintage wooden skateboard: [0.164, 0.695, 0.641, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000180135_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager carrying a backpack is standing holding a vintage wooden skateboard to their right side.\nObjects: [teenager carrying a backpack, vintage wooden skateboard]"
      },
      {
        "from": "gpt",
        "value": "teenager carrying a backpack: [0.164, 0.008, 0.664, 0.914]\nvintage wooden skateboard: [0.164, 0.695, 0.641, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000180135_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.164, 0.008, 0.664, 0.914]\nskateboard: [0.164, 0.695, 0.641, 0.969]\nGiven the above layout, shift the person to the right by 0.305."
      },
      {
        "from": "gpt",
        "value": "person: [0.469, 0.008, 0.969, 0.914]\nskateboard: [0.164, 0.695, 0.641, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000180188",
    "conversations": [
      {
        "from": "human",
        "value": "The train is oriented diagonally from the bottom right corner to the upper left side of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.031, 0.281, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000180188_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is oriented diagonally from the bottom right corner to the upper left side of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.031, 0.281, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000180188_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the Amtrak passenger train is oriented diagonally from the bottom right corner to the upper left side of the image."
      },
      {
        "from": "gpt",
        "value": "Amtrak passenger train: [0.031, 0.281, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000180188_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the Amtrak passenger train is oriented diagonally from the bottom right corner to the upper left side of the image.\nObjects: [Amtrak passenger train]"
      },
      {
        "from": "gpt",
        "value": "Amtrak passenger train: [0.031, 0.281, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000180188_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.031, 0.281, 0.992, 0.680]\nGiven the above layout, shift the train downwards by 0.164."
      },
      {
        "from": "gpt",
        "value": "train: [0.031, 0.445, 0.992, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000180792",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center of the image, facing forward."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.383, 0.625, 0.594, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000180792_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center of the image, facing forward.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.383, 0.625, 0.594, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000180792_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain toilet is at the center of the image, facing forward."
      },
      {
        "from": "gpt",
        "value": "porcelain toilet: [0.383, 0.625, 0.594, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000180792_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain toilet is at the center of the image, facing forward.\nObjects: [porcelain toilet]"
      },
      {
        "from": "gpt",
        "value": "porcelain toilet: [0.383, 0.625, 0.594, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000180792_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.383, 0.625, 0.594, 0.977]\nGiven the above layout, shift the toilet upwards by 0.328."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.383, 0.297, 0.594, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000180798",
    "conversations": [
      {
        "from": "human",
        "value": "The cell phone is lying diagonally across a blue textured fabric."
      },
      {
        "from": "gpt",
        "value": "cell phone: [0.469, 0.289, 0.727, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000180798_key",
    "conversations": [
      {
        "from": "human",
        "value": "The cell phone is lying diagonally across a blue textured fabric.\nObjects: [cell phone]"
      },
      {
        "from": "gpt",
        "value": "cell phone: [0.469, 0.289, 0.727, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000180798_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the sleek black smartphone is lying diagonally across a blue textured fabric."
      },
      {
        "from": "gpt",
        "value": "sleek black smartphone: [0.469, 0.289, 0.727, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000180798_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the sleek black smartphone is lying diagonally across a blue textured fabric.\nObjects: [sleek black smartphone]"
      },
      {
        "from": "gpt",
        "value": "sleek black smartphone: [0.469, 0.289, 0.727, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000180798_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cell phone: [0.469, 0.289, 0.727, 0.898]\nGiven the above layout, shift the cell phone to the left by 0.320."
      },
      {
        "from": "gpt",
        "value": "cell phone: [0.148, 0.289, 0.406, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000182162",
    "conversations": [
      {
        "from": "human",
        "value": "The couch is at the center of the image, angled to the right."
      },
      {
        "from": "gpt",
        "value": "couch: [0.164, 0.414, 0.453, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000182162_key",
    "conversations": [
      {
        "from": "human",
        "value": "The couch is at the center of the image, angled to the right.\nObjects: [couch]"
      },
      {
        "from": "gpt",
        "value": "couch: [0.164, 0.414, 0.453, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000182162_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the brown leather couch is at the center of the image, angled to the right."
      },
      {
        "from": "gpt",
        "value": "brown leather couch: [0.164, 0.414, 0.453, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000182162_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the brown leather couch is at the center of the image, angled to the right.\nObjects: [brown leather couch]"
      },
      {
        "from": "gpt",
        "value": "brown leather couch: [0.164, 0.414, 0.453, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000182162_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: couch: [0.164, 0.414, 0.453, 0.680]\nGiven the above layout, shift the couch to the right by 0.539."
      },
      {
        "from": "gpt",
        "value": "couch: [0.703, 0.414, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000183049",
    "conversations": [
      {
        "from": "human",
        "value": "Books are arranged vertically on shelves, with each shelf containing a different arrangement of books side by side."
      },
      {
        "from": "gpt",
        "value": "book: [0.164, 0.648, 0.688, 0.867]\nbook: [0.164, 0.445, 0.469, 0.633]\nbook: [0.516, 0.422, 0.594, 0.633]\nbook: [0.562, 0.156, 0.641, 0.359]"
      }
    ]
  },
  {
    "id": "coco_000000183049_key",
    "conversations": [
      {
        "from": "human",
        "value": "Books are arranged vertically on shelves, with each shelf containing a different arrangement of books side by side.\nObjects: [book, book, book, book]"
      },
      {
        "from": "gpt",
        "value": "book: [0.164, 0.648, 0.688, 0.867]\nbook: [0.164, 0.445, 0.469, 0.633]\nbook: [0.516, 0.422, 0.594, 0.633]\nbook: [0.562, 0.156, 0.641, 0.359]"
      }
    ]
  },
  {
    "id": "coco_000000183500",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying in the center of the image, slightly tilted to the right."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.148, 0.281, 0.836, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000183500_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying in the center of the image, slightly tilted to the right.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.148, 0.281, 0.836, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000183500_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an blue and white jet plane is flying in the center of the image, slightly tilted to the right."
      },
      {
        "from": "gpt",
        "value": "blue and white jet plane: [0.148, 0.281, 0.836, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000183500_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an blue and white jet plane is flying in the center of the image, slightly tilted to the right.\nObjects: [blue and white jet plane]"
      },
      {
        "from": "gpt",
        "value": "blue and white jet plane: [0.148, 0.281, 0.836, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000183500_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.148, 0.281, 0.836, 0.688]\nGiven the above layout, shift the airplane downwards by 0.047."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.148, 0.328, 0.836, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000184338",
    "conversations": [
      {
        "from": "human",
        "value": "An old, painted truck is placed at the center of the image facing slightly to the left."
      },
      {
        "from": "gpt",
        "value": "truck: [0.023, 0.180, 0.852, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000184338_key",
    "conversations": [
      {
        "from": "human",
        "value": "An old, painted truck is placed at the center of the image facing slightly to the left.\nObjects: [truck]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.023, 0.180, 0.852, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000184338_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an old, painted vintage ice cream van is placed at the center of the image facing slightly to the left."
      },
      {
        "from": "gpt",
        "value": "vintage ice cream van: [0.023, 0.180, 0.852, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000184338_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an old, painted vintage ice cream van is placed at the center of the image facing slightly to the left.\nObjects: [vintage ice cream van]"
      },
      {
        "from": "gpt",
        "value": "vintage ice cream van: [0.023, 0.180, 0.852, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000184338_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.023, 0.180, 0.852, 0.820]\nGiven the above layout, shift the truck upwards by 0.164."
      },
      {
        "from": "gpt",
        "value": "truck: [0.023, 0.016, 0.852, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000196843",
    "conversations": [
      {
        "from": "human",
        "value": "A bicycle is parked on the left side of a bus, and another bicycle is parked to the right of the first bicycle, all aligned horizontally."
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.203, 0.992, 0.789]\nbicycle: [0.688, 0.531, 0.867, 0.758]\nbicycle: [0.000, 0.711, 0.211, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000196843_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bicycle is parked on the left side of a bus, and another bicycle is parked to the right of the first bicycle, all aligned horizontally.\nObjects: [bus, bicycle, bicycle]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.203, 0.992, 0.789]\nbicycle: [0.688, 0.531, 0.867, 0.758]\nbicycle: [0.000, 0.711, 0.211, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000197022",
    "conversations": [
      {
        "from": "human",
        "value": "A whole pizza is on a wooden board to the left, and a slice of pizza is on the right, placed directly on the table."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.039, 0.219, 0.789, 0.656]\npizza: [0.258, 0.664, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000197022_key",
    "conversations": [
      {
        "from": "human",
        "value": "A whole pizza is on a wooden board to the left, and a slice of pizza is on the right, placed directly on the table.\nObjects: [pizza, pizza]"
      },
      {
        "from": "gpt",
        "value": "pizza: [0.039, 0.219, 0.789, 0.656]\npizza: [0.258, 0.664, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000197658",
    "conversations": [
      {
        "from": "human",
        "value": "The person is wearing a baseball uniform and is crouched over on a baseball field, ready to field a ball."
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.219, 0.914, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000197658_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is wearing a baseball uniform and is crouched over on a baseball field, ready to field a ball.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.219, 0.914, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000197658_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the Baseball player in a white uniform is wearing a baseball uniform and is crouched over on a baseball field, ready to field a ball."
      },
      {
        "from": "gpt",
        "value": "Baseball player in a white uniform: [0.320, 0.219, 0.914, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000197658_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the Baseball player in a white uniform is wearing a baseball uniform and is crouched over on a baseball field, ready to field a ball.\nObjects: [Baseball player in a white uniform]"
      },
      {
        "from": "gpt",
        "value": "Baseball player in a white uniform: [0.320, 0.219, 0.914, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000197658_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.320, 0.219, 0.914, 0.898]\nGiven the above layout, shift the person to the left by 0.312."
      },
      {
        "from": "gpt",
        "value": "person: [0.008, 0.219, 0.602, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000198510",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center on train tracks facing away with a train to the right."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.023, 0.398, 0.656]\nperson: [0.414, 0.297, 0.773, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000198510_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center on train tracks facing away with a train to the right.\nObjects: [train, person]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.023, 0.398, 0.656]\nperson: [0.414, 0.297, 0.773, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000200162",
    "conversations": [
      {
        "from": "human",
        "value": "A train is on the tracks beneath a traffic light which is positioned above to the left."
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.406, 0.891, 0.695]\ntraffic light: [0.625, 0.172, 0.695, 0.320]"
      }
    ]
  },
  {
    "id": "coco_000000200162_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is on the tracks beneath a traffic light which is positioned above to the left.\nObjects: [train, traffic light]"
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.406, 0.891, 0.695]\ntraffic light: [0.625, 0.172, 0.695, 0.320]"
      }
    ]
  },
  {
    "id": "coco_000000200252",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is centered in the image with a checkered pattern bedsheet."
      },
      {
        "from": "gpt",
        "value": "bed: [0.031, 0.344, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000200252_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is centered in the image with a checkered pattern bedsheet.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.031, 0.344, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000200252_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the queen-sized bed with blue and white checkered bedsheet is centered in the image with a checkered pattern queen-sized bed with blue and white checkered bedsheetsheet."
      },
      {
        "from": "gpt",
        "value": "queen-sized bed with blue and white checkered bedsheet: [0.031, 0.344, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000200252_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the queen-sized bed with blue and white checkered bedsheet is centered in the image with a checkered pattern queen-sized bed with blue and white checkered bedsheetsheet.\nObjects: [queen-sized bed with blue and white checkered bedsheet]"
      },
      {
        "from": "gpt",
        "value": "queen-sized bed with blue and white checkered bedsheet: [0.031, 0.344, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000200252_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.031, 0.344, 0.992, 0.867]\nGiven the above layout, shift the bed upwards by 0.062."
      },
      {
        "from": "gpt",
        "value": "bed: [0.031, 0.281, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000202228",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in front of a mirror, taking a photo with their right hand raised, wearing a white and red jacket and black pants."
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.266, 0.609, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000202228_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in front of a mirror, taking a photo with their right hand raised, wearing a white and red jacket and black pants.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.266, 0.609, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000202228_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a fashion model in casual clothing is standing in front of a mirror, taking a photo with their right hand raised, wearing a white and red jacket and black pants."
      },
      {
        "from": "gpt",
        "value": "fashion model in casual clothing: [0.320, 0.266, 0.609, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000202228_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a fashion model in casual clothing is standing in front of a mirror, taking a photo with their right hand raised, wearing a white and red jacket and black pants.\nObjects: [fashion model in casual clothing]"
      },
      {
        "from": "gpt",
        "value": "fashion model in casual clothing: [0.320, 0.266, 0.609, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000202228_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.320, 0.266, 0.609, 0.742]\nGiven the above layout, shift the person to the right by 0.172."
      },
      {
        "from": "gpt",
        "value": "person: [0.492, 0.266, 0.781, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000203864",
    "conversations": [
      {
        "from": "human",
        "value": "One person is in the foreground, to the right, looking ready to hit a tennis ball, and the second person is in the background, to the left, also preparing to play."
      },
      {
        "from": "gpt",
        "value": "person: [0.391, 0.273, 0.672, 0.797]\nperson: [0.172, 0.242, 0.336, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000203864_key",
    "conversations": [
      {
        "from": "human",
        "value": "One person is in the foreground, to the right, looking ready to hit a tennis ball, and the second person is in the background, to the left, also preparing to play.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.391, 0.273, 0.672, 0.797]\nperson: [0.172, 0.242, 0.336, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000204329",
    "conversations": [
      {
        "from": "human",
        "value": "A surfboard with a Brazilian flag design standing upright in the sand at the center."
      },
      {
        "from": "gpt",
        "value": "surfboard: [0.258, 0.188, 0.430, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000204329_key",
    "conversations": [
      {
        "from": "human",
        "value": "A surfboard with a Brazilian flag design standing upright in the sand at the center.\nObjects: [surfboard]"
      },
      {
        "from": "gpt",
        "value": "surfboard: [0.258, 0.188, 0.430, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000204329_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a surfboard with tropical design with a brazilian flag design standing upright in the sand at the center."
      },
      {
        "from": "gpt",
        "value": "surfboard with tropical design: [0.258, 0.188, 0.430, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000204329_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a surfboard with tropical design with a brazilian flag design standing upright in the sand at the center.\nObjects: [surfboard with tropical design]"
      },
      {
        "from": "gpt",
        "value": "surfboard with tropical design: [0.258, 0.188, 0.430, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000204329_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: surfboard: [0.258, 0.188, 0.430, 0.781]\nGiven the above layout, shift the surfboard to the right by 0.125."
      },
      {
        "from": "gpt",
        "value": "surfboard: [0.383, 0.188, 0.555, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000204871",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is at the center of the image with a sticker of an elephant on it."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.195, 0.078, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000204871_key",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is at the center of the image with a sticker of an elephant on it.\nObjects: [fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.195, 0.078, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000204871_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red fire hydrant is at the center of the image with a sticker of an elephant on it."
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.195, 0.078, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000204871_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red fire hydrant is at the center of the image with a sticker of an elephant on it.\nObjects: [red fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.195, 0.078, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000204871_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: fire hydrant: [0.195, 0.078, 0.867, 0.977]\nGiven the above layout, shift the fire hydrant to the left by 0.094."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.102, 0.078, 0.773, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000205105",
    "conversations": [
      {
        "from": "human",
        "value": "The person is at the center of the image, playing tennis."
      },
      {
        "from": "gpt",
        "value": "person: [0.219, 0.359, 0.469, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000205105_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is at the center of the image, playing tennis.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.219, 0.359, 0.469, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000205105_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the middle-aged man is at the center of the image, playing tennis."
      },
      {
        "from": "gpt",
        "value": "middle-aged man: [0.219, 0.359, 0.469, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000205105_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the middle-aged man is at the center of the image, playing tennis.\nObjects: [middle-aged man]"
      },
      {
        "from": "gpt",
        "value": "middle-aged man: [0.219, 0.359, 0.469, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000205105_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.219, 0.359, 0.469, 0.828]\nGiven the above layout, shift the person to the right by 0.039."
      },
      {
        "from": "gpt",
        "value": "person: [0.258, 0.359, 0.508, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000205289",
    "conversations": [
      {
        "from": "human",
        "value": "An old-fashioned truck is positioned in the center of the image on a field."
      },
      {
        "from": "gpt",
        "value": "truck: [0.227, 0.336, 0.750, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000205289_key",
    "conversations": [
      {
        "from": "human",
        "value": "An old-fashioned truck is positioned in the center of the image on a field.\nObjects: [truck]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.227, 0.336, 0.750, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000205289_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an old-fashioned vintage red truck is positioned in the center of the image on a field."
      },
      {
        "from": "gpt",
        "value": "vintage red truck: [0.227, 0.336, 0.750, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000205289_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an old-fashioned vintage red truck is positioned in the center of the image on a field.\nObjects: [vintage red truck]"
      },
      {
        "from": "gpt",
        "value": "vintage red truck: [0.227, 0.336, 0.750, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000205289_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.227, 0.336, 0.750, 0.586]\nGiven the above layout, shift the truck downwards by 0.188."
      },
      {
        "from": "gpt",
        "value": "truck: [0.227, 0.523, 0.750, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000205401",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is at the center of the image, docked on the water's edge with mountains in the background."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.164, 0.398, 0.844, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000205401_key",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is at the center of the image, docked on the waters edge with mountains in the background.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.164, 0.398, 0.844, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000205401_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the hydroplane is at the center of the image, docked on the water's edge with mountains in the background."
      },
      {
        "from": "gpt",
        "value": "hydroplane: [0.164, 0.398, 0.844, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000205401_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the hydroplane is at the center of the image, docked on the waters edge with mountains in the background.\nObjects: [hydroplane]"
      },
      {
        "from": "gpt",
        "value": "hydroplane: [0.164, 0.398, 0.844, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000205401_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.164, 0.398, 0.844, 0.602]\nGiven the above layout, shift the airplane upwards by 0.055."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.164, 0.344, 0.844, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000222235",
    "conversations": [
      {
        "from": "human",
        "value": "A cat at the center, partially hidden by green plants."
      },
      {
        "from": "gpt",
        "value": "cat: [0.188, 0.367, 0.672, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000222235_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat at the center, partially hidden by green plants.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.188, 0.367, 0.672, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000222235_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a ginger kitten at the center, partially hidden by green plants."
      },
      {
        "from": "gpt",
        "value": "ginger kitten: [0.188, 0.367, 0.672, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000222235_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a ginger kitten at the center, partially hidden by green plants.\nObjects: [ginger kitten]"
      },
      {
        "from": "gpt",
        "value": "ginger kitten: [0.188, 0.367, 0.672, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000222235_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.188, 0.367, 0.672, 0.766]\nGiven the above layout, shift the cat upwards by 0.344."
      },
      {
        "from": "gpt",
        "value": "cat: [0.188, 0.023, 0.672, 0.422]"
      }
    ]
  },
  {
    "id": "coco_000000222863",
    "conversations": [
      {
        "from": "human",
        "value": "The cow is at the center of the image facing forward."
      },
      {
        "from": "gpt",
        "value": "cow: [0.227, 0.164, 0.602, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000222863_key",
    "conversations": [
      {
        "from": "human",
        "value": "The cow is at the center of the image facing forward.\nObjects: [cow]"
      },
      {
        "from": "gpt",
        "value": "cow: [0.227, 0.164, 0.602, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000222863_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the large black and white cow is at the center of the image facing forward."
      },
      {
        "from": "gpt",
        "value": "large black and white cow: [0.227, 0.164, 0.602, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000222863_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the large black and white cow is at the center of the image facing forward.\nObjects: [large black and white cow]"
      },
      {
        "from": "gpt",
        "value": "large black and white cow: [0.227, 0.164, 0.602, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000222863_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cow: [0.227, 0.164, 0.602, 0.828]\nGiven the above layout, shift the cow to the right by 0.203."
      },
      {
        "from": "gpt",
        "value": "cow: [0.430, 0.164, 0.805, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000223789",
    "conversations": [
      {
        "from": "human",
        "value": "A sink at the center against a tiled wall with toiletries on a shelf above it."
      },
      {
        "from": "gpt",
        "value": "sink: [0.156, 0.516, 0.719, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000223789_key",
    "conversations": [
      {
        "from": "human",
        "value": "A sink at the center against a tiled wall with toiletries on a shelf above it.\nObjects: [sink]"
      },
      {
        "from": "gpt",
        "value": "sink: [0.156, 0.516, 0.719, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000223789_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a porcelain basin at the center against a tiled wall with toiletries on a shelf above it."
      },
      {
        "from": "gpt",
        "value": "porcelain basin: [0.156, 0.516, 0.719, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000223789_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a porcelain basin at the center against a tiled wall with toiletries on a shelf above it.\nObjects: [porcelain basin]"
      },
      {
        "from": "gpt",
        "value": "porcelain basin: [0.156, 0.516, 0.719, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000223789_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sink: [0.156, 0.516, 0.719, 0.961]\nGiven the above layout, shift the sink upwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "sink: [0.156, 0.477, 0.719, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000223955",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center of the image, facing away with their arm extended upwards to the right as if throwing something."
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.297, 0.719, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000223955_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center of the image, facing away with their arm extended upwards to the right as if throwing something.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.297, 0.719, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000223955_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a middle-aged man is standing at the center of the image, facing away with their arm extended upwards to the right as if throwing something."
      },
      {
        "from": "gpt",
        "value": "middle-aged man: [0.344, 0.297, 0.719, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000223955_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a middle-aged man is standing at the center of the image, facing away with their arm extended upwards to the right as if throwing something.\nObjects: [middle-aged man]"
      },
      {
        "from": "gpt",
        "value": "middle-aged man: [0.344, 0.297, 0.719, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000223955_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.344, 0.297, 0.719, 0.820]\nGiven the above layout, shift the person to the left by 0.023."
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.297, 0.695, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000224200",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is sitting on the ground to the left of a fire hydrant, with its leash attached to the hydrant."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.641, 0.000, 0.992, 0.758]\ndog: [0.086, 0.375, 0.477, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000224200_key",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is sitting on the ground to the left of a fire hydrant, with its leash attached to the hydrant.\nObjects: [fire hydrant, dog]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.641, 0.000, 0.992, 0.758]\ndog: [0.086, 0.375, 0.477, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000225405",
    "conversations": [
      {
        "from": "human",
        "value": "One person is running from the right towards another person in the center, who is facing the first person and controlling a soccer ball."
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.203, 0.445, 0.828]\nperson: [0.523, 0.289, 0.789, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000225405_key",
    "conversations": [
      {
        "from": "human",
        "value": "One person is running from the right towards another person in the center, who is facing the first person and controlling a soccer ball.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.203, 0.445, 0.828]\nperson: [0.523, 0.289, 0.789, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000227686",
    "conversations": [
      {
        "from": "human",
        "value": "A horse at the center, facing to the right."
      },
      {
        "from": "gpt",
        "value": "horse: [0.195, 0.352, 0.695, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000227686_key",
    "conversations": [
      {
        "from": "human",
        "value": "A horse at the center, facing to the right.\nObjects: [horse]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.195, 0.352, 0.695, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000227686_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a black stallion at the center, facing to the right."
      },
      {
        "from": "gpt",
        "value": "black stallion: [0.195, 0.352, 0.695, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000227686_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a black stallion at the center, facing to the right.\nObjects: [black stallion]"
      },
      {
        "from": "gpt",
        "value": "black stallion: [0.195, 0.352, 0.695, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000227686_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: horse: [0.195, 0.352, 0.695, 0.969]\nGiven the above layout, shift the horse upwards by 0.305."
      },
      {
        "from": "gpt",
        "value": "horse: [0.195, 0.047, 0.695, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000228981",
    "conversations": [
      {
        "from": "human",
        "value": "Two cell phones placed next to each other on a flat surface, with one on the left and the other on the right."
      },
      {
        "from": "gpt",
        "value": "cell phone: [0.148, 0.312, 0.383, 0.703]\ncell phone: [0.625, 0.359, 0.758, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000228981_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two cell phones placed next to each other on a flat surface, with one on the left and the other on the right.\nObjects: [cell phone, cell phone]"
      },
      {
        "from": "gpt",
        "value": "cell phone: [0.148, 0.312, 0.383, 0.703]\ncell phone: [0.625, 0.359, 0.758, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000229221",
    "conversations": [
      {
        "from": "human",
        "value": "A cow at the center of the image facing forward."
      },
      {
        "from": "gpt",
        "value": "cow: [0.227, 0.305, 0.750, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000229221_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cow at the center of the image facing forward.\nObjects: [cow]"
      },
      {
        "from": "gpt",
        "value": "cow: [0.227, 0.305, 0.750, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000229221_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a brown heifer at the center of the image facing forward."
      },
      {
        "from": "gpt",
        "value": "brown heifer: [0.227, 0.305, 0.750, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000229221_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a brown heifer at the center of the image facing forward.\nObjects: [brown heifer]"
      },
      {
        "from": "gpt",
        "value": "brown heifer: [0.227, 0.305, 0.750, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000229221_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cow: [0.227, 0.305, 0.750, 0.820]\nGiven the above layout, shift the cow upwards by 0.148."
      },
      {
        "from": "gpt",
        "value": "cow: [0.227, 0.156, 0.750, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000229553",
    "conversations": [
      {
        "from": "human",
        "value": "A person is crouched low on a skateboard, gliding to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.094, 0.203, 0.781, 0.719]\nskateboard: [0.250, 0.680, 0.844, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000229553_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is crouched low on a skateboard, gliding to the right.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.094, 0.203, 0.781, 0.719]\nskateboard: [0.250, 0.680, 0.844, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000229553_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a adventurous teenager is crouched low on a colorful skateboard, gliding to the right."
      },
      {
        "from": "gpt",
        "value": "adventurous teenager: [0.094, 0.203, 0.781, 0.719]\ncolorful skateboard: [0.250, 0.680, 0.844, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000229553_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a adventurous teenager is crouched low on a colorful skateboard, gliding to the right.\nObjects: [adventurous teenager, colorful skateboard]"
      },
      {
        "from": "gpt",
        "value": "adventurous teenager: [0.094, 0.203, 0.781, 0.719]\ncolorful skateboard: [0.250, 0.680, 0.844, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000229553_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.094, 0.203, 0.781, 0.719]\nskateboard: [0.250, 0.680, 0.844, 0.781]\nGiven the above layout, shift the skateboard downwards by 0.164."
      },
      {
        "from": "gpt",
        "value": "person: [0.094, 0.203, 0.781, 0.719]\nskateboard: [0.250, 0.844, 0.844, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000229601",
    "conversations": [
      {
        "from": "human",
        "value": "A person in blue is standing in the center, a blurred person in red is running to the left of the person in blue, and there is another person farther back in the field."
      },
      {
        "from": "gpt",
        "value": "person: [0.133, 0.281, 0.406, 0.711]\nperson: [0.727, 0.266, 0.914, 0.719]\nperson: [0.305, 0.312, 0.344, 0.469]"
      }
    ]
  },
  {
    "id": "coco_000000229601_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in blue is standing in the center, a blurred person in red is running to the left of the person in blue, and there is another person farther back in the field.\nObjects: [person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.133, 0.281, 0.406, 0.711]\nperson: [0.727, 0.266, 0.914, 0.719]\nperson: [0.305, 0.312, 0.344, 0.469]"
      }
    ]
  },
  {
    "id": "coco_000000229747",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying diagonally from the bottom left to the upper right of the image."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.266, 0.375, 0.656, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000229747_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying diagonally from the bottom left to the upper right of the image.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.266, 0.375, 0.656, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000229747_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an red glider is flying diagonally from the bottom left to the upper right of the image."
      },
      {
        "from": "gpt",
        "value": "red glider: [0.266, 0.375, 0.656, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000229747_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an red glider is flying diagonally from the bottom left to the upper right of the image.\nObjects: [red glider]"
      },
      {
        "from": "gpt",
        "value": "red glider: [0.266, 0.375, 0.656, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000229747_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.266, 0.375, 0.656, 0.609]\nGiven the above layout, shift the airplane downwards by 0.289."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.266, 0.664, 0.656, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000229753",
    "conversations": [
      {
        "from": "human",
        "value": "Two giraffes side by side; one is to the left and slightly behind the other, which is to the right and in a closer view."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.609, 0.398, 0.836, 0.820]\ngiraffe: [0.312, 0.477, 0.570, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000229753_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two giraffes side by side; one is to the left and slightly behind the other, which is to the right and in a closer view.\nObjects: [giraffe, giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.609, 0.398, 0.836, 0.820]\ngiraffe: [0.312, 0.477, 0.570, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000244411",
    "conversations": [
      {
        "from": "human",
        "value": "Two cows in a field, one cow is slightly to the right of the other cow."
      },
      {
        "from": "gpt",
        "value": "cow: [0.547, 0.328, 0.773, 0.664]\ncow: [0.117, 0.352, 0.375, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000244411_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two cows in a field, one cow is slightly to the right of the other cow.\nObjects: [cow, cow]"
      },
      {
        "from": "gpt",
        "value": "cow: [0.547, 0.328, 0.773, 0.664]\ncow: [0.117, 0.352, 0.375, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000245320",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding on the right side of the image, above the skateboard which is on a ramp."
      },
      {
        "from": "gpt",
        "value": "person: [0.445, 0.141, 0.766, 0.453]\nskateboard: [0.516, 0.422, 0.695, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000245320_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding on the right side of the image, above the skateboard which is on a ramp.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.445, 0.141, 0.766, 0.453]\nskateboard: [0.516, 0.422, 0.695, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000245320_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teen red red skateboarder is red skateboarding on the right side of the image, above the red skateboard which is on a ramp."
      },
      {
        "from": "gpt",
        "value": "teen red skateboarder: [0.445, 0.141, 0.766, 0.453]\nred skateboard: [0.516, 0.422, 0.695, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000245320_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teen red red skateboarder is red skateboarding on the right side of the image, above the red skateboard which is on a ramp.\nObjects: [teen red skateboarder, red skateboard]"
      },
      {
        "from": "gpt",
        "value": "teen red skateboarder: [0.445, 0.141, 0.766, 0.453]\nred skateboard: [0.516, 0.422, 0.695, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000245320_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.445, 0.141, 0.766, 0.453]\nskateboard: [0.516, 0.422, 0.695, 0.500]\nGiven the above layout, shift the skateboard downwards by 0.250."
      },
      {
        "from": "gpt",
        "value": "person: [0.445, 0.141, 0.766, 0.453]\nskateboard: [0.516, 0.672, 0.695, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000248334",
    "conversations": [
      {
        "from": "human",
        "value": "The boat is on the water towards the right side of the image."
      },
      {
        "from": "gpt",
        "value": "boat: [0.383, 0.250, 0.992, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000248334_key",
    "conversations": [
      {
        "from": "human",
        "value": "The boat is on the water towards the right side of the image.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.383, 0.250, 0.992, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000248334_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the sleek speedboat is on the water towards the right side of the image."
      },
      {
        "from": "gpt",
        "value": "sleek speedboat: [0.383, 0.250, 0.992, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000248334_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the sleek speedboat is on the water towards the right side of the image.\nObjects: [sleek speedboat]"
      },
      {
        "from": "gpt",
        "value": "sleek speedboat: [0.383, 0.250, 0.992, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000248334_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.383, 0.250, 0.992, 0.695]\nGiven the above layout, shift the boat to the left by 0.125."
      },
      {
        "from": "gpt",
        "value": "boat: [0.258, 0.250, 0.867, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000248631",
    "conversations": [
      {
        "from": "human",
        "value": "A laptop is positioned to the left, and a mouse is connected to the right side of the laptop."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.008, 0.266, 0.664, 0.797]\nmouse: [0.711, 0.547, 0.961, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000248631_key",
    "conversations": [
      {
        "from": "human",
        "value": "A laptop is positioned to the left, and a mouse is connected to the right side of the laptop.\nObjects: [laptop, mouse]"
      },
      {
        "from": "gpt",
        "value": "laptop: [0.008, 0.266, 0.664, 0.797]\nmouse: [0.711, 0.547, 0.961, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000249025",
    "conversations": [
      {
        "from": "human",
        "value": "The vase is at the center with a rose inside it."
      },
      {
        "from": "gpt",
        "value": "vase: [0.320, 0.391, 0.695, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000249025_key",
    "conversations": [
      {
        "from": "human",
        "value": "The vase is at the center with a rose inside it.\nObjects: [vase]"
      },
      {
        "from": "gpt",
        "value": "vase: [0.320, 0.391, 0.695, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000249025_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain vase with intricate design is at the center with a rose inside it."
      },
      {
        "from": "gpt",
        "value": "porcelain vase with intricate design: [0.320, 0.391, 0.695, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000249025_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain vase with intricate design is at the center with a rose inside it.\nObjects: [porcelain vase with intricate design]"
      },
      {
        "from": "gpt",
        "value": "porcelain vase with intricate design: [0.320, 0.391, 0.695, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000249025_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: vase: [0.320, 0.391, 0.695, 0.883]\nGiven the above layout, shift the vase upwards by 0.320."
      },
      {
        "from": "gpt",
        "value": "vase: [0.320, 0.070, 0.695, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000249550",
    "conversations": [
      {
        "from": "human",
        "value": "A potted plant is on a small round table to the right of the bed."
      },
      {
        "from": "gpt",
        "value": "bed: [0.172, 0.320, 0.578, 0.984]\npotted plant: [0.625, 0.352, 0.789, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000249550_key",
    "conversations": [
      {
        "from": "human",
        "value": "A potted plant is on a small round table to the right of the bed.\nObjects: [bed, potted plant]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.172, 0.320, 0.578, 0.984]\npotted plant: [0.625, 0.352, 0.789, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000249550_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a succulent in a clay pot is on a small round table to the right of the king-sized bed with white sheets."
      },
      {
        "from": "gpt",
        "value": "king-sized bed with white sheets: [0.172, 0.320, 0.578, 0.984]\nsucculent in a clay pot: [0.625, 0.352, 0.789, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000249550_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a succulent in a clay pot is on a small round table to the right of the king-sized bed with white sheets.\nObjects: [king-sized bed with white sheets, succulent in a clay pot]"
      },
      {
        "from": "gpt",
        "value": "king-sized bed with white sheets: [0.172, 0.320, 0.578, 0.984]\nsucculent in a clay pot: [0.625, 0.352, 0.789, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000249550_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.172, 0.320, 0.578, 0.984]\npotted plant: [0.625, 0.352, 0.789, 0.586]\nGiven the above layout, shift the bed upwards by 0.258."
      },
      {
        "from": "gpt",
        "value": "bed: [0.172, 0.062, 0.578, 0.727]\npotted plant: [0.625, 0.352, 0.789, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000250619",
    "conversations": [
      {
        "from": "human",
        "value": "A person is lying down under an umbrella at the center of the image."
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.312, 0.289, 0.758, 0.656]\nperson: [0.406, 0.586, 0.703, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000250619_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is lying down under an umbrella at the center of the image.\nObjects: [umbrella, person]"
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.312, 0.289, 0.758, 0.656]\nperson: [0.406, 0.586, 0.703, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000250619_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a sun-bathing individual is lying down under an rainbow-colored parasol at the center of the image."
      },
      {
        "from": "gpt",
        "value": "rainbow-colored parasol: [0.312, 0.289, 0.758, 0.656]\nsun-bathing individual: [0.406, 0.586, 0.703, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000250619_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a sun-bathing individual is lying down under an rainbow-colored parasol at the center of the image.\nObjects: [rainbow-colored parasol, sun-bathing individual]"
      },
      {
        "from": "gpt",
        "value": "rainbow-colored parasol: [0.312, 0.289, 0.758, 0.656]\nsun-bathing individual: [0.406, 0.586, 0.703, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000250619_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: umbrella: [0.312, 0.289, 0.758, 0.656]\nperson: [0.406, 0.586, 0.703, 0.688]\nGiven the above layout, shift the umbrella to the left by 0.094."
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.219, 0.289, 0.664, 0.656]\nperson: [0.406, 0.586, 0.703, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000253002",
    "conversations": [
      {
        "from": "human",
        "value": "The image shows a red bus with a logo at the center."
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.164, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000253002_key",
    "conversations": [
      {
        "from": "human",
        "value": "The image shows a red bus with a logo at the center.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.164, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000253002_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the image shows a red double-decker city bus with a logo at the center."
      },
      {
        "from": "gpt",
        "value": "double-decker city bus: [0.000, 0.164, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000253002_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the image shows a red double-decker city bus with a logo at the center.\nObjects: [double-decker city bus]"
      },
      {
        "from": "gpt",
        "value": "double-decker city bus: [0.000, 0.164, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000253002_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.000, 0.164, 0.992, 0.820]\nGiven the above layout, shift the bus downwards by 0.164."
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.328, 0.992, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000253819",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the air above a skateboard on the ground."
      },
      {
        "from": "gpt",
        "value": "person: [0.305, 0.172, 0.734, 0.664]\nskateboard: [0.469, 0.531, 0.633, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000253819_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the air above a skateboard on the ground.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.305, 0.172, 0.734, 0.664]\nskateboard: [0.469, 0.531, 0.633, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000253819_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager is in the air above a green skateboard on the ground."
      },
      {
        "from": "gpt",
        "value": "teenager: [0.305, 0.172, 0.734, 0.664]\ngreen skateboard: [0.469, 0.531, 0.633, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000253819_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager is in the air above a green skateboard on the ground.\nObjects: [teenager, green skateboard]"
      },
      {
        "from": "gpt",
        "value": "teenager: [0.305, 0.172, 0.734, 0.664]\ngreen skateboard: [0.469, 0.531, 0.633, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000253819_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.305, 0.172, 0.734, 0.664]\nskateboard: [0.469, 0.531, 0.633, 0.695]\nGiven the above layout, shift the person to the left by 0.297."
      },
      {
        "from": "gpt",
        "value": "person: [0.008, 0.172, 0.438, 0.664]\nskateboard: [0.469, 0.531, 0.633, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000255664",
    "conversations": [
      {
        "from": "human",
        "value": "The dog is in the center of the image, jumping up towards the left side."
      },
      {
        "from": "gpt",
        "value": "dog: [0.188, 0.203, 0.641, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000255664_key",
    "conversations": [
      {
        "from": "human",
        "value": "The dog is in the center of the image, jumping up towards the left side.\nObjects: [dog]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.188, 0.203, 0.641, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000255664_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the golden retriever puppy is in the center of the image, jumping up towards the left side."
      },
      {
        "from": "gpt",
        "value": "golden retriever puppy: [0.188, 0.203, 0.641, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000255664_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the golden retriever puppy is in the center of the image, jumping up towards the left side.\nObjects: [golden retriever puppy]"
      },
      {
        "from": "gpt",
        "value": "golden retriever puppy: [0.188, 0.203, 0.641, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000255664_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.188, 0.203, 0.641, 0.797]\nGiven the above layout, shift the dog to the right by 0.234."
      },
      {
        "from": "gpt",
        "value": "dog: [0.422, 0.203, 0.875, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000255718",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is at the center of the image."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.281, 0.086, 0.727, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000255718_key",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is at the center of the image.\nObjects: [fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.281, 0.086, 0.727, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000255718_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the ornate street lamp is at the center of the image."
      },
      {
        "from": "gpt",
        "value": "ornate street lamp: [0.281, 0.086, 0.727, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000255718_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the ornate street lamp is at the center of the image.\nObjects: [ornate street lamp]"
      },
      {
        "from": "gpt",
        "value": "ornate street lamp: [0.281, 0.086, 0.727, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000255718_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: fire hydrant: [0.281, 0.086, 0.727, 0.945]\nGiven the above layout, shift the fire hydrant to the left by 0.086."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.195, 0.086, 0.641, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000255965",
    "conversations": [
      {
        "from": "human",
        "value": "The cat is sitting to the right, against a brick wall looking towards the camera."
      },
      {
        "from": "gpt",
        "value": "cat: [0.000, 0.391, 0.852, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000255965_key",
    "conversations": [
      {
        "from": "human",
        "value": "The cat is sitting to the right, against a brick wall looking towards the camera.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.000, 0.391, 0.852, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000255965_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the tuxedo kitten is sitting to the right, against a brick wall looking towards the camera."
      },
      {
        "from": "gpt",
        "value": "tuxedo kitten: [0.000, 0.391, 0.852, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000255965_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the tuxedo kitten is sitting to the right, against a brick wall looking towards the camera.\nObjects: [tuxedo kitten]"
      },
      {
        "from": "gpt",
        "value": "tuxedo kitten: [0.000, 0.391, 0.852, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000255965_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.000, 0.391, 0.852, 0.781]\nGiven the above layout, shift the cat upwards by 0.383."
      },
      {
        "from": "gpt",
        "value": "cat: [0.000, 0.008, 0.852, 0.398]"
      }
    ]
  },
  {
    "id": "coco_000000256195",
    "conversations": [
      {
        "from": "human",
        "value": "A red train with the number 746 turning slightly to the right on the railway track."
      },
      {
        "from": "gpt",
        "value": "train: [0.156, 0.258, 0.875, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000256195_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red train with the number 746 turning slightly to the right on the railway track.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.156, 0.258, 0.875, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000256195_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red blue locomotive with number 858 with the number 746 turning slightly to the right on the railway track."
      },
      {
        "from": "gpt",
        "value": "blue locomotive with number 858: [0.156, 0.258, 0.875, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000256195_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red blue locomotive with number 858 with the number 746 turning slightly to the right on the railway track.\nObjects: [blue locomotive with number 858]"
      },
      {
        "from": "gpt",
        "value": "blue locomotive with number 858: [0.156, 0.258, 0.875, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000256195_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.156, 0.258, 0.875, 0.766]\nGiven the above layout, shift the train upwards by 0.102."
      },
      {
        "from": "gpt",
        "value": "train: [0.156, 0.156, 0.875, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000271457",
    "conversations": [
      {
        "from": "human",
        "value": "A bench is at the bottom right corner, partially obscured by tall grass."
      },
      {
        "from": "gpt",
        "value": "bench: [0.328, 0.578, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000271457_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bench is at the bottom right corner, partially obscured by tall grass.\nObjects: [bench]"
      },
      {
        "from": "gpt",
        "value": "bench: [0.328, 0.578, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000271457_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a old wooden bench is at the bottom right corner, partially obscured by tall grass."
      },
      {
        "from": "gpt",
        "value": "old wooden bench: [0.328, 0.578, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000271457_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a old wooden bench is at the bottom right corner, partially obscured by tall grass.\nObjects: [old wooden bench]"
      },
      {
        "from": "gpt",
        "value": "old wooden bench: [0.328, 0.578, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000271457_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bench: [0.328, 0.578, 0.992, 0.820]\nGiven the above layout, shift the bench upwards by 0.500."
      },
      {
        "from": "gpt",
        "value": "bench: [0.328, 0.078, 0.992, 0.320]"
      }
    ]
  },
  {
    "id": "coco_000000272136",
    "conversations": [
      {
        "from": "human",
        "value": "A close-up view of an airplane fuselage with the cockpit to the left and the tail to the right."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.008, 0.242, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000272136_key",
    "conversations": [
      {
        "from": "human",
        "value": "A close-up view of an airplane fuselage with the cockpit to the left and the tail to the right.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.008, 0.242, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000272136_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a close-up view of an Boeing 747 jetliner fuselage with the cockpit to the left and the tail to the right."
      },
      {
        "from": "gpt",
        "value": "Boeing 747 jetliner: [0.008, 0.242, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000272136_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a close-up view of an Boeing 747 jetliner fuselage with the cockpit to the left and the tail to the right.\nObjects: [Boeing 747 jetliner]"
      },
      {
        "from": "gpt",
        "value": "Boeing 747 jetliner: [0.008, 0.242, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000272136_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.008, 0.242, 0.992, 0.820]\nGiven the above layout, shift the airplane upwards by 0.219."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.008, 0.023, 0.992, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000272566",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the right sitting beside a pile of apples at the center."
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.289, 0.586, 0.625]\napple: [0.117, 0.625, 0.461, 0.781]\nperson: [0.523, 0.344, 0.617, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000272566_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the right sitting beside a pile of apples at the center.\nObjects: [person, apple, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.289, 0.586, 0.625]\napple: [0.117, 0.625, 0.461, 0.781]\nperson: [0.523, 0.344, 0.617, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000273712",
    "conversations": [
      {
        "from": "human",
        "value": "A black refrigerator is standing on the left side of the image, near a doorway."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.125, 0.125, 0.609, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000273712_key",
    "conversations": [
      {
        "from": "human",
        "value": "A black refrigerator is standing on the left side of the image, near a doorway.\nObjects: [refrigerator]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.125, 0.125, 0.609, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000273712_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a black stainless steel refrigerator is standing on the left side of the image, near a doorway."
      },
      {
        "from": "gpt",
        "value": "stainless steel refrigerator: [0.125, 0.125, 0.609, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000273712_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a black stainless steel refrigerator is standing on the left side of the image, near a doorway.\nObjects: [stainless steel refrigerator]"
      },
      {
        "from": "gpt",
        "value": "stainless steel refrigerator: [0.125, 0.125, 0.609, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000273712_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: refrigerator: [0.125, 0.125, 0.609, 0.930]\nGiven the above layout, shift the refrigerator to the right by 0.148."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.273, 0.125, 0.758, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000274272",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left of a bus, which is behind a car."
      },
      {
        "from": "gpt",
        "value": "bus: [0.281, 0.430, 0.992, 0.867]\ncar: [0.039, 0.719, 0.336, 0.859]\nperson: [0.672, 0.578, 0.750, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000274272_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left of a bus, which is behind a car.\nObjects: [bus, car, person]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.281, 0.430, 0.992, 0.867]\ncar: [0.039, 0.719, 0.336, 0.859]\nperson: [0.672, 0.578, 0.750, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000276284",
    "conversations": [
      {
        "from": "human",
        "value": "The motorcycle is parked diagonally in the center of a parking space."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.367, 0.352, 0.805, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000276284_key",
    "conversations": [
      {
        "from": "human",
        "value": "The motorcycle is parked diagonally in the center of a parking space.\nObjects: [motorcycle]"
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.367, 0.352, 0.805, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000276284_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the cherry red motorcycle is parked diagonally in the center of a parking space."
      },
      {
        "from": "gpt",
        "value": "cherry red motorcycle: [0.367, 0.352, 0.805, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000276284_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the cherry red motorcycle is parked diagonally in the center of a parking space.\nObjects: [cherry red motorcycle]"
      },
      {
        "from": "gpt",
        "value": "cherry red motorcycle: [0.367, 0.352, 0.805, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000276284_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: motorcycle: [0.367, 0.352, 0.805, 0.781]\nGiven the above layout, shift the motorcycle to the left by 0.164."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.203, 0.352, 0.641, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000278973",
    "conversations": [
      {
        "from": "human",
        "value": "A person is lying on a surfboard in the center of the image, amidst the waves."
      },
      {
        "from": "gpt",
        "value": "person: [0.125, 0.320, 0.430, 0.625]\nsurfboard: [0.234, 0.570, 0.453, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000278973_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is lying on a surfboard in the center of the image, amidst the waves.\nObjects: [person, surfboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.125, 0.320, 0.430, 0.625]\nsurfboard: [0.234, 0.570, 0.453, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000281032",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in front of an oven, using it."
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.250, 0.875, 0.820]\noven: [0.000, 0.688, 0.477, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000281032_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in front of an oven, using it.\nObjects: [person, oven]"
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.250, 0.875, 0.820]\noven: [0.000, 0.688, 0.477, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000281032_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a chef is standing in front of an commercial kitchen oven, using it."
      },
      {
        "from": "gpt",
        "value": "chef: [0.328, 0.250, 0.875, 0.820]\ncommercial kitchen oven: [0.000, 0.688, 0.477, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000281032_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a chef is standing in front of an commercial kitchen oven, using it.\nObjects: [chef, commercial kitchen oven]"
      },
      {
        "from": "gpt",
        "value": "chef: [0.328, 0.250, 0.875, 0.820]\ncommercial kitchen oven: [0.000, 0.688, 0.477, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000281032_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.328, 0.250, 0.875, 0.820]\noven: [0.000, 0.688, 0.477, 0.820]\nGiven the above layout, shift the person upwards by 0.109."
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.141, 0.875, 0.711]\noven: [0.000, 0.688, 0.477, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000281759",
    "conversations": [
      {
        "from": "human",
        "value": "From left to right: first person, second person, third person, fourth person, all standing in a row."
      },
      {
        "from": "gpt",
        "value": "person: [0.148, 0.320, 0.312, 0.789]\nperson: [0.594, 0.383, 0.727, 0.812]\nperson: [0.320, 0.367, 0.438, 0.797]\nperson: [0.461, 0.391, 0.586, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000281759_key",
    "conversations": [
      {
        "from": "human",
        "value": "From left to right: first person, second person, third person, fourth person, all standing in a row.\nObjects: [person, person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.148, 0.320, 0.312, 0.789]\nperson: [0.594, 0.383, 0.727, 0.812]\nperson: [0.320, 0.367, 0.438, 0.797]\nperson: [0.461, 0.391, 0.586, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000282037",
    "conversations": [
      {
        "from": "human",
        "value": "A person is pitching a baseball towards another person who is waiting to catch it."
      },
      {
        "from": "gpt",
        "value": "person: [0.656, 0.453, 0.992, 0.844]\nperson: [0.195, 0.281, 0.305, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000282037_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is pitching a baseball towards another person who is waiting to catch it.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.656, 0.453, 0.992, 0.844]\nperson: [0.195, 0.281, 0.305, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000282296",
    "conversations": [
      {
        "from": "human",
        "value": "A vintage-style refrigerator is standing at the center of the image."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.258, 0.086, 0.680, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000282296_key",
    "conversations": [
      {
        "from": "human",
        "value": "A vintage-style refrigerator is standing at the center of the image.\nObjects: [refrigerator]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.258, 0.086, 0.680, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000282296_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a vintage-style antique wooden fridge is standing at the center of the image."
      },
      {
        "from": "gpt",
        "value": "antique wooden fridge: [0.258, 0.086, 0.680, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000282296_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a vintage-style antique wooden fridge is standing at the center of the image.\nObjects: [antique wooden fridge]"
      },
      {
        "from": "gpt",
        "value": "antique wooden fridge: [0.258, 0.086, 0.680, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000282296_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: refrigerator: [0.258, 0.086, 0.680, 0.852]\nGiven the above layout, shift the refrigerator to the right by 0.156."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.414, 0.086, 0.836, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000282912",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe's head and neck are at the center-right of the image, extending diagonally towards the bottom left, with the face slightly turned towards the camera."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.125, 0.180, 0.812, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000282912_key",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffes head and neck are at the center-right of the image, extending diagonally towards the bottom left, with the face slightly turned towards the camera.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.125, 0.180, 0.812, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000282912_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the towering giraffe's head and neck are at the center-right of the image, extending diagonally towards the bottom left, with the face slightly turned towards the camera."
      },
      {
        "from": "gpt",
        "value": "towering giraffe: [0.125, 0.180, 0.812, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000282912_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the towering giraffes head and neck are at the center-right of the image, extending diagonally towards the bottom left, with the face slightly turned towards the camera.\nObjects: [towering giraffe]"
      },
      {
        "from": "gpt",
        "value": "towering giraffe: [0.125, 0.180, 0.812, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000282912_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.125, 0.180, 0.812, 0.984]\nGiven the above layout, shift the giraffe upwards by 0.094."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.125, 0.086, 0.812, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000283038",
    "conversations": [
      {
        "from": "human",
        "value": "A stop sign is positioned in the foreground slightly to the right of the center."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.227, 0.242, 0.672, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000283038_key",
    "conversations": [
      {
        "from": "human",
        "value": "A stop sign is positioned in the foreground slightly to the right of the center.\nObjects: [stop sign]"
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.227, 0.242, 0.672, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000283038_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a shiny red stop sign is positioned in the foreground slightly to the right of the center."
      },
      {
        "from": "gpt",
        "value": "shiny red stop sign: [0.227, 0.242, 0.672, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000283038_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a shiny red stop sign is positioned in the foreground slightly to the right of the center.\nObjects: [shiny red stop sign]"
      },
      {
        "from": "gpt",
        "value": "shiny red stop sign: [0.227, 0.242, 0.672, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000283038_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: stop sign: [0.227, 0.242, 0.672, 0.727]\nGiven the above layout, shift the stop sign to the right by 0.102."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.328, 0.242, 0.773, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000283412",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is lying on a bed with a cup to the left side of the dog."
      },
      {
        "from": "gpt",
        "value": "dog: [0.000, 0.172, 0.680, 0.812]\nbed: [0.664, 0.320, 0.992, 0.570]\ncup: [0.000, 0.602, 0.211, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000283412_key",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is lying on a bed with a cup to the left side of the dog.\nObjects: [dog, bed, cup]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.000, 0.172, 0.680, 0.812]\nbed: [0.664, 0.320, 0.992, 0.570]\ncup: [0.000, 0.602, 0.211, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000283412_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a sleeping poodle is lying on a comfy king-sized bed with a white coffee cup to the left side of the sleeping poodle."
      },
      {
        "from": "gpt",
        "value": "sleeping poodle: [0.000, 0.172, 0.680, 0.812]\ncomfy king-sized bed: [0.664, 0.320, 0.992, 0.570]\nwhite coffee cup: [0.000, 0.602, 0.211, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000283412_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a sleeping poodle is lying on a comfy king-sized bed with a white coffee cup to the left side of the sleeping poodle.\nObjects: [sleeping poodle, comfy king-sized bed, white coffee cup]"
      },
      {
        "from": "gpt",
        "value": "sleeping poodle: [0.000, 0.172, 0.680, 0.812]\ncomfy king-sized bed: [0.664, 0.320, 0.992, 0.570]\nwhite coffee cup: [0.000, 0.602, 0.211, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000283412_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.000, 0.172, 0.680, 0.812]\nbed: [0.664, 0.320, 0.992, 0.570]\ncup: [0.000, 0.602, 0.211, 0.828]\nGiven the above layout, shift the dog upwards by 0.156."
      },
      {
        "from": "gpt",
        "value": "dog: [0.000, 0.016, 0.680, 0.656]\nbed: [0.664, 0.320, 0.992, 0.570]\ncup: [0.000, 0.602, 0.211, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000292488",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center facing away from the viewer, holding up a mobile phone with the right hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.109, 0.273, 0.656, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000292488_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center facing away from the viewer, holding up a mobile phone with the right hand.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.109, 0.273, 0.656, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000292488_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman is standing in the center facing away from the viewer, holding up a mobile phone with the right hand."
      },
      {
        "from": "gpt",
        "value": "young woman: [0.109, 0.273, 0.656, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000292488_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman is standing in the center facing away from the viewer, holding up a mobile phone with the right hand.\nObjects: [young woman]"
      },
      {
        "from": "gpt",
        "value": "young woman: [0.109, 0.273, 0.656, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000292488_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.109, 0.273, 0.656, 0.828]\nGiven the above layout, shift the person to the right by 0.078."
      },
      {
        "from": "gpt",
        "value": "person: [0.188, 0.273, 0.734, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000294162",
    "conversations": [
      {
        "from": "human",
        "value": "A white laptop is center on a dark surface, and a white mouse is to the right of the laptop."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.203, 0.117, 0.727, 0.703]\nmouse: [0.648, 0.641, 0.852, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000294162_key",
    "conversations": [
      {
        "from": "human",
        "value": "A white laptop is center on a dark surface, and a white mouse is to the right of the laptop.\nObjects: [laptop, mouse]"
      },
      {
        "from": "gpt",
        "value": "laptop: [0.203, 0.117, 0.727, 0.703]\nmouse: [0.648, 0.641, 0.852, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000294162_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a white black sketchbook is center on a dark surface, and a white silver mouse is to the right of the black sketchbook."
      },
      {
        "from": "gpt",
        "value": "black sketchbook: [0.203, 0.117, 0.727, 0.703]\nsilver mouse: [0.648, 0.641, 0.852, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000294162_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a white black sketchbook is center on a dark surface, and a white silver mouse is to the right of the black sketchbook.\nObjects: [black sketchbook, silver mouse]"
      },
      {
        "from": "gpt",
        "value": "black sketchbook: [0.203, 0.117, 0.727, 0.703]\nsilver mouse: [0.648, 0.641, 0.852, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000294162_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: laptop: [0.203, 0.117, 0.727, 0.703]\nmouse: [0.648, 0.641, 0.852, 0.828]\nGiven the above layout, shift the laptop to the left by 0.039."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.164, 0.117, 0.688, 0.703]\nmouse: [0.648, 0.641, 0.852, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000294783",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is at the center of the image with pillows on it."
      },
      {
        "from": "gpt",
        "value": "bed: [0.031, 0.617, 0.469, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000294783_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is at the center of the image with pillows on it.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.031, 0.617, 0.469, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000294783_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the king-sized bed is at the center of the image with pillows on it."
      },
      {
        "from": "gpt",
        "value": "king-sized bed: [0.031, 0.617, 0.469, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000294783_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the king-sized bed is at the center of the image with pillows on it.\nObjects: [king-sized bed]"
      },
      {
        "from": "gpt",
        "value": "king-sized bed: [0.031, 0.617, 0.469, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000294783_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.031, 0.617, 0.469, 0.820]\nGiven the above layout, shift the bed upwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "bed: [0.031, 0.547, 0.469, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000295138",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding, balancing on the edge of the skateboard which is at the bottom center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.250, 0.172, 0.602, 0.703]\nskateboard: [0.258, 0.680, 0.602, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000295138_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding, balancing on the edge of the skateboard which is at the bottom center of the image.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.250, 0.172, 0.602, 0.703]\nskateboard: [0.258, 0.680, 0.602, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000295138_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage boy is black and white skateboarding, balancing on the edge of the black and white skateboard which is at the bottom center of the image."
      },
      {
        "from": "gpt",
        "value": "teenage boy: [0.250, 0.172, 0.602, 0.703]\nblack and white skateboard: [0.258, 0.680, 0.602, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000295138_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage boy is black and white skateboarding, balancing on the edge of the black and white skateboard which is at the bottom center of the image.\nObjects: [teenage boy, black and white skateboard]"
      },
      {
        "from": "gpt",
        "value": "teenage boy: [0.250, 0.172, 0.602, 0.703]\nblack and white skateboard: [0.258, 0.680, 0.602, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000295138_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.250, 0.172, 0.602, 0.703]\nskateboard: [0.258, 0.680, 0.602, 0.742]\nGiven the above layout, shift the person to the right by 0.039."
      },
      {
        "from": "gpt",
        "value": "person: [0.289, 0.172, 0.641, 0.703]\nskateboard: [0.258, 0.680, 0.602, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000295809",
    "conversations": [
      {
        "from": "human",
        "value": "A bicycle symbol painted on the road at the center."
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.195, 0.555, 0.719, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000295809_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bicycle symbol painted on the road at the center.\nObjects: [bicycle]"
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.195, 0.555, 0.719, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000295809_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a blue road bike symbol painted on the road at the center."
      },
      {
        "from": "gpt",
        "value": "blue road bike: [0.195, 0.555, 0.719, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000295809_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a blue road bike symbol painted on the road at the center.\nObjects: [blue road bike]"
      },
      {
        "from": "gpt",
        "value": "blue road bike: [0.195, 0.555, 0.719, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000295809_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bicycle: [0.195, 0.555, 0.719, 0.867]\nGiven the above layout, shift the bicycle upwards by 0.250."
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.195, 0.305, 0.719, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000296231",
    "conversations": [
      {
        "from": "human",
        "value": "A television is situated at the center of the image on a stand, with a chair to the right of the television."
      },
      {
        "from": "gpt",
        "value": "tv: [0.250, 0.484, 0.539, 0.844]\nchair: [0.891, 0.594, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000296231_key",
    "conversations": [
      {
        "from": "human",
        "value": "A television is situated at the center of the image on a stand, with a chair to the right of the television.\nObjects: [tv, chair]"
      },
      {
        "from": "gpt",
        "value": "tv: [0.250, 0.484, 0.539, 0.844]\nchair: [0.891, 0.594, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000296231_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a television is situated at the center of the image on a stand, with a wooden dining chair to the right of the television."
      },
      {
        "from": "gpt",
        "value": "flat screen television: [0.250, 0.484, 0.539, 0.844]\nwooden dining chair: [0.891, 0.594, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000296231_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a television is situated at the center of the image on a stand, with a wooden dining chair to the right of the television.\nObjects: [flat screen television, wooden dining chair]"
      },
      {
        "from": "gpt",
        "value": "flat screen television: [0.250, 0.484, 0.539, 0.844]\nwooden dining chair: [0.891, 0.594, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000296231_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: tv: [0.250, 0.484, 0.539, 0.844]\nchair: [0.891, 0.594, 0.992, 0.867]\nGiven the above layout, shift the tv upwards by 0.086."
      },
      {
        "from": "gpt",
        "value": "tv: [0.250, 0.398, 0.539, 0.758]\nchair: [0.891, 0.594, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000297343",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is positioned to the left of the image, slanted against a pale wall."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.094, 0.398, 0.383, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000297343_key",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is positioned to the left of the image, slanted against a pale wall.\nObjects: [stop sign]"
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.094, 0.398, 0.383, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000297343_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red octagonal stop sign is positioned to the left of the image, slanted against a pale wall."
      },
      {
        "from": "gpt",
        "value": "red octagonal stop sign: [0.094, 0.398, 0.383, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000297343_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red octagonal stop sign is positioned to the left of the image, slanted against a pale wall.\nObjects: [red octagonal stop sign]"
      },
      {
        "from": "gpt",
        "value": "red octagonal stop sign: [0.094, 0.398, 0.383, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000297343_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: stop sign: [0.094, 0.398, 0.383, 0.695]\nGiven the above layout, shift the stop sign to the right by 0.078."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.172, 0.398, 0.461, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000300155",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is perched on a branch in the center of the image, with outstretched tail feathers."
      },
      {
        "from": "gpt",
        "value": "bird: [0.430, 0.406, 0.711, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000300155_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is perched on a branch in the center of the image, with outstretched tail feathers.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.430, 0.406, 0.711, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000300155_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a stunning peacock is perched on a branch in the center of the image, with outstretched tail feathers."
      },
      {
        "from": "gpt",
        "value": "stunning peacock: [0.430, 0.406, 0.711, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000300155_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a stunning peacock is perched on a branch in the center of the image, with outstretched tail feathers.\nObjects: [stunning peacock]"
      },
      {
        "from": "gpt",
        "value": "stunning peacock: [0.430, 0.406, 0.711, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000300155_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.430, 0.406, 0.711, 0.711]\nGiven the above layout, shift the bird to the left by 0.102."
      },
      {
        "from": "gpt",
        "value": "bird: [0.328, 0.406, 0.609, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000300842",
    "conversations": [
      {
        "from": "human",
        "value": "A skateboard at the bottom center of the image with blue wheels and an orange deck, captured in motion."
      },
      {
        "from": "gpt",
        "value": "skateboard: [0.250, 0.383, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000300842_key",
    "conversations": [
      {
        "from": "human",
        "value": "A skateboard at the bottom center of the image with blue wheels and an orange deck, captured in motion.\nObjects: [skateboard]"
      },
      {
        "from": "gpt",
        "value": "skateboard: [0.250, 0.383, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000300842_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red surfboard at the bottom center of the image with blue wheels and an orange deck, captured in motion."
      },
      {
        "from": "gpt",
        "value": "red surfboard: [0.250, 0.383, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000300842_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red surfboard at the bottom center of the image with blue wheels and an orange deck, captured in motion.\nObjects: [red surfboard]"
      },
      {
        "from": "gpt",
        "value": "red surfboard: [0.250, 0.383, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000300842_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: skateboard: [0.250, 0.383, 0.992, 0.727]\nGiven the above layout, shift the skateboard upwards by 0.336."
      },
      {
        "from": "gpt",
        "value": "skateboard: [0.250, 0.047, 0.992, 0.391]"
      }
    ]
  },
  {
    "id": "coco_000000301421",
    "conversations": [
      {
        "from": "human",
        "value": "A laptop sits on a table to the right of a TV, with a chair in front of the laptop and another chair to the left of the table."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.383, 0.602, 0.773, 0.812]\nchair: [0.008, 0.609, 0.281, 0.820]\ntv: [0.438, 0.250, 0.672, 0.445]\nchair: [0.867, 0.469, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000301421_key",
    "conversations": [
      {
        "from": "human",
        "value": "A laptop sits on a table to the right of a TV, with a chair in front of the laptop and another chair to the left of the table.\nObjects: [laptop, chair, tv, chair]"
      },
      {
        "from": "gpt",
        "value": "laptop: [0.383, 0.602, 0.773, 0.812]\nchair: [0.008, 0.609, 0.281, 0.820]\ntv: [0.438, 0.250, 0.672, 0.445]\nchair: [0.867, 0.469, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000301563",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the center of the image skiing downhill with skis attached to their feet."
      },
      {
        "from": "gpt",
        "value": "person: [0.336, 0.289, 0.578, 0.625]\nskis: [0.406, 0.594, 0.648, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000301563_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the center of the image skiing downhill with skis attached to their feet.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.336, 0.289, 0.578, 0.625]\nskis: [0.406, 0.594, 0.648, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000301563_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a skiing enthusiast in the center of the image skiing downhill with professional racing skis attached to their feet."
      },
      {
        "from": "gpt",
        "value": "skiing enthusiast: [0.336, 0.289, 0.578, 0.625]\nprofessional racing skis: [0.406, 0.594, 0.648, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000301563_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a skiing enthusiast in the center of the image skiing downhill with professional racing skis attached to their feet.\nObjects: [skiing enthusiast, professional racing skis]"
      },
      {
        "from": "gpt",
        "value": "skiing enthusiast: [0.336, 0.289, 0.578, 0.625]\nprofessional racing skis: [0.406, 0.594, 0.648, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000301563_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.336, 0.289, 0.578, 0.625]\nskis: [0.406, 0.594, 0.648, 0.648]\nGiven the above layout, shift the skis to the right by 0.086."
      },
      {
        "from": "gpt",
        "value": "person: [0.336, 0.289, 0.578, 0.625]\nskis: [0.492, 0.594, 0.734, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000301981",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe is at the center, bending its neck towards the right."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.289, 0.312, 0.852, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000301981_key",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe is at the center, bending its neck towards the right.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.289, 0.312, 0.852, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000301981_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the tall ostrich is at the center, bending its neck towards the right."
      },
      {
        "from": "gpt",
        "value": "tall ostrich: [0.289, 0.312, 0.852, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000301981_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the tall ostrich is at the center, bending its neck towards the right.\nObjects: [tall ostrich]"
      },
      {
        "from": "gpt",
        "value": "tall ostrich: [0.289, 0.312, 0.852, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000301981_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.289, 0.312, 0.852, 0.727]\nGiven the above layout, shift the giraffe upwards by 0.062."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.289, 0.250, 0.852, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000302452",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe is at the center, behind a wooden fence, with a person on either side of the giraffe, all facing towards the giraffe."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.328, 0.258, 0.664, 0.992]\nperson: [0.766, 0.414, 0.961, 0.641]\nperson: [0.000, 0.438, 0.133, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000302452_key",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe is at the center, behind a wooden fence, with a person on either side of the giraffe, all facing towards the giraffe.\nObjects: [giraffe, person, person]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.328, 0.258, 0.664, 0.992]\nperson: [0.766, 0.414, 0.961, 0.641]\nperson: [0.000, 0.438, 0.133, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000314294",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant stands to the right of a tree in the center of the image."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.453, 0.352, 0.750, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000314294_key",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant stands to the right of a tree in the center of the image.\nObjects: [elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.453, 0.352, 0.750, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000314294_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an towering African elephant stands to the right of a tree in the center of the image."
      },
      {
        "from": "gpt",
        "value": "towering African elephant: [0.453, 0.352, 0.750, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000314294_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an towering African elephant stands to the right of a tree in the center of the image.\nObjects: [towering African elephant]"
      },
      {
        "from": "gpt",
        "value": "towering African elephant: [0.453, 0.352, 0.750, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000314294_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: elephant: [0.453, 0.352, 0.750, 0.602]\nGiven the above layout, shift the elephant to the left by 0.023."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.430, 0.352, 0.727, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000315257",
    "conversations": [
      {
        "from": "human",
        "value": "A bird with its wings spread is landing on a blue bowl at the center of the image."
      },
      {
        "from": "gpt",
        "value": "bird: [0.102, 0.273, 0.859, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000315257_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bird with its wings spread is landing on a blue bowl at the center of the image.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.102, 0.273, 0.859, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000315257_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a graceful sparrow with its wings spread is landing on a blue bowl at the center of the image."
      },
      {
        "from": "gpt",
        "value": "a graceful sparrow: [0.102, 0.273, 0.859, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000315257_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a graceful sparrow with its wings spread is landing on a blue bowl at the center of the image.\nObjects: [a graceful sparrow]"
      },
      {
        "from": "gpt",
        "value": "a graceful sparrow: [0.102, 0.273, 0.859, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000315257_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.102, 0.273, 0.859, 0.711]\nGiven the above layout, shift the bird downwards by 0.227."
      },
      {
        "from": "gpt",
        "value": "bird: [0.102, 0.500, 0.859, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000316015",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is sitting in front of a keyboard, and a TV is visible in the background behind the cat."
      },
      {
        "from": "gpt",
        "value": "cat: [0.609, 0.430, 0.914, 0.828]\ntv: [0.258, 0.266, 0.656, 0.523]\nkeyboard: [0.250, 0.562, 0.648, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000316015_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is sitting in front of a keyboard, and a TV is visible in the background behind the cat.\nObjects: [cat, tv, keyboard]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.609, 0.430, 0.914, 0.828]\ntv: [0.258, 0.266, 0.656, 0.523]\nkeyboard: [0.250, 0.562, 0.648, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000316015_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a Persian cat is sitting in front of a black computer keyboard, and a large flat-screen TV is visible in the background behind the Persian cat."
      },
      {
        "from": "gpt",
        "value": "Persian cat: [0.609, 0.430, 0.914, 0.828]\nlarge flat-screen TV: [0.258, 0.266, 0.656, 0.523]\nblack computer keyboard: [0.250, 0.562, 0.648, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000316015_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a Persian cat is sitting in front of a black computer keyboard, and a large flat-screen TV is visible in the background behind the Persian cat.\nObjects: [Persian cat, large flat-screen TV, black computer keyboard]"
      },
      {
        "from": "gpt",
        "value": "Persian cat: [0.609, 0.430, 0.914, 0.828]\nlarge flat-screen TV: [0.258, 0.266, 0.656, 0.523]\nblack computer keyboard: [0.250, 0.562, 0.648, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000316015_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.609, 0.430, 0.914, 0.828]\ntv: [0.258, 0.266, 0.656, 0.523]\nkeyboard: [0.250, 0.562, 0.648, 0.727]\nGiven the above layout, shift the tv upwards by 0.250."
      },
      {
        "from": "gpt",
        "value": "cat: [0.609, 0.430, 0.914, 0.828]\ntv: [0.258, 0.016, 0.656, 0.273]\nkeyboard: [0.250, 0.562, 0.648, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000317024",
    "conversations": [
      {
        "from": "human",
        "value": "The zebra is standing in the center of the image facing to the right."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.148, 0.156, 0.875, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000317024_key",
    "conversations": [
      {
        "from": "human",
        "value": "The zebra is standing in the center of the image facing to the right.\nObjects: [zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.148, 0.156, 0.875, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000317024_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the playful Dalmatian is standing in the center of the image facing to the right."
      },
      {
        "from": "gpt",
        "value": "playful Dalmatian: [0.148, 0.156, 0.875, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000317024_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the playful Dalmatian is standing in the center of the image facing to the right.\nObjects: [playful Dalmatian]"
      },
      {
        "from": "gpt",
        "value": "playful Dalmatian: [0.148, 0.156, 0.875, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000317024_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: zebra: [0.148, 0.156, 0.875, 0.844]\nGiven the above layout, shift the zebra upwards by 0.016."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.148, 0.141, 0.875, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000318455",
    "conversations": [
      {
        "from": "human",
        "value": "A cake is placed on a dining table at the center."
      },
      {
        "from": "gpt",
        "value": "dining table: [0.008, 0.375, 0.992, 0.859]\ncake: [0.617, 0.398, 0.812, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000318455_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cake is placed on a dining table at the center.\nObjects: [dining table, cake]"
      },
      {
        "from": "gpt",
        "value": "dining table: [0.008, 0.375, 0.992, 0.859]\ncake: [0.617, 0.398, 0.812, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000318455_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a creamy vanilla cake is placed on a mahogany dining table at the center."
      },
      {
        "from": "gpt",
        "value": "mahogany dining table: [0.008, 0.375, 0.992, 0.859]\ncreamy vanilla cake: [0.617, 0.398, 0.812, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000318455_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a creamy vanilla cake is placed on a mahogany dining table at the center.\nObjects: [mahogany dining table, creamy vanilla cake]"
      },
      {
        "from": "gpt",
        "value": "mahogany dining table: [0.008, 0.375, 0.992, 0.859]\ncreamy vanilla cake: [0.617, 0.398, 0.812, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000318455_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dining table: [0.008, 0.375, 0.992, 0.859]\ncake: [0.617, 0.398, 0.812, 0.547]\nGiven the above layout, shift the dining table upwards by 0.117."
      },
      {
        "from": "gpt",
        "value": "dining table: [0.008, 0.258, 0.992, 0.742]\ncake: [0.617, 0.398, 0.812, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000318908",
    "conversations": [
      {
        "from": "human",
        "value": "There is no information provided about the dog's layout in the image. Would you like a description of the dog instead?"
      },
      {
        "from": "gpt",
        "value": "dog: [0.188, 0.164, 0.766, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000318908_key",
    "conversations": [
      {
        "from": "human",
        "value": "There is no information provided about the dogs layout in the image. Would you like a description of the dog instead?\nObjects: [dog]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.188, 0.164, 0.766, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000318908_aug",
    "conversations": [
      {
        "from": "human",
        "value": "there is no information provided about the large German Shepherd's layout in the image. would you like a description of the large German Shepherd instead?"
      },
      {
        "from": "gpt",
        "value": "large German Shepherd: [0.188, 0.164, 0.766, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000318908_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "there is no information provided about the large German Shepherds layout in the image. would you like a description of the large German Shepherd instead?\nObjects: [large German Shepherd]"
      },
      {
        "from": "gpt",
        "value": "large German Shepherd: [0.188, 0.164, 0.766, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000318908_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.188, 0.164, 0.766, 0.734]\nGiven the above layout, shift the dog downwards by 0.188."
      },
      {
        "from": "gpt",
        "value": "dog: [0.188, 0.352, 0.766, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000320490",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center, swinging a baseball bat to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.484, 0.477, 0.727, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000320490_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center, swinging a baseball bat to the right.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.484, 0.477, 0.727, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000320490_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a boy in a baseball uniform is standing in the center, swinging a baseball bat to the right."
      },
      {
        "from": "gpt",
        "value": "a boy in a baseball uniform: [0.484, 0.477, 0.727, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000320490_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a boy in a baseball uniform is standing in the center, swinging a baseball bat to the right.\nObjects: [a boy in a baseball uniform]"
      },
      {
        "from": "gpt",
        "value": "a boy in a baseball uniform: [0.484, 0.477, 0.727, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000320490_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.484, 0.477, 0.727, 0.828]\nGiven the above layout, shift the person to the left by 0.398."
      },
      {
        "from": "gpt",
        "value": "person: [0.086, 0.477, 0.328, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000321887",
    "conversations": [
      {
        "from": "human",
        "value": "The sheep is positioned to the left side of the image, facing towards the right."
      },
      {
        "from": "gpt",
        "value": "sheep: [0.000, 0.234, 0.750, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000321887_key",
    "conversations": [
      {
        "from": "human",
        "value": "The sheep is positioned to the left side of the image, facing towards the right.\nObjects: [sheep]"
      },
      {
        "from": "gpt",
        "value": "sheep: [0.000, 0.234, 0.750, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000321887_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the fluffy white goat is positioned to the left side of the image, facing towards the right."
      },
      {
        "from": "gpt",
        "value": "fluffy white goat: [0.000, 0.234, 0.750, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000321887_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the fluffy white goat is positioned to the left side of the image, facing towards the right.\nObjects: [fluffy white goat]"
      },
      {
        "from": "gpt",
        "value": "fluffy white goat: [0.000, 0.234, 0.750, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000321887_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sheep: [0.000, 0.234, 0.750, 0.820]\nGiven the above layout, shift the sheep to the right by 0.117."
      },
      {
        "from": "gpt",
        "value": "sheep: [0.117, 0.234, 0.867, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000323751",
    "conversations": [
      {
        "from": "human",
        "value": "A train is approaching on the railroad tracks, slightly bending to the right as it enters the station."
      },
      {
        "from": "gpt",
        "value": "train: [0.188, 0.344, 0.750, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000323751_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is approaching on the railroad tracks, slightly bending to the right as it enters the station.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.188, 0.344, 0.750, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000323751_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a silver streamliner is approaching on the railroad tracks, slightly bending to the right as it enters the station."
      },
      {
        "from": "gpt",
        "value": "silver streamliner: [0.188, 0.344, 0.750, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000323751_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a silver streamliner is approaching on the railroad tracks, slightly bending to the right as it enters the station.\nObjects: [silver streamliner]"
      },
      {
        "from": "gpt",
        "value": "silver streamliner: [0.188, 0.344, 0.750, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000323751_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.188, 0.344, 0.750, 0.742]\nGiven the above layout, shift the train upwards by 0.148."
      },
      {
        "from": "gpt",
        "value": "train: [0.188, 0.195, 0.750, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000323828",
    "conversations": [
      {
        "from": "human",
        "value": "The train is coming towards the foreground down the center of multiple parallel train tracks."
      },
      {
        "from": "gpt",
        "value": "train: [0.383, 0.109, 0.641, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000323828_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is coming towards the foreground down the center of multiple parallel train tracks.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.383, 0.109, 0.641, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000323828_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the vintage steam locomotive is coming towards the foreground down the center of multiple parallel vintage steam locomotive tracks."
      },
      {
        "from": "gpt",
        "value": "vintage steam locomotive: [0.383, 0.109, 0.641, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000323828_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the vintage steam locomotive is coming towards the foreground down the center of multiple parallel vintage steam locomotive tracks.\nObjects: [vintage steam locomotive]"
      },
      {
        "from": "gpt",
        "value": "vintage steam locomotive: [0.383, 0.109, 0.641, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000323828_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.383, 0.109, 0.641, 0.867]\nGiven the above layout, shift the train to the left by 0.219."
      },
      {
        "from": "gpt",
        "value": "train: [0.164, 0.109, 0.422, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000324614",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on the right side of the image with their right arm raised holding a pen."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.281, 0.555, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000324614_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on the right side of the image with their right arm raised holding a pen.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.281, 0.555, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000324614_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a adult woman is sitting on the right side of the image with their right arm raised holding a pen."
      },
      {
        "from": "gpt",
        "value": "adult woman: [0.000, 0.281, 0.555, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000324614_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a adult woman is sitting on the right side of the image with their right arm raised holding a pen.\nObjects: [adult woman]"
      },
      {
        "from": "gpt",
        "value": "adult woman: [0.000, 0.281, 0.555, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000324614_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.000, 0.281, 0.555, 0.828]\nGiven the above layout, shift the person to the right by 0.195."
      },
      {
        "from": "gpt",
        "value": "person: [0.195, 0.281, 0.750, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000324818",
    "conversations": [
      {
        "from": "human",
        "value": "Two birds are perched on a branch, one to the left of the other."
      },
      {
        "from": "gpt",
        "value": "bird: [0.305, 0.344, 0.578, 0.820]\nbird: [0.609, 0.375, 0.812, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000324818_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two birds are perched on a branch, one to the left of the other.\nObjects: [bird, bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.305, 0.344, 0.578, 0.820]\nbird: [0.609, 0.375, 0.812, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000325031",
    "conversations": [
      {
        "from": "human",
        "value": "The elephant is in the center of the image with intricate designs covering its body."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.117, 0.125, 0.883, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000325031_key",
    "conversations": [
      {
        "from": "human",
        "value": "The elephant is in the center of the image with intricate designs covering its body.\nObjects: [elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.117, 0.125, 0.883, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000325031_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the decorated elephant is in the center of the image with intricate designs covering its body."
      },
      {
        "from": "gpt",
        "value": "decorated elephant: [0.117, 0.125, 0.883, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000325031_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the decorated elephant is in the center of the image with intricate designs covering its body.\nObjects: [decorated elephant]"
      },
      {
        "from": "gpt",
        "value": "decorated elephant: [0.117, 0.125, 0.883, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000325031_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: elephant: [0.117, 0.125, 0.883, 0.875]\nGiven the above layout, shift the elephant upwards by 0.016."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.117, 0.109, 0.883, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000325306",
    "conversations": [
      {
        "from": "human",
        "value": "One zebra is facing the camera with its head turned toward the second zebra, which is positioned behind the first and facing away."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.195, 0.164, 0.781, 0.859]\nzebra: [0.922, 0.289, 0.984, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000325306_key",
    "conversations": [
      {
        "from": "human",
        "value": "One zebra is facing the camera with its head turned toward the second zebra, which is positioned behind the first and facing away.\nObjects: [zebra, zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.195, 0.164, 0.781, 0.859]\nzebra: [0.922, 0.289, 0.984, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000343453",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center of the image wearing a blue jacket and green pants, with skis on their feet and poles beside them on the ground."
      },
      {
        "from": "gpt",
        "value": "person: [0.391, 0.211, 0.680, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000343453_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center of the image wearing a blue jacket and green pants, with skis on their feet and poles beside them on the ground.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.391, 0.211, 0.680, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000343453_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall skier in winter attire is standing in the center of the image wearing a blue jacket and green pants, with skis on their feet and poles beside them on the ground."
      },
      {
        "from": "gpt",
        "value": "tall skier in winter attire: [0.391, 0.211, 0.680, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000343453_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall skier in winter attire is standing in the center of the image wearing a blue jacket and green pants, with skis on their feet and poles beside them on the ground.\nObjects: [tall skier in winter attire]"
      },
      {
        "from": "gpt",
        "value": "tall skier in winter attire: [0.391, 0.211, 0.680, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000343453_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.391, 0.211, 0.680, 0.859]\nGiven the above layout, shift the person to the left by 0.219."
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.211, 0.461, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000343803",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center of the image with their body slightly bent forward and arms outstretched as if they are throwing something."
      },
      {
        "from": "gpt",
        "value": "person: [0.195, 0.211, 0.680, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000343803_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center of the image with their body slightly bent forward and arms outstretched as if they are throwing something.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.195, 0.211, 0.680, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000343803_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a athlete throwing a discus is standing in the center of the image with their body slightly bent forward and arms outstretched as if they are throwing something."
      },
      {
        "from": "gpt",
        "value": "athlete throwing a discus: [0.195, 0.211, 0.680, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000343803_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a athlete throwing a discus is standing in the center of the image with their body slightly bent forward and arms outstretched as if they are throwing something.\nObjects: [athlete throwing a discus]"
      },
      {
        "from": "gpt",
        "value": "athlete throwing a discus: [0.195, 0.211, 0.680, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000343803_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.195, 0.211, 0.680, 0.945]\nGiven the above layout, shift the person to the right by 0.281."
      },
      {
        "from": "gpt",
        "value": "person: [0.477, 0.211, 0.961, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000343934",
    "conversations": [
      {
        "from": "human",
        "value": "A blue motorcycle is parked at the center, angled to the left, against a wall with graffiti."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.273, 0.398, 0.766, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000343934_key",
    "conversations": [
      {
        "from": "human",
        "value": "A blue motorcycle is parked at the center, angled to the left, against a wall with graffiti.\nObjects: [motorcycle]"
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.273, 0.398, 0.766, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000343934_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a blue ruby red scooter is parked at the center, angled to the left, against a wall with graffiti."
      },
      {
        "from": "gpt",
        "value": "ruby red scooter: [0.273, 0.398, 0.766, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000343934_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a blue ruby red scooter is parked at the center, angled to the left, against a wall with graffiti.\nObjects: [ruby red scooter]"
      },
      {
        "from": "gpt",
        "value": "ruby red scooter: [0.273, 0.398, 0.766, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000343934_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: motorcycle: [0.273, 0.398, 0.766, 0.766]\nGiven the above layout, shift the motorcycle upwards by 0.242."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.273, 0.156, 0.766, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000343937",
    "conversations": [
      {
        "from": "human",
        "value": "A person is snowboarding down a slope, positioned toward the bottom right of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.430, 0.188, 0.633, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000343937_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is snowboarding down a slope, positioned toward the bottom right of the image.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.430, 0.188, 0.633, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000343937_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a snowboarder with a blue jacket is snowboarding down a slope, positioned toward the bottom right of the image."
      },
      {
        "from": "gpt",
        "value": "snowboarder with a blue jacket: [0.430, 0.188, 0.633, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000343937_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a snowboarder with a blue jacket is snowboarding down a slope, positioned toward the bottom right of the image.\nObjects: [snowboarder with a blue jacket]"
      },
      {
        "from": "gpt",
        "value": "snowboarder with a blue jacket: [0.430, 0.188, 0.633, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000343937_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.430, 0.188, 0.633, 0.797]\nGiven the above layout, shift the person to the left by 0.055."
      },
      {
        "from": "gpt",
        "value": "person: [0.375, 0.188, 0.578, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000344909",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is in the center of the image."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.297, 0.008, 0.852, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000344909_key",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is in the center of the image.\nObjects: [fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.297, 0.008, 0.852, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000344909_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red and white striped fire hydrant is in the center of the image."
      },
      {
        "from": "gpt",
        "value": "red and white striped fire hydrant: [0.297, 0.008, 0.852, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000344909_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red and white striped fire hydrant is in the center of the image.\nObjects: [red and white striped fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "red and white striped fire hydrant: [0.297, 0.008, 0.852, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000344909_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: fire hydrant: [0.297, 0.008, 0.852, 0.977]\nGiven the above layout, shift the fire hydrant to the left by 0.141."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.156, 0.008, 0.711, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000347163",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is in the center foreground of the image."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.102, 0.227, 0.602, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000347163_key",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is in the center foreground of the image.\nObjects: [stop sign]"
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.102, 0.227, 0.602, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000347163_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red and white stop sign is in the center foreground of the image."
      },
      {
        "from": "gpt",
        "value": "red and white stop sign: [0.102, 0.227, 0.602, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000347163_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red and white stop sign is in the center foreground of the image.\nObjects: [red and white stop sign]"
      },
      {
        "from": "gpt",
        "value": "red and white stop sign: [0.102, 0.227, 0.602, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000347163_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: stop sign: [0.102, 0.227, 0.602, 0.719]\nGiven the above layout, shift the stop sign to the right by 0.211."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.312, 0.227, 0.812, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000348012",
    "conversations": [
      {
        "from": "human",
        "value": "The scissors are placed on top of the tape, with the blades slightly open and pointing to the right."
      },
      {
        "from": "gpt",
        "value": "scissors: [0.000, 0.172, 0.992, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000348012_key",
    "conversations": [
      {
        "from": "human",
        "value": "The scissors are placed on top of the tape, with the blades slightly open and pointing to the right.\nObjects: [scissors]"
      },
      {
        "from": "gpt",
        "value": "scissors: [0.000, 0.172, 0.992, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000348012_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the shiny metallic scissors are placed on top of the tape, with the blades slightly open and pointing to the right."
      },
      {
        "from": "gpt",
        "value": "shiny metallic scissors: [0.000, 0.172, 0.992, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000348012_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the shiny metallic scissors are placed on top of the tape, with the blades slightly open and pointing to the right.\nObjects: [shiny metallic scissors]"
      },
      {
        "from": "gpt",
        "value": "shiny metallic scissors: [0.000, 0.172, 0.992, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000348012_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: scissors: [0.000, 0.172, 0.992, 0.555]\nGiven the above layout, shift the scissors downwards by 0.289."
      },
      {
        "from": "gpt",
        "value": "scissors: [0.000, 0.461, 0.992, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000350488",
    "conversations": [
      {
        "from": "human",
        "value": "A zebra is standing in the center of the image, grazing on grass."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.172, 0.328, 0.594, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000350488_key",
    "conversations": [
      {
        "from": "human",
        "value": "A zebra is standing in the center of the image, grazing on grass.\nObjects: [zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.172, 0.328, 0.594, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000350488_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a wild-striped horse is standing in the center of the image, grazing on grass."
      },
      {
        "from": "gpt",
        "value": "wild-striped horse: [0.172, 0.328, 0.594, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000350488_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a wild-striped horse is standing in the center of the image, grazing on grass.\nObjects: [wild-striped horse]"
      },
      {
        "from": "gpt",
        "value": "wild-striped horse: [0.172, 0.328, 0.594, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000350488_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: zebra: [0.172, 0.328, 0.594, 0.742]\nGiven the above layout, shift the zebra to the right by 0.180."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.352, 0.328, 0.773, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000352584",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is against the wall, to the right of the image, behind a red rope barrier."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.188, 0.031, 0.742, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000352584_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is against the wall, to the right of the image, behind a red rope barrier.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.188, 0.031, 0.742, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000352584_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the antique ceramic toilet is against the wall, to the right of the image, behind a red rope barrier."
      },
      {
        "from": "gpt",
        "value": "antique ceramic toilet: [0.188, 0.031, 0.742, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000352584_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the antique ceramic toilet is against the wall, to the right of the image, behind a red rope barrier.\nObjects: [antique ceramic toilet]"
      },
      {
        "from": "gpt",
        "value": "antique ceramic toilet: [0.188, 0.031, 0.742, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000352584_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.188, 0.031, 0.742, 0.953]\nGiven the above layout, shift the toilet to the right by 0.094."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.281, 0.031, 0.836, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000354829",
    "conversations": [
      {
        "from": "human",
        "value": "The car is parked on a street with its side facing the viewpoint."
      },
      {
        "from": "gpt",
        "value": "car: [0.164, 0.289, 0.734, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000354829_key",
    "conversations": [
      {
        "from": "human",
        "value": "The car is parked on a street with its side facing the viewpoint.\nObjects: [car]"
      },
      {
        "from": "gpt",
        "value": "car: [0.164, 0.289, 0.734, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000354829_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red convertible is parked on a street with its side facing the viewpoint."
      },
      {
        "from": "gpt",
        "value": "red convertible: [0.164, 0.289, 0.734, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000354829_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red convertible is parked on a street with its side facing the viewpoint.\nObjects: [red convertible]"
      },
      {
        "from": "gpt",
        "value": "red convertible: [0.164, 0.289, 0.734, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000354829_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: car: [0.164, 0.289, 0.734, 0.594]\nGiven the above layout, shift the car downwards by 0.117."
      },
      {
        "from": "gpt",
        "value": "car: [0.164, 0.406, 0.734, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000355817",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is on the right side of the image, angled slightly towards the left."
      },
      {
        "from": "gpt",
        "value": "bus: [0.203, 0.328, 0.977, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000355817_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is on the right side of the image, angled slightly towards the left.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.203, 0.328, 0.977, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000355817_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the large city bus is on the right side of the image, angled slightly towards the left."
      },
      {
        "from": "gpt",
        "value": "large city bus: [0.203, 0.328, 0.977, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000355817_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the large city bus is on the right side of the image, angled slightly towards the left.\nObjects: [large city bus]"
      },
      {
        "from": "gpt",
        "value": "large city bus: [0.203, 0.328, 0.977, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000355817_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.203, 0.328, 0.977, 0.641]\nGiven the above layout, shift the bus downwards by 0.352."
      },
      {
        "from": "gpt",
        "value": "bus: [0.203, 0.680, 0.977, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000355905",
    "conversations": [
      {
        "from": "human",
        "value": "A white dog walking on a beach to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "dog: [0.133, 0.227, 0.836, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000355905_key",
    "conversations": [
      {
        "from": "human",
        "value": "A white dog walking on a beach to the right side of the image.\nObjects: [dog]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.133, 0.227, 0.836, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000355905_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a white white Labrador Retriever walking on a beach to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "white Labrador Retriever: [0.133, 0.227, 0.836, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000355905_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a white white Labrador Retriever walking on a beach to the right side of the image.\nObjects: [white Labrador Retriever]"
      },
      {
        "from": "gpt",
        "value": "white Labrador Retriever: [0.133, 0.227, 0.836, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000355905_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.133, 0.227, 0.836, 0.844]\nGiven the above layout, shift the dog upwards by 0.180."
      },
      {
        "from": "gpt",
        "value": "dog: [0.133, 0.047, 0.836, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000356427",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing to the left of a backpack on the ground."
      },
      {
        "from": "gpt",
        "value": "person: [0.250, 0.266, 0.461, 0.820]\nbackpack: [0.430, 0.680, 0.562, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000356427_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing to the left of a backpack on the ground.\nObjects: [person, backpack]"
      },
      {
        "from": "gpt",
        "value": "person: [0.250, 0.266, 0.461, 0.820]\nbackpack: [0.430, 0.680, 0.562, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000356427_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman standing to the left of a small brown leather backpack on the ground."
      },
      {
        "from": "gpt",
        "value": "young woman: [0.250, 0.266, 0.461, 0.820]\nsmall brown leather backpack: [0.430, 0.680, 0.562, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000356427_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman standing to the left of a small brown leather backpack on the ground.\nObjects: [young woman, small brown leather backpack]"
      },
      {
        "from": "gpt",
        "value": "young woman: [0.250, 0.266, 0.461, 0.820]\nsmall brown leather backpack: [0.430, 0.680, 0.562, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000356427_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.250, 0.266, 0.461, 0.820]\nbackpack: [0.430, 0.680, 0.562, 0.828]\nGiven the above layout, shift the backpack to the right by 0.398."
      },
      {
        "from": "gpt",
        "value": "person: [0.250, 0.266, 0.461, 0.820]\nbackpack: [0.828, 0.680, 0.961, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000370818",
    "conversations": [
      {
        "from": "human",
        "value": "The sink is at the bottom right corner of the image."
      },
      {
        "from": "gpt",
        "value": "sink: [0.461, 0.703, 0.859, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000370818_key",
    "conversations": [
      {
        "from": "human",
        "value": "The sink is at the bottom right corner of the image.\nObjects: [sink]"
      },
      {
        "from": "gpt",
        "value": "sink: [0.461, 0.703, 0.859, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000370818_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the modern stainless steel sink is at the bottom right corner of the image."
      },
      {
        "from": "gpt",
        "value": "modern stainless steel sink: [0.461, 0.703, 0.859, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000370818_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the modern stainless steel sink is at the bottom right corner of the image.\nObjects: [modern stainless steel sink]"
      },
      {
        "from": "gpt",
        "value": "modern stainless steel sink: [0.461, 0.703, 0.859, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000370818_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sink: [0.461, 0.703, 0.859, 0.906]\nGiven the above layout, shift the sink upwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "sink: [0.461, 0.633, 0.859, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000371699",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting at the dining table on the left, and a dog is lying on the floor to the right of the table."
      },
      {
        "from": "gpt",
        "value": "dining table: [0.555, 0.430, 0.867, 0.820]\ndog: [0.586, 0.836, 0.742, 0.992]\nperson: [0.125, 0.383, 0.227, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000371699_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting at the dining table on the left, and a dog is lying on the floor to the right of the table.\nObjects: [dining table, dog, person]"
      },
      {
        "from": "gpt",
        "value": "dining table: [0.555, 0.430, 0.867, 0.820]\ndog: [0.586, 0.836, 0.742, 0.992]\nperson: [0.125, 0.383, 0.227, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000372317",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is parked on the side of the street facing the right."
      },
      {
        "from": "gpt",
        "value": "bus: [0.055, 0.289, 0.906, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000372317_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is parked on the side of the street facing the right.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.055, 0.289, 0.906, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000372317_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker bus is parked on the side of the street facing the right."
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.055, 0.289, 0.906, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000372317_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker bus is parked on the side of the street facing the right.\nObjects: [double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.055, 0.289, 0.906, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000372317_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.055, 0.289, 0.906, 0.578]\nGiven the above layout, shift the bus downwards by 0.055."
      },
      {
        "from": "gpt",
        "value": "bus: [0.055, 0.344, 0.906, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000374551",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is perched on a branch toward the right side of the image."
      },
      {
        "from": "gpt",
        "value": "bird: [0.055, 0.344, 0.781, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000374551_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is perched on a branch toward the right side of the image.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.055, 0.344, 0.781, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000374551_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a small parakeet is perched on a branch toward the right side of the image."
      },
      {
        "from": "gpt",
        "value": "small parakeet: [0.055, 0.344, 0.781, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000374551_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a small parakeet is perched on a branch toward the right side of the image.\nObjects: [small parakeet]"
      },
      {
        "from": "gpt",
        "value": "small parakeet: [0.055, 0.344, 0.781, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000374551_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.055, 0.344, 0.781, 0.625]\nGiven the above layout, shift the bird downwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "bird: [0.055, 0.367, 0.781, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000375493",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing to the left of a fire hydrant."
      },
      {
        "from": "gpt",
        "value": "person: [0.391, 0.164, 0.594, 0.859]\nfire hydrant: [0.531, 0.578, 0.656, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000375493_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing to the left of a fire hydrant.\nObjects: [person, fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "person: [0.391, 0.164, 0.594, 0.859]\nfire hydrant: [0.531, 0.578, 0.656, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000375493_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall passer-by standing to the left of a red fire hydrant."
      },
      {
        "from": "gpt",
        "value": "tall passer-by: [0.391, 0.164, 0.594, 0.859]\nred fire hydrant: [0.531, 0.578, 0.656, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000375493_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall passer-by standing to the left of a red fire hydrant.\nObjects: [tall passer-by, red fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "tall passer-by: [0.391, 0.164, 0.594, 0.859]\nred fire hydrant: [0.531, 0.578, 0.656, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000375493_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.391, 0.164, 0.594, 0.859]\nfire hydrant: [0.531, 0.578, 0.656, 0.820]\nGiven the above layout, shift the person to the left by 0.078."
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.164, 0.516, 0.859]\nfire hydrant: [0.531, 0.578, 0.656, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000376278",
    "conversations": [
      {
        "from": "human",
        "value": "One zebra is lying on the ground in the foreground, while two other zebras are standing in the background, one partially obscured by the other."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.062, 0.289, 0.953, 0.672]\nzebra: [0.719, 0.312, 0.992, 0.445]\nzebra: [0.930, 0.188, 0.992, 0.359]"
      }
    ]
  },
  {
    "id": "coco_000000376278_key",
    "conversations": [
      {
        "from": "human",
        "value": "One zebra is lying on the ground in the foreground, while two other zebras are standing in the background, one partially obscured by the other.\nObjects: [zebra, zebra, zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.062, 0.289, 0.953, 0.672]\nzebra: [0.719, 0.312, 0.992, 0.445]\nzebra: [0.930, 0.188, 0.992, 0.359]"
      }
    ]
  },
  {
    "id": "coco_000000377000",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is sitting on the left side, gazing out of a window with its back facing us."
      },
      {
        "from": "gpt",
        "value": "cat: [0.086, 0.055, 0.578, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000377000_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is sitting on the left side, gazing out of a window with its back facing us.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.086, 0.055, 0.578, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000377000_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a Siamese cat is sitting on the left side, gazing out of a window with its back facing us."
      },
      {
        "from": "gpt",
        "value": "Siamese cat: [0.086, 0.055, 0.578, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000377000_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a Siamese cat is sitting on the left side, gazing out of a window with its back facing us.\nObjects: [Siamese cat]"
      },
      {
        "from": "gpt",
        "value": "Siamese cat: [0.086, 0.055, 0.578, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000377000_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.086, 0.055, 0.578, 0.867]\nGiven the above layout, shift the cat to the right by 0.320."
      },
      {
        "from": "gpt",
        "value": "cat: [0.406, 0.055, 0.898, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000378116",
    "conversations": [
      {
        "from": "human",
        "value": "A person is surfing on a wave at the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.500, 0.297, 0.766, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000378116_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is surfing on a wave at the center of the image.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.500, 0.297, 0.766, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000378116_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young surfer is surfing on a wave at the center of the image."
      },
      {
        "from": "gpt",
        "value": "young surfer: [0.500, 0.297, 0.766, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000378116_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young surfer is surfing on a wave at the center of the image.\nObjects: [young surfer]"
      },
      {
        "from": "gpt",
        "value": "young surfer: [0.500, 0.297, 0.766, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000378116_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.500, 0.297, 0.766, 0.570]\nGiven the above layout, shift the person to the left by 0.320."
      },
      {
        "from": "gpt",
        "value": "person: [0.180, 0.297, 0.445, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000378454",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the air, above the beach, leaning towards the right, with their left foot extended towards a frisbee."
      },
      {
        "from": "gpt",
        "value": "person: [0.242, 0.344, 0.625, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000378454_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the air, above the beach, leaning towards the right, with their left foot extended towards a frisbee.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.242, 0.344, 0.625, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000378454_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young athlete is in the air, above the beach, leaning towards the right, with their left foot extended towards a frisbee."
      },
      {
        "from": "gpt",
        "value": "young athlete: [0.242, 0.344, 0.625, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000378454_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young athlete is in the air, above the beach, leaning towards the right, with their left foot extended towards a frisbee.\nObjects: [young athlete]"
      },
      {
        "from": "gpt",
        "value": "young athlete: [0.242, 0.344, 0.625, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000378454_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.242, 0.344, 0.625, 0.562]\nGiven the above layout, shift the person downwards by 0.133."
      },
      {
        "from": "gpt",
        "value": "person: [0.242, 0.477, 0.625, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000378673",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding mid-air to the right of the center of the image at a skatepark."
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.234, 0.641, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000378673_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding mid-air to the right of the center of the image at a skatepark.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.234, 0.641, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000378673_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young skateboarder is skateboarding mid-air to the right of the center of the image at a skatepark."
      },
      {
        "from": "gpt",
        "value": "young skateboarder: [0.367, 0.234, 0.641, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000378673_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young skateboarder is skateboarding mid-air to the right of the center of the image at a skatepark.\nObjects: [young skateboarder]"
      },
      {
        "from": "gpt",
        "value": "young skateboarder: [0.367, 0.234, 0.641, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000378673_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.367, 0.234, 0.641, 0.586]\nGiven the above layout, shift the person downwards by 0.078."
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.312, 0.641, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000379441",
    "conversations": [
      {
        "from": "human",
        "value": "A couch is on the right side of the image, and a bench is to the left of the couch."
      },
      {
        "from": "gpt",
        "value": "couch: [0.523, 0.562, 0.875, 0.852]\nbench: [0.039, 0.656, 0.391, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000379441_key",
    "conversations": [
      {
        "from": "human",
        "value": "A couch is on the right side of the image, and a bench is to the left of the couch.\nObjects: [couch, bench]"
      },
      {
        "from": "gpt",
        "value": "couch: [0.523, 0.562, 0.875, 0.852]\nbench: [0.039, 0.656, 0.391, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000379441_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a vintage leather couch is on the right side of the image, and a wooden garden bench is to the left of the vintage leather couch."
      },
      {
        "from": "gpt",
        "value": "vintage leather couch: [0.523, 0.562, 0.875, 0.852]\nwooden garden bench: [0.039, 0.656, 0.391, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000379441_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a vintage leather couch is on the right side of the image, and a wooden garden bench is to the left of the vintage leather couch.\nObjects: [vintage leather couch, wooden garden bench]"
      },
      {
        "from": "gpt",
        "value": "vintage leather couch: [0.523, 0.562, 0.875, 0.852]\nwooden garden bench: [0.039, 0.656, 0.391, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000379441_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: couch: [0.523, 0.562, 0.875, 0.852]\nbench: [0.039, 0.656, 0.391, 0.867]\nGiven the above layout, shift the couch upwards by 0.094."
      },
      {
        "from": "gpt",
        "value": "couch: [0.523, 0.469, 0.875, 0.758]\nbench: [0.039, 0.656, 0.391, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000379453",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying at the center of the image against a clear blue sky."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.258, 0.281, 0.797, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000379453_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying at the center of the image against a clear blue sky.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.258, 0.281, 0.797, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000379453_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an commercial jet is flying at the center of the image against a clear blue sky."
      },
      {
        "from": "gpt",
        "value": "commercial jet: [0.258, 0.281, 0.797, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000379453_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an commercial jet is flying at the center of the image against a clear blue sky.\nObjects: [commercial jet]"
      },
      {
        "from": "gpt",
        "value": "commercial jet: [0.258, 0.281, 0.797, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000379453_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.258, 0.281, 0.797, 0.703]\nGiven the above layout, shift the airplane downwards by 0.062."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.258, 0.344, 0.797, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000379533",
    "conversations": [
      {
        "from": "human",
        "value": "A zebra in the foreground on the right, with an elephant in the background on the left."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.398, 0.617, 0.852, 0.859]\nelephant: [0.203, 0.344, 0.406, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000379533_key",
    "conversations": [
      {
        "from": "human",
        "value": "A zebra in the foreground on the right, with an elephant in the background on the left.\nObjects: [zebra, elephant]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.398, 0.617, 0.852, 0.859]\nelephant: [0.203, 0.344, 0.406, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000379533_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a black and white horse in the foreground on the right, with an large grey hippo in the background on the left."
      },
      {
        "from": "gpt",
        "value": "black and white horse: [0.398, 0.617, 0.852, 0.859]\nlarge grey hippo: [0.203, 0.344, 0.406, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000379533_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a black and white horse in the foreground on the right, with an large grey hippo in the background on the left.\nObjects: [black and white horse, large grey hippo]"
      },
      {
        "from": "gpt",
        "value": "black and white horse: [0.398, 0.617, 0.852, 0.859]\nlarge grey hippo: [0.203, 0.344, 0.406, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000379533_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: zebra: [0.398, 0.617, 0.852, 0.859]\nelephant: [0.203, 0.344, 0.406, 0.484]\nGiven the above layout, shift the elephant upwards by 0.109."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.398, 0.617, 0.852, 0.859]\nelephant: [0.203, 0.234, 0.406, 0.375]"
      }
    ]
  },
  {
    "id": "coco_000000398905",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center behind a keyboard."
      },
      {
        "from": "gpt",
        "value": "person: [0.336, 0.211, 0.789, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000398905_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center behind a keyboard.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.336, 0.211, 0.789, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000398905_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a woman is standing at the center behind a keyboard."
      },
      {
        "from": "gpt",
        "value": "woman: [0.336, 0.211, 0.789, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000398905_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a woman is standing at the center behind a keyboard.\nObjects: [woman]"
      },
      {
        "from": "gpt",
        "value": "woman: [0.336, 0.211, 0.789, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000398905_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.336, 0.211, 0.789, 0.734]\nGiven the above layout, shift the person to the left by 0.172."
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.211, 0.617, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000404128",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is in the center of the image, positioned on the ground facing forward."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.055, 0.391, 0.820, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000404128_key",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is in the center of the image, positioned on the ground facing forward.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.055, 0.391, 0.820, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000404128_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the commercial jetliner is in the center of the image, positioned on the ground facing forward."
      },
      {
        "from": "gpt",
        "value": "commercial jetliner: [0.055, 0.391, 0.820, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000404128_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the commercial jetliner is in the center of the image, positioned on the ground facing forward.\nObjects: [commercial jetliner]"
      },
      {
        "from": "gpt",
        "value": "commercial jetliner: [0.055, 0.391, 0.820, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000404128_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.055, 0.391, 0.820, 0.695]\nGiven the above layout, shift the airplane upwards by 0.281."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.055, 0.109, 0.820, 0.414]"
      }
    ]
  },
  {
    "id": "coco_000000404249",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing on a skateboard in the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.227, 0.188, 0.617, 0.812]\nskateboard: [0.305, 0.742, 0.516, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000404249_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing on a skateboard in the center of the image.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.227, 0.188, 0.617, 0.812]\nskateboard: [0.305, 0.742, 0.516, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000404249_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage bright graffiti-print bright graffiti-print skateboarder standing on a bright graffiti-print skateboard in the center of the image."
      },
      {
        "from": "gpt",
        "value": "teenage bright graffiti-print skateboarder: [0.227, 0.188, 0.617, 0.812]\nbright graffiti-print skateboard: [0.305, 0.742, 0.516, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000404249_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage bright graffiti-print bright graffiti-print skateboarder standing on a bright graffiti-print skateboard in the center of the image.\nObjects: [teenage bright graffiti-print skateboarder, bright graffiti-print skateboard]"
      },
      {
        "from": "gpt",
        "value": "teenage bright graffiti-print skateboarder: [0.227, 0.188, 0.617, 0.812]\nbright graffiti-print skateboard: [0.305, 0.742, 0.516, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000404249_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.227, 0.188, 0.617, 0.812]\nskateboard: [0.305, 0.742, 0.516, 0.867]\nGiven the above layout, shift the person to the right by 0.164."
      },
      {
        "from": "gpt",
        "value": "person: [0.391, 0.188, 0.781, 0.812]\nskateboard: [0.305, 0.742, 0.516, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000404805",
    "conversations": [
      {
        "from": "human",
        "value": "A person at the center holding a blue surfboard in the water."
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.383, 0.633, 0.633]\nsurfboard: [0.352, 0.570, 0.562, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000404805_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person at the center holding a blue surfboard in the water.\nObjects: [person, surfboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.383, 0.633, 0.633]\nsurfboard: [0.352, 0.570, 0.562, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000404805_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a man in a wetsuit at the center holding a blue large blue surfboard in the water."
      },
      {
        "from": "gpt",
        "value": "man in a wetsuit: [0.344, 0.383, 0.633, 0.633]\nlarge blue surfboard: [0.352, 0.570, 0.562, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000404805_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a man in a wetsuit at the center holding a blue large blue surfboard in the water.\nObjects: [man in a wetsuit, large blue surfboard]"
      },
      {
        "from": "gpt",
        "value": "man in a wetsuit: [0.344, 0.383, 0.633, 0.633]\nlarge blue surfboard: [0.352, 0.570, 0.562, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000404805_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.344, 0.383, 0.633, 0.633]\nsurfboard: [0.352, 0.570, 0.562, 0.625]\nGiven the above layout, shift the person upwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.359, 0.633, 0.609]\nsurfboard: [0.352, 0.570, 0.562, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000407002",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center wearing skis."
      },
      {
        "from": "gpt",
        "value": "person: [0.453, 0.289, 0.633, 0.891]\nskis: [0.211, 0.820, 0.695, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000407002_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center wearing skis.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.453, 0.289, 0.633, 0.891]\nskis: [0.211, 0.820, 0.695, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000407002_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a an individual in a snowsuit is standing in the center wearing a pair of blue skis."
      },
      {
        "from": "gpt",
        "value": "an individual in a snowsuit: [0.453, 0.289, 0.633, 0.891]\na pair of blue skis: [0.211, 0.820, 0.695, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000407002_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a an individual in a snowsuit is standing in the center wearing a pair of blue skis.\nObjects: [an individual in a snowsuit, a pair of blue skis]"
      },
      {
        "from": "gpt",
        "value": "an individual in a snowsuit: [0.453, 0.289, 0.633, 0.891]\na pair of blue skis: [0.211, 0.820, 0.695, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000407002_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.453, 0.289, 0.633, 0.891]\nskis: [0.211, 0.820, 0.695, 0.945]\nGiven the above layout, shift the skis to the right by 0.023."
      },
      {
        "from": "gpt",
        "value": "person: [0.453, 0.289, 0.633, 0.891]\nskis: [0.234, 0.820, 0.719, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000407403",
    "conversations": [
      {
        "from": "human",
        "value": "The vase is at the center with flowers coming out from its top."
      },
      {
        "from": "gpt",
        "value": "vase: [0.500, 0.281, 0.820, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000407403_key",
    "conversations": [
      {
        "from": "human",
        "value": "The vase is at the center with flowers coming out from its top.\nObjects: [vase]"
      },
      {
        "from": "gpt",
        "value": "vase: [0.500, 0.281, 0.820, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000407403_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the ceramic jug filled with flowers is at the center with flowers coming out from its top."
      },
      {
        "from": "gpt",
        "value": "ceramic jug filled with flowers: [0.500, 0.281, 0.820, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000407403_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the ceramic jug filled with flowers is at the center with flowers coming out from its top.\nObjects: [ceramic jug filled with flowers]"
      },
      {
        "from": "gpt",
        "value": "ceramic jug filled with flowers: [0.500, 0.281, 0.820, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000407403_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: vase: [0.500, 0.281, 0.820, 0.750]\nGiven the above layout, shift the vase to the left by 0.359."
      },
      {
        "from": "gpt",
        "value": "vase: [0.141, 0.281, 0.461, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000407518",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is perched at the center on top of a chain-link fence."
      },
      {
        "from": "gpt",
        "value": "bird: [0.578, 0.305, 0.867, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000407518_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is perched at the center on top of a chain-link fence.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.578, 0.305, 0.867, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000407518_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a little sparrow is perched at the center on top of a chain-link fence."
      },
      {
        "from": "gpt",
        "value": "little sparrow: [0.578, 0.305, 0.867, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000407518_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a little sparrow is perched at the center on top of a chain-link fence.\nObjects: [little sparrow]"
      },
      {
        "from": "gpt",
        "value": "little sparrow: [0.578, 0.305, 0.867, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000407518_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.578, 0.305, 0.867, 0.758]\nGiven the above layout, shift the bird to the left by 0.500."
      },
      {
        "from": "gpt",
        "value": "bird: [0.078, 0.305, 0.367, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000409198",
    "conversations": [
      {
        "from": "human",
        "value": "A person is running to the right while holding a frisbee."
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.227, 0.711, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000409198_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is running to the right while holding a frisbee.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.227, 0.711, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000409198_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a woman in sportswear is running to the right while holding a frisbee."
      },
      {
        "from": "gpt",
        "value": "a woman in sportswear: [0.312, 0.227, 0.711, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000409198_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a woman in sportswear is running to the right while holding a frisbee.\nObjects: [a woman in sportswear]"
      },
      {
        "from": "gpt",
        "value": "a woman in sportswear: [0.312, 0.227, 0.711, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000409198_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.312, 0.227, 0.711, 0.758]\nGiven the above layout, shift the person to the left by 0.102."
      },
      {
        "from": "gpt",
        "value": "person: [0.211, 0.227, 0.609, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000410487",
    "conversations": [
      {
        "from": "human",
        "value": "An oven door is open at the center with a tray of cookies inside."
      },
      {
        "from": "gpt",
        "value": "oven: [0.211, 0.000, 0.766, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000410487_key",
    "conversations": [
      {
        "from": "human",
        "value": "An oven door is open at the center with a tray of cookies inside.\nObjects: [oven]"
      },
      {
        "from": "gpt",
        "value": "oven: [0.211, 0.000, 0.766, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000410487_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an stainless steel oven door is open at the center with a tray of cookies inside."
      },
      {
        "from": "gpt",
        "value": "stainless steel oven: [0.211, 0.000, 0.766, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000410487_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an stainless steel oven door is open at the center with a tray of cookies inside.\nObjects: [stainless steel oven]"
      },
      {
        "from": "gpt",
        "value": "stainless steel oven: [0.211, 0.000, 0.766, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000410487_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: oven: [0.211, 0.000, 0.766, 0.578]\nGiven the above layout, shift the oven downwards by 0.297."
      },
      {
        "from": "gpt",
        "value": "oven: [0.211, 0.297, 0.766, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000412286",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center of the image, playing tennis."
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.305, 0.578, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000412286_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center of the image, playing tennis.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.305, 0.578, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000412286_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a professional tennis player is standing in the center of the image, playing tennis."
      },
      {
        "from": "gpt",
        "value": "professional tennis player: [0.320, 0.305, 0.578, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000412286_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a professional tennis player is standing in the center of the image, playing tennis.\nObjects: [professional tennis player]"
      },
      {
        "from": "gpt",
        "value": "professional tennis player: [0.320, 0.305, 0.578, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000412286_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.320, 0.305, 0.578, 0.891]\nGiven the above layout, shift the person to the right by 0.359."
      },
      {
        "from": "gpt",
        "value": "person: [0.680, 0.305, 0.938, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000415238",
    "conversations": [
      {
        "from": "human",
        "value": "A potted plant is at the center of the table, with a chair to the right of the table."
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.336, 0.141, 0.617, 0.680]\nchair: [0.352, 0.695, 0.625, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000415238_key",
    "conversations": [
      {
        "from": "human",
        "value": "A potted plant is at the center of the table, with a chair to the right of the table.\nObjects: [potted plant, chair]"
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.336, 0.141, 0.617, 0.680]\nchair: [0.352, 0.695, 0.625, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000415238_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a geranium in a clay pot is at the center of the table, with a antique oak chair to the right of the table."
      },
      {
        "from": "gpt",
        "value": "geranium in a clay pot: [0.336, 0.141, 0.617, 0.680]\nantique oak chair: [0.352, 0.695, 0.625, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000415238_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a geranium in a clay pot is at the center of the table, with a antique oak chair to the right of the table.\nObjects: [geranium in a clay pot, antique oak chair]"
      },
      {
        "from": "gpt",
        "value": "geranium in a clay pot: [0.336, 0.141, 0.617, 0.680]\nantique oak chair: [0.352, 0.695, 0.625, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000415238_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: potted plant: [0.336, 0.141, 0.617, 0.680]\nchair: [0.352, 0.695, 0.625, 0.852]\nGiven the above layout, shift the chair to the right by 0.047."
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.336, 0.141, 0.617, 0.680]\nchair: [0.398, 0.695, 0.672, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000415716",
    "conversations": [
      {
        "from": "human",
        "value": "A chair is to the right of the couch."
      },
      {
        "from": "gpt",
        "value": "chair: [0.562, 0.562, 0.852, 0.867]\ncouch: [0.000, 0.711, 0.375, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000415716_key",
    "conversations": [
      {
        "from": "human",
        "value": "A chair is to the right of the couch.\nObjects: [chair, couch]"
      },
      {
        "from": "gpt",
        "value": "chair: [0.562, 0.562, 0.852, 0.867]\ncouch: [0.000, 0.711, 0.375, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000415716_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a mahogany armchair is to the right of the velvet deep-sea blue sofa."
      },
      {
        "from": "gpt",
        "value": "mahogany armchair: [0.562, 0.562, 0.852, 0.867]\nvelvet deep-sea blue sofa: [0.000, 0.711, 0.375, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000415716_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a mahogany armchair is to the right of the velvet deep-sea blue sofa.\nObjects: [mahogany armchair, velvet deep-sea blue sofa]"
      },
      {
        "from": "gpt",
        "value": "mahogany armchair: [0.562, 0.562, 0.852, 0.867]\nvelvet deep-sea blue sofa: [0.000, 0.711, 0.375, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000415716_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: chair: [0.562, 0.562, 0.852, 0.867]\ncouch: [0.000, 0.711, 0.375, 0.859]\nGiven the above layout, shift the chair upwards by 0.352."
      },
      {
        "from": "gpt",
        "value": "chair: [0.562, 0.211, 0.852, 0.516]\ncouch: [0.000, 0.711, 0.375, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000415748",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant at the center of the image with decorations on its face and body."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.219, 0.438, 0.633, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000415748_key",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant at the center of the image with decorations on its face and body.\nObjects: [elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.219, 0.438, 0.633, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000415748_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an a heavily ornamented elephant at the center of the image with decorations on its face and body."
      },
      {
        "from": "gpt",
        "value": "a heavily ornamented elephant: [0.219, 0.438, 0.633, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000415748_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an a heavily ornamented elephant at the center of the image with decorations on its face and body.\nObjects: [a heavily ornamented elephant]"
      },
      {
        "from": "gpt",
        "value": "a heavily ornamented elephant: [0.219, 0.438, 0.633, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000415748_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: elephant: [0.219, 0.438, 0.633, 0.953]\nGiven the above layout, shift the elephant upwards by 0.281."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.219, 0.156, 0.633, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000431848",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a skateboard, performing a trick at the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.305, 0.156, 0.789, 0.750]\nskateboard: [0.500, 0.594, 0.719, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000431848_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a skateboard, performing a trick at the center of the image.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.305, 0.156, 0.789, 0.750]\nskateboard: [0.500, 0.594, 0.719, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000431848_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage boy is standing on a blue skateboard, performing a trick at the center of the image."
      },
      {
        "from": "gpt",
        "value": "teenage boy: [0.305, 0.156, 0.789, 0.750]\nblue skateboard: [0.500, 0.594, 0.719, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000431848_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage boy is standing on a blue skateboard, performing a trick at the center of the image.\nObjects: [teenage boy, blue skateboard]"
      },
      {
        "from": "gpt",
        "value": "teenage boy: [0.305, 0.156, 0.789, 0.750]\nblue skateboard: [0.500, 0.594, 0.719, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000431848_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.305, 0.156, 0.789, 0.750]\nskateboard: [0.500, 0.594, 0.719, 0.812]\nGiven the above layout, shift the person to the left by 0.281."
      },
      {
        "from": "gpt",
        "value": "person: [0.023, 0.156, 0.508, 0.750]\nskateboard: [0.500, 0.594, 0.719, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000433134",
    "conversations": [
      {
        "from": "human",
        "value": "The cat is at the center of the image looking upwards."
      },
      {
        "from": "gpt",
        "value": "cat: [0.352, 0.133, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000433134_key",
    "conversations": [
      {
        "from": "human",
        "value": "The cat is at the center of the image looking upwards.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.352, 0.133, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000433134_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the brown calico kitten is at the center of the image looking upwards."
      },
      {
        "from": "gpt",
        "value": "brown calico kitten: [0.352, 0.133, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000433134_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the brown calico kitten is at the center of the image looking upwards.\nObjects: [brown calico kitten]"
      },
      {
        "from": "gpt",
        "value": "brown calico kitten: [0.352, 0.133, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000433134_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.352, 0.133, 0.992, 0.859]\nGiven the above layout, shift the cat to the left by 0.328."
      },
      {
        "from": "gpt",
        "value": "cat: [0.023, 0.133, 0.664, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000433515",
    "conversations": [
      {
        "from": "human",
        "value": "A colorful kite flying in the sky at the center of the image."
      },
      {
        "from": "gpt",
        "value": "kite: [0.320, 0.273, 0.797, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000433515_key",
    "conversations": [
      {
        "from": "human",
        "value": "A colorful kite flying in the sky at the center of the image.\nObjects: [kite]"
      },
      {
        "from": "gpt",
        "value": "kite: [0.320, 0.273, 0.797, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000433515_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a colorful vibrant rainbow kite flying in the sky at the center of the image."
      },
      {
        "from": "gpt",
        "value": "vibrant rainbow kite: [0.320, 0.273, 0.797, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000433515_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a colorful vibrant rainbow kite flying in the sky at the center of the image.\nObjects: [vibrant rainbow kite]"
      },
      {
        "from": "gpt",
        "value": "vibrant rainbow kite: [0.320, 0.273, 0.797, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000433515_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: kite: [0.320, 0.273, 0.797, 0.453]\nGiven the above layout, shift the kite downwards by 0.336."
      },
      {
        "from": "gpt",
        "value": "kite: [0.320, 0.609, 0.797, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000435880",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is located in the center right of the image with its side covered in various magnets and papers."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.586, 0.344, 0.883, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000435880_key",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is located in the center right of the image with its side covered in various magnets and papers.\nObjects: [refrigerator]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.586, 0.344, 0.883, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000435880_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel refrigerator decorated with colorful magnets and reminders is located in the center right of the image with its side covered in various magnets and papers."
      },
      {
        "from": "gpt",
        "value": "stainless steel refrigerator decorated with colorful magnets and reminders: [0.586, 0.344, 0.883, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000435880_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel refrigerator decorated with colorful magnets and reminders is located in the center right of the image with its side covered in various magnets and papers.\nObjects: [stainless steel refrigerator decorated with colorful magnets and reminders]"
      },
      {
        "from": "gpt",
        "value": "stainless steel refrigerator decorated with colorful magnets and reminders: [0.586, 0.344, 0.883, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000435880_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: refrigerator: [0.586, 0.344, 0.883, 0.844]\nGiven the above layout, shift the refrigerator to the left by 0.211."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.375, 0.344, 0.672, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000436551",
    "conversations": [
      {
        "from": "human",
        "value": "Two black swans in water, one in the foreground to the left with its head down, and the other behind it to the right, with its head raised."
      },
      {
        "from": "gpt",
        "value": "bird: [0.070, 0.258, 0.820, 0.797]\nbird: [0.758, 0.266, 0.992, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000436551_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two black swans in water, one in the foreground to the left with its head down, and the other behind it to the right, with its head raised.\nObjects: [bird, bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.070, 0.258, 0.820, 0.797]\nbird: [0.758, 0.266, 0.992, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000437392",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is adorned with a pink fluffy cover, with two large googly eyes attached to the wall above it, giving the appearance of a face."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.367, 0.156, 0.734, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000437392_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is adorned with a pink fluffy cover, with two large googly eyes attached to the wall above it, giving the appearance of a face.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.367, 0.156, 0.734, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000437392_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the sea shell shaped toilet is adorned with a pink fluffy cover, with two large googly eyes attached to the wall above it, giving the appearance of a face."
      },
      {
        "from": "gpt",
        "value": "sea shell shaped toilet: [0.367, 0.156, 0.734, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000437392_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the sea shell shaped toilet is adorned with a pink fluffy cover, with two large googly eyes attached to the wall above it, giving the appearance of a face.\nObjects: [sea shell shaped toilet]"
      },
      {
        "from": "gpt",
        "value": "sea shell shaped toilet: [0.367, 0.156, 0.734, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000437392_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.367, 0.156, 0.734, 0.961]\nGiven the above layout, shift the toilet to the left by 0.125."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.242, 0.156, 0.609, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000438876",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the right holding a tennis racket with their arm extended to the left."
      },
      {
        "from": "gpt",
        "value": "person: [0.336, 0.203, 0.695, 0.820]\ntennis racket: [0.672, 0.664, 0.781, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000438876_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the right holding a tennis racket with their arm extended to the left.\nObjects: [person, tennis racket]"
      },
      {
        "from": "gpt",
        "value": "person: [0.336, 0.203, 0.695, 0.820]\ntennis racket: [0.672, 0.664, 0.781, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000438876_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a person on the right holding a tennis racket with their arm extended to the left."
      },
      {
        "from": "gpt",
        "value": "person: [0.336, 0.203, 0.695, 0.820]\ntennis racket: [0.672, 0.664, 0.781, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000438876_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a person on the right holding a tennis racket with their arm extended to the left.\nObjects: [person, tennis racket]"
      },
      {
        "from": "gpt",
        "value": "person: [0.336, 0.203, 0.695, 0.820]\ntennis racket: [0.672, 0.664, 0.781, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000438876_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.336, 0.203, 0.695, 0.820]\ntennis racket: [0.672, 0.664, 0.781, 0.812]\nGiven the above layout, shift the person to the left by 0.133."
      },
      {
        "from": "gpt",
        "value": "person: [0.203, 0.203, 0.562, 0.820]\ntennis racket: [0.672, 0.664, 0.781, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000442480",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is at the center with vehicles on either side of it."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.094, 0.430, 0.961, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000442480_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is at the center with vehicles on either side of it.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.094, 0.430, 0.961, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000442480_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an blue commercial jet is at the center with vehicles on either side of it."
      },
      {
        "from": "gpt",
        "value": "blue commercial jet: [0.094, 0.430, 0.961, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000442480_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an blue commercial jet is at the center with vehicles on either side of it.\nObjects: [blue commercial jet]"
      },
      {
        "from": "gpt",
        "value": "blue commercial jet: [0.094, 0.430, 0.961, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000442480_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.094, 0.430, 0.961, 0.570]\nGiven the above layout, shift the airplane upwards by 0.289."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.094, 0.141, 0.961, 0.281]"
      }
    ]
  },
  {
    "id": "coco_000000443498",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is at the center facing forward."
      },
      {
        "from": "gpt",
        "value": "bus: [0.289, 0.312, 0.727, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000443498_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is at the center facing forward.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.289, 0.312, 0.727, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000443498_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the city transit vehicle is at the center facing forward."
      },
      {
        "from": "gpt",
        "value": "city transit vehicle: [0.289, 0.312, 0.727, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000443498_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the city transit vehicle is at the center facing forward.\nObjects: [city transit vehicle]"
      },
      {
        "from": "gpt",
        "value": "city transit vehicle: [0.289, 0.312, 0.727, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000443498_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.289, 0.312, 0.727, 0.727]\nGiven the above layout, shift the bus upwards by 0.273."
      },
      {
        "from": "gpt",
        "value": "bus: [0.289, 0.039, 0.727, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000444879",
    "conversations": [
      {
        "from": "human",
        "value": "A train is approaching on the tracks curving from the right to the left side of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.289, 0.406, 0.664, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000444879_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is approaching on the tracks curving from the right to the left side of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.289, 0.406, 0.664, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000444879_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a diesel locomotive is approaching on the tracks curving from the right to the left side of the image."
      },
      {
        "from": "gpt",
        "value": "diesel locomotive: [0.289, 0.406, 0.664, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000444879_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a diesel locomotive is approaching on the tracks curving from the right to the left side of the image.\nObjects: [diesel locomotive]"
      },
      {
        "from": "gpt",
        "value": "diesel locomotive: [0.289, 0.406, 0.664, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000444879_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.289, 0.406, 0.664, 0.688]\nGiven the above layout, shift the train upwards by 0.359."
      },
      {
        "from": "gpt",
        "value": "train: [0.289, 0.047, 0.664, 0.328]"
      }
    ]
  },
  {
    "id": "coco_000000445658",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is to the left of the oven, which is at the center of the image."
      },
      {
        "from": "gpt",
        "value": "oven: [0.211, 0.445, 0.453, 0.781]\nrefrigerator: [0.000, 0.281, 0.078, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000445658_key",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is to the left of the oven, which is at the center of the image.\nObjects: [oven, refrigerator]"
      },
      {
        "from": "gpt",
        "value": "oven: [0.211, 0.445, 0.453, 0.781]\nrefrigerator: [0.000, 0.281, 0.078, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000445658_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the tall double-door refrigerator is to the left of the compact professional-grade oven, which is at the center of the image."
      },
      {
        "from": "gpt",
        "value": "compact professional-grade oven: [0.211, 0.445, 0.453, 0.781]\ntall double-door refrigerator: [0.000, 0.281, 0.078, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000445658_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the tall double-door refrigerator is to the left of the compact professional-grade oven, which is at the center of the image.\nObjects: [compact professional-grade oven, tall double-door refrigerator]"
      },
      {
        "from": "gpt",
        "value": "compact professional-grade oven: [0.211, 0.445, 0.453, 0.781]\ntall double-door refrigerator: [0.000, 0.281, 0.078, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000445658_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: oven: [0.211, 0.445, 0.453, 0.781]\nrefrigerator: [0.000, 0.281, 0.078, 0.805]\nGiven the above layout, shift the oven to the right by 0.086."
      },
      {
        "from": "gpt",
        "value": "oven: [0.297, 0.445, 0.539, 0.781]\nrefrigerator: [0.000, 0.281, 0.078, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000445675",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe standing in the center of the image with bushes in the background."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.367, 0.164, 0.648, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000445675_key",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe standing in the center of the image with bushes in the background.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.367, 0.164, 0.648, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000445675_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a towering giraffe standing in the center of the image with bushes in the background."
      },
      {
        "from": "gpt",
        "value": "towering giraffe: [0.367, 0.164, 0.648, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000445675_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a towering giraffe standing in the center of the image with bushes in the background.\nObjects: [towering giraffe]"
      },
      {
        "from": "gpt",
        "value": "towering giraffe: [0.367, 0.164, 0.648, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000445675_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.367, 0.164, 0.648, 0.812]\nGiven the above layout, shift the giraffe to the left by 0.016."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.352, 0.164, 0.633, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000445999",
    "conversations": [
      {
        "from": "human",
        "value": "A person with long hair is visible from the chest up, with their right hand held up near their chin."
      },
      {
        "from": "gpt",
        "value": "person: [0.180, 0.023, 0.812, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000445999_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person with long hair is visible from the chest up, with their right hand held up near their chin.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.180, 0.023, 0.812, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000445999_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a woman with curly hair with long hair is visible from the chest up, with their right hand held up near their chin."
      },
      {
        "from": "gpt",
        "value": "woman with curly hair: [0.180, 0.023, 0.812, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000445999_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a woman with curly hair with long hair is visible from the chest up, with their right hand held up near their chin.\nObjects: [woman with curly hair]"
      },
      {
        "from": "gpt",
        "value": "woman with curly hair: [0.180, 0.023, 0.812, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000445999_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.180, 0.023, 0.812, 0.984]\nGiven the above layout, shift the person to the left by 0.172."
      },
      {
        "from": "gpt",
        "value": "person: [0.008, 0.023, 0.641, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000448365",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the air above a skateboard at a skatepark."
      },
      {
        "from": "gpt",
        "value": "person: [0.234, 0.219, 0.578, 0.688]\nskateboard: [0.305, 0.578, 0.539, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000448365_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the air above a skateboard at a skatepark.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.234, 0.219, 0.578, 0.688]\nskateboard: [0.305, 0.578, 0.539, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000448365_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a sweatshirt-clad skater is in the air above a multicolored skateboard at a skatepark."
      },
      {
        "from": "gpt",
        "value": "sweatshirt-clad skater: [0.234, 0.219, 0.578, 0.688]\nmulticolored skateboard: [0.305, 0.578, 0.539, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000448365_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a sweatshirt-clad skater is in the air above a multicolored skateboard at a skatepark.\nObjects: [sweatshirt-clad skater, multicolored skateboard]"
      },
      {
        "from": "gpt",
        "value": "sweatshirt-clad skater: [0.234, 0.219, 0.578, 0.688]\nmulticolored skateboard: [0.305, 0.578, 0.539, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000448365_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.234, 0.219, 0.578, 0.688]\nskateboard: [0.305, 0.578, 0.539, 0.797]\nGiven the above layout, shift the person to the right by 0.180."
      },
      {
        "from": "gpt",
        "value": "person: [0.414, 0.219, 0.758, 0.688]\nskateboard: [0.305, 0.578, 0.539, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000450488",
    "conversations": [
      {
        "from": "human",
        "value": "A bed is positioned in the center of the image, with its headboard against the right wall."
      },
      {
        "from": "gpt",
        "value": "bed: [0.172, 0.562, 0.531, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000450488_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bed is positioned in the center of the image, with its headboard against the right wall.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.172, 0.562, 0.531, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000450488_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a queen-size bed is positioned in the center of the image, with its headboard against the right wall."
      },
      {
        "from": "gpt",
        "value": "queen-size bed: [0.172, 0.562, 0.531, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000450488_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a queen-size bed is positioned in the center of the image, with its headboard against the right wall.\nObjects: [queen-size bed]"
      },
      {
        "from": "gpt",
        "value": "queen-size bed: [0.172, 0.562, 0.531, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000450488_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.172, 0.562, 0.531, 0.953]\nGiven the above layout, shift the bed upwards by 0.250."
      },
      {
        "from": "gpt",
        "value": "bed: [0.172, 0.312, 0.531, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000451090",
    "conversations": [
      {
        "from": "human",
        "value": "A boat at the center of the image, floating on water with land and mountains in the background."
      },
      {
        "from": "gpt",
        "value": "boat: [0.227, 0.336, 0.594, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000451090_key",
    "conversations": [
      {
        "from": "human",
        "value": "A boat at the center of the image, floating on water with land and mountains in the background.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.227, 0.336, 0.594, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000451090_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a small white yacht at the center of the image, floating on water with land and mountains in the background."
      },
      {
        "from": "gpt",
        "value": "small white yacht: [0.227, 0.336, 0.594, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000451090_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a small white yacht at the center of the image, floating on water with land and mountains in the background.\nObjects: [small white yacht]"
      },
      {
        "from": "gpt",
        "value": "small white yacht: [0.227, 0.336, 0.594, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000451090_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.227, 0.336, 0.594, 0.648]\nGiven the above layout, shift the boat to the right by 0.023."
      },
      {
        "from": "gpt",
        "value": "boat: [0.250, 0.336, 0.617, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000451693",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza on top of a stack of plates."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.109, 0.203, 0.891, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000451693_key",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza on top of a stack of plates.\nObjects: [pizza]"
      },
      {
        "from": "gpt",
        "value": "pizza: [0.109, 0.203, 0.891, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000451693_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a pizza on top of a stack of plates."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.109, 0.203, 0.891, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000451693_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a pizza on top of a stack of plates.\nObjects: [pizza]"
      },
      {
        "from": "gpt",
        "value": "pizza: [0.109, 0.203, 0.891, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000451693_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: pizza: [0.109, 0.203, 0.891, 0.688]\nGiven the above layout, shift the pizza downwards by 0.195."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.109, 0.398, 0.891, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000452321",
    "conversations": [
      {
        "from": "human",
        "value": "A red bus is in the foreground on the right, with another bus in the background to the left."
      },
      {
        "from": "gpt",
        "value": "bus: [0.602, 0.336, 0.992, 0.797]\nbus: [0.000, 0.445, 0.289, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000452321_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red bus is in the foreground on the right, with another bus in the background to the left.\nObjects: [bus, bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.602, 0.336, 0.992, 0.797]\nbus: [0.000, 0.445, 0.289, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000453341",
    "conversations": [
      {
        "from": "human",
        "value": "The couch is at the center of the image with a patterned cover on it."
      },
      {
        "from": "gpt",
        "value": "couch: [0.062, 0.633, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000453341_key",
    "conversations": [
      {
        "from": "human",
        "value": "The couch is at the center of the image with a patterned cover on it.\nObjects: [couch]"
      },
      {
        "from": "gpt",
        "value": "couch: [0.062, 0.633, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000453341_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the blue velvet loveseat is at the center of the image with a patterned cover on it."
      },
      {
        "from": "gpt",
        "value": "blue velvet loveseat: [0.062, 0.633, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000453341_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the blue velvet loveseat is at the center of the image with a patterned cover on it.\nObjects: [blue velvet loveseat]"
      },
      {
        "from": "gpt",
        "value": "blue velvet loveseat: [0.062, 0.633, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000453341_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: couch: [0.062, 0.633, 0.992, 0.859]\nGiven the above layout, shift the couch upwards by 0.211."
      },
      {
        "from": "gpt",
        "value": "couch: [0.062, 0.422, 0.992, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000453860",
    "conversations": [
      {
        "from": "human",
        "value": "Two suitcases are standing upright next to each other, with the left one slightly in front of the right one."
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.531, 0.227, 0.938, 0.750]\nsuitcase: [0.047, 0.219, 0.430, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000453860_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two suitcases are standing upright next to each other, with the left one slightly in front of the right one.\nObjects: [suitcase, suitcase]"
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.531, 0.227, 0.938, 0.750]\nsuitcase: [0.047, 0.219, 0.430, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000455981",
    "conversations": [
      {
        "from": "human",
        "value": "A toilet is at the center with its lid open."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.211, 0.008, 0.805, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000455981_key",
    "conversations": [
      {
        "from": "human",
        "value": "A toilet is at the center with its lid open.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.211, 0.008, 0.805, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000455981_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a porcelain sink is at the center with its lid open."
      },
      {
        "from": "gpt",
        "value": "porcelain sink: [0.211, 0.008, 0.805, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000455981_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a porcelain sink is at the center with its lid open.\nObjects: [porcelain sink]"
      },
      {
        "from": "gpt",
        "value": "porcelain sink: [0.211, 0.008, 0.805, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000455981_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.211, 0.008, 0.805, 0.883]\nGiven the above layout, shift the toilet to the left by 0.039."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.172, 0.008, 0.766, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000457884",
    "conversations": [
      {
        "from": "human",
        "value": "Three people are positioned on a baseball field with the person in the center attempting to catch a ball, a person on the left running towards the center, and a person on the right standing and watching."
      },
      {
        "from": "gpt",
        "value": "person: [0.430, 0.320, 0.625, 0.734]\nperson: [0.812, 0.344, 0.953, 0.625]\nperson: [0.664, 0.391, 0.758, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000457884_key",
    "conversations": [
      {
        "from": "human",
        "value": "Three people are positioned on a baseball field with the person in the center attempting to catch a ball, a person on the left running towards the center, and a person on the right standing and watching.\nObjects: [person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.430, 0.320, 0.625, 0.734]\nperson: [0.812, 0.344, 0.953, 0.625]\nperson: [0.664, 0.391, 0.758, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000458109",
    "conversations": [
      {
        "from": "human",
        "value": "A train is on the tracks to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.125, 0.992, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000458109_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is on the tracks to the right side of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.125, 0.992, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000458109_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a blue cargo train is on the tracks to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "blue cargo train: [0.000, 0.125, 0.992, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000458109_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a blue cargo train is on the tracks to the right side of the image.\nObjects: [blue cargo train]"
      },
      {
        "from": "gpt",
        "value": "blue cargo train: [0.000, 0.125, 0.992, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000458109_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.125, 0.992, 0.555]\nGiven the above layout, shift the train downwards by 0.430."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.555, 0.992, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000458410",
    "conversations": [
      {
        "from": "human",
        "value": "The couch is on the right side of the image with a patterned design."
      },
      {
        "from": "gpt",
        "value": "couch: [0.594, 0.492, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000458410_key",
    "conversations": [
      {
        "from": "human",
        "value": "The couch is on the right side of the image with a patterned design.\nObjects: [couch]"
      },
      {
        "from": "gpt",
        "value": "couch: [0.594, 0.492, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000458410_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the striped loveseat is on the right side of the image with a patterned design."
      },
      {
        "from": "gpt",
        "value": "striped loveseat: [0.594, 0.492, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000458410_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the striped loveseat is on the right side of the image with a patterned design.\nObjects: [striped loveseat]"
      },
      {
        "from": "gpt",
        "value": "striped loveseat: [0.594, 0.492, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000458410_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: couch: [0.594, 0.492, 0.992, 0.867]\nGiven the above layout, shift the couch to the left by 0.047."
      },
      {
        "from": "gpt",
        "value": "couch: [0.547, 0.492, 0.945, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000459634",
    "conversations": [
      {
        "from": "human",
        "value": "A motorcycle is traveling ahead on a road, viewed from the perspective of a person following behind on another motorcycle."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.492, 0.594, 0.992, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000459634_key",
    "conversations": [
      {
        "from": "human",
        "value": "A motorcycle is traveling ahead on a road, viewed from the perspective of a person following behind on another motorcycle.\nObjects: [motorcycle]"
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.492, 0.594, 0.992, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000459634_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek black sports bike is traveling ahead on a road, viewed from the perspective of a person following behind on another sleek black sports bike."
      },
      {
        "from": "gpt",
        "value": "sleek black sports bike: [0.492, 0.594, 0.992, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000459634_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek black sports bike is traveling ahead on a road, viewed from the perspective of a person following behind on another sleek black sports bike.\nObjects: [sleek black sports bike]"
      },
      {
        "from": "gpt",
        "value": "sleek black sports bike: [0.492, 0.594, 0.992, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000459634_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: motorcycle: [0.492, 0.594, 0.992, 0.906]\nGiven the above layout, shift the motorcycle upwards by 0.328."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.492, 0.266, 0.992, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000460229",
    "conversations": [
      {
        "from": "human",
        "value": "A stop sign in the foreground on the right, with a truck visible in the background on the left."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.281, 0.125, 0.641, 0.477]\ntruck: [0.555, 0.469, 0.789, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000460229_key",
    "conversations": [
      {
        "from": "human",
        "value": "A stop sign in the foreground on the right, with a truck visible in the background on the left.\nObjects: [stop sign, truck]"
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.281, 0.125, 0.641, 0.477]\ntruck: [0.555, 0.469, 0.789, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000460229_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red stop sign in the foreground on the right, with a big cargo truck visible in the background on the left."
      },
      {
        "from": "gpt",
        "value": "red stop sign: [0.281, 0.125, 0.641, 0.477]\nbig cargo truck: [0.555, 0.469, 0.789, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000460229_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red stop sign in the foreground on the right, with a big cargo truck visible in the background on the left.\nObjects: [red stop sign, big cargo truck]"
      },
      {
        "from": "gpt",
        "value": "red stop sign: [0.281, 0.125, 0.641, 0.477]\nbig cargo truck: [0.555, 0.469, 0.789, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000460229_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: stop sign: [0.281, 0.125, 0.641, 0.477]\ntruck: [0.555, 0.469, 0.789, 0.711]\nGiven the above layout, shift the stop sign to the left by 0.133."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.148, 0.125, 0.508, 0.477]\ntruck: [0.555, 0.469, 0.789, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000475484",
    "conversations": [
      {
        "from": "human",
        "value": "A parking meter in the foreground on the right, and a car visible in the background on the far left."
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.594, 0.039, 0.781, 0.422]\ncar: [0.383, 0.523, 0.586, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000475484_key",
    "conversations": [
      {
        "from": "human",
        "value": "A parking meter in the foreground on the right, and a car visible in the background on the far left.\nObjects: [parking meter, car]"
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.594, 0.039, 0.781, 0.422]\ncar: [0.383, 0.523, 0.586, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000475484_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a traditional parking meter in the foreground on the right, and a red sports car visible in the background on the far left."
      },
      {
        "from": "gpt",
        "value": "traditional parking meter: [0.594, 0.039, 0.781, 0.422]\nred sports car: [0.383, 0.523, 0.586, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000475484_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a traditional parking meter in the foreground on the right, and a red sports car visible in the background on the far left.\nObjects: [traditional parking meter, red sports car]"
      },
      {
        "from": "gpt",
        "value": "traditional parking meter: [0.594, 0.039, 0.781, 0.422]\nred sports car: [0.383, 0.523, 0.586, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000475484_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: parking meter: [0.594, 0.039, 0.781, 0.422]\ncar: [0.383, 0.523, 0.586, 0.602]\nGiven the above layout, shift the car downwards by 0.328."
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.594, 0.039, 0.781, 0.422]\ncar: [0.383, 0.852, 0.586, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000475904",
    "conversations": [
      {
        "from": "human",
        "value": "A boat is located at the bottom right corner of the image."
      },
      {
        "from": "gpt",
        "value": "boat: [0.555, 0.562, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000475904_key",
    "conversations": [
      {
        "from": "human",
        "value": "A boat is located at the bottom right corner of the image.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.555, 0.562, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000475904_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a small sailboat is located at the bottom right corner of the image."
      },
      {
        "from": "gpt",
        "value": "small sailboat: [0.555, 0.562, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000475904_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a small sailboat is located at the bottom right corner of the image.\nObjects: [small sailboat]"
      },
      {
        "from": "gpt",
        "value": "small sailboat: [0.555, 0.562, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000475904_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.555, 0.562, 0.992, 0.820]\nGiven the above layout, shift the boat upwards by 0.172."
      },
      {
        "from": "gpt",
        "value": "boat: [0.555, 0.391, 0.992, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000477227",
    "conversations": [
      {
        "from": "human",
        "value": "A boat is docked near the shore in the background, and another boat is to the right of it, partially obscured by the foreground."
      },
      {
        "from": "gpt",
        "value": "boat: [0.102, 0.359, 0.547, 0.555]\nboat: [0.336, 0.547, 0.719, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000477227_key",
    "conversations": [
      {
        "from": "human",
        "value": "A boat is docked near the shore in the background, and another boat is to the right of it, partially obscured by the foreground.\nObjects: [boat, boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.102, 0.359, 0.547, 0.555]\nboat: [0.336, 0.547, 0.719, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000477623",
    "conversations": [
      {
        "from": "human",
        "value": "An orange train with black stripes at the front is on the tracks facing the right side of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.148, 0.242, 0.859, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000477623_key",
    "conversations": [
      {
        "from": "human",
        "value": "An orange train with black stripes at the front is on the tracks facing the right side of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.148, 0.242, 0.859, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000477623_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an orange red locomotive with black outlines with black stripes at the front is on the tracks facing the right side of the image."
      },
      {
        "from": "gpt",
        "value": "red locomotive with black outlines: [0.148, 0.242, 0.859, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000477623_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an orange red locomotive with black outlines with black stripes at the front is on the tracks facing the right side of the image.\nObjects: [red locomotive with black outlines]"
      },
      {
        "from": "gpt",
        "value": "red locomotive with black outlines: [0.148, 0.242, 0.859, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000477623_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.148, 0.242, 0.859, 0.789]\nGiven the above layout, shift the train upwards by 0.219."
      },
      {
        "from": "gpt",
        "value": "train: [0.148, 0.023, 0.859, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000478286",
    "conversations": [
      {
        "from": "human",
        "value": "A colorful train is crossing a bridge in the background."
      },
      {
        "from": "gpt",
        "value": "train: [0.242, 0.430, 0.992, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000478286_key",
    "conversations": [
      {
        "from": "human",
        "value": "A colorful train is crossing a bridge in the background.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.242, 0.430, 0.992, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000478286_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a colorful picturesque steam engine is crossing a bridge in the background."
      },
      {
        "from": "gpt",
        "value": "picturesque steam engine: [0.242, 0.430, 0.992, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000478286_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a colorful picturesque steam engine is crossing a bridge in the background.\nObjects: [picturesque steam engine]"
      },
      {
        "from": "gpt",
        "value": "picturesque steam engine: [0.242, 0.430, 0.992, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000478286_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.242, 0.430, 0.992, 0.617]\nGiven the above layout, shift the train upwards by 0.430."
      },
      {
        "from": "gpt",
        "value": "train: [0.242, 0.000, 0.992, 0.188]"
      }
    ]
  },
  {
    "id": "coco_000000479030",
    "conversations": [
      {
        "from": "human",
        "value": "The train is positioned horizontally in the center of the image, with the front facing to the left."
      },
      {
        "from": "gpt",
        "value": "train: [0.156, 0.258, 0.914, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000479030_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is positioned horizontally in the center of the image, with the front facing to the left.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.156, 0.258, 0.914, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000479030_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the large freight locomotive is positioned horizontally in the center of the image, with the front facing to the left."
      },
      {
        "from": "gpt",
        "value": "large freight locomotive: [0.156, 0.258, 0.914, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000479030_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the large freight locomotive is positioned horizontally in the center of the image, with the front facing to the left.\nObjects: [large freight locomotive]"
      },
      {
        "from": "gpt",
        "value": "large freight locomotive: [0.156, 0.258, 0.914, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000479030_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.156, 0.258, 0.914, 0.594]\nGiven the above layout, shift the train downwards by 0.211."
      },
      {
        "from": "gpt",
        "value": "train: [0.156, 0.469, 0.914, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000479596",
    "conversations": [
      {
        "from": "human",
        "value": "Oranges are piled up in the foreground to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "orange: [0.000, 0.422, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000479596_key",
    "conversations": [
      {
        "from": "human",
        "value": "Oranges are piled up in the foreground to the right side of the image.\nObjects: [orange]"
      },
      {
        "from": "gpt",
        "value": "orange: [0.000, 0.422, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000479596_aug",
    "conversations": [
      {
        "from": "human",
        "value": "bunch of peachess are piled up in the foreground to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "bunch of peaches: [0.000, 0.422, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000479596_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "bunch of peachess are piled up in the foreground to the right side of the image.\nObjects: [bunch of peaches]"
      },
      {
        "from": "gpt",
        "value": "bunch of peaches: [0.000, 0.422, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000479596_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: orange: [0.000, 0.422, 0.992, 0.828]\nGiven the above layout, shift the orange upwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "orange: [0.000, 0.398, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000480275",
    "conversations": [
      {
        "from": "human",
        "value": "A person is seated behind a cart, partly obscured by the cart's contents on the right side of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.617, 0.430, 0.992, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000480275_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is seated behind a cart, partly obscured by the carts contents on the right side of the image.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.617, 0.430, 0.992, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000480275_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a man wearing a hat is seated behind a cart, partly obscured by the cart's contents on the right side of the image."
      },
      {
        "from": "gpt",
        "value": "a man wearing a hat: [0.617, 0.430, 0.992, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000480275_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a man wearing a hat is seated behind a cart, partly obscured by the carts contents on the right side of the image.\nObjects: [a man wearing a hat]"
      },
      {
        "from": "gpt",
        "value": "a man wearing a hat: [0.617, 0.430, 0.992, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000480275_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.617, 0.430, 0.992, 0.719]\nGiven the above layout, shift the person to the left by 0.336."
      },
      {
        "from": "gpt",
        "value": "person: [0.281, 0.430, 0.656, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000482100",
    "conversations": [
      {
        "from": "human",
        "value": "Two toilets side by side outdoors, with one slightly in front of the other."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.391, 0.422, 0.664, 0.664]\ntoilet: [0.656, 0.398, 0.898, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000482100_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two toilets side by side outdoors, with one slightly in front of the other.\nObjects: [toilet, toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.391, 0.422, 0.664, 0.664]\ntoilet: [0.656, 0.398, 0.898, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000482970",
    "conversations": [
      {
        "from": "human",
        "value": "The laptop is at the center of the image, positioned on a table facing slightly to the left."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.281, 0.383, 0.719, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000482970_key",
    "conversations": [
      {
        "from": "human",
        "value": "The laptop is at the center of the image, positioned on a table facing slightly to the left.\nObjects: [laptop]"
      },
      {
        "from": "gpt",
        "value": "laptop: [0.281, 0.383, 0.719, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000482970_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the white MacBook Pro is at the center of the image, positioned on a table facing slightly to the left."
      },
      {
        "from": "gpt",
        "value": "white MacBook Pro: [0.281, 0.383, 0.719, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000482970_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the white MacBook Pro is at the center of the image, positioned on a table facing slightly to the left.\nObjects: [white MacBook Pro]"
      },
      {
        "from": "gpt",
        "value": "white MacBook Pro: [0.281, 0.383, 0.719, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000482970_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: laptop: [0.281, 0.383, 0.719, 0.758]\nGiven the above layout, shift the laptop upwards by 0.094."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.281, 0.289, 0.719, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000483050",
    "conversations": [
      {
        "from": "human",
        "value": "A bed is centered in the image with white and red pillows on top, flanked by two bedside tables with lamps."
      },
      {
        "from": "gpt",
        "value": "bed: [0.016, 0.445, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000483050_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bed is centered in the image with white and red pillows on top, flanked by two bedside tables with lamps.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.016, 0.445, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000483050_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a queen-size bed with pristine white and rich red pillows is centered in the image with white and red pillows on top, flanked by two queen-size bed with pristine white and rich red pillowsside tables with lamps."
      },
      {
        "from": "gpt",
        "value": "queen-size bed with pristine white and rich red pillows: [0.016, 0.445, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000483050_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a queen-size bed with pristine white and rich red pillows is centered in the image with white and red pillows on top, flanked by two queen-size bed with pristine white and rich red pillowsside tables with lamps.\nObjects: [queen-size bed with pristine white and rich red pillows]"
      },
      {
        "from": "gpt",
        "value": "queen-size bed with pristine white and rich red pillows: [0.016, 0.445, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000483050_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.016, 0.445, 0.992, 0.859]\nGiven the above layout, shift the bed upwards by 0.297."
      },
      {
        "from": "gpt",
        "value": "bed: [0.016, 0.148, 0.992, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000483667",
    "conversations": [
      {
        "from": "human",
        "value": "A person is wearing a red tie at the center front of their shirt."
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.008, 0.828, 0.977]\ntie: [0.477, 0.617, 0.555, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000483667_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is wearing a red tie at the center front of their shirt.\nObjects: [person, tie]"
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.008, 0.828, 0.977]\ntie: [0.477, 0.617, 0.555, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000483667_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a person is wearing a red tie at the center front of their shirt."
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.008, 0.828, 0.977]\ntie: [0.477, 0.617, 0.555, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000483667_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a person is wearing a red tie at the center front of their shirt.\nObjects: [person, tie]"
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.008, 0.828, 0.977]\ntie: [0.477, 0.617, 0.555, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000483667_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.172, 0.008, 0.828, 0.977]\ntie: [0.477, 0.617, 0.555, 0.992]\nGiven the above layout, shift the person to the left by 0.086."
      },
      {
        "from": "gpt",
        "value": "person: [0.086, 0.008, 0.742, 0.977]\ntie: [0.477, 0.617, 0.555, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000484296",
    "conversations": [
      {
        "from": "human",
        "value": "One zebra standing on the left; another zebra lying down on the right."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.039, 0.195, 0.477, 0.609]\nzebra: [0.594, 0.469, 0.930, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000484296_key",
    "conversations": [
      {
        "from": "human",
        "value": "One zebra standing on the left; another zebra lying down on the right.\nObjects: [zebra, zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.039, 0.195, 0.477, 0.609]\nzebra: [0.594, 0.469, 0.930, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000500049",
    "conversations": [
      {
        "from": "human",
        "value": "A large airplane is parked on the tarmac at the center of the image."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.000, 0.281, 0.773, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000500049_key",
    "conversations": [
      {
        "from": "human",
        "value": "A large airplane is parked on the tarmac at the center of the image.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.000, 0.281, 0.773, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000500049_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a large jumbo jet plane is parked on the tarmac at the center of the image."
      },
      {
        "from": "gpt",
        "value": "jumbo jet plane: [0.000, 0.281, 0.773, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000500049_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a large jumbo jet plane is parked on the tarmac at the center of the image.\nObjects: [jumbo jet plane]"
      },
      {
        "from": "gpt",
        "value": "jumbo jet plane: [0.000, 0.281, 0.773, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000500049_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.000, 0.281, 0.773, 0.570]\nGiven the above layout, shift the airplane downwards by 0.375."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.000, 0.656, 0.773, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000501368",
    "conversations": [
      {
        "from": "human",
        "value": "The person is at the center, facing away from the camera, with their head slightly turned to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.359, 0.008, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000501368_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is at the center, facing away from the camera, with their head slightly turned to the right.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.359, 0.008, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000501368_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the young man in a blue jacket is at the center, facing away from the camera, with their head slightly turned to the right."
      },
      {
        "from": "gpt",
        "value": "young man in a blue jacket: [0.359, 0.008, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000501368_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the young man in a blue jacket is at the center, facing away from the camera, with their head slightly turned to the right.\nObjects: [young man in a blue jacket]"
      },
      {
        "from": "gpt",
        "value": "young man in a blue jacket: [0.359, 0.008, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000501368_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.359, 0.008, 0.867, 0.977]\nGiven the above layout, shift the person to the left by 0.344."
      },
      {
        "from": "gpt",
        "value": "person: [0.016, 0.008, 0.523, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000502732",
    "conversations": [
      {
        "from": "human",
        "value": "A stainless steel refrigerator is at the center with its handles in the middle."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.234, 0.133, 0.742, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000502732_key",
    "conversations": [
      {
        "from": "human",
        "value": "A stainless steel refrigerator is at the center with its handles in the middle.\nObjects: [refrigerator]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.234, 0.133, 0.742, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000502732_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a stainless steel metallic silver double-door refrigerator is at the center with its handles in the middle."
      },
      {
        "from": "gpt",
        "value": "metallic silver double-door refrigerator: [0.234, 0.133, 0.742, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000502732_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a stainless steel metallic silver double-door refrigerator is at the center with its handles in the middle.\nObjects: [metallic silver double-door refrigerator]"
      },
      {
        "from": "gpt",
        "value": "metallic silver double-door refrigerator: [0.234, 0.133, 0.742, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000502732_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: refrigerator: [0.234, 0.133, 0.742, 0.977]\nGiven the above layout, shift the refrigerator to the right by 0.094."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.328, 0.133, 0.836, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000504589",
    "conversations": [
      {
        "from": "human",
        "value": "One person is standing on the left side throwing a frisbee, and another person is on the right side preparing to catch it."
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.562, 0.406, 0.984]\nperson: [0.578, 0.562, 0.758, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000504589_key",
    "conversations": [
      {
        "from": "human",
        "value": "One person is standing on the left side throwing a frisbee, and another person is on the right side preparing to catch it.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.562, 0.406, 0.984]\nperson: [0.578, 0.562, 0.758, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000505638",
    "conversations": [
      {
        "from": "human",
        "value": "The train is positioned diagonally from the bottom left to the top right of the image, with the front facing the right."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.133, 0.812, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000505638_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is positioned diagonally from the bottom left to the top right of the image, with the front facing the right.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.133, 0.812, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000505638_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red freight train is positioned diagonally from the bottom left to the top right of the image, with the front facing the right."
      },
      {
        "from": "gpt",
        "value": "red freight train: [0.000, 0.133, 0.812, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000505638_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red freight train is positioned diagonally from the bottom left to the top right of the image, with the front facing the right.\nObjects: [red freight train]"
      },
      {
        "from": "gpt",
        "value": "red freight train: [0.000, 0.133, 0.812, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000505638_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.133, 0.812, 0.852]\nGiven the above layout, shift the train to the right by 0.148."
      },
      {
        "from": "gpt",
        "value": "train: [0.148, 0.133, 0.961, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000508482",
    "conversations": [
      {
        "from": "human",
        "value": "The image shows an open doorway of a train with the interior visible inside, centered in the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.125, 0.000, 0.867, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000508482_key",
    "conversations": [
      {
        "from": "human",
        "value": "The image shows an open doorway of a train with the interior visible inside, centered in the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.125, 0.000, 0.867, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000508482_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the image shows an open doorway of a Double-decker bus with the interior visible inside, centered in the image."
      },
      {
        "from": "gpt",
        "value": "Double-decker bus: [0.125, 0.000, 0.867, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000508482_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the image shows an open doorway of a Double-decker bus with the interior visible inside, centered in the image.\nObjects: [Double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "Double-decker bus: [0.125, 0.000, 0.867, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000508482_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.125, 0.000, 0.867, 0.828]\nGiven the above layout, shift the train downwards by 0.141."
      },
      {
        "from": "gpt",
        "value": "train: [0.125, 0.141, 0.867, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000508602",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is standing on top of a car roof."
      },
      {
        "from": "gpt",
        "value": "car: [0.000, 0.570, 0.992, 0.914]\nbird: [0.297, 0.234, 0.586, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000508602_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is standing on top of a car roof.\nObjects: [car, bird]"
      },
      {
        "from": "gpt",
        "value": "car: [0.000, 0.570, 0.992, 0.914]\nbird: [0.297, 0.234, 0.586, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000508602_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a blue jay is standing on top of a green SUV roof."
      },
      {
        "from": "gpt",
        "value": "green SUV: [0.000, 0.570, 0.992, 0.914]\nblue jay: [0.297, 0.234, 0.586, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000508602_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a blue jay is standing on top of a green SUV roof.\nObjects: [green SUV, blue jay]"
      },
      {
        "from": "gpt",
        "value": "green SUV: [0.000, 0.570, 0.992, 0.914]\nblue jay: [0.297, 0.234, 0.586, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000508602_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: car: [0.000, 0.570, 0.992, 0.914]\nbird: [0.297, 0.234, 0.586, 0.578]\nGiven the above layout, shift the bird upwards by 0.211."
      },
      {
        "from": "gpt",
        "value": "car: [0.000, 0.570, 0.992, 0.914]\nbird: [0.297, 0.023, 0.586, 0.367]"
      }
    ]
  },
  {
    "id": "coco_000000509008",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is positioned horizontally across the image with its rear facing the viewer's left and the front towards the right."
      },
      {
        "from": "gpt",
        "value": "bus: [0.016, 0.328, 0.969, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000509008_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is positioned horizontally across the image with its rear facing the viewers left and the front towards the right.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.016, 0.328, 0.969, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000509008_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the blue double-decker bus is positioned horizontally across the image with its rear facing the viewer's left and the front towards the right."
      },
      {
        "from": "gpt",
        "value": "blue double-decker bus: [0.016, 0.328, 0.969, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000509008_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the blue double-decker bus is positioned horizontally across the image with its rear facing the viewers left and the front towards the right.\nObjects: [blue double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "blue double-decker bus: [0.016, 0.328, 0.969, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000509008_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.016, 0.328, 0.969, 0.766]\nGiven the above layout, shift the bus upwards by 0.281."
      },
      {
        "from": "gpt",
        "value": "bus: [0.016, 0.047, 0.969, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000512194",
    "conversations": [
      {
        "from": "human",
        "value": "The vase is at the center with flowers in it."
      },
      {
        "from": "gpt",
        "value": "vase: [0.477, 0.578, 0.828, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000512194_key",
    "conversations": [
      {
        "from": "human",
        "value": "The vase is at the center with flowers in it.\nObjects: [vase]"
      },
      {
        "from": "gpt",
        "value": "vase: [0.477, 0.578, 0.828, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000512194_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the ceramic teapot with blooming flowers is at the center with flowers in it."
      },
      {
        "from": "gpt",
        "value": "ceramic teapot with blooming flowers: [0.477, 0.578, 0.828, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000512194_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the ceramic teapot with blooming flowers is at the center with flowers in it.\nObjects: [ceramic teapot with blooming flowers]"
      },
      {
        "from": "gpt",
        "value": "ceramic teapot with blooming flowers: [0.477, 0.578, 0.828, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000512194_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: vase: [0.477, 0.578, 0.828, 0.852]\nGiven the above layout, shift the vase upwards by 0.359."
      },
      {
        "from": "gpt",
        "value": "vase: [0.477, 0.219, 0.828, 0.492]"
      }
    ]
  },
  {
    "id": "coco_000000512330",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is open and facing towards the right with food items visible on the shelves."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.305, 0.000, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000512330_key",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is open and facing towards the right with food items visible on the shelves.\nObjects: [refrigerator]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.305, 0.000, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000512330_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel refrigerator is open and facing towards the right with food items visible on the shelves."
      },
      {
        "from": "gpt",
        "value": "stainless steel refrigerator: [0.305, 0.000, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000512330_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel refrigerator is open and facing towards the right with food items visible on the shelves.\nObjects: [stainless steel refrigerator]"
      },
      {
        "from": "gpt",
        "value": "stainless steel refrigerator: [0.305, 0.000, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000512330_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: refrigerator: [0.305, 0.000, 0.828, 0.992]\nGiven the above layout, shift the refrigerator to the left by 0.148."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.156, 0.000, 0.680, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000513484",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is sitting on the ground, facing to the left."
      },
      {
        "from": "gpt",
        "value": "bear: [0.016, 0.219, 0.742, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000513484_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is sitting on the ground, facing to the left.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.016, 0.219, 0.742, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000513484_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the hefty brown bear is sitting on the ground, facing to the left."
      },
      {
        "from": "gpt",
        "value": "hefty brown bear: [0.016, 0.219, 0.742, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000513484_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the hefty brown bear is sitting on the ground, facing to the left.\nObjects: [hefty brown bear]"
      },
      {
        "from": "gpt",
        "value": "hefty brown bear: [0.016, 0.219, 0.742, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000513484_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.016, 0.219, 0.742, 0.789]\nGiven the above layout, shift the bear to the right by 0.031."
      },
      {
        "from": "gpt",
        "value": "bear: [0.047, 0.219, 0.773, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000513580",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is in the air to the left above a motorcycle that is on the ground to the right."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.203, 0.297, 0.789, 0.617]\nmotorcycle: [0.164, 0.602, 0.383, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000513580_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is in the air to the left above a motorcycle that is on the ground to the right.\nObjects: [airplane, motorcycle]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.203, 0.297, 0.789, 0.617]\nmotorcycle: [0.164, 0.602, 0.383, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000513580_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an commercial jetliner is in the air to the left above a red sports motorcycle that is on the ground to the right."
      },
      {
        "from": "gpt",
        "value": "commercial jetliner: [0.203, 0.297, 0.789, 0.617]\nred sports motorcycle: [0.164, 0.602, 0.383, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000513580_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an commercial jetliner is in the air to the left above a red sports motorcycle that is on the ground to the right.\nObjects: [commercial jetliner, red sports motorcycle]"
      },
      {
        "from": "gpt",
        "value": "commercial jetliner: [0.203, 0.297, 0.789, 0.617]\nred sports motorcycle: [0.164, 0.602, 0.383, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000513580_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.203, 0.297, 0.789, 0.617]\nmotorcycle: [0.164, 0.602, 0.383, 0.734]\nGiven the above layout, shift the airplane upwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.203, 0.227, 0.789, 0.547]\nmotorcycle: [0.164, 0.602, 0.383, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000514376",
    "conversations": [
      {
        "from": "human",
        "value": "There is no bus in the image; it's a tram in the center moving away from the foreground."
      },
      {
        "from": "gpt",
        "value": "bus: [0.445, 0.406, 0.781, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000514376_key",
    "conversations": [
      {
        "from": "human",
        "value": "There is no bus in the image; its a tram in the center moving away from the foreground.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.445, 0.406, 0.781, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000514376_aug",
    "conversations": [
      {
        "from": "human",
        "value": "there is no bright green van in the image; it's a tram in the center moving away from the foreground."
      },
      {
        "from": "gpt",
        "value": "bright green van: [0.445, 0.406, 0.781, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000514376_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "there is no bright green van in the image; its a tram in the center moving away from the foreground.\nObjects: [bright green van]"
      },
      {
        "from": "gpt",
        "value": "bright green van: [0.445, 0.406, 0.781, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000514376_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.445, 0.406, 0.781, 0.648]\nGiven the above layout, shift the bus to the left by 0.242."
      },
      {
        "from": "gpt",
        "value": "bus: [0.203, 0.406, 0.539, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000530466",
    "conversations": [
      {
        "from": "human",
        "value": "A graffiti-covered train is stationed on the tracks to the right of the image, adjacent to a platform."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.125, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000530466_key",
    "conversations": [
      {
        "from": "human",
        "value": "A graffiti-covered train is stationed on the tracks to the right of the image, adjacent to a platform.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.125, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000530466_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a graffiti-covered multi-colored freight train is stationed on the tracks to the right of the image, adjacent to a platform."
      },
      {
        "from": "gpt",
        "value": "multi-colored freight train: [0.000, 0.125, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000530466_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a graffiti-covered multi-colored freight train is stationed on the tracks to the right of the image, adjacent to a platform.\nObjects: [multi-colored freight train]"
      },
      {
        "from": "gpt",
        "value": "multi-colored freight train: [0.000, 0.125, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000530466_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.125, 0.992, 0.820]\nGiven the above layout, shift the train downwards by 0.172."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.297, 0.992, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000532761",
    "conversations": [
      {
        "from": "human",
        "value": "A couch is positioned to the left of the room facing towards the center. A chair is to the right of the couch, angled towards the center. A television is located to the far right, facing the couch and chair."
      },
      {
        "from": "gpt",
        "value": "couch: [0.000, 0.477, 0.359, 0.859]\nchair: [0.578, 0.438, 0.828, 0.648]\ntv: [0.828, 0.359, 0.992, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000532761_key",
    "conversations": [
      {
        "from": "human",
        "value": "A couch is positioned to the left of the room facing towards the center. A chair is to the right of the couch, angled towards the center. A television is located to the far right, facing the couch and chair.\nObjects: [couch, chair, tv]"
      },
      {
        "from": "gpt",
        "value": "couch: [0.000, 0.477, 0.359, 0.859]\nchair: [0.578, 0.438, 0.828, 0.648]\ntv: [0.828, 0.359, 0.992, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000532761_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a comfortable blue couch is positioned to the left of the room facing towards the center. a vintage wooden chair is to the right of the comfortable blue couch, angled towards the center. a television is located to the far right, facing the comfortable blue couch and vintage wooden chair."
      },
      {
        "from": "gpt",
        "value": "comfortable blue couch: [0.000, 0.477, 0.359, 0.859]\nvintage wooden chair: [0.578, 0.438, 0.828, 0.648]\nflat-screen TV: [0.828, 0.359, 0.992, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000532761_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a comfortable blue couch is positioned to the left of the room facing towards the center. a vintage wooden chair is to the right of the comfortable blue couch, angled towards the center. a television is located to the far right, facing the comfortable blue couch and vintage wooden chair.\nObjects: [comfortable blue couch, vintage wooden chair, flat-screen TV]"
      },
      {
        "from": "gpt",
        "value": "comfortable blue couch: [0.000, 0.477, 0.359, 0.859]\nvintage wooden chair: [0.578, 0.438, 0.828, 0.648]\nflat-screen TV: [0.828, 0.359, 0.992, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000532761_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: couch: [0.000, 0.477, 0.359, 0.859]\nchair: [0.578, 0.438, 0.828, 0.648]\ntv: [0.828, 0.359, 0.992, 0.656]\nGiven the above layout, shift the tv upwards by 0.219."
      },
      {
        "from": "gpt",
        "value": "couch: [0.000, 0.477, 0.359, 0.859]\nchair: [0.578, 0.438, 0.828, 0.648]\ntv: [0.828, 0.141, 0.992, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000532855",
    "conversations": [
      {
        "from": "human",
        "value": "The person is partially visible at the top center of the image, standing on one leg with the other leg raised."
      },
      {
        "from": "gpt",
        "value": "person: [0.102, 0.141, 0.539, 0.492]"
      }
    ]
  },
  {
    "id": "coco_000000532855_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is partially visible at the top center of the image, standing on one leg with the other leg raised.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.102, 0.141, 0.539, 0.492]"
      }
    ]
  },
  {
    "id": "coco_000000532855_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the ballet dancer is partially visible at the top center of the image, standing on one leg with the other leg raised."
      },
      {
        "from": "gpt",
        "value": "ballet dancer: [0.102, 0.141, 0.539, 0.492]"
      }
    ]
  },
  {
    "id": "coco_000000532855_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the ballet dancer is partially visible at the top center of the image, standing on one leg with the other leg raised.\nObjects: [ballet dancer]"
      },
      {
        "from": "gpt",
        "value": "ballet dancer: [0.102, 0.141, 0.539, 0.492]"
      }
    ]
  },
  {
    "id": "coco_000000532855_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.102, 0.141, 0.539, 0.492]\nGiven the above layout, shift the person downwards by 0.273."
      },
      {
        "from": "gpt",
        "value": "person: [0.102, 0.414, 0.539, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000533816",
    "conversations": [
      {
        "from": "human",
        "value": "Two people facing each other across a tennis net with a third person standing to the right, beside the person on the near side."
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.344, 0.578, 0.797]\nperson: [0.617, 0.367, 0.758, 0.828]\nperson: [0.164, 0.375, 0.273, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000533816_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two people facing each other across a tennis net with a third person standing to the right, beside the person on the near side.\nObjects: [person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.344, 0.578, 0.797]\nperson: [0.617, 0.367, 0.758, 0.828]\nperson: [0.164, 0.375, 0.273, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000533855",
    "conversations": [
      {
        "from": "human",
        "value": "A donut with white icing and colorful sprinkles is at the center, resting on a dark surface."
      },
      {
        "from": "gpt",
        "value": "donut: [0.570, 0.344, 0.992, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000533855_key",
    "conversations": [
      {
        "from": "human",
        "value": "A donut with white icing and colorful sprinkles is at the center, resting on a dark surface.\nObjects: [donut]"
      },
      {
        "from": "gpt",
        "value": "donut: [0.570, 0.344, 0.992, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000533855_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a glazed pastry with rainbow sprinkles with white icing and colorful sprinkles is at the center, resting on a dark surface."
      },
      {
        "from": "gpt",
        "value": "glazed pastry with rainbow sprinkles: [0.570, 0.344, 0.992, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000533855_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a glazed pastry with rainbow sprinkles with white icing and colorful sprinkles is at the center, resting on a dark surface.\nObjects: [glazed pastry with rainbow sprinkles]"
      },
      {
        "from": "gpt",
        "value": "glazed pastry with rainbow sprinkles: [0.570, 0.344, 0.992, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000533855_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: donut: [0.570, 0.344, 0.992, 0.719]\nGiven the above layout, shift the donut to the left by 0.320."
      },
      {
        "from": "gpt",
        "value": "donut: [0.250, 0.344, 0.672, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000537241",
    "conversations": [
      {
        "from": "human",
        "value": "The donut is at the center of the image on a piece of paper."
      },
      {
        "from": "gpt",
        "value": "donut: [0.203, 0.203, 0.844, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000537241_key",
    "conversations": [
      {
        "from": "human",
        "value": "The donut is at the center of the image on a piece of paper.\nObjects: [donut]"
      },
      {
        "from": "gpt",
        "value": "donut: [0.203, 0.203, 0.844, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000537241_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the chocolate glazed donut is at the center of the image on a piece of paper."
      },
      {
        "from": "gpt",
        "value": "chocolate glazed donut: [0.203, 0.203, 0.844, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000537241_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the chocolate glazed donut is at the center of the image on a piece of paper.\nObjects: [chocolate glazed donut]"
      },
      {
        "from": "gpt",
        "value": "chocolate glazed donut: [0.203, 0.203, 0.844, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000537241_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: donut: [0.203, 0.203, 0.844, 0.773]\nGiven the above layout, shift the donut downwards by 0.219."
      },
      {
        "from": "gpt",
        "value": "donut: [0.203, 0.422, 0.844, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000537827",
    "conversations": [
      {
        "from": "human",
        "value": "Two people in baseball uniforms, one on the left and one slightly ahead to the right, both facing away and looking towards the field."
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.445, 0.367, 0.797]\nperson: [0.680, 0.367, 0.781, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000537827_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two people in baseball uniforms, one on the left and one slightly ahead to the right, both facing away and looking towards the field.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.445, 0.367, 0.797]\nperson: [0.680, 0.367, 0.781, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000542856",
    "conversations": [
      {
        "from": "human",
        "value": "A white and red bus is positioned in the center of the image, facing towards the right."
      },
      {
        "from": "gpt",
        "value": "bus: [0.008, 0.430, 0.922, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000542856_key",
    "conversations": [
      {
        "from": "human",
        "value": "A white and red bus is positioned in the center of the image, facing towards the right.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.008, 0.430, 0.922, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000542856_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a white and red double-decker bus is positioned in the center of the image, facing towards the right."
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.008, 0.430, 0.922, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000542856_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a white and red double-decker bus is positioned in the center of the image, facing towards the right.\nObjects: [double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.008, 0.430, 0.922, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000542856_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.008, 0.430, 0.922, 0.758]\nGiven the above layout, shift the bus upwards by 0.016."
      },
      {
        "from": "gpt",
        "value": "bus: [0.008, 0.414, 0.922, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000543047",
    "conversations": [
      {
        "from": "human",
        "value": "Two couches facing each other with a dining table at the center behind them."
      },
      {
        "from": "gpt",
        "value": "couch: [0.000, 0.508, 0.328, 0.859]\ncouch: [0.703, 0.492, 0.992, 0.867]\ndining table: [0.438, 0.438, 0.680, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000543047_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two couches facing each other with a dining table at the center behind them.\nObjects: [couch, couch, dining table]"
      },
      {
        "from": "gpt",
        "value": "couch: [0.000, 0.508, 0.328, 0.859]\ncouch: [0.703, 0.492, 0.992, 0.867]\ndining table: [0.438, 0.438, 0.680, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000543300",
    "conversations": [
      {
        "from": "human",
        "value": "The boat is centered on the water in front of buildings in the background."
      },
      {
        "from": "gpt",
        "value": "boat: [0.039, 0.531, 0.922, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000543300_key",
    "conversations": [
      {
        "from": "human",
        "value": "The boat is centered on the water in front of buildings in the background.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.039, 0.531, 0.922, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000543300_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the small fishing vessel is centered on the water in front of buildings in the background."
      },
      {
        "from": "gpt",
        "value": "small fishing vessel: [0.039, 0.531, 0.922, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000543300_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the small fishing vessel is centered on the water in front of buildings in the background.\nObjects: [small fishing vessel]"
      },
      {
        "from": "gpt",
        "value": "small fishing vessel: [0.039, 0.531, 0.922, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000543300_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.039, 0.531, 0.922, 0.734]\nGiven the above layout, shift the boat upwards by 0.344."
      },
      {
        "from": "gpt",
        "value": "boat: [0.039, 0.188, 0.922, 0.391]"
      }
    ]
  },
  {
    "id": "coco_000000543528",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is centered in the image, flying towards the viewer against a backdrop of white clouds."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.289, 0.250, 0.812, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000543528_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is centered in the image, flying towards the viewer against a backdrop of white clouds.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.289, 0.250, 0.812, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000543528_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an red biplane is centered in the image, flying towards the viewer against a backdrop of white clouds."
      },
      {
        "from": "gpt",
        "value": "red biplane: [0.289, 0.250, 0.812, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000543528_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an red biplane is centered in the image, flying towards the viewer against a backdrop of white clouds.\nObjects: [red biplane]"
      },
      {
        "from": "gpt",
        "value": "red biplane: [0.289, 0.250, 0.812, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000543528_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.289, 0.250, 0.812, 0.500]\nGiven the above layout, shift the airplane downwards by 0.414."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.289, 0.664, 0.812, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000544052",
    "conversations": [
      {
        "from": "human",
        "value": "The skateboard is at the center of the image with a figure standing on top of it."
      },
      {
        "from": "gpt",
        "value": "skateboard: [0.211, 0.594, 0.531, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000544052_key",
    "conversations": [
      {
        "from": "human",
        "value": "The skateboard is at the center of the image with a figure standing on top of it.\nObjects: [skateboard]"
      },
      {
        "from": "gpt",
        "value": "skateboard: [0.211, 0.594, 0.531, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000544052_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red skateboard is at the center of the image with a figure standing on top of it."
      },
      {
        "from": "gpt",
        "value": "red skateboard: [0.211, 0.594, 0.531, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000544052_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red skateboard is at the center of the image with a figure standing on top of it.\nObjects: [red skateboard]"
      },
      {
        "from": "gpt",
        "value": "red skateboard: [0.211, 0.594, 0.531, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000544052_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: skateboard: [0.211, 0.594, 0.531, 0.961]\nGiven the above layout, shift the skateboard upwards by 0.109."
      },
      {
        "from": "gpt",
        "value": "skateboard: [0.211, 0.484, 0.531, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000561256",
    "conversations": [
      {
        "from": "human",
        "value": "A person wearing a red shirt and a blue skirt, standing at the center, holding a device with their right hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.500, 0.312, 0.828, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000561256_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person wearing a red shirt and a blue skirt, standing at the center, holding a device with their right hand.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.500, 0.312, 0.828, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000561256_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a lady in a polka-dot dress wearing a red shirt and a blue skirt, standing at the center, holding a device with their right hand."
      },
      {
        "from": "gpt",
        "value": "lady in a polka-dot dress: [0.500, 0.312, 0.828, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000561256_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a lady in a polka-dot dress wearing a red shirt and a blue skirt, standing at the center, holding a device with their right hand.\nObjects: [lady in a polka-dot dress]"
      },
      {
        "from": "gpt",
        "value": "lady in a polka-dot dress: [0.500, 0.312, 0.828, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000561256_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.500, 0.312, 0.828, 0.859]\nGiven the above layout, shift the person to the left by 0.359."
      },
      {
        "from": "gpt",
        "value": "person: [0.141, 0.312, 0.469, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000562448",
    "conversations": [
      {
        "from": "human",
        "value": "A bus in motion, centered in the image, moving from left to right."
      },
      {
        "from": "gpt",
        "value": "bus: [0.039, 0.383, 0.734, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000562448_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bus in motion, centered in the image, moving from left to right.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.039, 0.383, 0.734, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000562448_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a city bus in motion, centered in the image, moving from left to right."
      },
      {
        "from": "gpt",
        "value": "city bus: [0.039, 0.383, 0.734, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000562448_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a city bus in motion, centered in the image, moving from left to right.\nObjects: [city bus]"
      },
      {
        "from": "gpt",
        "value": "city bus: [0.039, 0.383, 0.734, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000562448_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.039, 0.383, 0.734, 0.602]\nGiven the above layout, shift the bus downwards by 0.141."
      },
      {
        "from": "gpt",
        "value": "bus: [0.039, 0.523, 0.734, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000563349",
    "conversations": [
      {
        "from": "human",
        "value": "A person is airborne to the right side of the image, holding onto cables and attached to a snowboard which is angled slightly upwards."
      },
      {
        "from": "gpt",
        "value": "person: [0.453, 0.383, 0.727, 0.641]\nsnowboard: [0.727, 0.469, 0.773, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000563349_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is airborne to the right side of the image, holding onto cables and attached to a snowboard which is angled slightly upwards.\nObjects: [person, snowboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.453, 0.383, 0.727, 0.641]\nsnowboard: [0.727, 0.469, 0.773, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000563349_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a neon green neon green snowboarder is airborne to the right side of the image, holding onto cables and attached to a neon green snowboard which is angled slightly upwards."
      },
      {
        "from": "gpt",
        "value": "neon green snowboarder: [0.453, 0.383, 0.727, 0.641]\nneon green snowboard: [0.727, 0.469, 0.773, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000563349_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a neon green neon green snowboarder is airborne to the right side of the image, holding onto cables and attached to a neon green snowboard which is angled slightly upwards.\nObjects: [neon green snowboarder, neon green snowboard]"
      },
      {
        "from": "gpt",
        "value": "neon green snowboarder: [0.453, 0.383, 0.727, 0.641]\nneon green snowboard: [0.727, 0.469, 0.773, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000563349_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.453, 0.383, 0.727, 0.641]\nsnowboard: [0.727, 0.469, 0.773, 0.688]\nGiven the above layout, shift the person to the left by 0.086."
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.383, 0.641, 0.641]\nsnowboard: [0.727, 0.469, 0.773, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000563702",
    "conversations": [
      {
        "from": "human",
        "value": "A firetruck is parked on the street facing the left side of the image."
      },
      {
        "from": "gpt",
        "value": "truck: [0.414, 0.430, 0.953, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000563702_key",
    "conversations": [
      {
        "from": "human",
        "value": "A firetruck is parked on the street facing the left side of the image.\nObjects: [truck]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.414, 0.430, 0.953, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000563702_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a firered firetruck is parked on the street facing the left side of the image."
      },
      {
        "from": "gpt",
        "value": "red firetruck: [0.414, 0.430, 0.953, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000563702_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a firered firetruck is parked on the street facing the left side of the image.\nObjects: [red firetruck]"
      },
      {
        "from": "gpt",
        "value": "red firetruck: [0.414, 0.430, 0.953, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000563702_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.414, 0.430, 0.953, 0.656]\nGiven the above layout, shift the truck upwards by 0.109."
      },
      {
        "from": "gpt",
        "value": "truck: [0.414, 0.320, 0.953, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000565607",
    "conversations": [
      {
        "from": "human",
        "value": "A fire hydrant to the left, with three potted plants in a row extending to the right."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.695, 0.250, 0.953, 0.695]\npotted plant: [0.023, 0.562, 0.281, 0.688]\npotted plant: [0.281, 0.539, 0.523, 0.672]\npotted plant: [0.484, 0.383, 0.633, 0.508]"
      }
    ]
  },
  {
    "id": "coco_000000565607_key",
    "conversations": [
      {
        "from": "human",
        "value": "A fire hydrant to the left, with three potted plants in a row extending to the right.\nObjects: [fire hydrant, potted plant, potted plant, potted plant]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.695, 0.250, 0.953, 0.695]\npotted plant: [0.023, 0.562, 0.281, 0.688]\npotted plant: [0.281, 0.539, 0.523, 0.672]\npotted plant: [0.484, 0.383, 0.633, 0.508]"
      }
    ]
  },
  {
    "id": "coco_000000565624",
    "conversations": [
      {
        "from": "human",
        "value": "One elephant stands to the left in the foreground, while the other is slightly behind it to the right."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.477, 0.406, 0.969, 0.781]\nelephant: [0.062, 0.406, 0.227, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000565624_key",
    "conversations": [
      {
        "from": "human",
        "value": "One elephant stands to the left in the foreground, while the other is slightly behind it to the right.\nObjects: [elephant, elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.477, 0.406, 0.969, 0.781]\nelephant: [0.062, 0.406, 0.227, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000567432",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying in the center of the image with its underside facing the viewer."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.266, 0.531, 0.586, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000567432_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying in the center of the image with its underside facing the viewer.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.266, 0.531, 0.586, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000567432_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an commercial airliner is flying in the center of the image with its underside facing the viewer."
      },
      {
        "from": "gpt",
        "value": "commercial airliner: [0.266, 0.531, 0.586, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000567432_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an commercial airliner is flying in the center of the image with its underside facing the viewer.\nObjects: [commercial airliner]"
      },
      {
        "from": "gpt",
        "value": "commercial airliner: [0.266, 0.531, 0.586, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000567432_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.266, 0.531, 0.586, 0.805]\nGiven the above layout, shift the airplane upwards by 0.344."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.266, 0.188, 0.586, 0.461]"
      }
    ]
  },
  {
    "id": "coco_000000568981",
    "conversations": [
      {
        "from": "human",
        "value": "A person is kneeling on the left, holding a camera, pointing it towards another person who is skateboarding on the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.023, 0.406, 0.391, 0.750]\nperson: [0.883, 0.180, 0.992, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000568981_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is kneeling on the left, holding a camera, pointing it towards another person who is skateboarding on the right.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.023, 0.406, 0.391, 0.750]\nperson: [0.883, 0.180, 0.992, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000569700",
    "conversations": [
      {
        "from": "human",
        "value": "A potted plant is to the left of a vase."
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.016, 0.203, 0.867, 0.828]\nvase: [0.391, 0.609, 0.555, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000569700_key",
    "conversations": [
      {
        "from": "human",
        "value": "A potted plant is to the left of a vase.\nObjects: [potted plant, vase]"
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.016, 0.203, 0.867, 0.828]\nvase: [0.391, 0.609, 0.555, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000570169",
    "conversations": [
      {
        "from": "human",
        "value": "The teddy bear is behind a colorful toy hammer bench set towards the back of the image."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.234, 0.008, 0.820, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000570169_key",
    "conversations": [
      {
        "from": "human",
        "value": "The teddy bear is behind a colorful toy hammer bench set towards the back of the image.\nObjects: [teddy bear]"
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.234, 0.008, 0.820, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000570169_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the fluffy rabbit is behind a colorful toy hammer bench set towards the back of the image."
      },
      {
        "from": "gpt",
        "value": "fluffy rabbit: [0.234, 0.008, 0.820, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000570169_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the fluffy rabbit is behind a colorful toy hammer bench set towards the back of the image.\nObjects: [fluffy rabbit]"
      },
      {
        "from": "gpt",
        "value": "fluffy rabbit: [0.234, 0.008, 0.820, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000570169_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: teddy bear: [0.234, 0.008, 0.820, 0.523]\nGiven the above layout, shift the teddy bear downwards by 0.086."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.234, 0.094, 0.820, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000571008",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is at the center of the image."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.227, 0.234, 0.766, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000571008_key",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is at the center of the image.\nObjects: [stop sign]"
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.227, 0.234, 0.766, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000571008_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red stop sign is at the center of the image."
      },
      {
        "from": "gpt",
        "value": "red stop sign: [0.227, 0.234, 0.766, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000571008_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red stop sign is at the center of the image.\nObjects: [red stop sign]"
      },
      {
        "from": "gpt",
        "value": "red stop sign: [0.227, 0.234, 0.766, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000571008_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: stop sign: [0.227, 0.234, 0.766, 0.750]\nGiven the above layout, shift the stop sign downwards by 0.086."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.227, 0.320, 0.766, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000571893",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is not visible in the image provided. A book is on a shelf to the right."
      },
      {
        "from": "gpt",
        "value": "oven: [0.008, 0.359, 0.500, 0.609]\nbook: [0.461, 0.383, 0.508, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000571893_key",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is not visible in the image provided. A book is on a shelf to the right.\nObjects: [oven, book]"
      },
      {
        "from": "gpt",
        "value": "oven: [0.008, 0.359, 0.500, 0.609]\nbook: [0.461, 0.383, 0.508, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000571893_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the kitchen stove is not visible in the image provided. a hardcover dictionary is on a shelf to the right."
      },
      {
        "from": "gpt",
        "value": "kitchen stove: [0.008, 0.359, 0.500, 0.609]\nhardcover dictionary: [0.461, 0.383, 0.508, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000571893_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the kitchen stove is not visible in the image provided. a hardcover dictionary is on a shelf to the right.\nObjects: [kitchen stove, hardcover dictionary]"
      },
      {
        "from": "gpt",
        "value": "kitchen stove: [0.008, 0.359, 0.500, 0.609]\nhardcover dictionary: [0.461, 0.383, 0.508, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000571893_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: oven: [0.008, 0.359, 0.500, 0.609]\nbook: [0.461, 0.383, 0.508, 0.531]\nGiven the above layout, shift the book to the right by 0.312."
      },
      {
        "from": "gpt",
        "value": "oven: [0.008, 0.359, 0.500, 0.609]\nbook: [0.773, 0.383, 0.820, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000571943",
    "conversations": [
      {
        "from": "human",
        "value": "The traffic light is at the upper left corner, showing a yellow light."
      },
      {
        "from": "gpt",
        "value": "traffic light: [0.062, 0.305, 0.336, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000571943_key",
    "conversations": [
      {
        "from": "human",
        "value": "The traffic light is at the upper left corner, showing a yellow light.\nObjects: [traffic light]"
      },
      {
        "from": "gpt",
        "value": "traffic light: [0.062, 0.305, 0.336, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000571943_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the street traffic light is at the upper left corner, showing a yellow light."
      },
      {
        "from": "gpt",
        "value": "street traffic light: [0.062, 0.305, 0.336, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000571943_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the street traffic light is at the upper left corner, showing a yellow light.\nObjects: [street traffic light]"
      },
      {
        "from": "gpt",
        "value": "street traffic light: [0.062, 0.305, 0.336, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000571943_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: traffic light: [0.062, 0.305, 0.336, 0.641]\nGiven the above layout, shift the traffic light to the right by 0.469."
      },
      {
        "from": "gpt",
        "value": "traffic light: [0.531, 0.305, 0.805, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000005060",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on the floor in the center, visible through a mirror in the foreground."
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.477, 0.625, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000005060_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on the floor in the center, visible through a mirror in the foreground.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.477, 0.625, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000005060_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman is sitting on the floor in the center, visible through a mirror in the foreground."
      },
      {
        "from": "gpt",
        "value": "young woman: [0.367, 0.477, 0.625, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000005060_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman is sitting on the floor in the center, visible through a mirror in the foreground.\nObjects: [young woman]"
      },
      {
        "from": "gpt",
        "value": "young woman: [0.367, 0.477, 0.625, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000005060_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.367, 0.477, 0.625, 0.773]\nGiven the above layout, shift the person upwards by 0.234."
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.242, 0.625, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000005503",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center of the image with the seat cover lifted up."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.234, 0.352, 0.711, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000005503_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center of the image with the seat cover lifted up.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.234, 0.352, 0.711, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000005503_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the clean white toilet is at the center of the image with the seat cover lifted up."
      },
      {
        "from": "gpt",
        "value": "clean white toilet: [0.234, 0.352, 0.711, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000005503_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the clean white toilet is at the center of the image with the seat cover lifted up.\nObjects: [clean white toilet]"
      },
      {
        "from": "gpt",
        "value": "clean white toilet: [0.234, 0.352, 0.711, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000005503_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.234, 0.352, 0.711, 0.938]\nGiven the above layout, shift the toilet upwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.234, 0.312, 0.711, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000005529",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skiing down a snowy slope, positioned slightly to the right of the image's center. "
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.180, 0.547, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000005529_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skiing down a snowy slope, positioned slightly to the right of the images center. \nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.180, 0.547, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000005529_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a winter sport enthusiast is skiing down a snowy slope, positioned slightly to the right of the image's center. "
      },
      {
        "from": "gpt",
        "value": "winter sport enthusiast: [0.273, 0.180, 0.547, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000005529_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a winter sport enthusiast is skiing down a snowy slope, positioned slightly to the right of the images center. \nObjects: [winter sport enthusiast]"
      },
      {
        "from": "gpt",
        "value": "winter sport enthusiast: [0.273, 0.180, 0.547, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000005529_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.273, 0.180, 0.547, 0.695]\nGiven the above layout, shift the person to the right by 0.273."
      },
      {
        "from": "gpt",
        "value": "person: [0.547, 0.180, 0.820, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000006040",
    "conversations": [
      {
        "from": "human",
        "value": "The train is positioned horizontally across the image with its front facing to the right."
      },
      {
        "from": "gpt",
        "value": "train: [0.102, 0.352, 0.930, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000006040_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is positioned horizontally across the image with its front facing to the right.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.102, 0.352, 0.930, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000006040_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red locomotive is positioned horizontally across the image with its front facing to the right."
      },
      {
        "from": "gpt",
        "value": "red locomotive: [0.102, 0.352, 0.930, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000006040_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red locomotive is positioned horizontally across the image with its front facing to the right.\nObjects: [red locomotive]"
      },
      {
        "from": "gpt",
        "value": "red locomotive: [0.102, 0.352, 0.930, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000006040_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.102, 0.352, 0.930, 0.703]\nGiven the above layout, shift the train upwards by 0.133."
      },
      {
        "from": "gpt",
        "value": "train: [0.102, 0.219, 0.930, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000007386",
    "conversations": [
      {
        "from": "human",
        "value": "A motorcycle to the left with a truck partially visible in the background to the right."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.086, 0.188, 0.992, 0.828]\ntruck: [0.656, 0.406, 0.859, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000007386_key",
    "conversations": [
      {
        "from": "human",
        "value": "A motorcycle to the left with a truck partially visible in the background to the right.\nObjects: [motorcycle, truck]"
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.086, 0.188, 0.992, 0.828]\ntruck: [0.656, 0.406, 0.859, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000007386_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a motorcycle to the left with a truck partially visible in the background to the right."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.086, 0.188, 0.992, 0.828]\ntruck: [0.656, 0.406, 0.859, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000007386_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a motorcycle to the left with a truck partially visible in the background to the right.\nObjects: [motorcycle, truck]"
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.086, 0.188, 0.992, 0.828]\ntruck: [0.656, 0.406, 0.859, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000007386_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: motorcycle: [0.086, 0.188, 0.992, 0.828]\ntruck: [0.656, 0.406, 0.859, 0.555]\nGiven the above layout, shift the motorcycle upwards by 0.141."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.086, 0.047, 0.992, 0.688]\ntruck: [0.656, 0.406, 0.859, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000007784",
    "conversations": [
      {
        "from": "human",
        "value": "A red and white kite flying in the center of the blue sky."
      },
      {
        "from": "gpt",
        "value": "kite: [0.188, 0.297, 0.664, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000007784_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red and white kite flying in the center of the blue sky.\nObjects: [kite]"
      },
      {
        "from": "gpt",
        "value": "kite: [0.188, 0.297, 0.664, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000007784_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red and white yellow and blue kite flying in the center of the blue sky."
      },
      {
        "from": "gpt",
        "value": "yellow and blue kite: [0.188, 0.297, 0.664, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000007784_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red and white yellow and blue kite flying in the center of the blue sky.\nObjects: [yellow and blue kite]"
      },
      {
        "from": "gpt",
        "value": "yellow and blue kite: [0.188, 0.297, 0.664, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000007784_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: kite: [0.188, 0.297, 0.664, 0.734]\nGiven the above layout, shift the kite to the right by 0.203."
      },
      {
        "from": "gpt",
        "value": "kite: [0.391, 0.297, 0.867, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000007977",
    "conversations": [
      {
        "from": "human",
        "value": "The person is at the center of the image, skateboarding from left to right."
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.227, 0.570, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000007977_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is at the center of the image, skateboarding from left to right.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.227, 0.570, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000007977_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the teenager in a denim jacket is at the center of the image, skateboarding from left to right."
      },
      {
        "from": "gpt",
        "value": "teenager in a denim jacket: [0.328, 0.227, 0.570, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000007977_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the teenager in a denim jacket is at the center of the image, skateboarding from left to right.\nObjects: [teenager in a denim jacket]"
      },
      {
        "from": "gpt",
        "value": "teenager in a denim jacket: [0.328, 0.227, 0.570, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000007977_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.328, 0.227, 0.570, 0.648]\nGiven the above layout, shift the person to the right by 0.406."
      },
      {
        "from": "gpt",
        "value": "person: [0.734, 0.227, 0.977, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000008532",
    "conversations": [
      {
        "from": "human",
        "value": "The person is wearing a checkered cap, a blue shirt, and a red tie."
      },
      {
        "from": "gpt",
        "value": "person: [0.242, 0.180, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000008532_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is wearing a checkered cap, a blue shirt, and a red tie.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.242, 0.180, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000008532_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the business professional wearing formal attire is wearing a checkered cap, a blue shirt, and a red tie."
      },
      {
        "from": "gpt",
        "value": "business professional wearing formal attire: [0.242, 0.180, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000008532_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the business professional wearing formal attire is wearing a checkered cap, a blue shirt, and a red tie.\nObjects: [business professional wearing formal attire]"
      },
      {
        "from": "gpt",
        "value": "business professional wearing formal attire: [0.242, 0.180, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000008532_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.242, 0.180, 0.992, 0.828]\nGiven the above layout, shift the person to the left by 0.180."
      },
      {
        "from": "gpt",
        "value": "person: [0.062, 0.180, 0.812, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000008844",
    "conversations": [
      {
        "from": "human",
        "value": "There are three clusters of bananas on a table in the foreground, and a person stands behind the table in the background, centered between the banana clusters."
      },
      {
        "from": "gpt",
        "value": "banana: [0.000, 0.344, 0.602, 0.812]\nperson: [0.555, 0.258, 0.898, 0.594]\nbanana: [0.578, 0.547, 0.844, 0.758]\nbanana: [0.844, 0.570, 0.992, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000008844_key",
    "conversations": [
      {
        "from": "human",
        "value": "There are three clusters of bananas on a table in the foreground, and a person stands behind the table in the background, centered between the banana clusters.\nObjects: [banana, person, banana, banana]"
      },
      {
        "from": "gpt",
        "value": "banana: [0.000, 0.344, 0.602, 0.812]\nperson: [0.555, 0.258, 0.898, 0.594]\nbanana: [0.578, 0.547, 0.844, 0.758]\nbanana: [0.844, 0.570, 0.992, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000009483",
    "conversations": [
      {
        "from": "human",
        "value": "A person stands to the left side of the room, in front of a table that holds a TV in the center."
      },
      {
        "from": "gpt",
        "value": "person: [0.055, 0.219, 0.273, 0.867]\ntv: [0.711, 0.453, 0.898, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000009483_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person stands to the left side of the room, in front of a table that holds a TV in the center.\nObjects: [person, tv]"
      },
      {
        "from": "gpt",
        "value": "person: [0.055, 0.219, 0.273, 0.867]\ntv: [0.711, 0.453, 0.898, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000010764",
    "conversations": [
      {
        "from": "human",
        "value": "A person crouched behind home plate in the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.336, 0.289, 0.750, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000010764_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person crouched behind home plate in the center of the image.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.336, 0.289, 0.750, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000010764_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a baseball catcher crouched behind home plate in the center of the image."
      },
      {
        "from": "gpt",
        "value": "baseball catcher: [0.336, 0.289, 0.750, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000010764_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a baseball catcher crouched behind home plate in the center of the image.\nObjects: [baseball catcher]"
      },
      {
        "from": "gpt",
        "value": "baseball catcher: [0.336, 0.289, 0.750, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000010764_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.336, 0.289, 0.750, 0.781]\nGiven the above layout, shift the person to the left by 0.133."
      },
      {
        "from": "gpt",
        "value": "person: [0.203, 0.289, 0.617, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000010995",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is in the center of the image, with the headboard against the wall on the right."
      },
      {
        "from": "gpt",
        "value": "bed: [0.164, 0.453, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000010995_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is in the center of the image, with the headboard against the wall on the right.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.164, 0.453, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000010995_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the Queen-sized bed with blue blankets is in the center of the image, with the headboard against the wall on the right."
      },
      {
        "from": "gpt",
        "value": "Queen-sized bed with blue blankets: [0.164, 0.453, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000010995_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the Queen-sized bed with blue blankets is in the center of the image, with the headboard against the wall on the right.\nObjects: [Queen-sized bed with blue blankets]"
      },
      {
        "from": "gpt",
        "value": "Queen-sized bed with blue blankets: [0.164, 0.453, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000010995_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.164, 0.453, 0.992, 0.859]\nGiven the above layout, shift the bed upwards by 0.414."
      },
      {
        "from": "gpt",
        "value": "bed: [0.164, 0.039, 0.992, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000011760",
    "conversations": [
      {
        "from": "human",
        "value": "Three zebras facing the camera; one in the center and one on each side slightly behind the central zebra."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.055, 0.320, 0.336, 0.766]\nzebra: [0.703, 0.305, 0.938, 0.812]\nzebra: [0.414, 0.320, 0.602, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000011760_key",
    "conversations": [
      {
        "from": "human",
        "value": "Three zebras facing the camera; one in the center and one on each side slightly behind the central zebra.\nObjects: [zebra, zebra, zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.055, 0.320, 0.336, 0.766]\nzebra: [0.703, 0.305, 0.938, 0.812]\nzebra: [0.414, 0.320, 0.602, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000012639",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing ready to bat at the center, another person is crouching as a catcher behind them, and a third person stands in the background observing."
      },
      {
        "from": "gpt",
        "value": "person: [0.156, 0.484, 0.406, 0.859]\nperson: [0.430, 0.320, 0.617, 0.805]\nperson: [0.758, 0.195, 0.852, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000012639_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing ready to bat at the center, another person is crouching as a catcher behind them, and a third person stands in the background observing.\nObjects: [person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.156, 0.484, 0.406, 0.859]\nperson: [0.430, 0.320, 0.617, 0.805]\nperson: [0.758, 0.195, 0.852, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000012667",
    "conversations": [
      {
        "from": "human",
        "value": "A banana is placed on top of the telephone to the right side."
      },
      {
        "from": "gpt",
        "value": "banana: [0.438, 0.203, 0.695, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000012667_key",
    "conversations": [
      {
        "from": "human",
        "value": "A banana is placed on top of the telephone to the right side.\nObjects: [banana]"
      },
      {
        "from": "gpt",
        "value": "banana: [0.438, 0.203, 0.695, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000012667_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a ripe banana is placed on top of the telephone to the right side."
      },
      {
        "from": "gpt",
        "value": "ripe banana: [0.438, 0.203, 0.695, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000012667_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a ripe banana is placed on top of the telephone to the right side.\nObjects: [ripe banana]"
      },
      {
        "from": "gpt",
        "value": "ripe banana: [0.438, 0.203, 0.695, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000012667_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: banana: [0.438, 0.203, 0.695, 0.570]\nGiven the above layout, shift the banana to the left by 0.047."
      },
      {
        "from": "gpt",
        "value": "banana: [0.391, 0.203, 0.648, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000013201",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center of the image, skateboarding on a ramp."
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.133, 0.664, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000013201_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center of the image, skateboarding on a ramp.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.133, 0.664, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000013201_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager with a red cap is in the center of the image, skateboarding on a ramp."
      },
      {
        "from": "gpt",
        "value": "teenager with a red cap: [0.312, 0.133, 0.664, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000013201_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager with a red cap is in the center of the image, skateboarding on a ramp.\nObjects: [teenager with a red cap]"
      },
      {
        "from": "gpt",
        "value": "teenager with a red cap: [0.312, 0.133, 0.664, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000013201_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.312, 0.133, 0.664, 0.789]\nGiven the above layout, shift the person to the right by 0.297."
      },
      {
        "from": "gpt",
        "value": "person: [0.609, 0.133, 0.961, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000013348",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is at the center of the image, parked on the tarmac."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.000, 0.383, 0.875, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000013348_key",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is at the center of the image, parked on the tarmac.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.000, 0.383, 0.875, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000013348_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the large commercial jetliner is at the center of the image, parked on the tarmac."
      },
      {
        "from": "gpt",
        "value": "large commercial jetliner: [0.000, 0.383, 0.875, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000013348_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the large commercial jetliner is at the center of the image, parked on the tarmac.\nObjects: [large commercial jetliner]"
      },
      {
        "from": "gpt",
        "value": "large commercial jetliner: [0.000, 0.383, 0.875, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000013348_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.000, 0.383, 0.875, 0.609]\nGiven the above layout, shift the airplane upwards by 0.242."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.000, 0.141, 0.875, 0.367]"
      }
    ]
  },
  {
    "id": "coco_000000013546",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding on a ramp at the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.727, 0.172, 0.891, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000013546_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding on a ramp at the center of the image.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.727, 0.172, 0.891, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000013546_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage boy is skateboarding on a ramp at the center of the image."
      },
      {
        "from": "gpt",
        "value": "teenage boy: [0.727, 0.172, 0.891, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000013546_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage boy is skateboarding on a ramp at the center of the image.\nObjects: [teenage boy]"
      },
      {
        "from": "gpt",
        "value": "teenage boy: [0.727, 0.172, 0.891, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000013546_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.727, 0.172, 0.891, 0.570]\nGiven the above layout, shift the person to the left by 0.461."
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.172, 0.430, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000014038",
    "conversations": [
      {
        "from": "human",
        "value": "A refrigerator is on the left, a dining table is at the center, and a potted plant is on the table."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.031, 0.406, 0.227, 0.820]\ndining table: [0.773, 0.633, 0.992, 0.820]\npotted plant: [0.773, 0.227, 0.859, 0.367]"
      }
    ]
  },
  {
    "id": "coco_000000014038_key",
    "conversations": [
      {
        "from": "human",
        "value": "A refrigerator is on the left, a dining table is at the center, and a potted plant is on the table.\nObjects: [refrigerator, dining table, potted plant]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.031, 0.406, 0.227, 0.820]\ndining table: [0.773, 0.633, 0.992, 0.820]\npotted plant: [0.773, 0.227, 0.859, 0.367]"
      }
    ]
  },
  {
    "id": "coco_000000014038_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a double-door fridge is on the left, a oak wood dining table is at the center, and a small fern in a terracotta pot is on the table."
      },
      {
        "from": "gpt",
        "value": "double-door fridge: [0.031, 0.406, 0.227, 0.820]\noak wood dining table: [0.773, 0.633, 0.992, 0.820]\nsmall fern in a terracotta pot: [0.773, 0.227, 0.859, 0.367]"
      }
    ]
  },
  {
    "id": "coco_000000014038_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a double-door fridge is on the left, a oak wood dining table is at the center, and a small fern in a terracotta pot is on the table.\nObjects: [double-door fridge, oak wood dining table, small fern in a terracotta pot]"
      },
      {
        "from": "gpt",
        "value": "double-door fridge: [0.031, 0.406, 0.227, 0.820]\noak wood dining table: [0.773, 0.633, 0.992, 0.820]\nsmall fern in a terracotta pot: [0.773, 0.227, 0.859, 0.367]"
      }
    ]
  },
  {
    "id": "coco_000000014038_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: refrigerator: [0.031, 0.406, 0.227, 0.820]\ndining table: [0.773, 0.633, 0.992, 0.820]\npotted plant: [0.773, 0.227, 0.859, 0.367]\nGiven the above layout, shift the potted plant upwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.031, 0.406, 0.227, 0.820]\ndining table: [0.773, 0.633, 0.992, 0.820]\npotted plant: [0.773, 0.188, 0.859, 0.328]"
      }
    ]
  },
  {
    "id": "coco_000000014380",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks at the center of the image, partially under the bridge."
      },
      {
        "from": "gpt",
        "value": "train: [0.289, 0.570, 0.992, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000014380_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks at the center of the image, partially under the bridge.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.289, 0.570, 0.992, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000014380_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the diesel locomotive is on the tracks at the center of the image, partially under the bridge."
      },
      {
        "from": "gpt",
        "value": "diesel locomotive: [0.289, 0.570, 0.992, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000014380_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the diesel locomotive is on the tracks at the center of the image, partially under the bridge.\nObjects: [diesel locomotive]"
      },
      {
        "from": "gpt",
        "value": "diesel locomotive: [0.289, 0.570, 0.992, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000014380_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.289, 0.570, 0.992, 0.758]\nGiven the above layout, shift the train upwards by 0.219."
      },
      {
        "from": "gpt",
        "value": "train: [0.289, 0.352, 0.992, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000014473",
    "conversations": [
      {
        "from": "human",
        "value": "A red and black train is on the tracks moving from left to right in the center of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.406, 0.922, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000014473_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red and black train is on the tracks moving from left to right in the center of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.406, 0.922, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000014473_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red and black red and black freight locomotive is on the tracks moving from left to right in the center of the image."
      },
      {
        "from": "gpt",
        "value": "red and black freight locomotive: [0.000, 0.406, 0.922, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000014473_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red and black red and black freight locomotive is on the tracks moving from left to right in the center of the image.\nObjects: [red and black freight locomotive]"
      },
      {
        "from": "gpt",
        "value": "red and black freight locomotive: [0.000, 0.406, 0.922, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000014473_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.406, 0.922, 0.641]\nGiven the above layout, shift the train upwards by 0.102."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.305, 0.922, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000014888",
    "conversations": [
      {
        "from": "human",
        "value": "The cow is in the center of the image with a milking machine attached to its udder."
      },
      {
        "from": "gpt",
        "value": "cow: [0.000, 0.125, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000014888_key",
    "conversations": [
      {
        "from": "human",
        "value": "The cow is in the center of the image with a milking machine attached to its udder.\nObjects: [cow]"
      },
      {
        "from": "gpt",
        "value": "cow: [0.000, 0.125, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000014888_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the highland cow is in the center of the image with a milking machine attached to its udder."
      },
      {
        "from": "gpt",
        "value": "highland cow: [0.000, 0.125, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000014888_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the highland cow is in the center of the image with a milking machine attached to its udder.\nObjects: [highland cow]"
      },
      {
        "from": "gpt",
        "value": "highland cow: [0.000, 0.125, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000014888_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cow: [0.000, 0.125, 0.992, 0.805]\nGiven the above layout, shift the cow downwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "cow: [0.000, 0.148, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000015278",
    "conversations": [
      {
        "from": "human",
        "value": "The broccoli is scattered across the plate, with some pieces in the center and others spread towards the edges."
      },
      {
        "from": "gpt",
        "value": "broccoli: [0.000, 0.188, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000015278_key",
    "conversations": [
      {
        "from": "human",
        "value": "The broccoli is scattered across the plate, with some pieces in the center and others spread towards the edges.\nObjects: [broccoli]"
      },
      {
        "from": "gpt",
        "value": "broccoli: [0.000, 0.188, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000015278_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the green peas is scattered across the plate, with some pieces in the center and others spread towards the edges."
      },
      {
        "from": "gpt",
        "value": "green peas: [0.000, 0.188, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000015278_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the green peas is scattered across the plate, with some pieces in the center and others spread towards the edges.\nObjects: [green peas]"
      },
      {
        "from": "gpt",
        "value": "green peas: [0.000, 0.188, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000015278_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: broccoli: [0.000, 0.188, 0.992, 0.859]\nGiven the above layout, shift the broccoli upwards by 0.016."
      },
      {
        "from": "gpt",
        "value": "broccoli: [0.000, 0.172, 0.992, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000015597",
    "conversations": [
      {
        "from": "human",
        "value": "A person on a skateboard at the center with a bicycle lying on its side to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.273, 0.477, 0.586]\nskateboard: [0.320, 0.492, 0.469, 0.594]\nbicycle: [0.641, 0.648, 0.820, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000015597_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person on a skateboard at the center with a bicycle lying on its side to the right.\nObjects: [person, skateboard, bicycle]"
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.273, 0.477, 0.586]\nskateboard: [0.320, 0.492, 0.469, 0.594]\nbicycle: [0.641, 0.648, 0.820, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000015597_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a person on a skateboard at the center with a bicycle lying on its side to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.273, 0.477, 0.586]\nskateboard: [0.320, 0.492, 0.469, 0.594]\nbicycle: [0.641, 0.648, 0.820, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000015597_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a person on a skateboard at the center with a bicycle lying on its side to the right.\nObjects: [person, skateboard, bicycle]"
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.273, 0.477, 0.586]\nskateboard: [0.320, 0.492, 0.469, 0.594]\nbicycle: [0.641, 0.648, 0.820, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000015597_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.172, 0.273, 0.477, 0.586]\nskateboard: [0.320, 0.492, 0.469, 0.594]\nbicycle: [0.641, 0.648, 0.820, 0.719]\nGiven the above layout, shift the person upwards by 0.188."
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.086, 0.477, 0.398]\nskateboard: [0.320, 0.492, 0.469, 0.594]\nbicycle: [0.641, 0.648, 0.820, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000039956",
    "conversations": [
      {
        "from": "human",
        "value": "A bed is centered in the foreground of the image with a chair to the right in the background."
      },
      {
        "from": "gpt",
        "value": "bed: [0.000, 0.492, 0.562, 0.797]\nchair: [0.805, 0.453, 0.992, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000039956_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bed is centered in the foreground of the image with a chair to the right in the background.\nObjects: [bed, chair]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.000, 0.492, 0.562, 0.797]\nchair: [0.805, 0.453, 0.992, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000039956_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a king-sized bed is centered in the foreground of the image with a wooden chair to the right in the background."
      },
      {
        "from": "gpt",
        "value": "king-sized bed: [0.000, 0.492, 0.562, 0.797]\nwooden chair: [0.805, 0.453, 0.992, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000039956_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a king-sized bed is centered in the foreground of the image with a wooden chair to the right in the background.\nObjects: [king-sized bed, wooden chair]"
      },
      {
        "from": "gpt",
        "value": "king-sized bed: [0.000, 0.492, 0.562, 0.797]\nwooden chair: [0.805, 0.453, 0.992, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000039956_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.000, 0.492, 0.562, 0.797]\nchair: [0.805, 0.453, 0.992, 0.664]\nGiven the above layout, shift the chair upwards by 0.062."
      },
      {
        "from": "gpt",
        "value": "bed: [0.000, 0.492, 0.562, 0.797]\nchair: [0.805, 0.391, 0.992, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000041633",
    "conversations": [
      {
        "from": "human",
        "value": "A red truck is positioned in the center of the image from a low angle, showcasing its right side with the bed of the truck visible."
      },
      {
        "from": "gpt",
        "value": "truck: [0.016, 0.430, 0.883, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000041633_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red truck is positioned in the center of the image from a low angle, showcasing its right side with the bed of the truck visible.\nObjects: [truck]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.016, 0.430, 0.883, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000041633_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red fire engine red pick-up truck is positioned in the center of the image from a low angle, showcasing its right side with the bed of the fire engine red pick-up truck visible."
      },
      {
        "from": "gpt",
        "value": "fire engine red pick-up truck: [0.016, 0.430, 0.883, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000041633_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red fire engine red pick-up truck is positioned in the center of the image from a low angle, showcasing its right side with the bed of the fire engine red pick-up truck visible.\nObjects: [fire engine red pick-up truck]"
      },
      {
        "from": "gpt",
        "value": "fire engine red pick-up truck: [0.016, 0.430, 0.883, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000041633_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.016, 0.430, 0.883, 0.820]\nGiven the above layout, shift the truck upwards by 0.266."
      },
      {
        "from": "gpt",
        "value": "truck: [0.016, 0.164, 0.883, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000042296",
    "conversations": [
      {
        "from": "human",
        "value": "A bear is playing with a green sports ball in the water, with a yellow ball floating to the left of the bear."
      },
      {
        "from": "gpt",
        "value": "bear: [0.227, 0.172, 0.914, 0.641]\nsports ball: [0.289, 0.508, 0.477, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000042296_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bear is playing with a green sports ball in the water, with a yellow ball floating to the left of the bear.\nObjects: [bear, sports ball]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.227, 0.172, 0.914, 0.641]\nsports ball: [0.289, 0.508, 0.477, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000042296_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a brown bear is playing with a green green football in the water, with a yellow ball floating to the left of the brown bear."
      },
      {
        "from": "gpt",
        "value": "brown bear: [0.227, 0.172, 0.914, 0.641]\ngreen football: [0.289, 0.508, 0.477, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000042296_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a brown bear is playing with a green green football in the water, with a yellow ball floating to the left of the brown bear.\nObjects: [brown bear, green football]"
      },
      {
        "from": "gpt",
        "value": "brown bear: [0.227, 0.172, 0.914, 0.641]\ngreen football: [0.289, 0.508, 0.477, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000042296_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.227, 0.172, 0.914, 0.641]\nsports ball: [0.289, 0.508, 0.477, 0.664]\nGiven the above layout, shift the sports ball downwards by 0.125."
      },
      {
        "from": "gpt",
        "value": "bear: [0.227, 0.172, 0.914, 0.641]\nsports ball: [0.289, 0.633, 0.477, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000042889",
    "conversations": [
      {
        "from": "human",
        "value": "A teddy bear is sitting behind a keyboard."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.242, 0.102, 0.805, 0.695]\nkeyboard: [0.250, 0.750, 0.820, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000042889_key",
    "conversations": [
      {
        "from": "human",
        "value": "A teddy bear is sitting behind a keyboard.\nObjects: [teddy bear, keyboard]"
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.242, 0.102, 0.805, 0.695]\nkeyboard: [0.250, 0.750, 0.820, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000042889_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a plush panda bear is sitting behind a electronic piano keyboard."
      },
      {
        "from": "gpt",
        "value": "plush panda bear: [0.242, 0.102, 0.805, 0.695]\nelectronic piano keyboard: [0.250, 0.750, 0.820, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000042889_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a plush panda bear is sitting behind a electronic piano keyboard.\nObjects: [plush panda bear, electronic piano keyboard]"
      },
      {
        "from": "gpt",
        "value": "plush panda bear: [0.242, 0.102, 0.805, 0.695]\nelectronic piano keyboard: [0.250, 0.750, 0.820, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000042889_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: teddy bear: [0.242, 0.102, 0.805, 0.695]\nkeyboard: [0.250, 0.750, 0.820, 0.992]\nGiven the above layout, shift the teddy bear to the left by 0.133."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.109, 0.102, 0.672, 0.695]\nkeyboard: [0.250, 0.750, 0.820, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000045070",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on top of a horse."
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.094, 0.672, 0.789]\nhorse: [0.000, 0.711, 0.992, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000045070_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on top of a horse.\nObjects: [person, horse]"
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.094, 0.672, 0.789]\nhorse: [0.000, 0.711, 0.992, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000045070_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a teenager in jeans is sitting on top of a palomino horse."
      },
      {
        "from": "gpt",
        "value": "a teenager in jeans: [0.172, 0.094, 0.672, 0.789]\npalomino horse: [0.000, 0.711, 0.992, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000045070_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a teenager in jeans is sitting on top of a palomino horse.\nObjects: [a teenager in jeans, palomino horse]"
      },
      {
        "from": "gpt",
        "value": "a teenager in jeans: [0.172, 0.094, 0.672, 0.789]\npalomino horse: [0.000, 0.711, 0.992, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000045070_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.172, 0.094, 0.672, 0.789]\nhorse: [0.000, 0.711, 0.992, 0.945]\nGiven the above layout, shift the person upwards by 0.016."
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.078, 0.672, 0.773]\nhorse: [0.000, 0.711, 0.992, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000046804",
    "conversations": [
      {
        "from": "human",
        "value": "A sheep is standing in the center of the image with a stone wall and vegetation in the background."
      },
      {
        "from": "gpt",
        "value": "sheep: [0.344, 0.219, 0.711, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000046804_key",
    "conversations": [
      {
        "from": "human",
        "value": "A sheep is standing in the center of the image with a stone wall and vegetation in the background.\nObjects: [sheep]"
      },
      {
        "from": "gpt",
        "value": "sheep: [0.344, 0.219, 0.711, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000046804_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a fluffy white lamb is standing in the center of the image with a stone wall and vegetation in the background."
      },
      {
        "from": "gpt",
        "value": "fluffy white lamb: [0.344, 0.219, 0.711, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000046804_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a fluffy white lamb is standing in the center of the image with a stone wall and vegetation in the background.\nObjects: [fluffy white lamb]"
      },
      {
        "from": "gpt",
        "value": "fluffy white lamb: [0.344, 0.219, 0.711, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000046804_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sheep: [0.344, 0.219, 0.711, 0.688]\nGiven the above layout, shift the sheep to the left by 0.234."
      },
      {
        "from": "gpt",
        "value": "sheep: [0.109, 0.219, 0.477, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000047801",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting with a plate of food in their lap, holding a fork in their right hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.094, 0.133, 0.906, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000047801_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting with a plate of food in their lap, holding a fork in their right hand.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.094, 0.133, 0.906, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000047801_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman is sitting with a plate of food in their lap, holding a fork in their right hand."
      },
      {
        "from": "gpt",
        "value": "young woman: [0.094, 0.133, 0.906, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000047801_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman is sitting with a plate of food in their lap, holding a fork in their right hand.\nObjects: [young woman]"
      },
      {
        "from": "gpt",
        "value": "young woman: [0.094, 0.133, 0.906, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000047801_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.094, 0.133, 0.906, 0.859]\nGiven the above layout, shift the person upwards by 0.109."
      },
      {
        "from": "gpt",
        "value": "person: [0.094, 0.023, 0.906, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000048564",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center of the image wearing a black jacket and a blue and white patterned garment underneath."
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.000, 0.820, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000048564_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center of the image wearing a black jacket and a blue and white patterned garment underneath.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.000, 0.820, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000048564_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a man in a formal suit is standing in the center of the image wearing a black jacket and a blue and white patterned garment underneath."
      },
      {
        "from": "gpt",
        "value": "a man in a formal suit: [0.172, 0.000, 0.820, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000048564_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a man in a formal suit is standing in the center of the image wearing a black jacket and a blue and white patterned garment underneath.\nObjects: [a man in a formal suit]"
      },
      {
        "from": "gpt",
        "value": "a man in a formal suit: [0.172, 0.000, 0.820, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000048564_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.172, 0.000, 0.820, 0.977]\nGiven the above layout, shift the person to the left by 0.156."
      },
      {
        "from": "gpt",
        "value": "person: [0.016, 0.000, 0.664, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000048924",
    "conversations": [
      {
        "from": "human",
        "value": "A motorcycle is positioned on the right side of the image with its front facing towards the left."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.438, 0.336, 0.727, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000048924_key",
    "conversations": [
      {
        "from": "human",
        "value": "A motorcycle is positioned on the right side of the image with its front facing towards the left.\nObjects: [motorcycle]"
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.438, 0.336, 0.727, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000048924_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red sports motorcycle is positioned on the right side of the image with its front facing towards the left."
      },
      {
        "from": "gpt",
        "value": "red sports motorcycle: [0.438, 0.336, 0.727, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000048924_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red sports motorcycle is positioned on the right side of the image with its front facing towards the left.\nObjects: [red sports motorcycle]"
      },
      {
        "from": "gpt",
        "value": "red sports motorcycle: [0.438, 0.336, 0.727, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000048924_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: motorcycle: [0.438, 0.336, 0.727, 0.797]\nGiven the above layout, shift the motorcycle to the left by 0.250."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.188, 0.336, 0.477, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000049759",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the foreground is preparing to serve a volleyball, two people are standing in the midground on the same side of the net, and another person is visible in the background on the opposite side of the net."
      },
      {
        "from": "gpt",
        "value": "person: [0.734, 0.391, 0.914, 0.852]\nperson: [0.852, 0.414, 0.906, 0.578]\nperson: [0.516, 0.398, 0.570, 0.547]\nperson: [0.328, 0.398, 0.375, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000049759_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the foreground is preparing to serve a volleyball, two people are standing in the midground on the same side of the net, and another person is visible in the background on the opposite side of the net.\nObjects: [person, person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.734, 0.391, 0.914, 0.852]\nperson: [0.852, 0.414, 0.906, 0.578]\nperson: [0.516, 0.398, 0.570, 0.547]\nperson: [0.328, 0.398, 0.375, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000050326",
    "conversations": [
      {
        "from": "human",
        "value": "A chair is in the foreground on the left, and a person stands in the background on the right, near the water's edge on a beach."
      },
      {
        "from": "gpt",
        "value": "chair: [0.625, 0.125, 0.992, 0.641]\nperson: [0.023, 0.188, 0.359, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000050326_key",
    "conversations": [
      {
        "from": "human",
        "value": "A chair is in the foreground on the left, and a person stands in the background on the right, near the waters edge on a beach.\nObjects: [chair, person]"
      },
      {
        "from": "gpt",
        "value": "chair: [0.625, 0.125, 0.992, 0.641]\nperson: [0.023, 0.188, 0.359, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000050326_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a wooden sun lounger is in the foreground on the left, and a surfer stands in the background on the right, near the water's edge on a beach."
      },
      {
        "from": "gpt",
        "value": "wooden sun lounger: [0.625, 0.125, 0.992, 0.641]\nsurfer: [0.023, 0.188, 0.359, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000050326_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a wooden sun lounger is in the foreground on the left, and a surfer stands in the background on the right, near the waters edge on a beach.\nObjects: [wooden sun lounger, surfer]"
      },
      {
        "from": "gpt",
        "value": "wooden sun lounger: [0.625, 0.125, 0.992, 0.641]\nsurfer: [0.023, 0.188, 0.359, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000050326_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: chair: [0.625, 0.125, 0.992, 0.641]\nperson: [0.023, 0.188, 0.359, 0.695]\nGiven the above layout, shift the person downwards by 0.078."
      },
      {
        "from": "gpt",
        "value": "chair: [0.625, 0.125, 0.992, 0.641]\nperson: [0.023, 0.266, 0.359, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000050679",
    "conversations": [
      {
        "from": "human",
        "value": "An orange is on the ground near the edge of a street, with cars in the background."
      },
      {
        "from": "gpt",
        "value": "orange: [0.211, 0.320, 0.539, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000050679_key",
    "conversations": [
      {
        "from": "human",
        "value": "An orange is on the ground near the edge of a street, with cars in the background.\nObjects: [orange]"
      },
      {
        "from": "gpt",
        "value": "orange: [0.211, 0.320, 0.539, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000050679_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an fallen apple is on the ground near the edge of a street, with cars in the background."
      },
      {
        "from": "gpt",
        "value": "fallen apple: [0.211, 0.320, 0.539, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000050679_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an fallen apple is on the ground near the edge of a street, with cars in the background.\nObjects: [fallen apple]"
      },
      {
        "from": "gpt",
        "value": "fallen apple: [0.211, 0.320, 0.539, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000050679_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: orange: [0.211, 0.320, 0.539, 0.648]\nGiven the above layout, shift the orange to the right by 0.023."
      },
      {
        "from": "gpt",
        "value": "orange: [0.234, 0.320, 0.562, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000051314",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the center of the image standing on a surfboard."
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.180, 0.688, 0.656]\nsurfboard: [0.070, 0.516, 0.336, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000051314_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the center of the image standing on a surfboard.\nObjects: [person, surfboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.180, 0.688, 0.656]\nsurfboard: [0.070, 0.516, 0.336, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000051314_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a individual with sunglasses in the center of the image standing on a multicolored surfboard."
      },
      {
        "from": "gpt",
        "value": "individual with sunglasses: [0.352, 0.180, 0.688, 0.656]\nmulticolored surfboard: [0.070, 0.516, 0.336, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000051314_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a individual with sunglasses in the center of the image standing on a multicolored surfboard.\nObjects: [individual with sunglasses, multicolored surfboard]"
      },
      {
        "from": "gpt",
        "value": "individual with sunglasses: [0.352, 0.180, 0.688, 0.656]\nmulticolored surfboard: [0.070, 0.516, 0.336, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000051314_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.352, 0.180, 0.688, 0.656]\nsurfboard: [0.070, 0.516, 0.336, 0.633]\nGiven the above layout, shift the person downwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.203, 0.688, 0.680]\nsurfboard: [0.070, 0.516, 0.336, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000080057",
    "conversations": [
      {
        "from": "human",
        "value": "The teddy bear is at the center behind a toy hammer and colorful pegs on a pegboard."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.172, 0.016, 0.758, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000080057_key",
    "conversations": [
      {
        "from": "human",
        "value": "The teddy bear is at the center behind a toy hammer and colorful pegs on a pegboard.\nObjects: [teddy bear]"
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.172, 0.016, 0.758, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000080057_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the fluffy teddy bear is at the center behind a toy hammer and colorful pegs on a pegboard."
      },
      {
        "from": "gpt",
        "value": "fluffy teddy bear: [0.172, 0.016, 0.758, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000080057_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the fluffy teddy bear is at the center behind a toy hammer and colorful pegs on a pegboard.\nObjects: [fluffy teddy bear]"
      },
      {
        "from": "gpt",
        "value": "fluffy teddy bear: [0.172, 0.016, 0.758, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000080057_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: teddy bear: [0.172, 0.016, 0.758, 0.625]\nGiven the above layout, shift the teddy bear downwards by 0.188."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.172, 0.203, 0.758, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000080273",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a snowboard, which is positioned at the center of the image on snow."
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.234, 0.586, 0.812]\nsnowboard: [0.172, 0.750, 0.766, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000080273_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a snowboard, which is positioned at the center of the image on snow.\nObjects: [person, snowboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.234, 0.586, 0.812]\nsnowboard: [0.172, 0.750, 0.766, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000080273_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek sleek snowboarding enthusiast is standing on a sleek snowboard, which is positioned at the center of the image on snow."
      },
      {
        "from": "gpt",
        "value": "sleek snowboarding enthusiast: [0.266, 0.234, 0.586, 0.812]\nsleek snowboard: [0.172, 0.750, 0.766, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000080273_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek sleek snowboarding enthusiast is standing on a sleek snowboard, which is positioned at the center of the image on snow.\nObjects: [sleek snowboarding enthusiast, sleek snowboard]"
      },
      {
        "from": "gpt",
        "value": "sleek snowboarding enthusiast: [0.266, 0.234, 0.586, 0.812]\nsleek snowboard: [0.172, 0.750, 0.766, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000080273_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.266, 0.234, 0.586, 0.812]\nsnowboard: [0.172, 0.750, 0.766, 0.828]\nGiven the above layout, shift the person upwards by 0.062."
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.172, 0.586, 0.750]\nsnowboard: [0.172, 0.750, 0.766, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000080671",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center, bending down, with skis attached to their feet on the snow."
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.344, 0.656, 0.734]\nskis: [0.312, 0.680, 0.719, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000080671_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center, bending down, with skis attached to their feet on the snow.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.344, 0.656, 0.734]\nskis: [0.312, 0.680, 0.719, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000080671_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a professional skier is at the center, bending down, with gleaming white skis attached to their feet on the snow."
      },
      {
        "from": "gpt",
        "value": "professional skier: [0.344, 0.344, 0.656, 0.734]\ngleaming white skis: [0.312, 0.680, 0.719, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000080671_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a professional skier is at the center, bending down, with gleaming white skis attached to their feet on the snow.\nObjects: [professional skier, gleaming white skis]"
      },
      {
        "from": "gpt",
        "value": "professional skier: [0.344, 0.344, 0.656, 0.734]\ngleaming white skis: [0.312, 0.680, 0.719, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000080671_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.344, 0.344, 0.656, 0.734]\nskis: [0.312, 0.680, 0.719, 0.750]\nGiven the above layout, shift the person upwards by 0.312."
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.031, 0.656, 0.422]\nskis: [0.312, 0.680, 0.719, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000081394",
    "conversations": [
      {
        "from": "human",
        "value": "The rear of a truck is at the center of the image, facing to the right."
      },
      {
        "from": "gpt",
        "value": "truck: [0.133, 0.156, 0.812, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000081394_key",
    "conversations": [
      {
        "from": "human",
        "value": "The rear of a truck is at the center of the image, facing to the right.\nObjects: [truck]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.133, 0.156, 0.812, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000081394_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the rear of a 18-wheeler semi-truck is at the center of the image, facing to the right."
      },
      {
        "from": "gpt",
        "value": "18-wheeler semi-truck: [0.133, 0.156, 0.812, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000081394_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the rear of a 18-wheeler semi-truck is at the center of the image, facing to the right.\nObjects: [18-wheeler semi-truck]"
      },
      {
        "from": "gpt",
        "value": "18-wheeler semi-truck: [0.133, 0.156, 0.812, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000081394_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.133, 0.156, 0.812, 0.797]\nGiven the above layout, shift the truck downwards by 0.125."
      },
      {
        "from": "gpt",
        "value": "truck: [0.133, 0.281, 0.812, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000082846",
    "conversations": [
      {
        "from": "human",
        "value": "A red bus is parked on the right side of the image."
      },
      {
        "from": "gpt",
        "value": "bus: [0.133, 0.406, 0.867, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000082846_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red bus is parked on the right side of the image.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.133, 0.406, 0.867, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000082846_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red blue double-decker bus is parked on the right side of the image."
      },
      {
        "from": "gpt",
        "value": "blue double-decker bus: [0.133, 0.406, 0.867, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000082846_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red blue double-decker bus is parked on the right side of the image.\nObjects: [blue double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "blue double-decker bus: [0.133, 0.406, 0.867, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000082846_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.133, 0.406, 0.867, 0.828]\nGiven the above layout, shift the bus upwards by 0.305."
      },
      {
        "from": "gpt",
        "value": "bus: [0.133, 0.102, 0.867, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000083113",
    "conversations": [
      {
        "from": "human",
        "value": "One elephant stands to the left of another elephant, both facing forward."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.703, 0.320, 0.961, 0.617]\nelephant: [0.383, 0.430, 0.609, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000083113_key",
    "conversations": [
      {
        "from": "human",
        "value": "One elephant stands to the left of another elephant, both facing forward.\nObjects: [elephant, elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.703, 0.320, 0.961, 0.617]\nelephant: [0.383, 0.430, 0.609, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000084752",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane mounted on pedestals at the center of the image, with its nose pointing to the left."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.039, 0.320, 0.961, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000084752_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane mounted on pedestals at the center of the image, with its nose pointing to the left.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.039, 0.320, 0.961, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000084752_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an large commercial jet mounted on pedestals at the center of the image, with its nose pointing to the left."
      },
      {
        "from": "gpt",
        "value": "large commercial jet: [0.039, 0.320, 0.961, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000084752_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an large commercial jet mounted on pedestals at the center of the image, with its nose pointing to the left.\nObjects: [large commercial jet]"
      },
      {
        "from": "gpt",
        "value": "large commercial jet: [0.039, 0.320, 0.961, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000084752_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.039, 0.320, 0.961, 0.672]\nGiven the above layout, shift the airplane upwards by 0.266."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.039, 0.055, 0.961, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000085329",
    "conversations": [
      {
        "from": "human",
        "value": "A person is wearing a tie at the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.391, 0.203, 0.930, 0.781]\ntie: [0.562, 0.586, 0.695, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000085329_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is wearing a tie at the center of the image.\nObjects: [person, tie]"
      },
      {
        "from": "gpt",
        "value": "person: [0.391, 0.203, 0.930, 0.781]\ntie: [0.562, 0.586, 0.695, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000085665",
    "conversations": [
      {
        "from": "human",
        "value": "The colorful kite is in the upper left corner of the image with its string trailing downwards towards the bottom right corner."
      },
      {
        "from": "gpt",
        "value": "kite: [0.469, 0.359, 0.789, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000085665_key",
    "conversations": [
      {
        "from": "human",
        "value": "The colorful kite is in the upper left corner of the image with its string trailing downwards towards the bottom right corner.\nObjects: [kite]"
      },
      {
        "from": "gpt",
        "value": "kite: [0.469, 0.359, 0.789, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000085665_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the colorful multicolored diamond-shaped kite is in the upper left corner of the image with its string trailing downwards towards the bottom right corner."
      },
      {
        "from": "gpt",
        "value": "multicolored diamond-shaped kite: [0.469, 0.359, 0.789, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000085665_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the colorful multicolored diamond-shaped kite is in the upper left corner of the image with its string trailing downwards towards the bottom right corner.\nObjects: [multicolored diamond-shaped kite]"
      },
      {
        "from": "gpt",
        "value": "multicolored diamond-shaped kite: [0.469, 0.359, 0.789, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000085665_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: kite: [0.469, 0.359, 0.789, 0.938]\nGiven the above layout, shift the kite to the left by 0.086."
      },
      {
        "from": "gpt",
        "value": "kite: [0.383, 0.359, 0.703, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000087875",
    "conversations": [
      {
        "from": "human",
        "value": "A fire hydrant stands to the right of the image with green foliage partially obscuring it on the left."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.227, 0.375, 0.461, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000087875_key",
    "conversations": [
      {
        "from": "human",
        "value": "A fire hydrant stands to the right of the image with green foliage partially obscuring it on the left.\nObjects: [fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.227, 0.375, 0.461, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000087875_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red fire hydrant stands to the right of the image with green foliage partially obscuring it on the left."
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.227, 0.375, 0.461, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000087875_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red fire hydrant stands to the right of the image with green foliage partially obscuring it on the left.\nObjects: [red fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.227, 0.375, 0.461, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000087875_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: fire hydrant: [0.227, 0.375, 0.461, 0.867]\nGiven the above layout, shift the fire hydrant to the right by 0.242."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.469, 0.375, 0.703, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000088485",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a frisbee in their hands at the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.289, 0.164, 0.656, 0.820]\nfrisbee: [0.266, 0.570, 0.445, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000088485_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a frisbee in their hands at the center of the image.\nObjects: [person, frisbee]"
      },
      {
        "from": "gpt",
        "value": "person: [0.289, 0.164, 0.656, 0.820]\nfrisbee: [0.266, 0.570, 0.445, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000088485_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a soccer player is holding a red frisbee in their hands at the center of the image."
      },
      {
        "from": "gpt",
        "value": "soccer player: [0.289, 0.164, 0.656, 0.820]\nred frisbee: [0.266, 0.570, 0.445, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000088485_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a soccer player is holding a red frisbee in their hands at the center of the image.\nObjects: [soccer player, red frisbee]"
      },
      {
        "from": "gpt",
        "value": "soccer player: [0.289, 0.164, 0.656, 0.820]\nred frisbee: [0.266, 0.570, 0.445, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000088485_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.289, 0.164, 0.656, 0.820]\nfrisbee: [0.266, 0.570, 0.445, 0.711]\nGiven the above layout, shift the person to the right by 0.203."
      },
      {
        "from": "gpt",
        "value": "person: [0.492, 0.164, 0.859, 0.820]\nfrisbee: [0.266, 0.570, 0.445, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000092839",
    "conversations": [
      {
        "from": "human",
        "value": "A bear is lying down with its head raised towards the upper right corner of the image."
      },
      {
        "from": "gpt",
        "value": "bear: [0.125, 0.133, 0.992, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000092839_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bear is lying down with its head raised towards the upper right corner of the image.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.125, 0.133, 0.992, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000092839_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a giant grizzly bear is lying down with its head raised towards the upper right corner of the image."
      },
      {
        "from": "gpt",
        "value": "giant grizzly bear: [0.125, 0.133, 0.992, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000092839_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a giant grizzly bear is lying down with its head raised towards the upper right corner of the image.\nObjects: [giant grizzly bear]"
      },
      {
        "from": "gpt",
        "value": "giant grizzly bear: [0.125, 0.133, 0.992, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000092839_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.125, 0.133, 0.992, 0.891]\nGiven the above layout, shift the bear upwards by 0.133."
      },
      {
        "from": "gpt",
        "value": "bear: [0.125, 0.000, 0.992, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000094614",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skiing down a snowy slope positioned at the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.445, 0.273, 0.688, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000094614_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skiing down a snowy slope positioned at the center of the image.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.445, 0.273, 0.688, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000094614_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a experienced skier is skiing down a snowy slope positioned at the center of the image."
      },
      {
        "from": "gpt",
        "value": "experienced skier: [0.445, 0.273, 0.688, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000094614_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a experienced skier is skiing down a snowy slope positioned at the center of the image.\nObjects: [experienced skier]"
      },
      {
        "from": "gpt",
        "value": "experienced skier: [0.445, 0.273, 0.688, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000094614_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.445, 0.273, 0.688, 0.727]\nGiven the above layout, shift the person to the left by 0.375."
      },
      {
        "from": "gpt",
        "value": "person: [0.070, 0.273, 0.312, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000122927",
    "conversations": [
      {
        "from": "human",
        "value": "One bird is at the center facing right, while another bird is in the background to the left."
      },
      {
        "from": "gpt",
        "value": "bird: [0.484, 0.461, 0.859, 0.727]\nbird: [0.016, 0.477, 0.211, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000122927_key",
    "conversations": [
      {
        "from": "human",
        "value": "One bird is at the center facing right, while another bird is in the background to the left.\nObjects: [bird, bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.484, 0.461, 0.859, 0.727]\nbird: [0.016, 0.477, 0.211, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000123480",
    "conversations": [
      {
        "from": "human",
        "value": "The person is wearing a striped shirt and is holding an object in their right hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.297, 0.609, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000123480_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is wearing a striped shirt and is holding an object in their right hand.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.297, 0.609, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000123480_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the individual wearing a polka-dotted shirt is wearing a striped shirt and is holding an object in their right hand."
      },
      {
        "from": "gpt",
        "value": "individual wearing a polka-dotted shirt: [0.172, 0.297, 0.609, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000123480_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the individual wearing a polka-dotted shirt is wearing a striped shirt and is holding an object in their right hand.\nObjects: [individual wearing a polka-dotted shirt]"
      },
      {
        "from": "gpt",
        "value": "individual wearing a polka-dotted shirt: [0.172, 0.297, 0.609, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000123480_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.172, 0.297, 0.609, 0.836]\nGiven the above layout, shift the person to the right by 0.320."
      },
      {
        "from": "gpt",
        "value": "person: [0.492, 0.297, 0.930, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000124277",
    "conversations": [
      {
        "from": "human",
        "value": "A train is on the elevated tracks curving to the right."
      },
      {
        "from": "gpt",
        "value": "train: [0.461, 0.328, 0.945, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000124277_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is on the elevated tracks curving to the right.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.461, 0.328, 0.945, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000124277_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a long freight train is on the elevated tracks curving to the right."
      },
      {
        "from": "gpt",
        "value": "long freight train: [0.461, 0.328, 0.945, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000124277_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a long freight train is on the elevated tracks curving to the right.\nObjects: [long freight train]"
      },
      {
        "from": "gpt",
        "value": "long freight train: [0.461, 0.328, 0.945, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000124277_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.461, 0.328, 0.945, 0.734]\nGiven the above layout, shift the train to the left by 0.023."
      },
      {
        "from": "gpt",
        "value": "train: [0.438, 0.328, 0.922, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000124442",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on the right side of the image, holding a kite."
      },
      {
        "from": "gpt",
        "value": "person: [0.508, 0.336, 0.688, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000124442_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on the right side of the image, holding a kite.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.508, 0.336, 0.688, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000124442_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man is standing on the right side of the image, holding a kite."
      },
      {
        "from": "gpt",
        "value": "tall man: [0.508, 0.336, 0.688, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000124442_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man is standing on the right side of the image, holding a kite.\nObjects: [tall man]"
      },
      {
        "from": "gpt",
        "value": "tall man: [0.508, 0.336, 0.688, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000124442_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.508, 0.336, 0.688, 0.758]\nGiven the above layout, shift the person to the left by 0.328."
      },
      {
        "from": "gpt",
        "value": "person: [0.180, 0.336, 0.359, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000125211",
    "conversations": [
      {
        "from": "human",
        "value": "The zebra is at the center of the image facing to the left."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.117, 0.258, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000125211_key",
    "conversations": [
      {
        "from": "human",
        "value": "The zebra is at the center of the image facing to the left.\nObjects: [zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.117, 0.258, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000125211_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the black and white penguin is at the center of the image facing to the left."
      },
      {
        "from": "gpt",
        "value": "black and white penguin: [0.117, 0.258, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000125211_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the black and white penguin is at the center of the image facing to the left.\nObjects: [black and white penguin]"
      },
      {
        "from": "gpt",
        "value": "black and white penguin: [0.117, 0.258, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000125211_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: zebra: [0.117, 0.258, 0.992, 0.859]\nGiven the above layout, shift the zebra upwards by 0.141."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.117, 0.117, 0.992, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000125472",
    "conversations": [
      {
        "from": "human",
        "value": "A person in mid-air above a skateboard that's on the ground."
      },
      {
        "from": "gpt",
        "value": "person: [0.305, 0.000, 0.789, 0.773]\nskateboard: [0.180, 0.758, 0.609, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000125472_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in mid-air above a skateboard thats on the ground.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.305, 0.000, 0.789, 0.773]\nskateboard: [0.180, 0.758, 0.609, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000125472_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a guy dressed in blue jeans and white t-shirt in mid-air above a graffiti-decorated skateboard that's on the ground."
      },
      {
        "from": "gpt",
        "value": "guy dressed in blue jeans and white t-shirt: [0.305, 0.000, 0.789, 0.773]\ngraffiti-decorated skateboard: [0.180, 0.758, 0.609, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000125472_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a guy dressed in blue jeans and white t-shirt in mid-air above a graffiti-decorated skateboard thats on the ground.\nObjects: [guy dressed in blue jeans and white t-shirt, graffiti-decorated skateboard]"
      },
      {
        "from": "gpt",
        "value": "guy dressed in blue jeans and white t-shirt: [0.305, 0.000, 0.789, 0.773]\ngraffiti-decorated skateboard: [0.180, 0.758, 0.609, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000125472_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.305, 0.000, 0.789, 0.773]\nskateboard: [0.180, 0.758, 0.609, 0.867]\nGiven the above layout, shift the person to the right by 0.070."
      },
      {
        "from": "gpt",
        "value": "person: [0.375, 0.000, 0.859, 0.773]\nskateboard: [0.180, 0.758, 0.609, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000125778",
    "conversations": [
      {
        "from": "human",
        "value": "A couch is positioned in the foreground to the left, a chair is to the right, and a potted plant is in the center between them further in the background."
      },
      {
        "from": "gpt",
        "value": "couch: [0.000, 0.484, 0.469, 0.867]\nchair: [0.422, 0.414, 0.664, 0.664]\npotted plant: [0.859, 0.648, 0.953, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000125778_key",
    "conversations": [
      {
        "from": "human",
        "value": "A couch is positioned in the foreground to the left, a chair is to the right, and a potted plant is in the center between them further in the background.\nObjects: [couch, chair, potted plant]"
      },
      {
        "from": "gpt",
        "value": "couch: [0.000, 0.484, 0.469, 0.867]\nchair: [0.422, 0.414, 0.664, 0.664]\npotted plant: [0.859, 0.648, 0.953, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000125778_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a leather loveseat is positioned in the foreground to the left, a wooden armchair is to the right, and a fern in a terracotta pot is in the center between them further in the background."
      },
      {
        "from": "gpt",
        "value": "leather loveseat: [0.000, 0.484, 0.469, 0.867]\nwooden armchair: [0.422, 0.414, 0.664, 0.664]\nfern in a terracotta pot: [0.859, 0.648, 0.953, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000125778_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a leather loveseat is positioned in the foreground to the left, a wooden armchair is to the right, and a fern in a terracotta pot is in the center between them further in the background.\nObjects: [leather loveseat, wooden armchair, fern in a terracotta pot]"
      },
      {
        "from": "gpt",
        "value": "leather loveseat: [0.000, 0.484, 0.469, 0.867]\nwooden armchair: [0.422, 0.414, 0.664, 0.664]\nfern in a terracotta pot: [0.859, 0.648, 0.953, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000125778_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: couch: [0.000, 0.484, 0.469, 0.867]\nchair: [0.422, 0.414, 0.664, 0.664]\npotted plant: [0.859, 0.648, 0.953, 0.812]\nGiven the above layout, shift the chair upwards by 0.016."
      },
      {
        "from": "gpt",
        "value": "couch: [0.000, 0.484, 0.469, 0.867]\nchair: [0.422, 0.398, 0.664, 0.648]\npotted plant: [0.859, 0.648, 0.953, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000125952",
    "conversations": [
      {
        "from": "human",
        "value": "A suitcase with an extended handle standing upright at the center, with a green jacket on top of it."
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.312, 0.008, 0.703, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000125952_key",
    "conversations": [
      {
        "from": "human",
        "value": "A suitcase with an extended handle standing upright at the center, with a green jacket on top of it.\nObjects: [suitcase]"
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.312, 0.008, 0.703, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000125952_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek leather briefcase with an extended handle standing upright at the center, with a green jacket on top of it."
      },
      {
        "from": "gpt",
        "value": "sleek leather briefcase: [0.312, 0.008, 0.703, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000125952_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek leather briefcase with an extended handle standing upright at the center, with a green jacket on top of it.\nObjects: [sleek leather briefcase]"
      },
      {
        "from": "gpt",
        "value": "sleek leather briefcase: [0.312, 0.008, 0.703, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000125952_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: suitcase: [0.312, 0.008, 0.703, 0.906]\nGiven the above layout, shift the suitcase to the left by 0.039."
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.273, 0.008, 0.664, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000126107",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is flying in the center of the image, angled towards the upper left."
      },
      {
        "from": "gpt",
        "value": "bird: [0.352, 0.148, 0.992, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000126107_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is flying in the center of the image, angled towards the upper left.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.352, 0.148, 0.992, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000126107_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a soaring eagle is flying in the center of the image, angled towards the upper left."
      },
      {
        "from": "gpt",
        "value": "soaring eagle: [0.352, 0.148, 0.992, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000126107_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a soaring eagle is flying in the center of the image, angled towards the upper left.\nObjects: [soaring eagle]"
      },
      {
        "from": "gpt",
        "value": "soaring eagle: [0.352, 0.148, 0.992, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000126107_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.352, 0.148, 0.992, 0.516]\nGiven the above layout, shift the bird downwards by 0.172."
      },
      {
        "from": "gpt",
        "value": "bird: [0.352, 0.320, 0.992, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000127182",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is on the left side, and the refrigerator is to the right of the oven."
      },
      {
        "from": "gpt",
        "value": "oven: [0.195, 0.570, 0.469, 0.961]\nrefrigerator: [0.555, 0.594, 0.766, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000127182_key",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is on the left side, and the refrigerator is to the right of the oven.\nObjects: [oven, refrigerator]"
      },
      {
        "from": "gpt",
        "value": "oven: [0.195, 0.570, 0.469, 0.961]\nrefrigerator: [0.555, 0.594, 0.766, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000127182_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel oven is on the left side, and the large white refrigerator is to the right of the stainless steel oven."
      },
      {
        "from": "gpt",
        "value": "stainless steel oven: [0.195, 0.570, 0.469, 0.961]\nlarge white refrigerator: [0.555, 0.594, 0.766, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000127182_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel oven is on the left side, and the large white refrigerator is to the right of the stainless steel oven.\nObjects: [stainless steel oven, large white refrigerator]"
      },
      {
        "from": "gpt",
        "value": "stainless steel oven: [0.195, 0.570, 0.469, 0.961]\nlarge white refrigerator: [0.555, 0.594, 0.766, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000127182_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: oven: [0.195, 0.570, 0.469, 0.961]\nrefrigerator: [0.555, 0.594, 0.766, 0.859]\nGiven the above layout, shift the oven upwards by 0.016."
      },
      {
        "from": "gpt",
        "value": "oven: [0.195, 0.555, 0.469, 0.945]\nrefrigerator: [0.555, 0.594, 0.766, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000127494",
    "conversations": [
      {
        "from": "human",
        "value": "A spoon is underneath the vegetables at the center of the plate."
      },
      {
        "from": "gpt",
        "value": "spoon: [0.023, 0.242, 0.461, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000127494_key",
    "conversations": [
      {
        "from": "human",
        "value": "A spoon is underneath the vegetables at the center of the plate.\nObjects: [spoon]"
      },
      {
        "from": "gpt",
        "value": "spoon: [0.023, 0.242, 0.461, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000127494_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a metallic teaspoon is underneath the vegetables at the center of the plate."
      },
      {
        "from": "gpt",
        "value": "metallic teaspoon: [0.023, 0.242, 0.461, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000127494_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a metallic teaspoon is underneath the vegetables at the center of the plate.\nObjects: [metallic teaspoon]"
      },
      {
        "from": "gpt",
        "value": "metallic teaspoon: [0.023, 0.242, 0.461, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000127494_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: spoon: [0.023, 0.242, 0.461, 0.555]\nGiven the above layout, shift the spoon to the right by 0.141."
      },
      {
        "from": "gpt",
        "value": "spoon: [0.164, 0.242, 0.602, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000127624",
    "conversations": [
      {
        "from": "human",
        "value": "A train is approaching on tracks that curve to the left in the foreground of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.164, 0.680, 0.992, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000127624_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is approaching on tracks that curve to the left in the foreground of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.164, 0.680, 0.992, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000127624_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a speeding locomotive is approaching on tracks that curve to the left in the foreground of the image."
      },
      {
        "from": "gpt",
        "value": "speeding locomotive: [0.164, 0.680, 0.992, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000127624_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a speeding locomotive is approaching on tracks that curve to the left in the foreground of the image.\nObjects: [speeding locomotive]"
      },
      {
        "from": "gpt",
        "value": "speeding locomotive: [0.164, 0.680, 0.992, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000127624_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.164, 0.680, 0.992, 0.914]\nGiven the above layout, shift the train upwards by 0.430."
      },
      {
        "from": "gpt",
        "value": "train: [0.164, 0.250, 0.992, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000128658",
    "conversations": [
      {
        "from": "human",
        "value": "Sliced bananas are placed to the right of the dessert on a plate."
      },
      {
        "from": "gpt",
        "value": "banana: [0.578, 0.359, 0.867, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000128658_key",
    "conversations": [
      {
        "from": "human",
        "value": "Sliced bananas are placed to the right of the dessert on a plate.\nObjects: [banana]"
      },
      {
        "from": "gpt",
        "value": "banana: [0.578, 0.359, 0.867, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000128658_aug",
    "conversations": [
      {
        "from": "human",
        "value": "sliced sliced strawberriess are placed to the right of the dessert on a plate."
      },
      {
        "from": "gpt",
        "value": "sliced strawberries: [0.578, 0.359, 0.867, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000128658_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "sliced sliced strawberriess are placed to the right of the dessert on a plate.\nObjects: [sliced strawberries]"
      },
      {
        "from": "gpt",
        "value": "sliced strawberries: [0.578, 0.359, 0.867, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000128658_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: banana: [0.578, 0.359, 0.867, 0.641]\nGiven the above layout, shift the banana to the left by 0.172."
      },
      {
        "from": "gpt",
        "value": "banana: [0.406, 0.359, 0.695, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000153217",
    "conversations": [
      {
        "from": "human",
        "value": "A black cat stands to the left of a motorcycle parked on grass."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.203, 0.008, 0.867, 0.828]\ncat: [0.156, 0.625, 0.445, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000153217_key",
    "conversations": [
      {
        "from": "human",
        "value": "A black cat stands to the left of a motorcycle parked on grass.\nObjects: [motorcycle, cat]"
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.203, 0.008, 0.867, 0.828]\ncat: [0.156, 0.625, 0.445, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000153343",
    "conversations": [
      {
        "from": "human",
        "value": "Two large teddy bears are displayed, one on the left and one on the right, separated by a partition decorated with foliage."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.102, 0.375, 0.445, 0.727]\nteddy bear: [0.562, 0.375, 0.875, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000153343_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two large teddy bears are displayed, one on the left and one on the right, separated by a partition decorated with foliage.\nObjects: [teddy bear, teddy bear]"
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.102, 0.375, 0.445, 0.727]\nteddy bear: [0.562, 0.375, 0.875, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000153568",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is at the center with a handwritten note attached to its upper half."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.000, 0.102, 0.992, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000153568_key",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is at the center with a handwritten note attached to its upper half.\nObjects: [stop sign]"
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.000, 0.102, 0.992, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000153568_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red stop sign with a handwritten note is at the center with a handwritten note attached to its upper half."
      },
      {
        "from": "gpt",
        "value": "red stop sign with a handwritten note: [0.000, 0.102, 0.992, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000153568_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red stop sign with a handwritten note is at the center with a handwritten note attached to its upper half.\nObjects: [red stop sign with a handwritten note]"
      },
      {
        "from": "gpt",
        "value": "red stop sign with a handwritten note: [0.000, 0.102, 0.992, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000153568_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: stop sign: [0.000, 0.102, 0.992, 0.836]\nGiven the above layout, shift the stop sign downwards by 0.117."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.000, 0.219, 0.992, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000154339",
    "conversations": [
      {
        "from": "human",
        "value": "Two clocks with one larger in the center and a smaller one to the right, slightly out of focus."
      },
      {
        "from": "gpt",
        "value": "clock: [0.234, 0.289, 0.727, 0.734]\nclock: [0.758, 0.562, 0.961, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000154339_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two clocks with one larger in the center and a smaller one to the right, slightly out of focus.\nObjects: [clock, clock]"
      },
      {
        "from": "gpt",
        "value": "clock: [0.234, 0.289, 0.727, 0.734]\nclock: [0.758, 0.562, 0.961, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000155291",
    "conversations": [
      {
        "from": "human",
        "value": "The cat is lying on a windowsill, facing slightly to the left with eyes closed."
      },
      {
        "from": "gpt",
        "value": "cat: [0.055, 0.289, 0.922, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000155291_key",
    "conversations": [
      {
        "from": "human",
        "value": "The cat is lying on a windowsill, facing slightly to the left with eyes closed.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.055, 0.289, 0.922, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000155291_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the sleepy yellow cat is lying on a windowsill, facing slightly to the left with eyes closed."
      },
      {
        "from": "gpt",
        "value": "sleepy yellow cat: [0.055, 0.289, 0.922, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000155291_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the sleepy yellow cat is lying on a windowsill, facing slightly to the left with eyes closed.\nObjects: [sleepy yellow cat]"
      },
      {
        "from": "gpt",
        "value": "sleepy yellow cat: [0.055, 0.289, 0.922, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000155291_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.055, 0.289, 0.922, 0.711]\nGiven the above layout, shift the cat upwards by 0.047."
      },
      {
        "from": "gpt",
        "value": "cat: [0.055, 0.242, 0.922, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000158956",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in front of a chair while placing an object on it."
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.227, 0.766, 0.812]\nchair: [0.945, 0.656, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000158956_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in front of a chair while placing an object on it.\nObjects: [person, chair]"
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.227, 0.766, 0.812]\nchair: [0.945, 0.656, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000158956_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young lady is standing in front of a mahogany armchair while placing an object on it."
      },
      {
        "from": "gpt",
        "value": "young lady: [0.266, 0.227, 0.766, 0.812]\nmahogany armchair: [0.945, 0.656, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000158956_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young lady is standing in front of a mahogany armchair while placing an object on it.\nObjects: [young lady, mahogany armchair]"
      },
      {
        "from": "gpt",
        "value": "young lady: [0.266, 0.227, 0.766, 0.812]\nmahogany armchair: [0.945, 0.656, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000158956_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.266, 0.227, 0.766, 0.812]\nchair: [0.945, 0.656, 0.992, 0.828]\nGiven the above layout, shift the person to the left by 0.117."
      },
      {
        "from": "gpt",
        "value": "person: [0.148, 0.227, 0.648, 0.812]\nchair: [0.945, 0.656, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000159112",
    "conversations": [
      {
        "from": "human",
        "value": "The pizza is at the center of the image with lemon wedges on top to the left side."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.000, 0.148, 0.992, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000159112_key",
    "conversations": [
      {
        "from": "human",
        "value": "The pizza is at the center of the image with lemon wedges on top to the left side.\nObjects: [pizza]"
      },
      {
        "from": "gpt",
        "value": "pizza: [0.000, 0.148, 0.992, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000159112_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the thick-crust margherita pizza with fresh basil leaves is at the center of the image with lemon wedges on top to the left side."
      },
      {
        "from": "gpt",
        "value": "thick-crust margherita pizza with fresh basil leaves: [0.000, 0.148, 0.992, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000159112_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the thick-crust margherita pizza with fresh basil leaves is at the center of the image with lemon wedges on top to the left side.\nObjects: [thick-crust margherita pizza with fresh basil leaves]"
      },
      {
        "from": "gpt",
        "value": "thick-crust margherita pizza with fresh basil leaves: [0.000, 0.148, 0.992, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000159112_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: pizza: [0.000, 0.148, 0.992, 0.836]\nGiven the above layout, shift the pizza downwards by 0.133."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.000, 0.281, 0.992, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000159977",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe stands in the center with a zebra to its right."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.516, 0.250, 0.805, 0.688]\nzebra: [0.312, 0.516, 0.383, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000159977_key",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe stands in the center with a zebra to its right.\nObjects: [giraffe, zebra]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.516, 0.250, 0.805, 0.688]\nzebra: [0.312, 0.516, 0.383, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000159977_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a adult giraffe stands in the center with a striped zebra to its right."
      },
      {
        "from": "gpt",
        "value": "adult giraffe: [0.516, 0.250, 0.805, 0.688]\nstriped zebra: [0.312, 0.516, 0.383, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000159977_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a adult giraffe stands in the center with a striped zebra to its right.\nObjects: [adult giraffe, striped zebra]"
      },
      {
        "from": "gpt",
        "value": "adult giraffe: [0.516, 0.250, 0.805, 0.688]\nstriped zebra: [0.312, 0.516, 0.383, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000159977_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.516, 0.250, 0.805, 0.688]\nzebra: [0.312, 0.516, 0.383, 0.656]\nGiven the above layout, shift the zebra to the left by 0.250."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.516, 0.250, 0.805, 0.688]\nzebra: [0.062, 0.516, 0.133, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000161879",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the right is skateboarding on a ramp."
      },
      {
        "from": "gpt",
        "value": "person: [0.086, 0.055, 0.367, 0.586]\nskateboard: [0.016, 0.516, 0.328, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000161879_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the right is skateboarding on a ramp.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.086, 0.055, 0.367, 0.586]\nskateboard: [0.016, 0.516, 0.328, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000161879_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager in a red hoodie on the right is black skateboarding on a ramp."
      },
      {
        "from": "gpt",
        "value": "teenager in a red hoodie: [0.086, 0.055, 0.367, 0.586]\nblack skateboard: [0.016, 0.516, 0.328, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000161879_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager in a red hoodie on the right is black skateboarding on a ramp.\nObjects: [teenager in a red hoodie, black skateboard]"
      },
      {
        "from": "gpt",
        "value": "teenager in a red hoodie: [0.086, 0.055, 0.367, 0.586]\nblack skateboard: [0.016, 0.516, 0.328, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000161879_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.086, 0.055, 0.367, 0.586]\nskateboard: [0.016, 0.516, 0.328, 0.609]\nGiven the above layout, shift the person to the right by 0.422."
      },
      {
        "from": "gpt",
        "value": "person: [0.508, 0.055, 0.789, 0.586]\nskateboard: [0.016, 0.516, 0.328, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000162035",
    "conversations": [
      {
        "from": "human",
        "value": "A person walks past a sign with two teddy bears, one on top of the sign and another at the base."
      },
      {
        "from": "gpt",
        "value": "person: [0.117, 0.125, 0.406, 0.773]\nteddy bear: [0.734, 0.422, 0.906, 0.820]\nteddy bear: [0.508, 0.133, 0.688, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000162035_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person walks past a sign with two teddy bears, one on top of the sign and another at the base.\nObjects: [person, teddy bear, teddy bear]"
      },
      {
        "from": "gpt",
        "value": "person: [0.117, 0.125, 0.406, 0.773]\nteddy bear: [0.734, 0.422, 0.906, 0.820]\nteddy bear: [0.508, 0.133, 0.688, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000162366",
    "conversations": [
      {
        "from": "human",
        "value": "A parking meter stands to the right of a brick wall, with a \"Pay Here\" sign attached above it on the wall."
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.555, 0.391, 0.836, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000162366_key",
    "conversations": [
      {
        "from": "human",
        "value": "A parking meter stands to the right of a brick wall, with a \"Pay Here\" sign attached above it on the wall.\nObjects: [parking meter]"
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.555, 0.391, 0.836, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000162366_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a digital parking meter stands to the right of a brick wall, with a \"pay here\" sign attached above it on the wall."
      },
      {
        "from": "gpt",
        "value": "digital parking meter: [0.555, 0.391, 0.836, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000162366_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a digital parking meter stands to the right of a brick wall, with a \"pay here\" sign attached above it on the wall.\nObjects: [digital parking meter]"
      },
      {
        "from": "gpt",
        "value": "digital parking meter: [0.555, 0.391, 0.836, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000162366_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: parking meter: [0.555, 0.391, 0.836, 0.766]\nGiven the above layout, shift the parking meter to the left by 0.172."
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.383, 0.391, 0.664, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000163155",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is sitting on the ground to the right, facing left towards a brick wall."
      },
      {
        "from": "gpt",
        "value": "cat: [0.008, 0.406, 0.844, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000163155_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is sitting on the ground to the right, facing left towards a brick wall.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.008, 0.406, 0.844, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000163155_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a golden retriever puppy is sitting on the ground to the right, facing left towards a brick wall."
      },
      {
        "from": "gpt",
        "value": "golden retriever puppy: [0.008, 0.406, 0.844, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000163155_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a golden retriever puppy is sitting on the ground to the right, facing left towards a brick wall.\nObjects: [golden retriever puppy]"
      },
      {
        "from": "gpt",
        "value": "golden retriever puppy: [0.008, 0.406, 0.844, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000163155_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.008, 0.406, 0.844, 0.781]\nGiven the above layout, shift the cat upwards by 0.234."
      },
      {
        "from": "gpt",
        "value": "cat: [0.008, 0.172, 0.844, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000186637",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe is standing to the right of a feeding station, facing it."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.227, 0.367, 0.570, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000186637_key",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe is standing to the right of a feeding station, facing it.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.227, 0.367, 0.570, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000186637_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall ostrich is standing to the right of a feeding station, facing it."
      },
      {
        "from": "gpt",
        "value": "tall ostrich: [0.227, 0.367, 0.570, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000186637_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall ostrich is standing to the right of a feeding station, facing it.\nObjects: [tall ostrich]"
      },
      {
        "from": "gpt",
        "value": "tall ostrich: [0.227, 0.367, 0.570, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000186637_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.227, 0.367, 0.570, 0.820]\nGiven the above layout, shift the giraffe to the right by 0.352."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.578, 0.367, 0.922, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000186929",
    "conversations": [
      {
        "from": "human",
        "value": "The orange is sliced and placed at the center with a peel curling outwards to the right."
      },
      {
        "from": "gpt",
        "value": "orange: [0.164, 0.000, 0.828, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000186929_key",
    "conversations": [
      {
        "from": "human",
        "value": "The orange is sliced and placed at the center with a peel curling outwards to the right.\nObjects: [orange]"
      },
      {
        "from": "gpt",
        "value": "orange: [0.164, 0.000, 0.828, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000186929_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the juicy tangerine is sliced and placed at the center with a peel curling outwards to the right."
      },
      {
        "from": "gpt",
        "value": "juicy tangerine: [0.164, 0.000, 0.828, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000186929_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the juicy tangerine is sliced and placed at the center with a peel curling outwards to the right.\nObjects: [juicy tangerine]"
      },
      {
        "from": "gpt",
        "value": "juicy tangerine: [0.164, 0.000, 0.828, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000186929_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: orange: [0.164, 0.000, 0.828, 0.984]\nGiven the above layout, shift the orange to the left by 0.133."
      },
      {
        "from": "gpt",
        "value": "orange: [0.031, 0.000, 0.695, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000186938",
    "conversations": [
      {
        "from": "human",
        "value": "A bird standing on the ground slightly to the left of center in the image."
      },
      {
        "from": "gpt",
        "value": "bird: [0.344, 0.242, 0.938, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000186938_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bird standing on the ground slightly to the left of center in the image.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.344, 0.242, 0.938, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000186938_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a small sparrow standing on the ground slightly to the left of center in the image."
      },
      {
        "from": "gpt",
        "value": "small sparrow: [0.344, 0.242, 0.938, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000186938_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a small sparrow standing on the ground slightly to the left of center in the image.\nObjects: [small sparrow]"
      },
      {
        "from": "gpt",
        "value": "small sparrow: [0.344, 0.242, 0.938, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000186938_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.344, 0.242, 0.938, 0.727]\nGiven the above layout, shift the bird to the left by 0.242."
      },
      {
        "from": "gpt",
        "value": "bird: [0.102, 0.242, 0.695, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000187144",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is parked in the foreground on the left, and a train is visible in the background on the right."
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.312, 0.641, 0.719]\ntrain: [0.633, 0.461, 0.992, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000187144_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is parked in the foreground on the left, and a train is visible in the background on the right.\nObjects: [bus, train]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.312, 0.641, 0.719]\ntrain: [0.633, 0.461, 0.992, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000187144_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red double-decker bus is parked in the foreground on the left, and a green steam locomotive is visible in the background on the right."
      },
      {
        "from": "gpt",
        "value": "red double-decker bus: [0.000, 0.312, 0.641, 0.719]\ngreen steam locomotive: [0.633, 0.461, 0.992, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000187144_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red double-decker bus is parked in the foreground on the left, and a green steam locomotive is visible in the background on the right.\nObjects: [red double-decker bus, green steam locomotive]"
      },
      {
        "from": "gpt",
        "value": "red double-decker bus: [0.000, 0.312, 0.641, 0.719]\ngreen steam locomotive: [0.633, 0.461, 0.992, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000187144_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.000, 0.312, 0.641, 0.719]\ntrain: [0.633, 0.461, 0.992, 0.516]\nGiven the above layout, shift the bus upwards by 0.203."
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.109, 0.641, 0.516]\ntrain: [0.633, 0.461, 0.992, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000188439",
    "conversations": [
      {
        "from": "human",
        "value": "The truck is on the right side of the image, loaded with materials and facing to the left."
      },
      {
        "from": "gpt",
        "value": "truck: [0.117, 0.508, 0.625, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000188439_key",
    "conversations": [
      {
        "from": "human",
        "value": "The truck is on the right side of the image, loaded with materials and facing to the left.\nObjects: [truck]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.117, 0.508, 0.625, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000188439_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red cargo truck loaded with building supplies is on the right side of the image, loaded with materials and facing to the left."
      },
      {
        "from": "gpt",
        "value": "red cargo truck loaded with building supplies: [0.117, 0.508, 0.625, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000188439_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red cargo truck loaded with building supplies is on the right side of the image, loaded with materials and facing to the left.\nObjects: [red cargo truck loaded with building supplies]"
      },
      {
        "from": "gpt",
        "value": "red cargo truck loaded with building supplies: [0.117, 0.508, 0.625, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000188439_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.117, 0.508, 0.625, 0.773]\nGiven the above layout, shift the truck upwards by 0.461."
      },
      {
        "from": "gpt",
        "value": "truck: [0.117, 0.047, 0.625, 0.312]"
      }
    ]
  },
  {
    "id": "coco_000000188906",
    "conversations": [
      {
        "from": "human",
        "value": "A banana sliced lengthwise and placed facing upward at the center of the plate."
      },
      {
        "from": "gpt",
        "value": "banana: [0.000, 0.133, 0.992, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000188906_key",
    "conversations": [
      {
        "from": "human",
        "value": "A banana sliced lengthwise and placed facing upward at the center of the plate.\nObjects: [banana]"
      },
      {
        "from": "gpt",
        "value": "banana: [0.000, 0.133, 0.992, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000188906_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a freshly peeled banana sliced lengthwise and placed facing upward at the center of the plate."
      },
      {
        "from": "gpt",
        "value": "freshly peeled banana: [0.000, 0.133, 0.992, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000188906_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a freshly peeled banana sliced lengthwise and placed facing upward at the center of the plate.\nObjects: [freshly peeled banana]"
      },
      {
        "from": "gpt",
        "value": "freshly peeled banana: [0.000, 0.133, 0.992, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000188906_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: banana: [0.000, 0.133, 0.992, 0.844]\nGiven the above layout, shift the banana downwards by 0.031."
      },
      {
        "from": "gpt",
        "value": "banana: [0.000, 0.164, 0.992, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000189820",
    "conversations": [
      {
        "from": "human",
        "value": "A chair is located to the right facing a keyboard at the center, with a TV in the background to the left side."
      },
      {
        "from": "gpt",
        "value": "chair: [0.570, 0.375, 0.961, 0.805]\nkeyboard: [0.133, 0.695, 0.430, 0.820]\ntv: [0.297, 0.289, 0.430, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000189820_key",
    "conversations": [
      {
        "from": "human",
        "value": "A chair is located to the right facing a keyboard at the center, with a TV in the background to the left side.\nObjects: [chair, keyboard, tv]"
      },
      {
        "from": "gpt",
        "value": "chair: [0.570, 0.375, 0.961, 0.805]\nkeyboard: [0.133, 0.695, 0.430, 0.820]\ntv: [0.297, 0.289, 0.430, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000189820_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a wooden rocking chair is located to the right facing a black piano keyboard at the center, with a large plasma tv in the background to the left side."
      },
      {
        "from": "gpt",
        "value": "wooden rocking chair: [0.570, 0.375, 0.961, 0.805]\nblack piano keyboard: [0.133, 0.695, 0.430, 0.820]\nlarge plasma tv: [0.297, 0.289, 0.430, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000189820_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a wooden rocking chair is located to the right facing a black piano keyboard at the center, with a large plasma tv in the background to the left side.\nObjects: [wooden rocking chair, black piano keyboard, large plasma tv]"
      },
      {
        "from": "gpt",
        "value": "wooden rocking chair: [0.570, 0.375, 0.961, 0.805]\nblack piano keyboard: [0.133, 0.695, 0.430, 0.820]\nlarge plasma tv: [0.297, 0.289, 0.430, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000189820_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: chair: [0.570, 0.375, 0.961, 0.805]\nkeyboard: [0.133, 0.695, 0.430, 0.820]\ntv: [0.297, 0.289, 0.430, 0.445]\nGiven the above layout, shift the tv upwards by 0.117."
      },
      {
        "from": "gpt",
        "value": "chair: [0.570, 0.375, 0.961, 0.805]\nkeyboard: [0.133, 0.695, 0.430, 0.820]\ntv: [0.297, 0.172, 0.430, 0.328]"
      }
    ]
  },
  {
    "id": "coco_000000190307",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the water, facing towards the right side of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.039, 0.602, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000190307_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the water, facing towards the right side of the image.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.039, 0.602, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000190307_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in a swimming suit is standing in the water, facing towards the right side of the image."
      },
      {
        "from": "gpt",
        "value": "woman in a swimming suit: [0.406, 0.039, 0.602, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000190307_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in a swimming suit is standing in the water, facing towards the right side of the image.\nObjects: [woman in a swimming suit]"
      },
      {
        "from": "gpt",
        "value": "woman in a swimming suit: [0.406, 0.039, 0.602, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000190307_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.406, 0.039, 0.602, 0.812]\nGiven the above layout, shift the person to the left by 0.148."
      },
      {
        "from": "gpt",
        "value": "person: [0.258, 0.039, 0.453, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000190648",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is placed at the center of the image, against the wall."
      },
      {
        "from": "gpt",
        "value": "bed: [0.086, 0.531, 0.789, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000190648_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is placed at the center of the image, against the wall.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.086, 0.531, 0.789, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000190648_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the king size bed is placed at the center of the image, against the wall."
      },
      {
        "from": "gpt",
        "value": "king size bed: [0.086, 0.531, 0.789, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000190648_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the king size bed is placed at the center of the image, against the wall.\nObjects: [king size bed]"
      },
      {
        "from": "gpt",
        "value": "king size bed: [0.086, 0.531, 0.789, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000190648_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.086, 0.531, 0.789, 0.859]\nGiven the above layout, shift the bed upwards by 0.375."
      },
      {
        "from": "gpt",
        "value": "bed: [0.086, 0.156, 0.789, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000192047",
    "conversations": [
      {
        "from": "human",
        "value": "The sink is at the center-bottom of the image, mounted against the wall."
      },
      {
        "from": "gpt",
        "value": "sink: [0.258, 0.805, 0.797, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000192047_key",
    "conversations": [
      {
        "from": "human",
        "value": "The sink is at the center-bottom of the image, mounted against the wall.\nObjects: [sink]"
      },
      {
        "from": "gpt",
        "value": "sink: [0.258, 0.805, 0.797, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000192047_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel sink is at the center-bottom of the image, mounted against the wall."
      },
      {
        "from": "gpt",
        "value": "stainless steel sink: [0.258, 0.805, 0.797, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000192047_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel sink is at the center-bottom of the image, mounted against the wall.\nObjects: [stainless steel sink]"
      },
      {
        "from": "gpt",
        "value": "stainless steel sink: [0.258, 0.805, 0.797, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000192047_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sink: [0.258, 0.805, 0.797, 0.984]\nGiven the above layout, shift the sink upwards by 0.766."
      },
      {
        "from": "gpt",
        "value": "sink: [0.258, 0.039, 0.797, 0.219]"
      }
    ]
  },
  {
    "id": "coco_000000192607",
    "conversations": [
      {
        "from": "human",
        "value": "A truck is parked on the left, and a person is standing to the right of the truck."
      },
      {
        "from": "gpt",
        "value": "truck: [0.000, 0.492, 0.727, 0.805]\nperson: [0.711, 0.516, 0.805, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000192607_key",
    "conversations": [
      {
        "from": "human",
        "value": "A truck is parked on the left, and a person is standing to the right of the truck.\nObjects: [truck, person]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.000, 0.492, 0.727, 0.805]\nperson: [0.711, 0.516, 0.805, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000192716",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is at the center, attached to a pole."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.266, 0.266, 0.734, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000192716_key",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is at the center, attached to a pole.\nObjects: [stop sign]"
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.266, 0.266, 0.734, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000192716_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red hexagonal stop sign is at the center, attached to a pole."
      },
      {
        "from": "gpt",
        "value": "red hexagonal stop sign: [0.266, 0.266, 0.734, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000192716_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red hexagonal stop sign is at the center, attached to a pole.\nObjects: [red hexagonal stop sign]"
      },
      {
        "from": "gpt",
        "value": "red hexagonal stop sign: [0.266, 0.266, 0.734, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000192716_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: stop sign: [0.266, 0.266, 0.734, 0.758]\nGiven the above layout, shift the stop sign to the left by 0.242."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.023, 0.266, 0.492, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000193429",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on a snow-covered slope with a snowboard in front of them."
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.320, 0.656, 0.633]\nsnowboard: [0.211, 0.594, 0.805, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000193429_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on a snow-covered slope with a snowboard in front of them.\nObjects: [person, snowboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.320, 0.656, 0.633]\nsnowboard: [0.211, 0.594, 0.805, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000193429_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a brightly colored brightly colored snowboarder in thick winter gear is sitting on a snow-covered slope with a brightly colored snowboard in front of them."
      },
      {
        "from": "gpt",
        "value": "brightly colored snowboarder in thick winter gear: [0.320, 0.320, 0.656, 0.633]\nbrightly colored snowboard: [0.211, 0.594, 0.805, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000193429_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a brightly colored brightly colored snowboarder in thick winter gear is sitting on a snow-covered slope with a brightly colored snowboard in front of them.\nObjects: [brightly colored snowboarder in thick winter gear, brightly colored snowboard]"
      },
      {
        "from": "gpt",
        "value": "brightly colored snowboarder in thick winter gear: [0.320, 0.320, 0.656, 0.633]\nbrightly colored snowboard: [0.211, 0.594, 0.805, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000193429_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.320, 0.320, 0.656, 0.633]\nsnowboard: [0.211, 0.594, 0.805, 0.742]\nGiven the above layout, shift the person upwards by 0.234."
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.086, 0.656, 0.398]\nsnowboard: [0.211, 0.594, 0.805, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000215644",
    "conversations": [
      {
        "from": "human",
        "value": "The microwave is at the center, nestled between wooden cabinets."
      },
      {
        "from": "gpt",
        "value": "microwave: [0.320, 0.453, 0.711, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000215644_key",
    "conversations": [
      {
        "from": "human",
        "value": "The microwave is at the center, nestled between wooden cabinets.\nObjects: [microwave]"
      },
      {
        "from": "gpt",
        "value": "microwave: [0.320, 0.453, 0.711, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000215644_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel microwave is at the center, nestled between wooden cabinets."
      },
      {
        "from": "gpt",
        "value": "stainless steel microwave: [0.320, 0.453, 0.711, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000215644_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel microwave is at the center, nestled between wooden cabinets.\nObjects: [stainless steel microwave]"
      },
      {
        "from": "gpt",
        "value": "stainless steel microwave: [0.320, 0.453, 0.711, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000215644_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: microwave: [0.320, 0.453, 0.711, 0.672]\nGiven the above layout, shift the microwave upwards by 0.156."
      },
      {
        "from": "gpt",
        "value": "microwave: [0.320, 0.297, 0.711, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000216516",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing centered on the skis on a snow-covered slope."
      },
      {
        "from": "gpt",
        "value": "person: [0.336, 0.180, 0.508, 0.914]\nskis: [0.125, 0.820, 0.758, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000216516_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing centered on the skis on a snow-covered slope.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.336, 0.180, 0.508, 0.914]\nskis: [0.125, 0.820, 0.758, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000216516_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young athlete is standing centered on the racing skis on a snow-covered slope."
      },
      {
        "from": "gpt",
        "value": "young athlete: [0.336, 0.180, 0.508, 0.914]\nracing skis: [0.125, 0.820, 0.758, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000216516_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young athlete is standing centered on the racing skis on a snow-covered slope.\nObjects: [young athlete, racing skis]"
      },
      {
        "from": "gpt",
        "value": "young athlete: [0.336, 0.180, 0.508, 0.914]\nracing skis: [0.125, 0.820, 0.758, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000216516_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.336, 0.180, 0.508, 0.914]\nskis: [0.125, 0.820, 0.758, 0.961]\nGiven the above layout, shift the skis to the right by 0.188."
      },
      {
        "from": "gpt",
        "value": "person: [0.336, 0.180, 0.508, 0.914]\nskis: [0.312, 0.820, 0.945, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000216636",
    "conversations": [
      {
        "from": "human",
        "value": "A partially sliced cake is in the center, with a candle to the right foreground."
      },
      {
        "from": "gpt",
        "value": "cake: [0.000, 0.164, 0.711, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000216636_key",
    "conversations": [
      {
        "from": "human",
        "value": "A partially sliced cake is in the center, with a candle to the right foreground.\nObjects: [cake]"
      },
      {
        "from": "gpt",
        "value": "cake: [0.000, 0.164, 0.711, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000216636_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a partially sliced strawberry cheesecake is in the center, with a candle to the right foreground."
      },
      {
        "from": "gpt",
        "value": "strawberry cheesecake: [0.000, 0.164, 0.711, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000216636_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a partially sliced strawberry cheesecake is in the center, with a candle to the right foreground.\nObjects: [strawberry cheesecake]"
      },
      {
        "from": "gpt",
        "value": "strawberry cheesecake: [0.000, 0.164, 0.711, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000216636_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cake: [0.000, 0.164, 0.711, 0.695]\nGiven the above layout, shift the cake downwards by 0.219."
      },
      {
        "from": "gpt",
        "value": "cake: [0.000, 0.383, 0.711, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000216739",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe's head is at the center with its neck angled slightly to the right, next to a tree on the right side."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.000, 0.242, 0.656, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000216739_key",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffes head is at the center with its neck angled slightly to the right, next to a tree on the right side.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.000, 0.242, 0.656, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000216739_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the elegant giraffe's head is at the center with its neck angled slightly to the right, next to a tree on the right side."
      },
      {
        "from": "gpt",
        "value": "elegant giraffe: [0.000, 0.242, 0.656, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000216739_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the elegant giraffes head is at the center with its neck angled slightly to the right, next to a tree on the right side.\nObjects: [elegant giraffe]"
      },
      {
        "from": "gpt",
        "value": "elegant giraffe: [0.000, 0.242, 0.656, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000216739_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.000, 0.242, 0.656, 0.828]\nGiven the above layout, shift the giraffe to the right by 0.062."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.062, 0.242, 0.719, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000217400",
    "conversations": [
      {
        "from": "human",
        "value": "A green and white train is stationary on the tracks, facing slightly to the left of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.328, 0.828, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000217400_key",
    "conversations": [
      {
        "from": "human",
        "value": "A green and white train is stationary on the tracks, facing slightly to the left of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.328, 0.828, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000217400_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a green and white vintage locomotive is stationary on the tracks, facing slightly to the left of the image."
      },
      {
        "from": "gpt",
        "value": "vintage locomotive: [0.000, 0.328, 0.828, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000217400_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a green and white vintage locomotive is stationary on the tracks, facing slightly to the left of the image.\nObjects: [vintage locomotive]"
      },
      {
        "from": "gpt",
        "value": "vintage locomotive: [0.000, 0.328, 0.828, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000217400_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.328, 0.828, 0.695]\nGiven the above layout, shift the train upwards by 0.125."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.203, 0.828, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000220310",
    "conversations": [
      {
        "from": "human",
        "value": "The teddy bear is on top of a green trash bin, leaning slightly to the right, with a red heart-shaped pillow with \"Love You\" written on it tucked under its left arm."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.289, 0.055, 0.789, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000220310_key",
    "conversations": [
      {
        "from": "human",
        "value": "The teddy bear is on top of a green trash bin, leaning slightly to the right, with a red heart-shaped pillow with \"Love You\" written on it tucked under its left arm.\nObjects: [teddy bear]"
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.289, 0.055, 0.789, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000220310_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the fluffy toy rabbit is on top of a green trash bin, leaning slightly to the right, with a red heart-shaped pillow with \"love you\" written on it tucked under its left arm."
      },
      {
        "from": "gpt",
        "value": "fluffy toy rabbit: [0.289, 0.055, 0.789, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000220310_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the fluffy toy rabbit is on top of a green trash bin, leaning slightly to the right, with a red heart-shaped pillow with \"love you\" written on it tucked under its left arm.\nObjects: [fluffy toy rabbit]"
      },
      {
        "from": "gpt",
        "value": "fluffy toy rabbit: [0.289, 0.055, 0.789, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000220310_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: teddy bear: [0.289, 0.055, 0.789, 0.602]\nGiven the above layout, shift the teddy bear downwards by 0.320."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.289, 0.375, 0.789, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000220858",
    "conversations": [
      {
        "from": "human",
        "value": "A boat is on the shore at the center of the image."
      },
      {
        "from": "gpt",
        "value": "boat: [0.336, 0.555, 0.961, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000220858_key",
    "conversations": [
      {
        "from": "human",
        "value": "A boat is on the shore at the center of the image.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.336, 0.555, 0.961, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000220858_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a small red kayak is on the shore at the center of the image."
      },
      {
        "from": "gpt",
        "value": "small red kayak: [0.336, 0.555, 0.961, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000220858_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a small red kayak is on the shore at the center of the image.\nObjects: [small red kayak]"
      },
      {
        "from": "gpt",
        "value": "small red kayak: [0.336, 0.555, 0.961, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000220858_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.336, 0.555, 0.961, 0.781]\nGiven the above layout, shift the boat upwards by 0.445."
      },
      {
        "from": "gpt",
        "value": "boat: [0.336, 0.109, 0.961, 0.336]"
      }
    ]
  },
  {
    "id": "coco_000000221017",
    "conversations": [
      {
        "from": "human",
        "value": "The bird is at the center of the image, facing right."
      },
      {
        "from": "gpt",
        "value": "bird: [0.375, 0.477, 0.680, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000221017_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bird is at the center of the image, facing right.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.375, 0.477, 0.680, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000221017_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the sparrow is at the center of the image, facing right."
      },
      {
        "from": "gpt",
        "value": "sparrow: [0.375, 0.477, 0.680, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000221017_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the sparrow is at the center of the image, facing right.\nObjects: [sparrow]"
      },
      {
        "from": "gpt",
        "value": "sparrow: [0.375, 0.477, 0.680, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000221017_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.375, 0.477, 0.680, 0.789]\nGiven the above layout, shift the bird upwards by 0.156."
      },
      {
        "from": "gpt",
        "value": "bird: [0.375, 0.320, 0.680, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000221693",
    "conversations": [
      {
        "from": "human",
        "value": "A dog in the center of the image holding a frisbee in its mouth."
      },
      {
        "from": "gpt",
        "value": "dog: [0.117, 0.195, 0.812, 0.820]\nfrisbee: [0.688, 0.547, 0.930, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000221693_key",
    "conversations": [
      {
        "from": "human",
        "value": "A dog in the center of the image holding a frisbee in its mouth.\nObjects: [dog, frisbee]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.117, 0.195, 0.812, 0.820]\nfrisbee: [0.688, 0.547, 0.930, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000221693_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a greyhound in the center of the image holding a green frisbee in its mouth."
      },
      {
        "from": "gpt",
        "value": "greyhound: [0.117, 0.195, 0.812, 0.820]\ngreen frisbee: [0.688, 0.547, 0.930, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000221693_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a greyhound in the center of the image holding a green frisbee in its mouth.\nObjects: [greyhound, green frisbee]"
      },
      {
        "from": "gpt",
        "value": "greyhound: [0.117, 0.195, 0.812, 0.820]\ngreen frisbee: [0.688, 0.547, 0.930, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000221693_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.117, 0.195, 0.812, 0.820]\nfrisbee: [0.688, 0.547, 0.930, 0.766]\nGiven the above layout, shift the dog upwards by 0.172."
      },
      {
        "from": "gpt",
        "value": "dog: [0.117, 0.023, 0.812, 0.648]\nfrisbee: [0.688, 0.547, 0.930, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000222825",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is on the left, and the oven is to the right of the refrigerator."
      },
      {
        "from": "gpt",
        "value": "oven: [0.586, 0.500, 0.828, 0.930]\nrefrigerator: [0.281, 0.375, 0.406, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000222825_key",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is on the left, and the oven is to the right of the refrigerator.\nObjects: [oven, refrigerator]"
      },
      {
        "from": "gpt",
        "value": "oven: [0.586, 0.500, 0.828, 0.930]\nrefrigerator: [0.281, 0.375, 0.406, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000222825_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the white full-sized refrigerator is on the left, and the stainless steel oven is to the right of the white full-sized refrigerator."
      },
      {
        "from": "gpt",
        "value": "stainless steel oven: [0.586, 0.500, 0.828, 0.930]\nwhite full-sized refrigerator: [0.281, 0.375, 0.406, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000222825_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the white full-sized refrigerator is on the left, and the stainless steel oven is to the right of the white full-sized refrigerator.\nObjects: [stainless steel oven, white full-sized refrigerator]"
      },
      {
        "from": "gpt",
        "value": "stainless steel oven: [0.586, 0.500, 0.828, 0.930]\nwhite full-sized refrigerator: [0.281, 0.375, 0.406, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000222825_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: oven: [0.586, 0.500, 0.828, 0.930]\nrefrigerator: [0.281, 0.375, 0.406, 0.875]\nGiven the above layout, shift the refrigerator upwards by 0.016."
      },
      {
        "from": "gpt",
        "value": "oven: [0.586, 0.500, 0.828, 0.930]\nrefrigerator: [0.281, 0.359, 0.406, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000222991",
    "conversations": [
      {
        "from": "human",
        "value": "The red umbrella is leaning against the wall to the left of the black boots."
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.312, 0.000, 0.422, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000222991_key",
    "conversations": [
      {
        "from": "human",
        "value": "The red umbrella is leaning against the wall to the left of the black boots.\nObjects: [umbrella]"
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.312, 0.000, 0.422, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000222991_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red bright red brolly is leaning against the wall to the left of the black boots."
      },
      {
        "from": "gpt",
        "value": "bright red brolly: [0.312, 0.000, 0.422, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000222991_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red bright red brolly is leaning against the wall to the left of the black boots.\nObjects: [bright red brolly]"
      },
      {
        "from": "gpt",
        "value": "bright red brolly: [0.312, 0.000, 0.422, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000222991_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: umbrella: [0.312, 0.000, 0.422, 0.844]\nGiven the above layout, shift the umbrella to the right by 0.422."
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.734, 0.000, 0.844, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000223130",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe stands at the center of the image facing to the right."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.375, 0.227, 0.664, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000223130_key",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe stands at the center of the image facing to the right.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.375, 0.227, 0.664, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000223130_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a giant dinosaur toy stands at the center of the image facing to the right."
      },
      {
        "from": "gpt",
        "value": "a giant dinosaur toy: [0.375, 0.227, 0.664, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000223130_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a giant dinosaur toy stands at the center of the image facing to the right.\nObjects: [a giant dinosaur toy]"
      },
      {
        "from": "gpt",
        "value": "a giant dinosaur toy: [0.375, 0.227, 0.664, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000223130_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.375, 0.227, 0.664, 0.922]\nGiven the above layout, shift the giraffe to the left by 0.055."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.320, 0.227, 0.609, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000224051",
    "conversations": [
      {
        "from": "human",
        "value": "The bicycle is leaning against a railing on the right side of a sidewalk."
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.539, 0.281, 0.781, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000224051_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bicycle is leaning against a railing on the right side of a sidewalk.\nObjects: [bicycle]"
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.539, 0.281, 0.781, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000224051_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the rusty red bicycle is leaning against a railing on the right side of a sidewalk."
      },
      {
        "from": "gpt",
        "value": "rusty red bicycle: [0.539, 0.281, 0.781, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000224051_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the rusty red bicycle is leaning against a railing on the right side of a sidewalk.\nObjects: [rusty red bicycle]"
      },
      {
        "from": "gpt",
        "value": "rusty red bicycle: [0.539, 0.281, 0.781, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000224051_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bicycle: [0.539, 0.281, 0.781, 0.727]\nGiven the above layout, shift the bicycle to the left by 0.273."
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.266, 0.281, 0.508, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000226592",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is in the center of the image, covered with a zebra print comforter and red pillows."
      },
      {
        "from": "gpt",
        "value": "bed: [0.109, 0.164, 0.992, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000226592_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is in the center of the image, covered with a zebra print comforter and red pillows.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.109, 0.164, 0.992, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000226592_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the king-size bed is in the center of the image, covered with a zebra print comforter and red pillows."
      },
      {
        "from": "gpt",
        "value": "king-size bed: [0.109, 0.164, 0.992, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000226592_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the king-size bed is in the center of the image, covered with a zebra print comforter and red pillows.\nObjects: [king-size bed]"
      },
      {
        "from": "gpt",
        "value": "king-size bed: [0.109, 0.164, 0.992, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000226592_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.109, 0.164, 0.992, 0.812]\nGiven the above layout, shift the bed downwards by 0.016."
      },
      {
        "from": "gpt",
        "value": "bed: [0.109, 0.180, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000248810",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe stands to the left of a metal fence, amid a background with trees and rocks."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.250, 0.258, 0.719, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000248810_key",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe stands to the left of a metal fence, amid a background with trees and rocks.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.250, 0.258, 0.719, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000248810_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a spotted giraffe stands to the left of a metal fence, amid a background with trees and rocks."
      },
      {
        "from": "gpt",
        "value": "spotted giraffe: [0.250, 0.258, 0.719, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000248810_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a spotted giraffe stands to the left of a metal fence, amid a background with trees and rocks.\nObjects: [spotted giraffe]"
      },
      {
        "from": "gpt",
        "value": "spotted giraffe: [0.250, 0.258, 0.719, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000248810_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.250, 0.258, 0.719, 0.930]\nGiven the above layout, shift the giraffe to the right by 0.117."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.367, 0.258, 0.836, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000249219",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is positioned on the right side of the image, with its front facing towards the left."
      },
      {
        "from": "gpt",
        "value": "bus: [0.141, 0.414, 0.805, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000249219_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is positioned on the right side of the image, with its front facing towards the left.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.141, 0.414, 0.805, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000249219_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the yellow school bus is positioned on the right side of the image, with its front facing towards the left."
      },
      {
        "from": "gpt",
        "value": "yellow school bus: [0.141, 0.414, 0.805, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000249219_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the yellow school bus is positioned on the right side of the image, with its front facing towards the left.\nObjects: [yellow school bus]"
      },
      {
        "from": "gpt",
        "value": "yellow school bus: [0.141, 0.414, 0.805, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000249219_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.141, 0.414, 0.805, 0.836]\nGiven the above layout, shift the bus upwards by 0.281."
      },
      {
        "from": "gpt",
        "value": "bus: [0.141, 0.133, 0.805, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000251537",
    "conversations": [
      {
        "from": "human",
        "value": "A carrot is on the lower right side of a red dining table."
      },
      {
        "from": "gpt",
        "value": "dining table: [0.008, 0.008, 0.992, 0.328]\ncarrot: [0.672, 0.477, 0.969, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000251537_key",
    "conversations": [
      {
        "from": "human",
        "value": "A carrot is on the lower right side of a red dining table.\nObjects: [dining table, carrot]"
      },
      {
        "from": "gpt",
        "value": "dining table: [0.008, 0.008, 0.992, 0.328]\ncarrot: [0.672, 0.477, 0.969, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000251537_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a fresh carrot is on the lower right side of a red mahogany dining table."
      },
      {
        "from": "gpt",
        "value": "mahogany dining table: [0.008, 0.008, 0.992, 0.328]\nfresh carrot: [0.672, 0.477, 0.969, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000251537_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a fresh carrot is on the lower right side of a red mahogany dining table.\nObjects: [mahogany dining table, fresh carrot]"
      },
      {
        "from": "gpt",
        "value": "mahogany dining table: [0.008, 0.008, 0.992, 0.328]\nfresh carrot: [0.672, 0.477, 0.969, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000251537_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dining table: [0.008, 0.008, 0.992, 0.328]\ncarrot: [0.672, 0.477, 0.969, 0.914]\nGiven the above layout, shift the carrot downwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "dining table: [0.008, 0.008, 0.992, 0.328]\ncarrot: [0.672, 0.547, 0.969, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000251824",
    "conversations": [
      {
        "from": "human",
        "value": "A person's hands are at the center, with scissors to the right side on the table."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.336, 0.992, 0.859]\nscissors: [0.727, 0.445, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000251824_key",
    "conversations": [
      {
        "from": "human",
        "value": "A persons hands are at the center, with scissors to the right side on the table.\nObjects: [person, scissors]"
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.336, 0.992, 0.859]\nscissors: [0.727, 0.445, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000251824_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a carpenter's hands's hands are at the center, with sharp tailoring scissors to the right side on the table."
      },
      {
        "from": "gpt",
        "value": "carpenter's hands: [0.000, 0.336, 0.992, 0.859]\nsharp tailoring scissors: [0.727, 0.445, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000251824_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a carpenters handss hands are at the center, with sharp tailoring scissors to the right side on the table.\nObjects: [\"carpenters hands\", sharp tailoring scissors]"
      },
      {
        "from": "gpt",
        "value": "carpenter's hands: [0.000, 0.336, 0.992, 0.859]\nsharp tailoring scissors: [0.727, 0.445, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000251824_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.000, 0.336, 0.992, 0.859]\nscissors: [0.727, 0.445, 0.992, 0.727]\nGiven the above layout, shift the person upwards by 0.242."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.094, 0.992, 0.617]\nscissors: [0.727, 0.445, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000252332",
    "conversations": [
      {
        "from": "human",
        "value": "A stop sign is in the center of the image with foliage in the background."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.125, 0.125, 0.836, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000252332_key",
    "conversations": [
      {
        "from": "human",
        "value": "A stop sign is in the center of the image with foliage in the background.\nObjects: [stop sign]"
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.125, 0.125, 0.836, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000252332_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a bright red stop sign is in the center of the image with foliage in the background."
      },
      {
        "from": "gpt",
        "value": "bright red stop sign: [0.125, 0.125, 0.836, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000252332_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a bright red stop sign is in the center of the image with foliage in the background.\nObjects: [bright red stop sign]"
      },
      {
        "from": "gpt",
        "value": "bright red stop sign: [0.125, 0.125, 0.836, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000252332_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: stop sign: [0.125, 0.125, 0.836, 0.828]\nGiven the above layout, shift the stop sign downwards by 0.164."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.125, 0.289, 0.836, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000255401",
    "conversations": [
      {
        "from": "human",
        "value": "A sink is positioned on the left, with a toilet to its right and another toilet directly across from the sink on the far side of the room."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.148, 0.070, 0.359, 0.539]\nsink: [0.695, 0.320, 0.906, 0.711]\ntoilet: [0.461, 0.227, 0.648, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000255401_key",
    "conversations": [
      {
        "from": "human",
        "value": "A sink is positioned on the left, with a toilet to its right and another toilet directly across from the sink on the far side of the room.\nObjects: [toilet, sink, toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.148, 0.070, 0.359, 0.539]\nsink: [0.695, 0.320, 0.906, 0.711]\ntoilet: [0.461, 0.227, 0.648, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000256868",
    "conversations": [
      {
        "from": "human",
        "value": "One person is skateboarding on a ledge at the center, while another person is watching and filming to the left."
      },
      {
        "from": "gpt",
        "value": "person: [0.211, 0.445, 0.461, 0.758]\nperson: [0.484, 0.258, 0.641, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000256868_key",
    "conversations": [
      {
        "from": "human",
        "value": "One person is skateboarding on a ledge at the center, while another person is watching and filming to the left.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.211, 0.445, 0.461, 0.758]\nperson: [0.484, 0.258, 0.641, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000257478",
    "conversations": [
      {
        "from": "human",
        "value": "A person wearing a baseball uniform standing alone on a grass field, slightly off-center to the left of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.500, 0.148, 0.859, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000257478_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person wearing a baseball uniform standing alone on a grass field, slightly off-center to the left of the image.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.500, 0.148, 0.859, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000257478_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a young woman wearing a baseball uniform wearing a baseball uniform standing alone on a grass field, slightly off-center to the left of the image."
      },
      {
        "from": "gpt",
        "value": "a young woman wearing a baseball uniform: [0.500, 0.148, 0.859, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000257478_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a young woman wearing a baseball uniform wearing a baseball uniform standing alone on a grass field, slightly off-center to the left of the image.\nObjects: [a young woman wearing a baseball uniform]"
      },
      {
        "from": "gpt",
        "value": "a young woman wearing a baseball uniform: [0.500, 0.148, 0.859, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000257478_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.500, 0.148, 0.859, 0.844]\nGiven the above layout, shift the person to the left by 0.055."
      },
      {
        "from": "gpt",
        "value": "person: [0.445, 0.148, 0.805, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000257865",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left, holding a tennis racket in the right hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.289, 0.562, 0.820]\ntennis racket: [0.359, 0.758, 0.625, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000257865_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left, holding a tennis racket in the right hand.\nObjects: [person, tennis racket]"
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.289, 0.562, 0.820]\ntennis racket: [0.359, 0.758, 0.625, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000257865_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a athletic man is standing to the left, holding a graphite tennis racket in the right hand."
      },
      {
        "from": "gpt",
        "value": "athletic man: [0.266, 0.289, 0.562, 0.820]\ngraphite tennis racket: [0.359, 0.758, 0.625, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000257865_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a athletic man is standing to the left, holding a graphite tennis racket in the right hand.\nObjects: [athletic man, graphite tennis racket]"
      },
      {
        "from": "gpt",
        "value": "athletic man: [0.266, 0.289, 0.562, 0.820]\ngraphite tennis racket: [0.359, 0.758, 0.625, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000257865_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.266, 0.289, 0.562, 0.820]\ntennis racket: [0.359, 0.758, 0.625, 0.828]\nGiven the above layout, shift the tennis racket to the right by 0.070."
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.289, 0.562, 0.820]\ntennis racket: [0.430, 0.758, 0.695, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000257896",
    "conversations": [
      {
        "from": "human",
        "value": "A person dressed in a green suit with a tie, wearing a light-colored hat, standing in the center of the image with a dusk sky in the background."
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.039, 0.859, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000257896_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person dressed in a green suit with a tie, wearing a light-colored hat, standing in the center of the image with a dusk sky in the background.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.039, 0.859, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000257896_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young man in a trendy blue suit dressed in a green suit with a tie, wearing a light-colored hat, standing in the center of the image with a dusk sky in the background."
      },
      {
        "from": "gpt",
        "value": "young man in a trendy blue suit: [0.312, 0.039, 0.859, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000257896_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young man in a trendy blue suit dressed in a green suit with a tie, wearing a light-colored hat, standing in the center of the image with a dusk sky in the background.\nObjects: [young man in a trendy blue suit]"
      },
      {
        "from": "gpt",
        "value": "young man in a trendy blue suit: [0.312, 0.039, 0.859, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000257896_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.312, 0.039, 0.859, 0.984]\nGiven the above layout, shift the person to the left by 0.195."
      },
      {
        "from": "gpt",
        "value": "person: [0.117, 0.039, 0.664, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000258388",
    "conversations": [
      {
        "from": "human",
        "value": "Person on the left on a skateboard, person on the right holding a flame towards the first person, and a third person in the background observing."
      },
      {
        "from": "gpt",
        "value": "person: [0.227, 0.266, 0.414, 0.641]\nperson: [0.633, 0.328, 0.797, 0.727]\nperson: [0.805, 0.492, 0.875, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000258388_key",
    "conversations": [
      {
        "from": "human",
        "value": "Person on the left on a skateboard, person on the right holding a flame towards the first person, and a third person in the background observing.\nObjects: [person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.227, 0.266, 0.414, 0.641]\nperson: [0.633, 0.328, 0.797, 0.727]\nperson: [0.805, 0.492, 0.875, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000259382",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe is centered in the image, walking to the right."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.211, 0.273, 0.656, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000259382_key",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe is centered in the image, walking to the right.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.211, 0.273, 0.656, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000259382_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a towering giraffe is centered in the image, walking to the right."
      },
      {
        "from": "gpt",
        "value": "towering giraffe: [0.211, 0.273, 0.656, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000259382_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a towering giraffe is centered in the image, walking to the right.\nObjects: [towering giraffe]"
      },
      {
        "from": "gpt",
        "value": "towering giraffe: [0.211, 0.273, 0.656, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000259382_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.211, 0.273, 0.656, 0.625]\nGiven the above layout, shift the giraffe downwards by 0.016."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.211, 0.289, 0.656, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000284725",
    "conversations": [
      {
        "from": "human",
        "value": "A red bus is in the background to the right, and a black car is in the foreground to the left."
      },
      {
        "from": "gpt",
        "value": "bus: [0.102, 0.375, 0.781, 0.648]\ncar: [0.227, 0.617, 0.586, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000284725_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red bus is in the background to the right, and a black car is in the foreground to the left.\nObjects: [bus, car]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.102, 0.375, 0.781, 0.648]\ncar: [0.227, 0.617, 0.586, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000284725_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red double-decker bus is in the background to the right, and a black sleek sedan is in the foreground to the left."
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.102, 0.375, 0.781, 0.648]\nsleek sedan: [0.227, 0.617, 0.586, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000284725_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red double-decker bus is in the background to the right, and a black sleek sedan is in the foreground to the left.\nObjects: [double-decker bus, sleek sedan]"
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.102, 0.375, 0.781, 0.648]\nsleek sedan: [0.227, 0.617, 0.586, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000284725_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.102, 0.375, 0.781, 0.648]\ncar: [0.227, 0.617, 0.586, 0.750]\nGiven the above layout, shift the bus upwards by 0.109."
      },
      {
        "from": "gpt",
        "value": "bus: [0.102, 0.266, 0.781, 0.539]\ncar: [0.227, 0.617, 0.586, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000284762",
    "conversations": [
      {
        "from": "human",
        "value": "The traffic light is on the left side of the image showing a red pedestrian signal."
      },
      {
        "from": "gpt",
        "value": "traffic light: [0.219, 0.250, 0.445, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000284762_key",
    "conversations": [
      {
        "from": "human",
        "value": "The traffic light is on the left side of the image showing a red pedestrian signal.\nObjects: [traffic light]"
      },
      {
        "from": "gpt",
        "value": "traffic light: [0.219, 0.250, 0.445, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000284762_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the city traffic light is on the left side of the image showing a red pedestrian signal."
      },
      {
        "from": "gpt",
        "value": "city traffic light: [0.219, 0.250, 0.445, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000284762_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the city traffic light is on the left side of the image showing a red pedestrian signal.\nObjects: [city traffic light]"
      },
      {
        "from": "gpt",
        "value": "city traffic light: [0.219, 0.250, 0.445, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000284762_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: traffic light: [0.219, 0.250, 0.445, 0.766]\nGiven the above layout, shift the traffic light to the right by 0.078."
      },
      {
        "from": "gpt",
        "value": "traffic light: [0.297, 0.250, 0.523, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000285047",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting at a table with a coffee cup in front of them, holding a smartphone in their right hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.234, 0.820, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000285047_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting at a table with a coffee cup in front of them, holding a smartphone in their right hand.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.234, 0.820, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000285047_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young man in glasses is sitting at a table with a coffee cup in front of them, holding a smartphone in their right hand."
      },
      {
        "from": "gpt",
        "value": "young man in glasses: [0.164, 0.234, 0.820, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000285047_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young man in glasses is sitting at a table with a coffee cup in front of them, holding a smartphone in their right hand.\nObjects: [young man in glasses]"
      },
      {
        "from": "gpt",
        "value": "young man in glasses: [0.164, 0.234, 0.820, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000285047_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.164, 0.234, 0.820, 0.977]\nGiven the above layout, shift the person upwards by 0.125."
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.109, 0.820, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000286503",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant is at the center reaching up with its trunk to a hanging hay feeder."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.359, 0.445, 0.812, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000286503_key",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant is at the center reaching up with its trunk to a hanging hay feeder.\nObjects: [elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.359, 0.445, 0.812, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000286503_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an tall giraffe is at the center reaching up with its trunk to a hanging hay feeder."
      },
      {
        "from": "gpt",
        "value": "tall giraffe: [0.359, 0.445, 0.812, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000286503_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an tall giraffe is at the center reaching up with its trunk to a hanging hay feeder.\nObjects: [tall giraffe]"
      },
      {
        "from": "gpt",
        "value": "tall giraffe: [0.359, 0.445, 0.812, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000286503_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: elephant: [0.359, 0.445, 0.812, 0.758]\nGiven the above layout, shift the elephant upwards by 0.180."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.359, 0.266, 0.812, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000286507",
    "conversations": [
      {
        "from": "human",
        "value": "A train on tracks moving from left to right through a snowy landscape."
      },
      {
        "from": "gpt",
        "value": "train: [0.180, 0.398, 0.930, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000286507_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train on tracks moving from left to right through a snowy landscape.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.180, 0.398, 0.930, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000286507_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red locomotive on tracks moving from left to right through a snowy landscape."
      },
      {
        "from": "gpt",
        "value": "red locomotive: [0.180, 0.398, 0.930, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000286507_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red locomotive on tracks moving from left to right through a snowy landscape.\nObjects: [red locomotive]"
      },
      {
        "from": "gpt",
        "value": "red locomotive: [0.180, 0.398, 0.930, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000286507_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.180, 0.398, 0.930, 0.609]\nGiven the above layout, shift the train upwards by 0.344."
      },
      {
        "from": "gpt",
        "value": "train: [0.180, 0.055, 0.930, 0.266]"
      }
    ]
  },
  {
    "id": "coco_000000286523",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a cell phone up to their ear with their right hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.344, 0.812, 0.883]\ncell phone: [0.656, 0.594, 0.750, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000286523_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a cell phone up to their ear with their right hand.\nObjects: [person, cell phone]"
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.344, 0.812, 0.883]\ncell phone: [0.656, 0.594, 0.750, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000286523_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a businessman is holding a black iPhone up to their ear with their right hand."
      },
      {
        "from": "gpt",
        "value": "businessman: [0.000, 0.344, 0.812, 0.883]\nblack iPhone: [0.656, 0.594, 0.750, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000286523_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a businessman is holding a black iPhone up to their ear with their right hand.\nObjects: [businessman, black iPhone]"
      },
      {
        "from": "gpt",
        "value": "businessman: [0.000, 0.344, 0.812, 0.883]\nblack iPhone: [0.656, 0.594, 0.750, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000286523_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.000, 0.344, 0.812, 0.883]\ncell phone: [0.656, 0.594, 0.750, 0.797]\nGiven the above layout, shift the person upwards by 0.336."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.008, 0.812, 0.547]\ncell phone: [0.656, 0.594, 0.750, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000287649",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is sitting to the right of a keyboard on a desk, and there is a book to the left of the keyboard."
      },
      {
        "from": "gpt",
        "value": "cat: [0.211, 0.133, 0.992, 0.750]\nkeyboard: [0.000, 0.734, 0.992, 0.867]\nbook: [0.727, 0.125, 0.992, 0.227]"
      }
    ]
  },
  {
    "id": "coco_000000287649_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is sitting to the right of a keyboard on a desk, and there is a book to the left of the keyboard.\nObjects: [cat, keyboard, book]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.211, 0.133, 0.992, 0.750]\nkeyboard: [0.000, 0.734, 0.992, 0.867]\nbook: [0.727, 0.125, 0.992, 0.227]"
      }
    ]
  },
  {
    "id": "coco_000000287649_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a black and white house cat is sitting to the right of a wireless keyboard on a desk, and there is a hardcover novel to the left of the wireless keyboard."
      },
      {
        "from": "gpt",
        "value": "black and white house cat: [0.211, 0.133, 0.992, 0.750]\nwireless keyboard: [0.000, 0.734, 0.992, 0.867]\nhardcover novel: [0.727, 0.125, 0.992, 0.227]"
      }
    ]
  },
  {
    "id": "coco_000000287649_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a black and white house cat is sitting to the right of a wireless keyboard on a desk, and there is a hardcover novel to the left of the wireless keyboard.\nObjects: [black and white house cat, wireless keyboard, hardcover novel]"
      },
      {
        "from": "gpt",
        "value": "black and white house cat: [0.211, 0.133, 0.992, 0.750]\nwireless keyboard: [0.000, 0.734, 0.992, 0.867]\nhardcover novel: [0.727, 0.125, 0.992, 0.227]"
      }
    ]
  },
  {
    "id": "coco_000000287649_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.211, 0.133, 0.992, 0.750]\nkeyboard: [0.000, 0.734, 0.992, 0.867]\nbook: [0.727, 0.125, 0.992, 0.227]\nGiven the above layout, shift the book upwards by 0.125."
      },
      {
        "from": "gpt",
        "value": "cat: [0.211, 0.133, 0.992, 0.750]\nkeyboard: [0.000, 0.734, 0.992, 0.867]\nbook: [0.727, 0.000, 0.992, 0.102]"
      }
    ]
  },
  {
    "id": "coco_000000287874",
    "conversations": [
      {
        "from": "human",
        "value": "A train on the right side of the railway tracks, facing forward."
      },
      {
        "from": "gpt",
        "value": "train: [0.312, 0.359, 0.625, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000287874_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train on the right side of the railway tracks, facing forward.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.312, 0.359, 0.625, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000287874_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a streamlined high-speed locomotive on the right side of the railway tracks, facing forward."
      },
      {
        "from": "gpt",
        "value": "streamlined high-speed locomotive: [0.312, 0.359, 0.625, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000287874_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a streamlined high-speed locomotive on the right side of the railway tracks, facing forward.\nObjects: [streamlined high-speed locomotive]"
      },
      {
        "from": "gpt",
        "value": "streamlined high-speed locomotive: [0.312, 0.359, 0.625, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000287874_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.312, 0.359, 0.625, 0.648]\nGiven the above layout, shift the train to the right by 0.062."
      },
      {
        "from": "gpt",
        "value": "train: [0.375, 0.359, 0.688, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000287959",
    "conversations": [
      {
        "from": "human",
        "value": "The sandwich is at the center with a bite taken out of it, revealing the fillings inside."
      },
      {
        "from": "gpt",
        "value": "sandwich: [0.000, 0.125, 0.695, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000287959_key",
    "conversations": [
      {
        "from": "human",
        "value": "The sandwich is at the center with a bite taken out of it, revealing the fillings inside.\nObjects: [sandwich]"
      },
      {
        "from": "gpt",
        "value": "sandwich: [0.000, 0.125, 0.695, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000287959_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the ham and cheese sandwich is at the center with a bite taken out of it, revealing the fillings inside."
      },
      {
        "from": "gpt",
        "value": "ham and cheese sandwich: [0.000, 0.125, 0.695, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000287959_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the ham and cheese sandwich is at the center with a bite taken out of it, revealing the fillings inside.\nObjects: [ham and cheese sandwich]"
      },
      {
        "from": "gpt",
        "value": "ham and cheese sandwich: [0.000, 0.125, 0.695, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000287959_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sandwich: [0.000, 0.125, 0.695, 0.812]\nGiven the above layout, shift the sandwich to the right by 0.219."
      },
      {
        "from": "gpt",
        "value": "sandwich: [0.219, 0.125, 0.914, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000288062",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center against a wall with a mural above it."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.281, 0.523, 0.648, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000288062_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center against a wall with a mural above it.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.281, 0.523, 0.648, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000288062_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain toilet is at the center against a wall with a mural above it."
      },
      {
        "from": "gpt",
        "value": "porcelain toilet: [0.281, 0.523, 0.648, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000288062_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain toilet is at the center against a wall with a mural above it.\nObjects: [porcelain toilet]"
      },
      {
        "from": "gpt",
        "value": "porcelain toilet: [0.281, 0.523, 0.648, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000288062_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.281, 0.523, 0.648, 0.914]\nGiven the above layout, shift the toilet upwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.281, 0.453, 0.648, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000288391",
    "conversations": [
      {
        "from": "human",
        "value": "A disassembled cell phone is mounted on a wall above a striped awning."
      },
      {
        "from": "gpt",
        "value": "cell phone: [0.180, 0.070, 0.422, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000288391_key",
    "conversations": [
      {
        "from": "human",
        "value": "A disassembled cell phone is mounted on a wall above a striped awning.\nObjects: [cell phone]"
      },
      {
        "from": "gpt",
        "value": "cell phone: [0.180, 0.070, 0.422, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000288391_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a disassembled deconstructed smartphone is mounted on a wall above a striped awning."
      },
      {
        "from": "gpt",
        "value": "deconstructed smartphone: [0.180, 0.070, 0.422, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000288391_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a disassembled deconstructed smartphone is mounted on a wall above a striped awning.\nObjects: [deconstructed smartphone]"
      },
      {
        "from": "gpt",
        "value": "deconstructed smartphone: [0.180, 0.070, 0.422, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000288391_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cell phone: [0.180, 0.070, 0.422, 0.539]\nGiven the above layout, shift the cell phone to the right by 0.547."
      },
      {
        "from": "gpt",
        "value": "cell phone: [0.727, 0.070, 0.969, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000288882",
    "conversations": [
      {
        "from": "human",
        "value": "One giraffe stands in the foreground facing to the right, and another giraffe is behind it, slightly to the left, facing towards the left."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.188, 0.219, 0.594, 0.773]\ngiraffe: [0.547, 0.219, 0.727, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000288882_key",
    "conversations": [
      {
        "from": "human",
        "value": "One giraffe stands in the foreground facing to the right, and another giraffe is behind it, slightly to the left, facing towards the left.\nObjects: [giraffe, giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.188, 0.219, 0.594, 0.773]\ngiraffe: [0.547, 0.219, 0.727, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000309173",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is mounted on a pole at the center of the image."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.289, 0.062, 0.797, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000309173_key",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is mounted on a pole at the center of the image.\nObjects: [stop sign]"
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.289, 0.062, 0.797, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000309173_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red traffic light is mounted on a pole at the center of the image."
      },
      {
        "from": "gpt",
        "value": "red traffic light: [0.289, 0.062, 0.797, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000309173_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red traffic light is mounted on a pole at the center of the image.\nObjects: [red traffic light]"
      },
      {
        "from": "gpt",
        "value": "red traffic light: [0.289, 0.062, 0.797, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000309173_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: stop sign: [0.289, 0.062, 0.797, 0.703]\nGiven the above layout, shift the stop sign to the left by 0.125."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.164, 0.062, 0.672, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000309495",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center of the image, against a tiled wall with a window to the right."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.445, 0.453, 0.820, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000309495_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center of the image, against a tiled wall with a window to the right.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.445, 0.453, 0.820, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000309495_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the modern white ceramic toilet is at the center of the image, against a tiled wall with a window to the right."
      },
      {
        "from": "gpt",
        "value": "modern white ceramic toilet: [0.445, 0.453, 0.820, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000309495_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the modern white ceramic toilet is at the center of the image, against a tiled wall with a window to the right.\nObjects: [modern white ceramic toilet]"
      },
      {
        "from": "gpt",
        "value": "modern white ceramic toilet: [0.445, 0.453, 0.820, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000309495_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.445, 0.453, 0.820, 0.852]\nGiven the above layout, shift the toilet upwards by 0.164."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.445, 0.289, 0.820, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000309655",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing in the center of the image with snow-covered mountains in the background."
      },
      {
        "from": "gpt",
        "value": "person: [0.375, 0.438, 0.555, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000309655_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing in the center of the image with snow-covered mountains in the background.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.375, 0.438, 0.555, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000309655_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a woman draped in winter clothing standing in the center of the image with snow-covered mountains in the background."
      },
      {
        "from": "gpt",
        "value": "woman draped in winter clothing: [0.375, 0.438, 0.555, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000309655_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a woman draped in winter clothing standing in the center of the image with snow-covered mountains in the background.\nObjects: [woman draped in winter clothing]"
      },
      {
        "from": "gpt",
        "value": "woman draped in winter clothing: [0.375, 0.438, 0.555, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000309655_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.375, 0.438, 0.555, 0.859]\nGiven the above layout, shift the person upwards by 0.367."
      },
      {
        "from": "gpt",
        "value": "person: [0.375, 0.070, 0.555, 0.492]"
      }
    ]
  },
  {
    "id": "coco_000000311883",
    "conversations": [
      {
        "from": "human",
        "value": "The train is positioned horizontally across the image with the front of the train facing to the right."
      },
      {
        "from": "gpt",
        "value": "train: [0.086, 0.445, 0.992, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000311883_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is positioned horizontally across the image with the front of the train facing to the right.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.086, 0.445, 0.992, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000311883_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red locomotive is positioned horizontally across the image with the front of the red locomotive facing to the right."
      },
      {
        "from": "gpt",
        "value": "red locomotive: [0.086, 0.445, 0.992, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000311883_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red locomotive is positioned horizontally across the image with the front of the red locomotive facing to the right.\nObjects: [red locomotive]"
      },
      {
        "from": "gpt",
        "value": "red locomotive: [0.086, 0.445, 0.992, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000311883_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.086, 0.445, 0.992, 0.609]\nGiven the above layout, shift the train upwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "train: [0.086, 0.375, 0.992, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000311909",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is angled from right to left, with the front of the bus facing towards the right side of the image."
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.188, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000311909_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is angled from right to left, with the front of the bus facing towards the right side of the image.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.188, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000311909_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red double-decker bus is angled from right to left, with the front of the red double-decker bus facing towards the right side of the image."
      },
      {
        "from": "gpt",
        "value": "red double-decker bus: [0.000, 0.188, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000311909_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red double-decker bus is angled from right to left, with the front of the red double-decker bus facing towards the right side of the image.\nObjects: [red double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "red double-decker bus: [0.000, 0.188, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000311909_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.000, 0.188, 0.992, 0.805]\nGiven the above layout, shift the bus upwards by 0.086."
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.102, 0.992, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000311928",
    "conversations": [
      {
        "from": "human",
        "value": "A person is swinging a baseball bat to the right side."
      },
      {
        "from": "gpt",
        "value": "person: [0.117, 0.234, 0.398, 0.789]\nbaseball bat: [0.391, 0.609, 0.867, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000311928_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is swinging a baseball bat to the right side.\nObjects: [person, baseball bat]"
      },
      {
        "from": "gpt",
        "value": "person: [0.117, 0.234, 0.398, 0.789]\nbaseball bat: [0.391, 0.609, 0.867, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000311928_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young athlete is swinging a wooden baseball bat to the right side."
      },
      {
        "from": "gpt",
        "value": "young athlete: [0.117, 0.234, 0.398, 0.789]\nwooden baseball bat: [0.391, 0.609, 0.867, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000311928_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young athlete is swinging a wooden baseball bat to the right side.\nObjects: [young athlete, wooden baseball bat]"
      },
      {
        "from": "gpt",
        "value": "young athlete: [0.117, 0.234, 0.398, 0.789]\nwooden baseball bat: [0.391, 0.609, 0.867, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000311928_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.117, 0.234, 0.398, 0.789]\nbaseball bat: [0.391, 0.609, 0.867, 0.711]\nGiven the above layout, shift the person upwards by 0.188."
      },
      {
        "from": "gpt",
        "value": "person: [0.117, 0.047, 0.398, 0.602]\nbaseball bat: [0.391, 0.609, 0.867, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000311950",
    "conversations": [
      {
        "from": "human",
        "value": "The hot dog is at the center of the image, surrounded by colorful confetti."
      },
      {
        "from": "gpt",
        "value": "hot dog: [0.391, 0.266, 0.609, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000311950_key",
    "conversations": [
      {
        "from": "human",
        "value": "The hot dog is at the center of the image, surrounded by colorful confetti.\nObjects: [hot dog]"
      },
      {
        "from": "gpt",
        "value": "hot dog: [0.391, 0.266, 0.609, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000311950_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the juicy hot dog is at the center of the image, surrounded by colorful confetti."
      },
      {
        "from": "gpt",
        "value": "juicy hot dog: [0.391, 0.266, 0.609, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000311950_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the juicy hot dog is at the center of the image, surrounded by colorful confetti.\nObjects: [juicy hot dog]"
      },
      {
        "from": "gpt",
        "value": "juicy hot dog: [0.391, 0.266, 0.609, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000311950_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: hot dog: [0.391, 0.266, 0.609, 0.711]\nGiven the above layout, shift the hot dog to the left by 0.055."
      },
      {
        "from": "gpt",
        "value": "hot dog: [0.336, 0.266, 0.555, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000312406",
    "conversations": [
      {
        "from": "human",
        "value": "A bowl is to the right of the bananas."
      },
      {
        "from": "gpt",
        "value": "banana: [0.062, 0.328, 0.453, 0.688]\nbowl: [0.641, 0.422, 0.820, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000312406_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bowl is to the right of the bananas.\nObjects: [banana, bowl]"
      },
      {
        "from": "gpt",
        "value": "banana: [0.062, 0.328, 0.453, 0.688]\nbowl: [0.641, 0.422, 0.820, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000312552",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center holding a bowl."
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.242, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000312552_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center holding a bowl.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.242, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000312552_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a adult woman is standing in the center holding a bowl."
      },
      {
        "from": "gpt",
        "value": "adult woman: [0.273, 0.242, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000312552_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a adult woman is standing in the center holding a bowl.\nObjects: [adult woman]"
      },
      {
        "from": "gpt",
        "value": "adult woman: [0.273, 0.242, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000312552_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.273, 0.242, 0.992, 0.859]\nGiven the above layout, shift the person to the left by 0.266."
      },
      {
        "from": "gpt",
        "value": "person: [0.008, 0.242, 0.727, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000313034",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the left facing and interacting with another person on the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.297, 0.500, 0.859]\nperson: [0.453, 0.266, 0.852, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000313034_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the left facing and interacting with another person on the right.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.297, 0.500, 0.859]\nperson: [0.453, 0.266, 0.852, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000313783",
    "conversations": [
      {
        "from": "human",
        "value": "A fork is placed to the left of a pile of chopped carrots."
      },
      {
        "from": "gpt",
        "value": "fork: [0.719, 0.133, 0.992, 0.539]\ncarrot: [0.000, 0.180, 0.133, 0.430]\ncarrot: [0.000, 0.414, 0.102, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000313783_key",
    "conversations": [
      {
        "from": "human",
        "value": "A fork is placed to the left of a pile of chopped carrots.\nObjects: [fork, carrot, carrot]"
      },
      {
        "from": "gpt",
        "value": "fork: [0.719, 0.133, 0.992, 0.539]\ncarrot: [0.000, 0.180, 0.133, 0.430]\ncarrot: [0.000, 0.414, 0.102, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000314177",
    "conversations": [
      {
        "from": "human",
        "value": "A person is seated at the center, wearing a cap and a patterned jacket, holding a camera with both hands."
      },
      {
        "from": "gpt",
        "value": "person: [0.383, 0.438, 0.625, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000314177_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is seated at the center, wearing a cap and a patterned jacket, holding a camera with both hands.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.383, 0.438, 0.625, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000314177_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a man in a baseball cap and a plaid jacket is seated at the center, wearing a cap and a patterned jacket, holding a camera with both hands."
      },
      {
        "from": "gpt",
        "value": "man in a baseball cap and a plaid jacket: [0.383, 0.438, 0.625, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000314177_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a man in a baseball cap and a plaid jacket is seated at the center, wearing a cap and a patterned jacket, holding a camera with both hands.\nObjects: [man in a baseball cap and a plaid jacket]"
      },
      {
        "from": "gpt",
        "value": "man in a baseball cap and a plaid jacket: [0.383, 0.438, 0.625, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000314177_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.383, 0.438, 0.625, 0.930]\nGiven the above layout, shift the person upwards by 0.203."
      },
      {
        "from": "gpt",
        "value": "person: [0.383, 0.234, 0.625, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000315187",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is on the right side of the image, traveling on the street."
      },
      {
        "from": "gpt",
        "value": "bus: [0.453, 0.594, 0.867, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000315187_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is on the right side of the image, traveling on the street.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.453, 0.594, 0.867, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000315187_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a city bus is on the right side of the image, traveling on the street."
      },
      {
        "from": "gpt",
        "value": "city bus: [0.453, 0.594, 0.867, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000315187_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a city bus is on the right side of the image, traveling on the street.\nObjects: [city bus]"
      },
      {
        "from": "gpt",
        "value": "city bus: [0.453, 0.594, 0.867, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000315187_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.453, 0.594, 0.867, 0.789]\nGiven the above layout, shift the bus upwards by 0.508."
      },
      {
        "from": "gpt",
        "value": "bus: [0.453, 0.086, 0.867, 0.281]"
      }
    ]
  },
  {
    "id": "coco_000000341681",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center of the image, playing tennis and reaching out to hit the ball."
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.383, 0.664, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000341681_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center of the image, playing tennis and reaching out to hit the ball.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.383, 0.664, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000341681_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a strong athlete is in the center of the image, playing tennis and reaching out to hit the ball."
      },
      {
        "from": "gpt",
        "value": "a strong athlete: [0.328, 0.383, 0.664, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000341681_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a strong athlete is in the center of the image, playing tennis and reaching out to hit the ball.\nObjects: [a strong athlete]"
      },
      {
        "from": "gpt",
        "value": "a strong athlete: [0.328, 0.383, 0.664, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000341681_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.328, 0.383, 0.664, 0.664]\nGiven the above layout, shift the person upwards by 0.219."
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.164, 0.664, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000341828",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a sandwich with their left hand and a cell phone with their right hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.008, 0.977, 0.977]\nsandwich: [0.062, 0.711, 0.469, 0.984]\ncell phone: [0.547, 0.422, 0.711, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000341828_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a sandwich with their left hand and a cell phone with their right hand.\nObjects: [person, sandwich, cell phone]"
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.008, 0.977, 0.977]\nsandwich: [0.062, 0.711, 0.469, 0.984]\ncell phone: [0.547, 0.422, 0.711, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000341828_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a student in a blue jacket is holding a tuna sandwich with their left hand and a iPhone 11 with their right hand."
      },
      {
        "from": "gpt",
        "value": "student in a blue jacket: [0.000, 0.008, 0.977, 0.977]\ntuna sandwich: [0.062, 0.711, 0.469, 0.984]\niPhone 11: [0.547, 0.422, 0.711, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000341828_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a student in a blue jacket is holding a tuna sandwich with their left hand and a iPhone 11 with their right hand.\nObjects: [student in a blue jacket, tuna sandwich, iPhone 11]"
      },
      {
        "from": "gpt",
        "value": "student in a blue jacket: [0.000, 0.008, 0.977, 0.977]\ntuna sandwich: [0.062, 0.711, 0.469, 0.984]\niPhone 11: [0.547, 0.422, 0.711, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000341828_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.000, 0.008, 0.977, 0.977]\nsandwich: [0.062, 0.711, 0.469, 0.984]\ncell phone: [0.547, 0.422, 0.711, 0.648]\nGiven the above layout, shift the person to the right by 0.016."
      },
      {
        "from": "gpt",
        "value": "person: [0.016, 0.008, 0.992, 0.977]\nsandwich: [0.062, 0.711, 0.469, 0.984]\ncell phone: [0.547, 0.422, 0.711, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000343524",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the right side of the image holding a tennis racket."
      },
      {
        "from": "gpt",
        "value": "person: [0.156, 0.203, 0.422, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000343524_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the right side of the image holding a tennis racket.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.156, 0.203, 0.422, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000343524_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a tennis player is standing to the right side of the image holding a tennis racket."
      },
      {
        "from": "gpt",
        "value": "a tennis player: [0.156, 0.203, 0.422, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000343524_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a tennis player is standing to the right side of the image holding a tennis racket.\nObjects: [a tennis player]"
      },
      {
        "from": "gpt",
        "value": "a tennis player: [0.156, 0.203, 0.422, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000343524_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.156, 0.203, 0.422, 0.773]\nGiven the above layout, shift the person to the right by 0.312."
      },
      {
        "from": "gpt",
        "value": "person: [0.469, 0.203, 0.734, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000343706",
    "conversations": [
      {
        "from": "human",
        "value": "A person's hand is holding a cell phone."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.117, 0.992, 0.867]\ncell phone: [0.281, 0.602, 0.484, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000343706_key",
    "conversations": [
      {
        "from": "human",
        "value": "A persons hand is holding a cell phone.\nObjects: [person, cell phone]"
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.117, 0.992, 0.867]\ncell phone: [0.281, 0.602, 0.484, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000343706_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman's hand is holding a sleek black smartphone."
      },
      {
        "from": "gpt",
        "value": "young woman: [0.000, 0.117, 0.992, 0.867]\nsleek black smartphone: [0.281, 0.602, 0.484, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000343706_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young womans hand is holding a sleek black smartphone.\nObjects: [young woman, sleek black smartphone]"
      },
      {
        "from": "gpt",
        "value": "young woman: [0.000, 0.117, 0.992, 0.867]\nsleek black smartphone: [0.281, 0.602, 0.484, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000343706_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.000, 0.117, 0.992, 0.867]\ncell phone: [0.281, 0.602, 0.484, 0.734]\nGiven the above layout, shift the person downwards by 0.094."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.211, 0.992, 0.961]\ncell phone: [0.281, 0.602, 0.484, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000344029",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is positioned in the center of the image, facing towards the left side."
      },
      {
        "from": "gpt",
        "value": "bus: [0.141, 0.297, 0.922, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000344029_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is positioned in the center of the image, facing towards the left side.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.141, 0.297, 0.922, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000344029_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the blue double-decker bus is positioned in the center of the image, facing towards the left side."
      },
      {
        "from": "gpt",
        "value": "blue double-decker bus: [0.141, 0.297, 0.922, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000344029_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the blue double-decker bus is positioned in the center of the image, facing towards the left side.\nObjects: [blue double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "blue double-decker bus: [0.141, 0.297, 0.922, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000344029_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.141, 0.297, 0.922, 0.750]\nGiven the above layout, shift the bus upwards by 0.117."
      },
      {
        "from": "gpt",
        "value": "bus: [0.141, 0.180, 0.922, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000344268",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at a podium, clapping, with a microphone in front."
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.188, 0.688, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000344268_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at a podium, clapping, with a microphone in front.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.188, 0.688, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000344268_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman is standing at a podium, clapping, with a microphone in front."
      },
      {
        "from": "gpt",
        "value": "young woman: [0.172, 0.188, 0.688, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000344268_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman is standing at a podium, clapping, with a microphone in front.\nObjects: [young woman]"
      },
      {
        "from": "gpt",
        "value": "young woman: [0.172, 0.188, 0.688, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000344268_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.172, 0.188, 0.688, 0.875]\nGiven the above layout, shift the person to the right by 0.023."
      },
      {
        "from": "gpt",
        "value": "person: [0.195, 0.188, 0.711, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000344816",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks, moving towards the right side of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.219, 0.242, 0.781, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000344816_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks, moving towards the right side of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.219, 0.242, 0.781, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000344816_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the speed bullet train is on the tracks, moving towards the right side of the image."
      },
      {
        "from": "gpt",
        "value": "speed bullet train: [0.219, 0.242, 0.781, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000344816_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the speed bullet train is on the tracks, moving towards the right side of the image.\nObjects: [speed bullet train]"
      },
      {
        "from": "gpt",
        "value": "speed bullet train: [0.219, 0.242, 0.781, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000344816_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.219, 0.242, 0.781, 0.750]\nGiven the above layout, shift the train upwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "train: [0.219, 0.172, 0.781, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000347544",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is at the center of the image with its rear facing towards the viewer."
      },
      {
        "from": "gpt",
        "value": "bus: [0.383, 0.234, 0.867, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000347544_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is at the center of the image with its rear facing towards the viewer.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.383, 0.234, 0.867, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000347544_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a city bus is at the center of the image with its rear facing towards the viewer."
      },
      {
        "from": "gpt",
        "value": "city bus: [0.383, 0.234, 0.867, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000347544_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a city bus is at the center of the image with its rear facing towards the viewer.\nObjects: [city bus]"
      },
      {
        "from": "gpt",
        "value": "city bus: [0.383, 0.234, 0.867, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000347544_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.383, 0.234, 0.867, 0.750]\nGiven the above layout, shift the bus to the left by 0.047."
      },
      {
        "from": "gpt",
        "value": "bus: [0.336, 0.234, 0.820, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000348243",
    "conversations": [
      {
        "from": "human",
        "value": "The horse is at the center facing forward."
      },
      {
        "from": "gpt",
        "value": "horse: [0.258, 0.281, 0.648, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000348243_key",
    "conversations": [
      {
        "from": "human",
        "value": "The horse is at the center facing forward.\nObjects: [horse]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.258, 0.281, 0.648, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000348243_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the tall brown horse is at the center facing forward."
      },
      {
        "from": "gpt",
        "value": "tall brown horse: [0.258, 0.281, 0.648, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000348243_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the tall brown horse is at the center facing forward.\nObjects: [tall brown horse]"
      },
      {
        "from": "gpt",
        "value": "tall brown horse: [0.258, 0.281, 0.648, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000348243_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: horse: [0.258, 0.281, 0.648, 0.789]\nGiven the above layout, shift the horse to the right by 0.234."
      },
      {
        "from": "gpt",
        "value": "horse: [0.492, 0.281, 0.883, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000348881",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is parked at the gate connected to a jet bridge on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.000, 0.141, 0.250, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000348881_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is parked at the gate connected to a jet bridge on the left side of the image.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.000, 0.141, 0.250, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000348881_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an large commercial airliner is parked at the gate connected to a jet bridge on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "large commercial airliner: [0.000, 0.141, 0.250, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000348881_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an large commercial airliner is parked at the gate connected to a jet bridge on the left side of the image.\nObjects: [large commercial airliner]"
      },
      {
        "from": "gpt",
        "value": "large commercial airliner: [0.000, 0.141, 0.250, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000348881_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.000, 0.141, 0.250, 0.547]\nGiven the above layout, shift the airplane to the right by 0.539."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.539, 0.141, 0.789, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000349302",
    "conversations": [
      {
        "from": "human",
        "value": "Two giraffes standing next to each other; one giraffe is slightly behind and to the left of the other."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.180, 0.297, 0.398, 0.766]\ngiraffe: [0.422, 0.352, 0.602, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000349302_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two giraffes standing next to each other; one giraffe is slightly behind and to the left of the other.\nObjects: [giraffe, giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.180, 0.297, 0.398, 0.766]\ngiraffe: [0.422, 0.352, 0.602, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000366225",
    "conversations": [
      {
        "from": "human",
        "value": "A keyboard is directly in front of a TV."
      },
      {
        "from": "gpt",
        "value": "tv: [0.188, 0.016, 0.781, 0.492]\nkeyboard: [0.211, 0.812, 0.758, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000366225_key",
    "conversations": [
      {
        "from": "human",
        "value": "A keyboard is directly in front of a TV.\nObjects: [tv, keyboard]"
      },
      {
        "from": "gpt",
        "value": "tv: [0.188, 0.016, 0.781, 0.492]\nkeyboard: [0.211, 0.812, 0.758, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000366225_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek gaming keyboard is directly in front of a large flat screen TV."
      },
      {
        "from": "gpt",
        "value": "large flat screen TV: [0.188, 0.016, 0.781, 0.492]\nsleek gaming keyboard: [0.211, 0.812, 0.758, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000366225_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek gaming keyboard is directly in front of a large flat screen TV.\nObjects: [large flat screen TV, sleek gaming keyboard]"
      },
      {
        "from": "gpt",
        "value": "large flat screen TV: [0.188, 0.016, 0.781, 0.492]\nsleek gaming keyboard: [0.211, 0.812, 0.758, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000366225_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: tv: [0.188, 0.016, 0.781, 0.492]\nkeyboard: [0.211, 0.812, 0.758, 0.938]\nGiven the above layout, shift the tv to the right by 0.047."
      },
      {
        "from": "gpt",
        "value": "tv: [0.234, 0.016, 0.828, 0.492]\nkeyboard: [0.211, 0.812, 0.758, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000376307",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting behind a dining table adorned with various fruits, including bananas at the center."
      },
      {
        "from": "gpt",
        "value": "dining table: [0.125, 0.555, 0.844, 0.992]\nperson: [0.617, 0.297, 0.867, 0.836]\nbanana: [0.633, 0.703, 0.789, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000376307_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting behind a dining table adorned with various fruits, including bananas at the center.\nObjects: [dining table, person, banana]"
      },
      {
        "from": "gpt",
        "value": "dining table: [0.125, 0.555, 0.844, 0.992]\nperson: [0.617, 0.297, 0.867, 0.836]\nbanana: [0.633, 0.703, 0.789, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000376307_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a person is sitting behind a dining table adorned with various fruits, including bananas at the center."
      },
      {
        "from": "gpt",
        "value": "dining table: [0.125, 0.555, 0.844, 0.992]\nperson: [0.617, 0.297, 0.867, 0.836]\nbanana: [0.633, 0.703, 0.789, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000376307_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a person is sitting behind a dining table adorned with various fruits, including bananas at the center.\nObjects: [dining table, person, banana]"
      },
      {
        "from": "gpt",
        "value": "dining table: [0.125, 0.555, 0.844, 0.992]\nperson: [0.617, 0.297, 0.867, 0.836]\nbanana: [0.633, 0.703, 0.789, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000376307_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dining table: [0.125, 0.555, 0.844, 0.992]\nperson: [0.617, 0.297, 0.867, 0.836]\nbanana: [0.633, 0.703, 0.789, 0.875]\nGiven the above layout, shift the person upwards by 0.219."
      },
      {
        "from": "gpt",
        "value": "dining table: [0.125, 0.555, 0.844, 0.992]\nperson: [0.617, 0.078, 0.867, 0.617]\nbanana: [0.633, 0.703, 0.789, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000376478",
    "conversations": [
      {
        "from": "human",
        "value": "A vase is centered on a wooden surface with a flower in it."
      },
      {
        "from": "gpt",
        "value": "vase: [0.203, 0.305, 0.539, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000376478_key",
    "conversations": [
      {
        "from": "human",
        "value": "A vase is centered on a wooden surface with a flower in it.\nObjects: [vase]"
      },
      {
        "from": "gpt",
        "value": "vase: [0.203, 0.305, 0.539, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000376478_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a porcelain vase with intricate design is centered on a wooden surface with a flower in it."
      },
      {
        "from": "gpt",
        "value": "porcelain vase with intricate design: [0.203, 0.305, 0.539, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000376478_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a porcelain vase with intricate design is centered on a wooden surface with a flower in it.\nObjects: [porcelain vase with intricate design]"
      },
      {
        "from": "gpt",
        "value": "porcelain vase with intricate design: [0.203, 0.305, 0.539, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000376478_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: vase: [0.203, 0.305, 0.539, 0.852]\nGiven the above layout, shift the vase to the right by 0.375."
      },
      {
        "from": "gpt",
        "value": "vase: [0.578, 0.305, 0.914, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000376900",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center of the image, tossing a tennis ball up with their right hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.250, 0.273, 0.492, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000376900_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center of the image, tossing a tennis ball up with their right hand.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.250, 0.273, 0.492, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000376900_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a adult man is standing at the center of the image, tossing a tennis ball up with their right hand."
      },
      {
        "from": "gpt",
        "value": "adult man: [0.250, 0.273, 0.492, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000376900_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a adult man is standing at the center of the image, tossing a tennis ball up with their right hand.\nObjects: [adult man]"
      },
      {
        "from": "gpt",
        "value": "adult man: [0.250, 0.273, 0.492, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000376900_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.250, 0.273, 0.492, 0.930]\nGiven the above layout, shift the person to the right by 0.125."
      },
      {
        "from": "gpt",
        "value": "person: [0.375, 0.273, 0.617, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000377497",
    "conversations": [
      {
        "from": "human",
        "value": "The head of a zebra is at the center right of the image, facing left."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.227, 0.055, 0.828, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000377497_key",
    "conversations": [
      {
        "from": "human",
        "value": "The head of a zebra is at the center right of the image, facing left.\nObjects: [zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.227, 0.055, 0.828, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000377497_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the head of a striped horse is at the center right of the image, facing left."
      },
      {
        "from": "gpt",
        "value": "striped horse: [0.227, 0.055, 0.828, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000377497_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the head of a striped horse is at the center right of the image, facing left.\nObjects: [striped horse]"
      },
      {
        "from": "gpt",
        "value": "striped horse: [0.227, 0.055, 0.828, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000377497_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: zebra: [0.227, 0.055, 0.828, 0.906]\nGiven the above layout, shift the zebra to the left by 0.188."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.039, 0.055, 0.641, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000377575",
    "conversations": [
      {
        "from": "human",
        "value": "A dog stands in front of a fire hydrant."
      },
      {
        "from": "gpt",
        "value": "dog: [0.258, 0.250, 0.602, 0.969]\nfire hydrant: [0.531, 0.305, 0.672, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000377575_key",
    "conversations": [
      {
        "from": "human",
        "value": "A dog stands in front of a fire hydrant.\nObjects: [dog, fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.258, 0.250, 0.602, 0.969]\nfire hydrant: [0.531, 0.305, 0.672, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000378099",
    "conversations": [
      {
        "from": "human",
        "value": "A keyboard is at the center with a mouse to its right on a wooden surface."
      },
      {
        "from": "gpt",
        "value": "keyboard: [0.047, 0.352, 0.828, 0.625]\nmouse: [0.805, 0.477, 0.945, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000378099_key",
    "conversations": [
      {
        "from": "human",
        "value": "A keyboard is at the center with a mouse to its right on a wooden surface.\nObjects: [keyboard, mouse]"
      },
      {
        "from": "gpt",
        "value": "keyboard: [0.047, 0.352, 0.828, 0.625]\nmouse: [0.805, 0.477, 0.945, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000378099_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek computer keyboard is at the center with a ergonomic wireless mouse to its right on a wooden surface."
      },
      {
        "from": "gpt",
        "value": "sleek computer keyboard: [0.047, 0.352, 0.828, 0.625]\nergonomic wireless mouse: [0.805, 0.477, 0.945, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000378099_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek computer keyboard is at the center with a ergonomic wireless mouse to its right on a wooden surface.\nObjects: [sleek computer keyboard, ergonomic wireless mouse]"
      },
      {
        "from": "gpt",
        "value": "sleek computer keyboard: [0.047, 0.352, 0.828, 0.625]\nergonomic wireless mouse: [0.805, 0.477, 0.945, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000378099_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: keyboard: [0.047, 0.352, 0.828, 0.625]\nmouse: [0.805, 0.477, 0.945, 0.664]\nGiven the above layout, shift the keyboard upwards by 0.227."
      },
      {
        "from": "gpt",
        "value": "keyboard: [0.047, 0.125, 0.828, 0.398]\nmouse: [0.805, 0.477, 0.945, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000380203",
    "conversations": [
      {
        "from": "human",
        "value": "A white horse is at the center of the image, grazing on the right side."
      },
      {
        "from": "gpt",
        "value": "horse: [0.227, 0.172, 0.766, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000380203_key",
    "conversations": [
      {
        "from": "human",
        "value": "A white horse is at the center of the image, grazing on the right side.\nObjects: [horse]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.227, 0.172, 0.766, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000380203_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a white dappled grey horse is at the center of the image, grazing on the right side."
      },
      {
        "from": "gpt",
        "value": "dappled grey horse: [0.227, 0.172, 0.766, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000380203_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a white dappled grey horse is at the center of the image, grazing on the right side.\nObjects: [dappled grey horse]"
      },
      {
        "from": "gpt",
        "value": "dappled grey horse: [0.227, 0.172, 0.766, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000380203_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: horse: [0.227, 0.172, 0.766, 0.891]\nGiven the above layout, shift the horse to the left by 0.109."
      },
      {
        "from": "gpt",
        "value": "horse: [0.117, 0.172, 0.656, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000381360",
    "conversations": [
      {
        "from": "human",
        "value": "A person in a wetsuit is surfing on the waves at the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.039, 0.297, 0.281, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000381360_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in a wetsuit is surfing on the waves at the center of the image.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.039, 0.297, 0.281, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000381360_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a an adventurous surfer in a wetsuit is surfing on the waves at the center of the image."
      },
      {
        "from": "gpt",
        "value": "an adventurous surfer: [0.039, 0.297, 0.281, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000381360_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a an adventurous surfer in a wetsuit is surfing on the waves at the center of the image.\nObjects: [an adventurous surfer]"
      },
      {
        "from": "gpt",
        "value": "an adventurous surfer: [0.039, 0.297, 0.281, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000381360_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.039, 0.297, 0.281, 0.641]\nGiven the above layout, shift the person to the right by 0.469."
      },
      {
        "from": "gpt",
        "value": "person: [0.508, 0.297, 0.750, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000382088",
    "conversations": [
      {
        "from": "human",
        "value": "A horse is in the center of the image, facing forward."
      },
      {
        "from": "gpt",
        "value": "horse: [0.289, 0.273, 0.672, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000382088_key",
    "conversations": [
      {
        "from": "human",
        "value": "A horse is in the center of the image, facing forward.\nObjects: [horse]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.289, 0.273, 0.672, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000382088_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a brown Clydesdale horse is in the center of the image, facing forward."
      },
      {
        "from": "gpt",
        "value": "brown Clydesdale horse: [0.289, 0.273, 0.672, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000382088_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a brown Clydesdale horse is in the center of the image, facing forward.\nObjects: [brown Clydesdale horse]"
      },
      {
        "from": "gpt",
        "value": "brown Clydesdale horse: [0.289, 0.273, 0.672, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000382088_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: horse: [0.289, 0.273, 0.672, 0.812]\nGiven the above layout, shift the horse to the right by 0.250."
      },
      {
        "from": "gpt",
        "value": "horse: [0.539, 0.273, 0.922, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000382696",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is on the left and the oven is to the right of it."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.102, 0.242, 0.328, 0.688]\noven: [0.375, 0.391, 0.602, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000382696_key",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is on the left and the oven is to the right of it.\nObjects: [refrigerator, oven]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.102, 0.242, 0.328, 0.688]\noven: [0.375, 0.391, 0.602, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000382696_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the shiny stainless-steel refrigerator is on the left and the black electric oven is to the right of it."
      },
      {
        "from": "gpt",
        "value": "shiny stainless-steel refrigerator: [0.102, 0.242, 0.328, 0.688]\nblack electric oven: [0.375, 0.391, 0.602, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000382696_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the shiny stainless-steel refrigerator is on the left and the black electric oven is to the right of it.\nObjects: [shiny stainless-steel refrigerator, black electric oven]"
      },
      {
        "from": "gpt",
        "value": "shiny stainless-steel refrigerator: [0.102, 0.242, 0.328, 0.688]\nblack electric oven: [0.375, 0.391, 0.602, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000382696_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: refrigerator: [0.102, 0.242, 0.328, 0.688]\noven: [0.375, 0.391, 0.602, 0.672]\nGiven the above layout, shift the oven to the right by 0.164."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.102, 0.242, 0.328, 0.688]\noven: [0.539, 0.391, 0.766, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000382743",
    "conversations": [
      {
        "from": "human",
        "value": "An umbrella is on the left side of the image with part of its canopy visible. Another umbrella is visible on the right side with its striped pattern."
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.617, 0.602, 0.992, 0.859]\numbrella: [0.000, 0.125, 0.188, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000382743_key",
    "conversations": [
      {
        "from": "human",
        "value": "An umbrella is on the left side of the image with part of its canopy visible. Another umbrella is visible on the right side with its striped pattern.\nObjects: [umbrella, umbrella]"
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.617, 0.602, 0.992, 0.859]\numbrella: [0.000, 0.125, 0.188, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000383606",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center of the image, reflected in a mirror above a sink to the right."
      },
      {
        "from": "gpt",
        "value": "sink: [0.211, 0.555, 0.602, 0.766]\nperson: [0.469, 0.320, 0.539, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000383606_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center of the image, reflected in a mirror above a sink to the right.\nObjects: [sink, person]"
      },
      {
        "from": "gpt",
        "value": "sink: [0.211, 0.555, 0.602, 0.766]\nperson: [0.469, 0.320, 0.539, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000383606_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in a blue dress is standing in the center of the image, reflected in a mirror above a ceramic basin to the right."
      },
      {
        "from": "gpt",
        "value": "ceramic basin: [0.211, 0.555, 0.602, 0.766]\nwoman in a blue dress: [0.469, 0.320, 0.539, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000383606_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in a blue dress is standing in the center of the image, reflected in a mirror above a ceramic basin to the right.\nObjects: [ceramic basin, woman in a blue dress]"
      },
      {
        "from": "gpt",
        "value": "ceramic basin: [0.211, 0.555, 0.602, 0.766]\nwoman in a blue dress: [0.469, 0.320, 0.539, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000383606_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sink: [0.211, 0.555, 0.602, 0.766]\nperson: [0.469, 0.320, 0.539, 0.562]\nGiven the above layout, shift the sink to the right by 0.102."
      },
      {
        "from": "gpt",
        "value": "sink: [0.312, 0.555, 0.703, 0.766]\nperson: [0.469, 0.320, 0.539, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000407574",
    "conversations": [
      {
        "from": "human",
        "value": "Two bunches of bananas are hanging, one above the other, from a metal hook attached to a wooden pole."
      },
      {
        "from": "gpt",
        "value": "banana: [0.273, 0.148, 0.719, 0.680]\nbanana: [0.258, 0.586, 0.609, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000407574_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two bunches of bananas are hanging, one above the other, from a metal hook attached to a wooden pole.\nObjects: [banana, banana]"
      },
      {
        "from": "gpt",
        "value": "banana: [0.273, 0.148, 0.719, 0.680]\nbanana: [0.258, 0.586, 0.609, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000417779",
    "conversations": [
      {
        "from": "human",
        "value": "A fire hydrant on the right side of the image, on the sidewalk near an intersection of streets."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.406, 0.430, 0.625, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000417779_key",
    "conversations": [
      {
        "from": "human",
        "value": "A fire hydrant on the right side of the image, on the sidewalk near an intersection of streets.\nObjects: [fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.406, 0.430, 0.625, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000417779_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red fire hydrant on the right side of the image, on the sidewalk near an intersection of streets."
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.406, 0.430, 0.625, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000417779_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red fire hydrant on the right side of the image, on the sidewalk near an intersection of streets.\nObjects: [red fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.406, 0.430, 0.625, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000417779_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: fire hydrant: [0.406, 0.430, 0.625, 0.859]\nGiven the above layout, shift the fire hydrant upwards by 0.164."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.406, 0.266, 0.625, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000419096",
    "conversations": [
      {
        "from": "human",
        "value": "The train is centered in the image, oriented diagonally from the bottom left to the top right."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.375, 0.953, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000419096_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is centered in the image, oriented diagonally from the bottom left to the top right.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.375, 0.953, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000419096_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the an antique steam locomotive is centered in the image, oriented diagonally from the bottom left to the top right."
      },
      {
        "from": "gpt",
        "value": "an antique steam locomotive: [0.000, 0.375, 0.953, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000419096_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the an antique steam locomotive is centered in the image, oriented diagonally from the bottom left to the top right.\nObjects: [an antique steam locomotive]"
      },
      {
        "from": "gpt",
        "value": "an antique steam locomotive: [0.000, 0.375, 0.953, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000419096_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.375, 0.953, 0.727]\nGiven the above layout, shift the train upwards by 0.312."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.062, 0.953, 0.414]"
      }
    ]
  },
  {
    "id": "coco_000000420069",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the foreground on the left watching another person in the middle ground throwing a frisbee."
      },
      {
        "from": "gpt",
        "value": "person: [0.094, 0.375, 0.250, 0.852]\nperson: [0.469, 0.414, 0.539, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000420069_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the foreground on the left watching another person in the middle ground throwing a frisbee.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.094, 0.375, 0.250, 0.852]\nperson: [0.469, 0.414, 0.539, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000420230",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant facing forward, centered in the image."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.195, 0.031, 0.773, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000420230_key",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant facing forward, centered in the image.\nObjects: [elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.195, 0.031, 0.773, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000420230_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an majestic Indian elephant facing forward, centered in the image."
      },
      {
        "from": "gpt",
        "value": "majestic Indian elephant: [0.195, 0.031, 0.773, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000420230_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an majestic Indian elephant facing forward, centered in the image.\nObjects: [majestic Indian elephant]"
      },
      {
        "from": "gpt",
        "value": "majestic Indian elephant: [0.195, 0.031, 0.773, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000420230_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: elephant: [0.195, 0.031, 0.773, 0.969]\nGiven the above layout, shift the elephant to the right by 0.031."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.227, 0.031, 0.805, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000420472",
    "conversations": [
      {
        "from": "human",
        "value": "One giraffe facing left and the other facing right, both meeting in the center with their necks crossed."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.008, 0.281, 0.484, 0.781]\ngiraffe: [0.516, 0.531, 0.992, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000420472_key",
    "conversations": [
      {
        "from": "human",
        "value": "One giraffe facing left and the other facing right, both meeting in the center with their necks crossed.\nObjects: [giraffe, giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.008, 0.281, 0.484, 0.781]\ngiraffe: [0.516, 0.531, 0.992, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000421757",
    "conversations": [
      {
        "from": "human",
        "value": "Two boats on the water, side by side, with one slightly ahead of the other."
      },
      {
        "from": "gpt",
        "value": "boat: [0.039, 0.305, 0.438, 0.547]\nboat: [0.445, 0.367, 0.781, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000421757_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two boats on the water, side by side, with one slightly ahead of the other.\nObjects: [boat, boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.039, 0.305, 0.438, 0.547]\nboat: [0.445, 0.367, 0.781, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000421834",
    "conversations": [
      {
        "from": "human",
        "value": "A red bird is perched on the right side of a green bird feeder."
      },
      {
        "from": "gpt",
        "value": "bird: [0.086, 0.391, 0.648, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000421834_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red bird is perched on the right side of a green bird feeder.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.086, 0.391, 0.648, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000421834_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red scarlet macaw is perched on the right side of a green scarlet macaw feeder."
      },
      {
        "from": "gpt",
        "value": "scarlet macaw: [0.086, 0.391, 0.648, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000421834_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red scarlet macaw is perched on the right side of a green scarlet macaw feeder.\nObjects: [scarlet macaw]"
      },
      {
        "from": "gpt",
        "value": "scarlet macaw: [0.086, 0.391, 0.648, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000421834_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.086, 0.391, 0.648, 0.570]\nGiven the above layout, shift the bird downwards by 0.055."
      },
      {
        "from": "gpt",
        "value": "bird: [0.086, 0.445, 0.648, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000423229",
    "conversations": [
      {
        "from": "human",
        "value": "An old-fashioned steam train is on tracks turning slightly to the right."
      },
      {
        "from": "gpt",
        "value": "train: [0.398, 0.344, 0.969, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000423229_key",
    "conversations": [
      {
        "from": "human",
        "value": "An old-fashioned steam train is on tracks turning slightly to the right.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.398, 0.344, 0.969, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000423229_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an old-fashioned steam vintage locomotive is on tracks turning slightly to the right."
      },
      {
        "from": "gpt",
        "value": "vintage locomotive: [0.398, 0.344, 0.969, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000423229_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an old-fashioned steam vintage locomotive is on tracks turning slightly to the right.\nObjects: [vintage locomotive]"
      },
      {
        "from": "gpt",
        "value": "vintage locomotive: [0.398, 0.344, 0.969, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000423229_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.398, 0.344, 0.969, 0.711]\nGiven the above layout, shift the train to the left by 0.398."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.344, 0.570, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000424521",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in mid-air above a skateboard, which is positioned on the ground to the bottom right of the person."
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.273, 0.539, 0.602]\nskateboard: [0.234, 0.523, 0.461, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000424521_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in mid-air above a skateboard, which is positioned on the ground to the bottom right of the person.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.273, 0.539, 0.602]\nskateboard: [0.234, 0.523, 0.461, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000424521_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager wearing a red shirt is in mid-air above a worn-out skateboard with scratches, which is positioned on the ground to the bottom right of the teenager wearing a red shirt."
      },
      {
        "from": "gpt",
        "value": "teenager wearing a red shirt: [0.273, 0.273, 0.539, 0.602]\nworn-out skateboard with scratches: [0.234, 0.523, 0.461, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000424521_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager wearing a red shirt is in mid-air above a worn-out skateboard with scratches, which is positioned on the ground to the bottom right of the teenager wearing a red shirt.\nObjects: [teenager wearing a red shirt, worn-out skateboard with scratches]"
      },
      {
        "from": "gpt",
        "value": "teenager wearing a red shirt: [0.273, 0.273, 0.539, 0.602]\nworn-out skateboard with scratches: [0.234, 0.523, 0.461, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000424521_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.273, 0.273, 0.539, 0.602]\nskateboard: [0.234, 0.523, 0.461, 0.617]\nGiven the above layout, shift the person to the right by 0.352."
      },
      {
        "from": "gpt",
        "value": "person: [0.625, 0.273, 0.891, 0.602]\nskateboard: [0.234, 0.523, 0.461, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000424776",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying above snow-covered ground, angled slightly to the right of the image."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.023, 0.305, 0.938, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000424776_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying above snow-covered ground, angled slightly to the right of the image.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.023, 0.305, 0.938, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000424776_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an red biplane is flying above snow-covered ground, angled slightly to the right of the image."
      },
      {
        "from": "gpt",
        "value": "red biplane: [0.023, 0.305, 0.938, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000424776_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an red biplane is flying above snow-covered ground, angled slightly to the right of the image.\nObjects: [red biplane]"
      },
      {
        "from": "gpt",
        "value": "red biplane: [0.023, 0.305, 0.938, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000424776_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.023, 0.305, 0.938, 0.680]\nGiven the above layout, shift the airplane downwards by 0.164."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.023, 0.469, 0.938, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000426166",
    "conversations": [
      {
        "from": "human",
        "value": "The bicycle is leaning against a wall between a green door to the left and a red door to the right."
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.211, 0.508, 0.508, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000426166_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bicycle is leaning against a wall between a green door to the left and a red door to the right.\nObjects: [bicycle]"
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.211, 0.508, 0.508, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000426166_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the shiny mountain bike is leaning against a wall between a green door to the left and a red door to the right."
      },
      {
        "from": "gpt",
        "value": "shiny mountain bike: [0.211, 0.508, 0.508, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000426166_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the shiny mountain bike is leaning against a wall between a green door to the left and a red door to the right.\nObjects: [shiny mountain bike]"
      },
      {
        "from": "gpt",
        "value": "shiny mountain bike: [0.211, 0.508, 0.508, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000426166_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bicycle: [0.211, 0.508, 0.508, 0.758]\nGiven the above layout, shift the bicycle upwards by 0.164."
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.211, 0.344, 0.508, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000426203",
    "conversations": [
      {
        "from": "human",
        "value": "A person is jumping over a bench with a skateboard."
      },
      {
        "from": "gpt",
        "value": "person: [0.438, 0.180, 0.664, 0.477]\nbench: [0.578, 0.641, 0.828, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000426203_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is jumping over a bench with a skateboard.\nObjects: [person, bench]"
      },
      {
        "from": "gpt",
        "value": "person: [0.438, 0.180, 0.664, 0.477]\nbench: [0.578, 0.641, 0.828, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000426203_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager in a hoodie is jumping over a park bench with a skateboard."
      },
      {
        "from": "gpt",
        "value": "teenager in a hoodie: [0.438, 0.180, 0.664, 0.477]\npark bench: [0.578, 0.641, 0.828, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000426203_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager in a hoodie is jumping over a park bench with a skateboard.\nObjects: [teenager in a hoodie, park bench]"
      },
      {
        "from": "gpt",
        "value": "teenager in a hoodie: [0.438, 0.180, 0.664, 0.477]\npark bench: [0.578, 0.641, 0.828, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000426203_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.438, 0.180, 0.664, 0.477]\nbench: [0.578, 0.641, 0.828, 0.859]\nGiven the above layout, shift the person to the left by 0.414."
      },
      {
        "from": "gpt",
        "value": "person: [0.023, 0.180, 0.250, 0.477]\nbench: [0.578, 0.641, 0.828, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000426253",
    "conversations": [
      {
        "from": "human",
        "value": "A bottle is to the right of the microwave."
      },
      {
        "from": "gpt",
        "value": "microwave: [0.070, 0.258, 0.922, 0.719]\nbottle: [0.914, 0.297, 0.992, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000426253_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bottle is to the right of the microwave.\nObjects: [microwave, bottle]"
      },
      {
        "from": "gpt",
        "value": "microwave: [0.070, 0.258, 0.922, 0.719]\nbottle: [0.914, 0.297, 0.992, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000426253_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a glass milk bottle is to the right of the countertop microwave."
      },
      {
        "from": "gpt",
        "value": "countertop microwave: [0.070, 0.258, 0.922, 0.719]\nglass milk bottle: [0.914, 0.297, 0.992, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000426253_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a glass milk bottle is to the right of the countertop microwave.\nObjects: [countertop microwave, glass milk bottle]"
      },
      {
        "from": "gpt",
        "value": "countertop microwave: [0.070, 0.258, 0.922, 0.719]\nglass milk bottle: [0.914, 0.297, 0.992, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000426253_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: microwave: [0.070, 0.258, 0.922, 0.719]\nbottle: [0.914, 0.297, 0.992, 0.578]\nGiven the above layout, shift the microwave downwards by 0.031."
      },
      {
        "from": "gpt",
        "value": "microwave: [0.070, 0.289, 0.922, 0.750]\nbottle: [0.914, 0.297, 0.992, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000446207",
    "conversations": [
      {
        "from": "human",
        "value": "A cell phone is lying on a flat surface in the foreground, to the left of a camera."
      },
      {
        "from": "gpt",
        "value": "cell phone: [0.172, 0.562, 0.773, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000446207_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cell phone is lying on a flat surface in the foreground, to the left of a camera.\nObjects: [cell phone]"
      },
      {
        "from": "gpt",
        "value": "cell phone: [0.172, 0.562, 0.773, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000446207_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a rose gold iPhone is lying on a flat surface in the foreground, to the left of a camera."
      },
      {
        "from": "gpt",
        "value": "rose gold iPhone: [0.172, 0.562, 0.773, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000446207_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a rose gold iPhone is lying on a flat surface in the foreground, to the left of a camera.\nObjects: [rose gold iPhone]"
      },
      {
        "from": "gpt",
        "value": "rose gold iPhone: [0.172, 0.562, 0.773, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000446207_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cell phone: [0.172, 0.562, 0.773, 0.852]\nGiven the above layout, shift the cell phone upwards by 0.305."
      },
      {
        "from": "gpt",
        "value": "cell phone: [0.172, 0.258, 0.773, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000455555",
    "conversations": [
      {
        "from": "human",
        "value": "One person is sitting on a skateboard in the foreground, and another person is crouching in the background to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.195, 0.227, 0.703, 0.805]\nperson: [0.734, 0.141, 0.969, 0.445]\nskateboard: [0.242, 0.695, 0.477, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000455555_key",
    "conversations": [
      {
        "from": "human",
        "value": "One person is sitting on a skateboard in the foreground, and another person is crouching in the background to the right.\nObjects: [person, person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.195, 0.227, 0.703, 0.805]\nperson: [0.734, 0.141, 0.969, 0.445]\nskateboard: [0.242, 0.695, 0.477, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000456303",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the air on a snowboard above another person who is on the ground."
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.133, 0.594, 0.492]\nsnowboard: [0.180, 0.688, 0.414, 0.789]\nperson: [0.406, 0.609, 0.531, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000456303_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the air on a snowboard above another person who is on the ground.\nObjects: [person, snowboard, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.133, 0.594, 0.492]\nsnowboard: [0.180, 0.688, 0.414, 0.789]\nperson: [0.406, 0.609, 0.531, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000456496",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on the right side with their back towards the viewer."
      },
      {
        "from": "gpt",
        "value": "person: [0.234, 0.273, 0.453, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000456496_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on the right side with their back towards the viewer.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.234, 0.273, 0.453, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000456496_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman wearing a red jacket is sitting on the right side with their back towards the viewer."
      },
      {
        "from": "gpt",
        "value": "young woman wearing a red jacket: [0.234, 0.273, 0.453, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000456496_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman wearing a red jacket is sitting on the right side with their back towards the viewer.\nObjects: [young woman wearing a red jacket]"
      },
      {
        "from": "gpt",
        "value": "young woman wearing a red jacket: [0.234, 0.273, 0.453, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000456496_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.234, 0.273, 0.453, 0.641]\nGiven the above layout, shift the person to the right by 0.273."
      },
      {
        "from": "gpt",
        "value": "person: [0.508, 0.273, 0.727, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000456865",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is on the ground towards the right of the image, with the front facing left."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.133, 0.414, 0.906, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000456865_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is on the ground towards the right of the image, with the front facing left.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.133, 0.414, 0.906, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000456865_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an large jumbo jet is on the ground towards the right of the image, with the front facing left."
      },
      {
        "from": "gpt",
        "value": "large jumbo jet: [0.133, 0.414, 0.906, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000456865_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an large jumbo jet is on the ground towards the right of the image, with the front facing left.\nObjects: [large jumbo jet]"
      },
      {
        "from": "gpt",
        "value": "large jumbo jet: [0.133, 0.414, 0.906, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000456865_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.133, 0.414, 0.906, 0.641]\nGiven the above layout, shift the airplane upwards by 0.133."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.133, 0.281, 0.906, 0.508]"
      }
    ]
  },
  {
    "id": "coco_000000457078",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the right of a TV that is on the left side."
      },
      {
        "from": "gpt",
        "value": "person: [0.703, 0.188, 0.992, 0.703]\ntv: [0.000, 0.469, 0.227, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000457078_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the right of a TV that is on the left side.\nObjects: [person, tv]"
      },
      {
        "from": "gpt",
        "value": "person: [0.703, 0.188, 0.992, 0.703]\ntv: [0.000, 0.469, 0.227, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000457078_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in a pink shirt is standing to the right of a flat-screen TV that is on the left side."
      },
      {
        "from": "gpt",
        "value": "woman in a pink shirt: [0.703, 0.188, 0.992, 0.703]\nflat-screen TV: [0.000, 0.469, 0.227, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000457078_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in a pink shirt is standing to the right of a flat-screen TV that is on the left side.\nObjects: [woman in a pink shirt, flat-screen TV]"
      },
      {
        "from": "gpt",
        "value": "woman in a pink shirt: [0.703, 0.188, 0.992, 0.703]\nflat-screen TV: [0.000, 0.469, 0.227, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000457078_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.703, 0.188, 0.992, 0.703]\ntv: [0.000, 0.469, 0.227, 0.734]\nGiven the above layout, shift the tv downwards by 0.156."
      },
      {
        "from": "gpt",
        "value": "person: [0.703, 0.188, 0.992, 0.703]\ntv: [0.000, 0.625, 0.227, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000460927",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is at the center of the image, standing on grass with mountains in the background."
      },
      {
        "from": "gpt",
        "value": "bear: [0.172, 0.312, 0.750, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000460927_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is at the center of the image, standing on grass with mountains in the background.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.172, 0.312, 0.750, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000460927_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the grizzly bear is at the center of the image, standing on grass with mountains in the background."
      },
      {
        "from": "gpt",
        "value": "grizzly bear: [0.172, 0.312, 0.750, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000460927_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the grizzly bear is at the center of the image, standing on grass with mountains in the background.\nObjects: [grizzly bear]"
      },
      {
        "from": "gpt",
        "value": "grizzly bear: [0.172, 0.312, 0.750, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000460927_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.172, 0.312, 0.750, 0.695]\nGiven the above layout, shift the bear upwards by 0.086."
      },
      {
        "from": "gpt",
        "value": "bear: [0.172, 0.227, 0.750, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000460929",
    "conversations": [
      {
        "from": "human",
        "value": "A bottle is to the left of a hot dog wrapped in foil."
      },
      {
        "from": "gpt",
        "value": "bottle: [0.570, 0.000, 0.773, 0.641]\nhot dog: [0.398, 0.555, 0.641, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000460929_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bottle is to the left of a hot dog wrapped in foil.\nObjects: [bottle, hot dog]"
      },
      {
        "from": "gpt",
        "value": "bottle: [0.570, 0.000, 0.773, 0.641]\nhot dog: [0.398, 0.555, 0.641, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000460929_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a glass water bottle is to the left of a Packed sandwich wrapped in foil."
      },
      {
        "from": "gpt",
        "value": "glass water bottle: [0.570, 0.000, 0.773, 0.641]\nPacked sandwich: [0.398, 0.555, 0.641, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000460929_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a glass water bottle is to the left of a Packed sandwich wrapped in foil.\nObjects: [glass water bottle, Packed sandwich]"
      },
      {
        "from": "gpt",
        "value": "glass water bottle: [0.570, 0.000, 0.773, 0.641]\nPacked sandwich: [0.398, 0.555, 0.641, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000460929_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bottle: [0.570, 0.000, 0.773, 0.641]\nhot dog: [0.398, 0.555, 0.641, 0.984]\nGiven the above layout, shift the hot dog to the left by 0.312."
      },
      {
        "from": "gpt",
        "value": "bottle: [0.570, 0.000, 0.773, 0.641]\nhot dog: [0.086, 0.555, 0.328, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000463842",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is at the center of the image, elevated on a platform of colorful bottles."
      },
      {
        "from": "gpt",
        "value": "bed: [0.117, 0.320, 0.883, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000463842_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is at the center of the image, elevated on a platform of colorful bottles.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.117, 0.320, 0.883, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000463842_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the king-size mahogany bed is at the center of the image, elevated on a platform of colorful bottles."
      },
      {
        "from": "gpt",
        "value": "king-size mahogany bed: [0.117, 0.320, 0.883, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000463842_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the king-size mahogany bed is at the center of the image, elevated on a platform of colorful bottles.\nObjects: [king-size mahogany bed]"
      },
      {
        "from": "gpt",
        "value": "king-size mahogany bed: [0.117, 0.320, 0.883, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000463842_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.117, 0.320, 0.883, 0.539]\nGiven the above layout, shift the bed downwards by 0.094."
      },
      {
        "from": "gpt",
        "value": "bed: [0.117, 0.414, 0.883, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000464144",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on skis."
      },
      {
        "from": "gpt",
        "value": "person: [0.258, 0.289, 0.656, 0.891]\nskis: [0.172, 0.820, 0.617, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000464144_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on skis.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.258, 0.289, 0.656, 0.891]\nskis: [0.172, 0.820, 0.617, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000464144_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young man is standing on red snow skis."
      },
      {
        "from": "gpt",
        "value": "young man: [0.258, 0.289, 0.656, 0.891]\nred snow skis: [0.172, 0.820, 0.617, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000464144_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young man is standing on red snow skis.\nObjects: [young man, red snow skis]"
      },
      {
        "from": "gpt",
        "value": "young man: [0.258, 0.289, 0.656, 0.891]\nred snow skis: [0.172, 0.820, 0.617, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000464144_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.258, 0.289, 0.656, 0.891]\nskis: [0.172, 0.820, 0.617, 0.945]\nGiven the above layout, shift the person to the right by 0.180."
      },
      {
        "from": "gpt",
        "value": "person: [0.438, 0.289, 0.836, 0.891]\nskis: [0.172, 0.820, 0.617, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000464358",
    "conversations": [
      {
        "from": "human",
        "value": "A bed is at the center of the image, and a chair is to the right of the bed near the window."
      },
      {
        "from": "gpt",
        "value": "bed: [0.078, 0.469, 0.656, 0.820]\nchair: [0.438, 0.422, 0.594, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000464358_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bed is at the center of the image, and a chair is to the right of the bed near the window.\nObjects: [bed, chair]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.078, 0.469, 0.656, 0.820]\nchair: [0.438, 0.422, 0.594, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000464358_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a velvet-covered king-size bed is at the center of the image, and a old-fashioned wooden rocking chair is to the right of the velvet-covered king-size bed near the window."
      },
      {
        "from": "gpt",
        "value": "velvet-covered king-size bed: [0.078, 0.469, 0.656, 0.820]\nold-fashioned wooden rocking chair: [0.438, 0.422, 0.594, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000464358_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a velvet-covered king-size bed is at the center of the image, and a old-fashioned wooden rocking chair is to the right of the velvet-covered king-size bed near the window.\nObjects: [velvet-covered king-size bed, old-fashioned wooden rocking chair]"
      },
      {
        "from": "gpt",
        "value": "velvet-covered king-size bed: [0.078, 0.469, 0.656, 0.820]\nold-fashioned wooden rocking chair: [0.438, 0.422, 0.594, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000464358_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.078, 0.469, 0.656, 0.820]\nchair: [0.438, 0.422, 0.594, 0.602]\nGiven the above layout, shift the chair upwards by 0.156."
      },
      {
        "from": "gpt",
        "value": "bed: [0.078, 0.469, 0.656, 0.820]\nchair: [0.438, 0.266, 0.594, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000479912",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is positioned at the center connected to a jet bridge on the left, facing towards the viewer."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.125, 0.352, 0.633, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000479912_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is positioned at the center connected to a jet bridge on the left, facing towards the viewer.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.125, 0.352, 0.633, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000479912_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an double-deck airliner is positioned at the center connected to a jet bridge on the left, facing towards the viewer."
      },
      {
        "from": "gpt",
        "value": "double-deck airliner: [0.125, 0.352, 0.633, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000479912_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an double-deck airliner is positioned at the center connected to a jet bridge on the left, facing towards the viewer.\nObjects: [double-deck airliner]"
      },
      {
        "from": "gpt",
        "value": "double-deck airliner: [0.125, 0.352, 0.633, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000479912_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.125, 0.352, 0.633, 0.695]\nGiven the above layout, shift the airplane to the right by 0.117."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.242, 0.352, 0.750, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000488385",
    "conversations": [
      {
        "from": "human",
        "value": "The motorcycle is parked on a sidewalk, facing to the left side of the image."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.164, 0.008, 0.703, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000488385_key",
    "conversations": [
      {
        "from": "human",
        "value": "The motorcycle is parked on a sidewalk, facing to the left side of the image.\nObjects: [motorcycle]"
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.164, 0.008, 0.703, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000488385_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the sleek sportbike is parked on a sidewalk, facing to the left side of the image."
      },
      {
        "from": "gpt",
        "value": "sleek sportbike: [0.164, 0.008, 0.703, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000488385_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the sleek sportbike is parked on a sidewalk, facing to the left side of the image.\nObjects: [sleek sportbike]"
      },
      {
        "from": "gpt",
        "value": "sleek sportbike: [0.164, 0.008, 0.703, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000488385_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: motorcycle: [0.164, 0.008, 0.703, 0.977]\nGiven the above layout, shift the motorcycle to the right by 0.211."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.375, 0.008, 0.914, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000488710",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in front of a sign, wearing a white t-shirt with a graphic design."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.141, 0.516, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000488710_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in front of a sign, wearing a white t-shirt with a graphic design.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.141, 0.516, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000488710_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man wearing a cap is standing in front of a sign, wearing a white t-shirt with a graphic design."
      },
      {
        "from": "gpt",
        "value": "tall man wearing a cap: [0.000, 0.141, 0.516, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000488710_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man wearing a cap is standing in front of a sign, wearing a white t-shirt with a graphic design.\nObjects: [tall man wearing a cap]"
      },
      {
        "from": "gpt",
        "value": "tall man wearing a cap: [0.000, 0.141, 0.516, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000488710_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.000, 0.141, 0.516, 0.883]\nGiven the above layout, shift the person to the right by 0.070."
      },
      {
        "from": "gpt",
        "value": "person: [0.070, 0.141, 0.586, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000489014",
    "conversations": [
      {
        "from": "human",
        "value": "A boat with a white sail, viewed from the right side, is sailing on the water."
      },
      {
        "from": "gpt",
        "value": "boat: [0.062, 0.125, 0.844, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000489014_key",
    "conversations": [
      {
        "from": "human",
        "value": "A boat with a white sail, viewed from the right side, is sailing on the water.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.062, 0.125, 0.844, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000489014_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a single-masted yacht with a white sail, viewed from the right side, is sailing on the water."
      },
      {
        "from": "gpt",
        "value": "single-masted yacht: [0.062, 0.125, 0.844, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000489014_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a single-masted yacht with a white sail, viewed from the right side, is sailing on the water.\nObjects: [single-masted yacht]"
      },
      {
        "from": "gpt",
        "value": "single-masted yacht: [0.062, 0.125, 0.844, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000489014_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.062, 0.125, 0.844, 0.719]\nGiven the above layout, shift the boat downwards by 0.211."
      },
      {
        "from": "gpt",
        "value": "boat: [0.062, 0.336, 0.844, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000489924",
    "conversations": [
      {
        "from": "human",
        "value": "A person is riding a skateboard, with their body partially visible at the top of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.133, 0.000, 0.883, 0.883]\nskateboard: [0.406, 0.703, 0.742, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000489924_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is riding a skateboard, with their body partially visible at the top of the image.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.133, 0.000, 0.883, 0.883]\nskateboard: [0.406, 0.703, 0.742, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000489924_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young graffiti-covered graffiti-covered skateboarder is riding a graffiti-covered skateboard, with their body partially visible at the top of the image."
      },
      {
        "from": "gpt",
        "value": "young graffiti-covered skateboarder: [0.133, 0.000, 0.883, 0.883]\ngraffiti-covered skateboard: [0.406, 0.703, 0.742, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000489924_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young graffiti-covered graffiti-covered skateboarder is riding a graffiti-covered skateboard, with their body partially visible at the top of the image.\nObjects: [young graffiti-covered skateboarder, graffiti-covered skateboard]"
      },
      {
        "from": "gpt",
        "value": "young graffiti-covered skateboarder: [0.133, 0.000, 0.883, 0.883]\ngraffiti-covered skateboard: [0.406, 0.703, 0.742, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000489924_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.133, 0.000, 0.883, 0.883]\nskateboard: [0.406, 0.703, 0.742, 0.992]\nGiven the above layout, shift the person to the left by 0.078."
      },
      {
        "from": "gpt",
        "value": "person: [0.055, 0.000, 0.805, 0.883]\nskateboard: [0.406, 0.703, 0.742, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000490125",
    "conversations": [
      {
        "from": "human",
        "value": "A truck parked in the background to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "truck: [0.281, 0.234, 0.719, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000490125_key",
    "conversations": [
      {
        "from": "human",
        "value": "A truck parked in the background to the right side of the image.\nObjects: [truck]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.281, 0.234, 0.719, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000490125_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red semi-trailer truck parked in the background to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "red semi-trailer truck: [0.281, 0.234, 0.719, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000490125_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red semi-trailer truck parked in the background to the right side of the image.\nObjects: [red semi-trailer truck]"
      },
      {
        "from": "gpt",
        "value": "red semi-trailer truck: [0.281, 0.234, 0.719, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000490125_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.281, 0.234, 0.719, 0.406]\nGiven the above layout, shift the truck downwards by 0.148."
      },
      {
        "from": "gpt",
        "value": "truck: [0.281, 0.383, 0.719, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000490470",
    "conversations": [
      {
        "from": "human",
        "value": "One boat is on the left side of the image, and another boat is to the right of it, both moored in the water."
      },
      {
        "from": "gpt",
        "value": "boat: [0.586, 0.125, 0.992, 0.578]\nboat: [0.000, 0.125, 0.305, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000490470_key",
    "conversations": [
      {
        "from": "human",
        "value": "One boat is on the left side of the image, and another boat is to the right of it, both moored in the water.\nObjects: [boat, boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.586, 0.125, 0.992, 0.578]\nboat: [0.000, 0.125, 0.305, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000490515",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on the snow with a snowboard to their right side."
      },
      {
        "from": "gpt",
        "value": "person: [0.297, 0.344, 0.797, 0.641]\nsnowboard: [0.758, 0.500, 0.789, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000490515_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on the snow with a snowboard to their right side.\nObjects: [person, snowboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.297, 0.344, 0.797, 0.641]\nsnowboard: [0.758, 0.500, 0.789, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000491216",
    "conversations": [
      {
        "from": "human",
        "value": "A refrigerator on the right and an oven on the left, with a chair in between them."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.133, 0.062, 0.297, 0.977]\nchair: [0.281, 0.484, 0.422, 0.883]\noven: [0.648, 0.445, 0.742, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000491216_key",
    "conversations": [
      {
        "from": "human",
        "value": "A refrigerator on the right and an oven on the left, with a chair in between them.\nObjects: [refrigerator, chair, oven]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.133, 0.062, 0.297, 0.977]\nchair: [0.281, 0.484, 0.422, 0.883]\noven: [0.648, 0.445, 0.742, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000492968",
    "conversations": [
      {
        "from": "human",
        "value": "A person is riding a snowboard, angled towards the left side of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.156, 0.227, 0.547, 0.711]\nsnowboard: [0.367, 0.648, 0.586, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000492968_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is riding a snowboard, angled towards the left side of the image.\nObjects: [person, snowboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.156, 0.227, 0.547, 0.711]\nsnowboard: [0.367, 0.648, 0.586, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000492968_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a sleek sleek snowboarder is riding a sleek snowboard, angled towards the left side of the image."
      },
      {
        "from": "gpt",
        "value": "a sleek snowboarder: [0.156, 0.227, 0.547, 0.711]\nsleek snowboard: [0.367, 0.648, 0.586, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000492968_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a sleek sleek snowboarder is riding a sleek snowboard, angled towards the left side of the image.\nObjects: [a sleek snowboarder, sleek snowboard]"
      },
      {
        "from": "gpt",
        "value": "a sleek snowboarder: [0.156, 0.227, 0.547, 0.711]\nsleek snowboard: [0.367, 0.648, 0.586, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000492968_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.156, 0.227, 0.547, 0.711]\nsnowboard: [0.367, 0.648, 0.586, 0.758]\nGiven the above layout, shift the snowboard to the right by 0.016."
      },
      {
        "from": "gpt",
        "value": "person: [0.156, 0.227, 0.547, 0.711]\nsnowboard: [0.383, 0.648, 0.602, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000493905",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center, serving a tennis ball on a court."
      },
      {
        "from": "gpt",
        "value": "person: [0.422, 0.195, 0.656, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000493905_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center, serving a tennis ball on a court.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.422, 0.195, 0.656, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000493905_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a male tennis player is at the center, serving a tennis ball on a court."
      },
      {
        "from": "gpt",
        "value": "male tennis player: [0.422, 0.195, 0.656, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000493905_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a male tennis player is at the center, serving a tennis ball on a court.\nObjects: [male tennis player]"
      },
      {
        "from": "gpt",
        "value": "male tennis player: [0.422, 0.195, 0.656, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000493905_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.422, 0.195, 0.656, 0.742]\nGiven the above layout, shift the person to the left by 0.398."
      },
      {
        "from": "gpt",
        "value": "person: [0.023, 0.195, 0.258, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000494427",
    "conversations": [
      {
        "from": "human",
        "value": "A laptop with an integrated keyboard at the center."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.148, 0.031, 0.867, 0.805]\nkeyboard: [0.234, 0.492, 0.805, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000494427_key",
    "conversations": [
      {
        "from": "human",
        "value": "A laptop with an integrated keyboard at the center.\nObjects: [laptop, keyboard]"
      },
      {
        "from": "gpt",
        "value": "laptop: [0.148, 0.031, 0.867, 0.805]\nkeyboard: [0.234, 0.492, 0.805, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000494427_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek laptop with an integrated mechanical keyboard at the center."
      },
      {
        "from": "gpt",
        "value": "sleek laptop: [0.148, 0.031, 0.867, 0.805]\nmechanical keyboard: [0.234, 0.492, 0.805, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000494427_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek laptop with an integrated mechanical keyboard at the center.\nObjects: [sleek laptop, mechanical keyboard]"
      },
      {
        "from": "gpt",
        "value": "sleek laptop: [0.148, 0.031, 0.867, 0.805]\nmechanical keyboard: [0.234, 0.492, 0.805, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000494427_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: laptop: [0.148, 0.031, 0.867, 0.805]\nkeyboard: [0.234, 0.492, 0.805, 0.656]\nGiven the above layout, shift the laptop downwards by 0.031."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.148, 0.062, 0.867, 0.836]\nkeyboard: [0.234, 0.492, 0.805, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000495054",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is parked on the tarmac, centered in the image."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.047, 0.367, 0.906, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000495054_key",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is parked on the tarmac, centered in the image.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.047, 0.367, 0.906, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000495054_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the white commercial jet is parked on the tarmac, centered in the image."
      },
      {
        "from": "gpt",
        "value": "white commercial jet: [0.047, 0.367, 0.906, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000495054_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the white commercial jet is parked on the tarmac, centered in the image.\nObjects: [white commercial jet]"
      },
      {
        "from": "gpt",
        "value": "white commercial jet: [0.047, 0.367, 0.906, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000495054_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.047, 0.367, 0.906, 0.602]\nGiven the above layout, shift the airplane downwards by 0.359."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.047, 0.727, 0.906, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000495448",
    "conversations": [
      {
        "from": "human",
        "value": "The cake is a three-tiered wedding cake with the top layer smaller than the middle, and the middle smaller than the base. It's adorned with pink and white flowers and rests on a decorative cake stand."
      },
      {
        "from": "gpt",
        "value": "cake: [0.188, 0.023, 0.688, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000495448_key",
    "conversations": [
      {
        "from": "human",
        "value": "The cake is a three-tiered wedding cake with the top layer smaller than the middle, and the middle smaller than the base. Its adorned with pink and white flowers and rests on a decorative cake stand.\nObjects: [cake]"
      },
      {
        "from": "gpt",
        "value": "cake: [0.188, 0.023, 0.688, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000495448_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the ornately decorated birthday cake is a three-tiered wedding ornately decorated birthday cake with the top layer smaller than the middle, and the middle smaller than the base. it's adorned with pink and white flowers and rests on a decorative ornately decorated birthday cake stand."
      },
      {
        "from": "gpt",
        "value": "ornately decorated birthday cake: [0.188, 0.023, 0.688, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000495448_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the ornately decorated birthday cake is a three-tiered wedding ornately decorated birthday cake with the top layer smaller than the middle, and the middle smaller than the base. its adorned with pink and white flowers and rests on a decorative ornately decorated birthday cake stand.\nObjects: [ornately decorated birthday cake]"
      },
      {
        "from": "gpt",
        "value": "ornately decorated birthday cake: [0.188, 0.023, 0.688, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000495448_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cake: [0.188, 0.023, 0.688, 0.836]\nGiven the above layout, shift the cake to the right by 0.078."
      },
      {
        "from": "gpt",
        "value": "cake: [0.266, 0.023, 0.766, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000516038",
    "conversations": [
      {
        "from": "human",
        "value": "A person stands on a pitcher's mound in the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.211, 0.352, 0.445, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000516038_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person stands on a pitchers mound in the center of the image.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.211, 0.352, 0.445, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000516038_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a baseball pitcher stands on a pitcher's mound in the center of the image."
      },
      {
        "from": "gpt",
        "value": "baseball pitcher: [0.211, 0.352, 0.445, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000516038_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a baseball pitcher stands on a pitchers mound in the center of the image.\nObjects: [baseball pitcher]"
      },
      {
        "from": "gpt",
        "value": "baseball pitcher: [0.211, 0.352, 0.445, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000516038_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.211, 0.352, 0.445, 0.672]\nGiven the above layout, shift the person to the right by 0.320."
      },
      {
        "from": "gpt",
        "value": "person: [0.531, 0.352, 0.766, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000523229",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is situated at the center of the image, with the seat cover down."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.250, 0.453, 0.727, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000523229_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is situated at the center of the image, with the seat cover down.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.250, 0.453, 0.727, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000523229_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain washroom fixture is situated at the center of the image, with the seat cover down."
      },
      {
        "from": "gpt",
        "value": "porcelain washroom fixture: [0.250, 0.453, 0.727, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000523229_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain washroom fixture is situated at the center of the image, with the seat cover down.\nObjects: [porcelain washroom fixture]"
      },
      {
        "from": "gpt",
        "value": "porcelain washroom fixture: [0.250, 0.453, 0.727, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000523229_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.250, 0.453, 0.727, 0.992]\nGiven the above layout, shift the toilet upwards by 0.164."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.250, 0.289, 0.727, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000523957",
    "conversations": [
      {
        "from": "human",
        "value": "In the foreground, a person is skateboarding to the left. Behind and to the right, another person stands watching. In the background to the right, a third person is walking away."
      },
      {
        "from": "gpt",
        "value": "person: [0.086, 0.289, 0.492, 0.711]\nperson: [0.531, 0.430, 0.625, 0.688]\nperson: [0.703, 0.430, 0.758, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000523957_key",
    "conversations": [
      {
        "from": "human",
        "value": "In the foreground, a person is skateboarding to the left. Behind and to the right, another person stands watching. In the background to the right, a third person is walking away.\nObjects: [person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.086, 0.289, 0.492, 0.711]\nperson: [0.531, 0.430, 0.625, 0.688]\nperson: [0.703, 0.430, 0.758, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000524280",
    "conversations": [
      {
        "from": "human",
        "value": "The cat is facing forward, with its ears at the top center of the image, surrounded by a blurred background."
      },
      {
        "from": "gpt",
        "value": "cat: [0.117, 0.016, 0.992, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000524280_key",
    "conversations": [
      {
        "from": "human",
        "value": "The cat is facing forward, with its ears at the top center of the image, surrounded by a blurred background.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.117, 0.016, 0.992, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000524280_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the ginger feline is facing forward, with its ears at the top center of the image, surrounded by a blurred background."
      },
      {
        "from": "gpt",
        "value": "ginger feline: [0.117, 0.016, 0.992, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000524280_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the ginger feline is facing forward, with its ears at the top center of the image, surrounded by a blurred background.\nObjects: [ginger feline]"
      },
      {
        "from": "gpt",
        "value": "ginger feline: [0.117, 0.016, 0.992, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000524280_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.117, 0.016, 0.992, 0.977]\nGiven the above layout, shift the cat to the left by 0.047."
      },
      {
        "from": "gpt",
        "value": "cat: [0.070, 0.016, 0.945, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000524742",
    "conversations": [
      {
        "from": "human",
        "value": "The side of the train is visible, extending horizontally across the image with graffiti art on it."
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.125, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000524742_key",
    "conversations": [
      {
        "from": "human",
        "value": "The side of the train is visible, extending horizontally across the image with graffiti art on it.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.125, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000524742_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the side of the freight train covered in street art is visible, extending horizontally across the image with graffiti art on it."
      },
      {
        "from": "gpt",
        "value": "freight train covered in street art: [0.008, 0.125, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000524742_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the side of the freight train covered in street art is visible, extending horizontally across the image with graffiti art on it.\nObjects: [freight train covered in street art]"
      },
      {
        "from": "gpt",
        "value": "freight train covered in street art: [0.008, 0.125, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000524742_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.008, 0.125, 0.992, 0.867]\nGiven the above layout, shift the train upwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.086, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000525286",
    "conversations": [
      {
        "from": "human",
        "value": "The clock is hanging on the wall to the left side of the image."
      },
      {
        "from": "gpt",
        "value": "clock: [0.039, 0.273, 0.445, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000525286_key",
    "conversations": [
      {
        "from": "human",
        "value": "The clock is hanging on the wall to the left side of the image.\nObjects: [clock]"
      },
      {
        "from": "gpt",
        "value": "clock: [0.039, 0.273, 0.445, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000525286_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the antique wall clock is hanging on the wall to the left side of the image."
      },
      {
        "from": "gpt",
        "value": "antique wall clock: [0.039, 0.273, 0.445, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000525286_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the antique wall clock is hanging on the wall to the left side of the image.\nObjects: [antique wall clock]"
      },
      {
        "from": "gpt",
        "value": "antique wall clock: [0.039, 0.273, 0.445, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000525286_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: clock: [0.039, 0.273, 0.445, 0.695]\nGiven the above layout, shift the clock to the right by 0.375."
      },
      {
        "from": "gpt",
        "value": "clock: [0.414, 0.273, 0.820, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000526751",
    "conversations": [
      {
        "from": "human",
        "value": "A boat on the shore in the right foreground of the image."
      },
      {
        "from": "gpt",
        "value": "boat: [0.375, 0.586, 0.859, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000526751_key",
    "conversations": [
      {
        "from": "human",
        "value": "A boat on the shore in the right foreground of the image.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.375, 0.586, 0.859, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000526751_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a white sailboat on the shore in the right foreground of the image."
      },
      {
        "from": "gpt",
        "value": "white sailboat: [0.375, 0.586, 0.859, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000526751_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a white sailboat on the shore in the right foreground of the image.\nObjects: [white sailboat]"
      },
      {
        "from": "gpt",
        "value": "white sailboat: [0.375, 0.586, 0.859, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000526751_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.375, 0.586, 0.859, 0.789]\nGiven the above layout, shift the boat upwards by 0.367."
      },
      {
        "from": "gpt",
        "value": "boat: [0.375, 0.219, 0.859, 0.422]"
      }
    ]
  },
  {
    "id": "coco_000000527029",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left of a table with several bunches of bananas."
      },
      {
        "from": "gpt",
        "value": "person: [0.039, 0.336, 0.484, 0.984]\nbanana: [0.672, 0.359, 0.875, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000527029_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left of a table with several bunches of bananas.\nObjects: [person, banana]"
      },
      {
        "from": "gpt",
        "value": "person: [0.039, 0.336, 0.484, 0.984]\nbanana: [0.672, 0.359, 0.875, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000527029_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young man is standing to the left of a table with several bunches of ripe banana bunchs."
      },
      {
        "from": "gpt",
        "value": "young man: [0.039, 0.336, 0.484, 0.984]\nripe banana bunch: [0.672, 0.359, 0.875, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000527029_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young man is standing to the left of a table with several bunches of ripe banana bunchs.\nObjects: [young man, ripe banana bunch]"
      },
      {
        "from": "gpt",
        "value": "young man: [0.039, 0.336, 0.484, 0.984]\nripe banana bunch: [0.672, 0.359, 0.875, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000527029_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.039, 0.336, 0.484, 0.984]\nbanana: [0.672, 0.359, 0.875, 0.484]\nGiven the above layout, shift the person upwards by 0.141."
      },
      {
        "from": "gpt",
        "value": "person: [0.039, 0.195, 0.484, 0.844]\nbanana: [0.672, 0.359, 0.875, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000528524",
    "conversations": [
      {
        "from": "human",
        "value": "One sheep is in front of the other, both facing away from the viewer, walking along a path."
      },
      {
        "from": "gpt",
        "value": "sheep: [0.320, 0.414, 0.531, 0.805]\nsheep: [0.547, 0.336, 0.664, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000528524_key",
    "conversations": [
      {
        "from": "human",
        "value": "One sheep is in front of the other, both facing away from the viewer, walking along a path.\nObjects: [sheep, sheep]"
      },
      {
        "from": "gpt",
        "value": "sheep: [0.320, 0.414, 0.531, 0.805]\nsheep: [0.547, 0.336, 0.664, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000529105",
    "conversations": [
      {
        "from": "human",
        "value": "A horse is lying down in the center of the image with greenery around it."
      },
      {
        "from": "gpt",
        "value": "horse: [0.281, 0.375, 0.742, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000529105_key",
    "conversations": [
      {
        "from": "human",
        "value": "A horse is lying down in the center of the image with greenery around it.\nObjects: [horse]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.281, 0.375, 0.742, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000529105_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a white horse is lying down in the center of the image with greenery around it."
      },
      {
        "from": "gpt",
        "value": "white horse: [0.281, 0.375, 0.742, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000529105_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a white horse is lying down in the center of the image with greenery around it.\nObjects: [white horse]"
      },
      {
        "from": "gpt",
        "value": "white horse: [0.281, 0.375, 0.742, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000529105_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: horse: [0.281, 0.375, 0.742, 0.680]\nGiven the above layout, shift the horse upwards by 0.258."
      },
      {
        "from": "gpt",
        "value": "horse: [0.281, 0.117, 0.742, 0.422]"
      }
    ]
  },
  {
    "id": "coco_000000530457",
    "conversations": [
      {
        "from": "human",
        "value": "A vase with tulips is placed on the right side at the bottom of a fireplace."
      },
      {
        "from": "gpt",
        "value": "vase: [0.438, 0.516, 0.797, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000530457_key",
    "conversations": [
      {
        "from": "human",
        "value": "A vase with tulips is placed on the right side at the bottom of a fireplace.\nObjects: [vase]"
      },
      {
        "from": "gpt",
        "value": "vase: [0.438, 0.516, 0.797, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000530457_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a ceramic vase with tulips with tulips is placed on the right side at the bottom of a fireplace."
      },
      {
        "from": "gpt",
        "value": "ceramic vase with tulips: [0.438, 0.516, 0.797, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000530457_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a ceramic vase with tulips with tulips is placed on the right side at the bottom of a fireplace.\nObjects: [ceramic vase with tulips]"
      },
      {
        "from": "gpt",
        "value": "ceramic vase with tulips: [0.438, 0.516, 0.797, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000530457_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: vase: [0.438, 0.516, 0.797, 0.938]\nGiven the above layout, shift the vase upwards by 0.156."
      },
      {
        "from": "gpt",
        "value": "vase: [0.438, 0.359, 0.797, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000531771",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is in the center of the image, with a black front and a digital control panel at the top."
      },
      {
        "from": "gpt",
        "value": "oven: [0.211, 0.047, 0.742, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000531771_key",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is in the center of the image, with a black front and a digital control panel at the top.\nObjects: [oven]"
      },
      {
        "from": "gpt",
        "value": "oven: [0.211, 0.047, 0.742, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000531771_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel oven is in the center of the image, with a black front and a digital control panel at the top."
      },
      {
        "from": "gpt",
        "value": "stainless steel oven: [0.211, 0.047, 0.742, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000531771_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel oven is in the center of the image, with a black front and a digital control panel at the top.\nObjects: [stainless steel oven]"
      },
      {
        "from": "gpt",
        "value": "stainless steel oven: [0.211, 0.047, 0.742, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000531771_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: oven: [0.211, 0.047, 0.742, 0.930]\nGiven the above layout, shift the oven to the right by 0.172."
      },
      {
        "from": "gpt",
        "value": "oven: [0.383, 0.047, 0.914, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000532071",
    "conversations": [
      {
        "from": "human",
        "value": "A bear is centered in the middle of the image, amidst green foliage and fallen trees."
      },
      {
        "from": "gpt",
        "value": "bear: [0.211, 0.492, 0.570, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000532071_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bear is centered in the middle of the image, amidst green foliage and fallen trees.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.211, 0.492, 0.570, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000532071_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a grizzly bear is centered in the middle of the image, amidst green foliage and fallen trees."
      },
      {
        "from": "gpt",
        "value": "grizzly bear: [0.211, 0.492, 0.570, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000532071_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a grizzly bear is centered in the middle of the image, amidst green foliage and fallen trees.\nObjects: [grizzly bear]"
      },
      {
        "from": "gpt",
        "value": "grizzly bear: [0.211, 0.492, 0.570, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000532071_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.211, 0.492, 0.570, 0.648]\nGiven the above layout, shift the bear upwards by 0.227."
      },
      {
        "from": "gpt",
        "value": "bear: [0.211, 0.266, 0.570, 0.422]"
      }
    ]
  },
  {
    "id": "coco_000000553094",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying upwards towards the left corner of the image."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.273, 0.234, 0.703, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000553094_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying upwards towards the left corner of the image.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.273, 0.234, 0.703, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000553094_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an jumbo jet is flying upwards towards the left corner of the image."
      },
      {
        "from": "gpt",
        "value": "jumbo jet: [0.273, 0.234, 0.703, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000553094_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an jumbo jet is flying upwards towards the left corner of the image.\nObjects: [jumbo jet]"
      },
      {
        "from": "gpt",
        "value": "jumbo jet: [0.273, 0.234, 0.703, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000553094_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.273, 0.234, 0.703, 0.781]\nGiven the above layout, shift the airplane to the right by 0.219."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.492, 0.234, 0.922, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000562197",
    "conversations": [
      {
        "from": "human",
        "value": "The broccoli is in the top right section of the divided plate."
      },
      {
        "from": "gpt",
        "value": "broccoli: [0.500, 0.016, 0.977, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000562197_key",
    "conversations": [
      {
        "from": "human",
        "value": "The broccoli is in the top right section of the divided plate.\nObjects: [broccoli]"
      },
      {
        "from": "gpt",
        "value": "broccoli: [0.500, 0.016, 0.977, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000562197_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the fresh green broccoli is in the top right section of the divided plate."
      },
      {
        "from": "gpt",
        "value": "fresh green broccoli: [0.500, 0.016, 0.977, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000562197_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the fresh green broccoli is in the top right section of the divided plate.\nObjects: [fresh green broccoli]"
      },
      {
        "from": "gpt",
        "value": "fresh green broccoli: [0.500, 0.016, 0.977, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000562197_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: broccoli: [0.500, 0.016, 0.977, 0.477]\nGiven the above layout, shift the broccoli downwards by 0.312."
      },
      {
        "from": "gpt",
        "value": "broccoli: [0.500, 0.328, 0.977, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000563281",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center of the image, facing towards the right side."
      },
      {
        "from": "gpt",
        "value": "person: [0.234, 0.008, 0.516, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000563281_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center of the image, facing towards the right side.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.234, 0.008, 0.516, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000563281_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a teenager is standing at the center of the image, facing towards the right side."
      },
      {
        "from": "gpt",
        "value": "a teenager: [0.234, 0.008, 0.516, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000563281_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a teenager is standing at the center of the image, facing towards the right side.\nObjects: [a teenager]"
      },
      {
        "from": "gpt",
        "value": "a teenager: [0.234, 0.008, 0.516, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000563281_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.234, 0.008, 0.516, 0.977]\nGiven the above layout, shift the person to the right by 0.039."
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.008, 0.555, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000563758",
    "conversations": [
      {
        "from": "human",
        "value": "A teddy bear facing slightly to the left, wearing a red bandana with a white pattern."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.164, 0.008, 0.828, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000563758_key",
    "conversations": [
      {
        "from": "human",
        "value": "A teddy bear facing slightly to the left, wearing a red bandana with a white pattern.\nObjects: [teddy bear]"
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.164, 0.008, 0.828, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000563758_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a furry stuffed toy rabbit facing slightly to the left, wearing a red bandana with a white pattern."
      },
      {
        "from": "gpt",
        "value": "furry stuffed toy rabbit: [0.164, 0.008, 0.828, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000563758_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a furry stuffed toy rabbit facing slightly to the left, wearing a red bandana with a white pattern.\nObjects: [furry stuffed toy rabbit]"
      },
      {
        "from": "gpt",
        "value": "furry stuffed toy rabbit: [0.164, 0.008, 0.828, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000563758_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: teddy bear: [0.164, 0.008, 0.828, 0.984]\nGiven the above layout, shift the teddy bear to the left by 0.070."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.094, 0.008, 0.758, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000565778",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on the back of a train moving towards the right."
      },
      {
        "from": "gpt",
        "value": "train: [0.250, 0.391, 0.781, 0.727]\nperson: [0.633, 0.477, 0.664, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000565778_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on the back of a train moving towards the right.\nObjects: [train, person]"
      },
      {
        "from": "gpt",
        "value": "train: [0.250, 0.391, 0.781, 0.727]\nperson: [0.633, 0.477, 0.664, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000565778_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a man in a business suit is standing on the back of a commuter train moving towards the right."
      },
      {
        "from": "gpt",
        "value": "commuter train: [0.250, 0.391, 0.781, 0.727]\nman in a business suit: [0.633, 0.477, 0.664, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000565778_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a man in a business suit is standing on the back of a commuter train moving towards the right.\nObjects: [commuter train, man in a business suit]"
      },
      {
        "from": "gpt",
        "value": "commuter train: [0.250, 0.391, 0.781, 0.727]\nman in a business suit: [0.633, 0.477, 0.664, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000565778_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.250, 0.391, 0.781, 0.727]\nperson: [0.633, 0.477, 0.664, 0.602]\nGiven the above layout, shift the train upwards by 0.273."
      },
      {
        "from": "gpt",
        "value": "train: [0.250, 0.117, 0.781, 0.453]\nperson: [0.633, 0.477, 0.664, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000566758",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is situated on the right side of the image, angled slightly towards the viewer."
      },
      {
        "from": "gpt",
        "value": "bus: [0.047, 0.289, 0.820, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000566758_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is situated on the right side of the image, angled slightly towards the viewer.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.047, 0.289, 0.820, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000566758_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the city double-decker bus is situated on the right side of the image, angled slightly towards the viewer."
      },
      {
        "from": "gpt",
        "value": "city double-decker bus: [0.047, 0.289, 0.820, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000566758_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the city double-decker bus is situated on the right side of the image, angled slightly towards the viewer.\nObjects: [city double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "city double-decker bus: [0.047, 0.289, 0.820, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000566758_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.047, 0.289, 0.820, 0.672]\nGiven the above layout, shift the bus downwards by 0.172."
      },
      {
        "from": "gpt",
        "value": "bus: [0.047, 0.461, 0.820, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000567740",
    "conversations": [
      {
        "from": "human",
        "value": "Two people standing on skis; one to the left raising ski poles in the air, the other to the right in a more relaxed pose."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.305, 0.344, 0.781]\nperson: [0.688, 0.297, 0.891, 0.852]\nskis: [0.086, 0.734, 0.430, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000567740_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two people standing on skis; one to the left raising ski poles in the air, the other to the right in a more relaxed pose.\nObjects: [person, person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.305, 0.344, 0.781]\nperson: [0.688, 0.297, 0.891, 0.852]\nskis: [0.086, 0.734, 0.430, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000568147",
    "conversations": [
      {
        "from": "human",
        "value": "There is a parking meter in the foreground on the right, and a car in the background on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.352, 0.047, 0.680, 0.680]\ncar: [0.703, 0.000, 0.867, 0.039]"
      }
    ]
  },
  {
    "id": "coco_000000568147_key",
    "conversations": [
      {
        "from": "human",
        "value": "There is a parking meter in the foreground on the right, and a car in the background on the left side of the image.\nObjects: [parking meter, car]"
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.352, 0.047, 0.680, 0.680]\ncar: [0.703, 0.000, 0.867, 0.039]"
      }
    ]
  },
  {
    "id": "coco_000000568147_aug",
    "conversations": [
      {
        "from": "human",
        "value": "there is a vintage parking meter in the foreground on the right, and a sleek silver car in the background on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "vintage parking meter: [0.352, 0.047, 0.680, 0.680]\nsleek silver car: [0.703, 0.000, 0.867, 0.039]"
      }
    ]
  },
  {
    "id": "coco_000000568147_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "there is a vintage parking meter in the foreground on the right, and a sleek silver car in the background on the left side of the image.\nObjects: [vintage parking meter, sleek silver car]"
      },
      {
        "from": "gpt",
        "value": "vintage parking meter: [0.352, 0.047, 0.680, 0.680]\nsleek silver car: [0.703, 0.000, 0.867, 0.039]"
      }
    ]
  },
  {
    "id": "coco_000000568147_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: parking meter: [0.352, 0.047, 0.680, 0.680]\ncar: [0.703, 0.000, 0.867, 0.039]\nGiven the above layout, shift the parking meter to the left by 0.281."
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.070, 0.047, 0.398, 0.680]\ncar: [0.703, 0.000, 0.867, 0.039]"
      }
    ]
  },
  {
    "id": "coco_000000568213",
    "conversations": [
      {
        "from": "human",
        "value": "One person is on the left reaching out to catch or throw a frisbee, and another person is on the right, facing and moving towards the first person."
      },
      {
        "from": "gpt",
        "value": "person: [0.219, 0.242, 0.547, 0.703]\nperson: [0.695, 0.203, 0.922, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000568213_key",
    "conversations": [
      {
        "from": "human",
        "value": "One person is on the left reaching out to catch or throw a frisbee, and another person is on the right, facing and moving towards the first person.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.219, 0.242, 0.547, 0.703]\nperson: [0.695, 0.203, 0.922, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000568290",
    "conversations": [
      {
        "from": "human",
        "value": "A red bus is positioned in the center of the image on a street, facing left."
      },
      {
        "from": "gpt",
        "value": "bus: [0.297, 0.359, 0.742, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000568290_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red bus is positioned in the center of the image on a street, facing left.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.297, 0.359, 0.742, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000568290_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red yellow double-decker bus is positioned in the center of the image on a street, facing left."
      },
      {
        "from": "gpt",
        "value": "yellow double-decker bus: [0.297, 0.359, 0.742, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000568290_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red yellow double-decker bus is positioned in the center of the image on a street, facing left.\nObjects: [yellow double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "yellow double-decker bus: [0.297, 0.359, 0.742, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000568290_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.297, 0.359, 0.742, 0.617]\nGiven the above layout, shift the bus downwards by 0.086."
      },
      {
        "from": "gpt",
        "value": "bus: [0.297, 0.445, 0.742, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000569565",
    "conversations": [
      {
        "from": "human",
        "value": "A yellow truck on the left connected to another truck section on the right, set on a road with cones around."
      },
      {
        "from": "gpt",
        "value": "truck: [0.203, 0.461, 0.688, 0.656]\ntruck: [0.734, 0.531, 0.961, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000569565_key",
    "conversations": [
      {
        "from": "human",
        "value": "A yellow truck on the left connected to another truck section on the right, set on a road with cones around.\nObjects: [truck, truck]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.203, 0.461, 0.688, 0.656]\ntruck: [0.734, 0.531, 0.961, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000569825",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the foreground to the left of another person who is blurred in the background."
      },
      {
        "from": "gpt",
        "value": "person: [0.531, 0.055, 0.766, 0.930]\nperson: [0.320, 0.016, 0.500, 0.172]"
      }
    ]
  },
  {
    "id": "coco_000000569825_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the foreground to the left of another person who is blurred in the background.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.531, 0.055, 0.766, 0.930]\nperson: [0.320, 0.016, 0.500, 0.172]"
      }
    ]
  },
  {
    "id": "coco_000000572303",
    "conversations": [
      {
        "from": "human",
        "value": "A train composed of several cars stretches from the left side of the image to the right side, situated on tracks that lead into the distance."
      },
      {
        "from": "gpt",
        "value": "train: [0.023, 0.180, 0.961, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000572303_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train composed of several cars stretches from the left side of the image to the right side, situated on tracks that lead into the distance.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.023, 0.180, 0.961, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000572303_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a long freight train composed of several cars stretches from the left side of the image to the right side, situated on tracks that lead into the distance."
      },
      {
        "from": "gpt",
        "value": "long freight train: [0.023, 0.180, 0.961, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000572303_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a long freight train composed of several cars stretches from the left side of the image to the right side, situated on tracks that lead into the distance.\nObjects: [long freight train]"
      },
      {
        "from": "gpt",
        "value": "long freight train: [0.023, 0.180, 0.961, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000572303_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.023, 0.180, 0.961, 0.672]\nGiven the above layout, shift the train downwards by 0.109."
      },
      {
        "from": "gpt",
        "value": "train: [0.023, 0.289, 0.961, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000016228",
    "conversations": [
      {
        "from": "human",
        "value": "A horse on the left is pulling a train carriage on the right."
      },
      {
        "from": "gpt",
        "value": "train: [0.188, 0.367, 0.539, 0.648]\nhorse: [0.523, 0.391, 0.836, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000016228_key",
    "conversations": [
      {
        "from": "human",
        "value": "A horse on the left is pulling a train carriage on the right.\nObjects: [train, horse]"
      },
      {
        "from": "gpt",
        "value": "train: [0.188, 0.367, 0.539, 0.648]\nhorse: [0.523, 0.391, 0.836, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000016228_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a strong brown horse on the left is pulling a train carriage on the right."
      },
      {
        "from": "gpt",
        "value": "train: [0.188, 0.367, 0.539, 0.648]\nstrong brown horse: [0.523, 0.391, 0.836, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000016228_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a strong brown horse on the left is pulling a train carriage on the right.\nObjects: [train, strong brown horse]"
      },
      {
        "from": "gpt",
        "value": "train: [0.188, 0.367, 0.539, 0.648]\nstrong brown horse: [0.523, 0.391, 0.836, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000016228_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.188, 0.367, 0.539, 0.648]\nhorse: [0.523, 0.391, 0.836, 0.703]\nGiven the above layout, shift the train upwards by 0.367."
      },
      {
        "from": "gpt",
        "value": "train: [0.188, 0.000, 0.539, 0.281]\nhorse: [0.523, 0.391, 0.836, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000021903",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the right feeding an elephant on the left."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.008, 0.297, 0.492, 0.727]\nperson: [0.516, 0.469, 0.852, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000021903_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the right feeding an elephant on the left.\nObjects: [elephant, person]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.008, 0.297, 0.492, 0.727]\nperson: [0.516, 0.469, 0.852, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000023126",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on the back of one horse while holding onto another horse to the right."
      },
      {
        "from": "gpt",
        "value": "horse: [0.000, 0.594, 0.758, 0.828]\nperson: [0.258, 0.188, 0.430, 0.703]\nhorse: [0.711, 0.633, 0.789, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000023126_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on the back of one horse while holding onto another horse to the right.\nObjects: [horse, person, horse]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.000, 0.594, 0.758, 0.828]\nperson: [0.258, 0.188, 0.430, 0.703]\nhorse: [0.711, 0.633, 0.789, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000024027",
    "conversations": [
      {
        "from": "human",
        "value": "A colorful kite flying in the sky towards the upper right corner of the image."
      },
      {
        "from": "gpt",
        "value": "kite: [0.430, 0.227, 0.883, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000024027_key",
    "conversations": [
      {
        "from": "human",
        "value": "A colorful kite flying in the sky towards the upper right corner of the image.\nObjects: [kite]"
      },
      {
        "from": "gpt",
        "value": "kite: [0.430, 0.227, 0.883, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000024027_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a colorful multicolored butterfly shaped kite flying in the sky towards the upper right corner of the image."
      },
      {
        "from": "gpt",
        "value": "multicolored butterfly shaped kite: [0.430, 0.227, 0.883, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000024027_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a colorful multicolored butterfly shaped kite flying in the sky towards the upper right corner of the image.\nObjects: [multicolored butterfly shaped kite]"
      },
      {
        "from": "gpt",
        "value": "multicolored butterfly shaped kite: [0.430, 0.227, 0.883, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000024027_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: kite: [0.430, 0.227, 0.883, 0.531]\nGiven the above layout, shift the kite downwards by 0.453."
      },
      {
        "from": "gpt",
        "value": "kite: [0.430, 0.680, 0.883, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000030675",
    "conversations": [
      {
        "from": "human",
        "value": "A train is shown angled from the front view to the right side of the image, heading to the right."
      },
      {
        "from": "gpt",
        "value": "train: [0.234, 0.430, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000030675_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is shown angled from the front view to the right side of the image, heading to the right.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.234, 0.430, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000030675_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a antique steam locomotive is shown angled from the front view to the right side of the image, heading to the right."
      },
      {
        "from": "gpt",
        "value": "antique steam locomotive: [0.234, 0.430, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000030675_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a antique steam locomotive is shown angled from the front view to the right side of the image, heading to the right.\nObjects: [antique steam locomotive]"
      },
      {
        "from": "gpt",
        "value": "antique steam locomotive: [0.234, 0.430, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000030675_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.234, 0.430, 0.992, 0.680]\nGiven the above layout, shift the train upwards by 0.242."
      },
      {
        "from": "gpt",
        "value": "train: [0.234, 0.188, 0.992, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000031093",
    "conversations": [
      {
        "from": "human",
        "value": "A person skateboarding at the center of a skatepark bowl."
      },
      {
        "from": "gpt",
        "value": "person: [0.336, 0.289, 0.695, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000031093_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person skateboarding at the center of a skatepark bowl.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.336, 0.289, 0.695, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000031093_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a young skater in a red t-shirt skateboarding at the center of a skatepark bowl."
      },
      {
        "from": "gpt",
        "value": "a young skater in a red t-shirt: [0.336, 0.289, 0.695, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000031093_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a young skater in a red t-shirt skateboarding at the center of a skatepark bowl.\nObjects: [a young skater in a red t-shirt]"
      },
      {
        "from": "gpt",
        "value": "a young skater in a red t-shirt: [0.336, 0.289, 0.695, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000031093_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.336, 0.289, 0.695, 0.672]\nGiven the above layout, shift the person to the left by 0.117."
      },
      {
        "from": "gpt",
        "value": "person: [0.219, 0.289, 0.578, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000031735",
    "conversations": [
      {
        "from": "human",
        "value": "A potted plant is on a stand to the left of a couch in the room."
      },
      {
        "from": "gpt",
        "value": "couch: [0.461, 0.484, 0.992, 0.836]\npotted plant: [0.031, 0.281, 0.344, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000031735_key",
    "conversations": [
      {
        "from": "human",
        "value": "A potted plant is on a stand to the left of a couch in the room.\nObjects: [couch, potted plant]"
      },
      {
        "from": "gpt",
        "value": "couch: [0.461, 0.484, 0.992, 0.836]\npotted plant: [0.031, 0.281, 0.344, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000031735_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a indoor ficus in a terracotta pot is on a stand to the left of a leather two-seater sofa in the room."
      },
      {
        "from": "gpt",
        "value": "leather two-seater sofa: [0.461, 0.484, 0.992, 0.836]\nindoor ficus in a terracotta pot: [0.031, 0.281, 0.344, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000031735_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a indoor ficus in a terracotta pot is on a stand to the left of a leather two-seater sofa in the room.\nObjects: [leather two-seater sofa, indoor ficus in a terracotta pot]"
      },
      {
        "from": "gpt",
        "value": "leather two-seater sofa: [0.461, 0.484, 0.992, 0.836]\nindoor ficus in a terracotta pot: [0.031, 0.281, 0.344, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000031735_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: couch: [0.461, 0.484, 0.992, 0.836]\npotted plant: [0.031, 0.281, 0.344, 0.578]\nGiven the above layout, shift the potted plant upwards by 0.211."
      },
      {
        "from": "gpt",
        "value": "couch: [0.461, 0.484, 0.992, 0.836]\npotted plant: [0.031, 0.070, 0.344, 0.367]"
      }
    ]
  },
  {
    "id": "coco_000000032817",
    "conversations": [
      {
        "from": "human",
        "value": "One person is standing to the left of the toilet, while another person is bent over, with their head inside the top tank of the toilet which is to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.258, 0.000, 0.555, 0.727]\nperson: [0.680, 0.094, 0.867, 0.625]\ntoilet: [0.336, 0.562, 0.523, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000032817_key",
    "conversations": [
      {
        "from": "human",
        "value": "One person is standing to the left of the toilet, while another person is bent over, with their head inside the top tank of the toilet which is to the right.\nObjects: [person, person, toilet]"
      },
      {
        "from": "gpt",
        "value": "person: [0.258, 0.000, 0.555, 0.727]\nperson: [0.680, 0.094, 0.867, 0.625]\ntoilet: [0.336, 0.562, 0.523, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000033109",
    "conversations": [
      {
        "from": "human",
        "value": "A blue truck is on a road towards the left side of the image."
      },
      {
        "from": "gpt",
        "value": "truck: [0.312, 0.273, 0.727, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000033109_key",
    "conversations": [
      {
        "from": "human",
        "value": "A blue truck is on a road towards the left side of the image.\nObjects: [truck]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.312, 0.273, 0.727, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000033109_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a blue red fire engine is on a road towards the left side of the image."
      },
      {
        "from": "gpt",
        "value": "red fire engine: [0.312, 0.273, 0.727, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000033109_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a blue red fire engine is on a road towards the left side of the image.\nObjects: [red fire engine]"
      },
      {
        "from": "gpt",
        "value": "red fire engine: [0.312, 0.273, 0.727, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000033109_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.312, 0.273, 0.727, 0.594]\nGiven the above layout, shift the truck downwards by 0.305."
      },
      {
        "from": "gpt",
        "value": "truck: [0.312, 0.578, 0.727, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000033114",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is centered in the background on the runway, with a row of parking meters in the foreground."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.250, 0.391, 0.781, 0.555]\nparking meter: [0.633, 0.531, 0.836, 0.750]\nparking meter: [0.383, 0.648, 0.492, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000033114_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is centered in the background on the runway, with a row of parking meters in the foreground.\nObjects: [airplane, parking meter, parking meter]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.250, 0.391, 0.781, 0.555]\nparking meter: [0.633, 0.531, 0.836, 0.750]\nparking meter: [0.383, 0.648, 0.492, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000034071",
    "conversations": [
      {
        "from": "human",
        "value": "Two parking meters in the foreground side by side with the right one slightly ahead of the left."
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.094, 0.500, 0.461, 0.820]\nparking meter: [0.453, 0.531, 0.789, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000034071_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two parking meters in the foreground side by side with the right one slightly ahead of the left.\nObjects: [parking meter, parking meter]"
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.094, 0.500, 0.461, 0.820]\nparking meter: [0.453, 0.531, 0.789, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000035062",
    "conversations": [
      {
        "from": "human",
        "value": "A bed with a patterned blanket occupies the center of the image, slightly inclined to the right, with pillows at the top end."
      },
      {
        "from": "gpt",
        "value": "bed: [0.164, 0.094, 0.820, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000035062_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bed with a patterned blanket occupies the center of the image, slightly inclined to the right, with pillows at the top end.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.164, 0.094, 0.820, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000035062_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a king-sized bed with a paisley-patterned duvet with a patterned blanket occupies the center of the image, slightly inclined to the right, with pillows at the top end."
      },
      {
        "from": "gpt",
        "value": "king-sized bed with a paisley-patterned duvet: [0.164, 0.094, 0.820, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000035062_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a king-sized bed with a paisley-patterned duvet with a patterned blanket occupies the center of the image, slightly inclined to the right, with pillows at the top end.\nObjects: [king-sized bed with a paisley-patterned duvet]"
      },
      {
        "from": "gpt",
        "value": "king-sized bed with a paisley-patterned duvet: [0.164, 0.094, 0.820, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000035062_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.164, 0.094, 0.820, 0.992]\nGiven the above layout, shift the bed to the right by 0.039."
      },
      {
        "from": "gpt",
        "value": "bed: [0.203, 0.094, 0.859, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000035197",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing on a skateboard in the foreground with another person sitting in the background."
      },
      {
        "from": "gpt",
        "value": "person: [0.203, 0.000, 0.570, 0.656]\nskateboard: [0.164, 0.539, 0.469, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000035197_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing on a skateboard in the foreground with another person sitting in the background.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.203, 0.000, 0.570, 0.656]\nskateboard: [0.164, 0.539, 0.469, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000035197_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage boy standing on a blue skateboard in the foreground with another teenage boy sitting in the background."
      },
      {
        "from": "gpt",
        "value": "teenage boy: [0.203, 0.000, 0.570, 0.656]\nblue skateboard: [0.164, 0.539, 0.469, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000035197_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage boy standing on a blue skateboard in the foreground with another teenage boy sitting in the background.\nObjects: [teenage boy, blue skateboard]"
      },
      {
        "from": "gpt",
        "value": "teenage boy: [0.203, 0.000, 0.570, 0.656]\nblue skateboard: [0.164, 0.539, 0.469, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000035197_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.203, 0.000, 0.570, 0.656]\nskateboard: [0.164, 0.539, 0.469, 0.703]\nGiven the above layout, shift the person to the right by 0.281."
      },
      {
        "from": "gpt",
        "value": "person: [0.484, 0.000, 0.852, 0.656]\nskateboard: [0.164, 0.539, 0.469, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000035326",
    "conversations": [
      {
        "from": "human",
        "value": "The image shows an oven located at the center bottom of the image under a stovetop."
      },
      {
        "from": "gpt",
        "value": "oven: [0.156, 0.602, 0.969, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000035326_key",
    "conversations": [
      {
        "from": "human",
        "value": "The image shows an oven located at the center bottom of the image under a stovetop.\nObjects: [oven]"
      },
      {
        "from": "gpt",
        "value": "oven: [0.156, 0.602, 0.969, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000035326_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the image shows an modern microwave located at the center bottom of the image under a stovetop."
      },
      {
        "from": "gpt",
        "value": "modern microwave: [0.156, 0.602, 0.969, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000035326_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the image shows an modern microwave located at the center bottom of the image under a stovetop.\nObjects: [modern microwave]"
      },
      {
        "from": "gpt",
        "value": "modern microwave: [0.156, 0.602, 0.969, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000035326_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: oven: [0.156, 0.602, 0.969, 0.867]\nGiven the above layout, shift the oven upwards by 0.062."
      },
      {
        "from": "gpt",
        "value": "oven: [0.156, 0.539, 0.969, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000075456",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza at the center of the image on a round silver tray."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.156, 0.258, 0.828, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000075456_key",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza at the center of the image on a round silver tray.\nObjects: [pizza]"
      },
      {
        "from": "gpt",
        "value": "pizza: [0.156, 0.258, 0.828, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000075456_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a mushroom and olive pizza on a round silver platter at the center of the image on a round silver tray."
      },
      {
        "from": "gpt",
        "value": "mushroom and olive pizza on a round silver platter: [0.156, 0.258, 0.828, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000075456_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a mushroom and olive pizza on a round silver platter at the center of the image on a round silver tray.\nObjects: [mushroom and olive pizza on a round silver platter]"
      },
      {
        "from": "gpt",
        "value": "mushroom and olive pizza on a round silver platter: [0.156, 0.258, 0.828, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000075456_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: pizza: [0.156, 0.258, 0.828, 0.719]\nGiven the above layout, shift the pizza downwards by 0.094."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.156, 0.352, 0.828, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000077396",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is lying on the floor to the left of a dining table, and another cat is standing on its hind legs with its front paws on a TV stand to the right of the table. The TV is on the stand in the background."
      },
      {
        "from": "gpt",
        "value": "dining table: [0.695, 0.594, 0.984, 0.867]\ntv: [0.422, 0.188, 0.773, 0.414]\ncat: [0.359, 0.438, 0.609, 0.695]\ncat: [0.141, 0.656, 0.406, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000077396_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is lying on the floor to the left of a dining table, and another cat is standing on its hind legs with its front paws on a TV stand to the right of the table. The TV is on the stand in the background.\nObjects: [dining table, tv, cat, cat]"
      },
      {
        "from": "gpt",
        "value": "dining table: [0.695, 0.594, 0.984, 0.867]\ntv: [0.422, 0.188, 0.773, 0.414]\ncat: [0.359, 0.438, 0.609, 0.695]\ncat: [0.141, 0.656, 0.406, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000078915",
    "conversations": [
      {
        "from": "human",
        "value": "The person is at the bottom center of the image, serving a tennis ball with a racquet above their head."
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.609, 0.594, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000078915_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is at the bottom center of the image, serving a tennis ball with a racquet above their head.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.609, 0.594, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000078915_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the athletic woman is at the bottom center of the image, serving a tennis ball with a racquet above their head."
      },
      {
        "from": "gpt",
        "value": "athletic woman: [0.328, 0.609, 0.594, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000078915_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the athletic woman is at the bottom center of the image, serving a tennis ball with a racquet above their head.\nObjects: [athletic woman]"
      },
      {
        "from": "gpt",
        "value": "athletic woman: [0.328, 0.609, 0.594, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000078915_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.328, 0.609, 0.594, 0.992]\nGiven the above layout, shift the person upwards by 0.086."
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.523, 0.594, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000079031",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a surfboard in the water."
      },
      {
        "from": "gpt",
        "value": "person: [0.094, 0.164, 0.516, 0.742]\nsurfboard: [0.000, 0.570, 0.938, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000079031_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a surfboard in the water.\nObjects: [person, surfboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.094, 0.164, 0.516, 0.742]\nsurfboard: [0.000, 0.570, 0.938, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000079031_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young man in wetsuit is standing on a red and white striped surfboard in the water."
      },
      {
        "from": "gpt",
        "value": "young man in wetsuit: [0.094, 0.164, 0.516, 0.742]\nred and white striped surfboard: [0.000, 0.570, 0.938, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000079031_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young man in wetsuit is standing on a red and white striped surfboard in the water.\nObjects: [young man in wetsuit, red and white striped surfboard]"
      },
      {
        "from": "gpt",
        "value": "young man in wetsuit: [0.094, 0.164, 0.516, 0.742]\nred and white striped surfboard: [0.000, 0.570, 0.938, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000079031_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.094, 0.164, 0.516, 0.742]\nsurfboard: [0.000, 0.570, 0.938, 0.820]\nGiven the above layout, shift the surfboard downwards by 0.055."
      },
      {
        "from": "gpt",
        "value": "person: [0.094, 0.164, 0.516, 0.742]\nsurfboard: [0.000, 0.625, 0.938, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000079188",
    "conversations": [
      {
        "from": "human",
        "value": "Two giraffes in the center of the image with one standing behind the other."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.125, 0.016, 0.820, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000079188_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two giraffes in the center of the image with one standing behind the other.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.125, 0.016, 0.820, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000079188_aug",
    "conversations": [
      {
        "from": "human",
        "value": "two towering giraffe with stretched necks in the center of the image with one standing behind the other."
      },
      {
        "from": "gpt",
        "value": "towering giraffe with stretched neck: [0.125, 0.016, 0.820, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000079188_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "two towering giraffe with stretched necks in the center of the image with one standing behind the other.\nObjects: [towering giraffe with stretched neck]"
      },
      {
        "from": "gpt",
        "value": "towering giraffe with stretched neck: [0.125, 0.016, 0.820, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000079188_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.125, 0.016, 0.820, 0.992]\nGiven the above layout, shift the giraffe to the right by 0.172."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.297, 0.016, 0.992, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000079408",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is in the center of the image."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.062, 0.180, 0.641, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000079408_key",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is in the center of the image.\nObjects: [stop sign]"
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.062, 0.180, 0.641, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000079408_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red traffic stop sign is in the center of the image."
      },
      {
        "from": "gpt",
        "value": "red traffic stop sign: [0.062, 0.180, 0.641, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000079408_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red traffic stop sign is in the center of the image.\nObjects: [red traffic stop sign]"
      },
      {
        "from": "gpt",
        "value": "red traffic stop sign: [0.062, 0.180, 0.641, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000079408_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: stop sign: [0.062, 0.180, 0.641, 0.797]\nGiven the above layout, shift the stop sign to the right by 0.312."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.375, 0.180, 0.953, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000079651",
    "conversations": [
      {
        "from": "human",
        "value": "Two identical bottles are placed on either side of a different bottle at the center, with two bananas lying in front of them, sloping to the left."
      },
      {
        "from": "gpt",
        "value": "bottle: [0.234, 0.125, 0.406, 0.734]\nbottle: [0.617, 0.141, 0.789, 0.711]\nbottle: [0.438, 0.125, 0.594, 0.711]\nbanana: [0.453, 0.664, 0.984, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000079651_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two identical bottles are placed on either side of a different bottle at the center, with two bananas lying in front of them, sloping to the left.\nObjects: [bottle, bottle, bottle, banana]"
      },
      {
        "from": "gpt",
        "value": "bottle: [0.234, 0.125, 0.406, 0.734]\nbottle: [0.617, 0.141, 0.789, 0.711]\nbottle: [0.438, 0.125, 0.594, 0.711]\nbanana: [0.453, 0.664, 0.984, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000079969",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center, serving in a tennis match."
      },
      {
        "from": "gpt",
        "value": "person: [0.438, 0.297, 0.617, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000079969_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center, serving in a tennis match.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.438, 0.297, 0.617, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000079969_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a professional tennis player is at the center, serving in a tennis match."
      },
      {
        "from": "gpt",
        "value": "professional tennis player: [0.438, 0.297, 0.617, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000079969_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a professional tennis player is at the center, serving in a tennis match.\nObjects: [professional tennis player]"
      },
      {
        "from": "gpt",
        "value": "professional tennis player: [0.438, 0.297, 0.617, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000079969_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.438, 0.297, 0.617, 0.812]\nGiven the above layout, shift the person to the left by 0.031."
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.297, 0.586, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000080022",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center, slightly to the right, holding a tennis racquet near the net."
      },
      {
        "from": "gpt",
        "value": "person: [0.430, 0.336, 0.664, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000080022_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center, slightly to the right, holding a tennis racquet near the net.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.430, 0.336, 0.664, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000080022_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tennis player is at the center, slightly to the right, holding a tennis racquet near the net."
      },
      {
        "from": "gpt",
        "value": "tennis player: [0.430, 0.336, 0.664, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000080022_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tennis player is at the center, slightly to the right, holding a tennis racquet near the net.\nObjects: [tennis player]"
      },
      {
        "from": "gpt",
        "value": "tennis player: [0.430, 0.336, 0.664, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000080022_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.430, 0.336, 0.664, 0.828]\nGiven the above layout, shift the person to the left by 0.352."
      },
      {
        "from": "gpt",
        "value": "person: [0.078, 0.336, 0.312, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000082812",
    "conversations": [
      {
        "from": "human",
        "value": "A train is on the left side of the image, with three people standing on the platform to the right of the train."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.562, 0.508, 0.766]\nperson: [0.539, 0.570, 0.656, 0.773]\nperson: [0.781, 0.516, 0.891, 0.719]\nperson: [0.914, 0.492, 0.992, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000082812_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is on the left side of the image, with three people standing on the platform to the right of the train.\nObjects: [train, person, person, person]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.562, 0.508, 0.766]\nperson: [0.539, 0.570, 0.656, 0.773]\nperson: [0.781, 0.516, 0.891, 0.719]\nperson: [0.914, 0.492, 0.992, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000085911",
    "conversations": [
      {
        "from": "human",
        "value": "The kite is partially submerged in the water, at the center of the image."
      },
      {
        "from": "gpt",
        "value": "kite: [0.297, 0.445, 0.680, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000085911_key",
    "conversations": [
      {
        "from": "human",
        "value": "The kite is partially submerged in the water, at the center of the image.\nObjects: [kite]"
      },
      {
        "from": "gpt",
        "value": "kite: [0.297, 0.445, 0.680, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000085911_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the rainbow-colored kite is partially submerged in the water, at the center of the image."
      },
      {
        "from": "gpt",
        "value": "rainbow-colored kite: [0.297, 0.445, 0.680, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000085911_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the rainbow-colored kite is partially submerged in the water, at the center of the image.\nObjects: [rainbow-colored kite]"
      },
      {
        "from": "gpt",
        "value": "rainbow-colored kite: [0.297, 0.445, 0.680, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000085911_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: kite: [0.297, 0.445, 0.680, 0.617]\nGiven the above layout, shift the kite upwards by 0.133."
      },
      {
        "from": "gpt",
        "value": "kite: [0.297, 0.312, 0.680, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000093965",
    "conversations": [
      {
        "from": "human",
        "value": "One zebra is positioned in the foreground facing left, and another zebra is behind it to the right, facing right."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.086, 0.289, 0.664, 0.797]\nzebra: [0.656, 0.211, 0.852, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000093965_key",
    "conversations": [
      {
        "from": "human",
        "value": "One zebra is positioned in the foreground facing left, and another zebra is behind it to the right, facing right.\nObjects: [zebra, zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.086, 0.289, 0.664, 0.797]\nzebra: [0.656, 0.211, 0.852, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000094185",
    "conversations": [
      {
        "from": "human",
        "value": "In front of the entrance to a shop, a person is partially visible to the left behind a large teddy bear."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.359, 0.469, 0.594, 0.859]\nperson: [0.000, 0.516, 0.039, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000094185_key",
    "conversations": [
      {
        "from": "human",
        "value": "In front of the entrance to a shop, a person is partially visible to the left behind a large teddy bear.\nObjects: [teddy bear, person]"
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.359, 0.469, 0.594, 0.859]\nperson: [0.000, 0.516, 0.039, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000094185_aug",
    "conversations": [
      {
        "from": "human",
        "value": "in front of the entrance to a shop, a woman wearing a hat is partially visible to the left behind a large fluffy panda bear."
      },
      {
        "from": "gpt",
        "value": "fluffy panda bear: [0.359, 0.469, 0.594, 0.859]\nwoman wearing a hat: [0.000, 0.516, 0.039, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000094185_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "in front of the entrance to a shop, a woman wearing a hat is partially visible to the left behind a large fluffy panda bear.\nObjects: [fluffy panda bear, woman wearing a hat]"
      },
      {
        "from": "gpt",
        "value": "fluffy panda bear: [0.359, 0.469, 0.594, 0.859]\nwoman wearing a hat: [0.000, 0.516, 0.039, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000094185_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: teddy bear: [0.359, 0.469, 0.594, 0.859]\nperson: [0.000, 0.516, 0.039, 0.688]\nGiven the above layout, shift the teddy bear upwards by 0.133."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.359, 0.336, 0.594, 0.727]\nperson: [0.000, 0.516, 0.039, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000106330",
    "conversations": [
      {
        "from": "human",
        "value": "A white teddy bear is sitting on the right side of the image, leaning slightly towards the left with a soft light highlighting its face from the left side."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.391, 0.188, 0.898, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000106330_key",
    "conversations": [
      {
        "from": "human",
        "value": "A white teddy bear is sitting on the right side of the image, leaning slightly towards the left with a soft light highlighting its face from the left side.\nObjects: [teddy bear]"
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.391, 0.188, 0.898, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000106330_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a white fluffy pink bunny is sitting on the right side of the image, leaning slightly towards the left with a soft light highlighting its face from the left side."
      },
      {
        "from": "gpt",
        "value": "fluffy pink bunny: [0.391, 0.188, 0.898, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000106330_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a white fluffy pink bunny is sitting on the right side of the image, leaning slightly towards the left with a soft light highlighting its face from the left side.\nObjects: [fluffy pink bunny]"
      },
      {
        "from": "gpt",
        "value": "fluffy pink bunny: [0.391, 0.188, 0.898, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000106330_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: teddy bear: [0.391, 0.188, 0.898, 0.781]\nGiven the above layout, shift the teddy bear to the left by 0.219."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.172, 0.188, 0.680, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000115898",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a surfboard in the water."
      },
      {
        "from": "gpt",
        "value": "person: [0.438, 0.172, 0.719, 0.625]\nsurfboard: [0.219, 0.539, 0.594, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000115898_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a surfboard in the water.\nObjects: [person, surfboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.438, 0.172, 0.719, 0.625]\nsurfboard: [0.219, 0.539, 0.594, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000115898_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall teenager is standing on a red surfboard in the water."
      },
      {
        "from": "gpt",
        "value": "tall teenager: [0.438, 0.172, 0.719, 0.625]\nred surfboard: [0.219, 0.539, 0.594, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000115898_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall teenager is standing on a red surfboard in the water.\nObjects: [tall teenager, red surfboard]"
      },
      {
        "from": "gpt",
        "value": "tall teenager: [0.438, 0.172, 0.719, 0.625]\nred surfboard: [0.219, 0.539, 0.594, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000115898_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.438, 0.172, 0.719, 0.625]\nsurfboard: [0.219, 0.539, 0.594, 0.648]\nGiven the above layout, shift the surfboard downwards by 0.234."
      },
      {
        "from": "gpt",
        "value": "person: [0.438, 0.172, 0.719, 0.625]\nsurfboard: [0.219, 0.773, 0.594, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000124798",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is on the right, and a car is parked to the left of the bus."
      },
      {
        "from": "gpt",
        "value": "bus: [0.266, 0.531, 0.633, 0.727]\ncar: [0.891, 0.648, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000124798_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is on the right, and a car is parked to the left of the bus.\nObjects: [bus, car]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.266, 0.531, 0.633, 0.727]\ncar: [0.891, 0.648, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000124798_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a double-decker bus is on the right, and a red Ferrari is parked to the left of the double-decker bus."
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.266, 0.531, 0.633, 0.727]\nred Ferrari: [0.891, 0.648, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000124798_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a double-decker bus is on the right, and a red Ferrari is parked to the left of the double-decker bus.\nObjects: [double-decker bus, red Ferrari]"
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.266, 0.531, 0.633, 0.727]\nred Ferrari: [0.891, 0.648, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000124798_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.266, 0.531, 0.633, 0.727]\ncar: [0.891, 0.648, 0.992, 0.828]\nGiven the above layout, shift the bus upwards by 0.156."
      },
      {
        "from": "gpt",
        "value": "bus: [0.266, 0.375, 0.633, 0.570]\ncar: [0.891, 0.648, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000125405",
    "conversations": [
      {
        "from": "human",
        "value": "One dog is in the foreground facing away, while another dog is in the background approaching from behind."
      },
      {
        "from": "gpt",
        "value": "dog: [0.344, 0.336, 0.594, 0.797]\ndog: [0.695, 0.172, 0.898, 0.430]"
      }
    ]
  },
  {
    "id": "coco_000000125405_key",
    "conversations": [
      {
        "from": "human",
        "value": "One dog is in the foreground facing away, while another dog is in the background approaching from behind.\nObjects: [dog, dog]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.344, 0.336, 0.594, 0.797]\ndog: [0.695, 0.172, 0.898, 0.430]"
      }
    ]
  },
  {
    "id": "coco_000000127476",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza with a slice missing, placed at the center on a circular tray."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.125, 0.070, 0.867, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000127476_key",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza with a slice missing, placed at the center on a circular tray.\nObjects: [pizza]"
      },
      {
        "from": "gpt",
        "value": "pizza: [0.125, 0.070, 0.867, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000127476_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a cheese and pepperoni pizza with a slice missing, placed at the center on a circular tray."
      },
      {
        "from": "gpt",
        "value": "cheese and pepperoni pizza: [0.125, 0.070, 0.867, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000127476_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a cheese and pepperoni pizza with a slice missing, placed at the center on a circular tray.\nObjects: [cheese and pepperoni pizza]"
      },
      {
        "from": "gpt",
        "value": "cheese and pepperoni pizza: [0.125, 0.070, 0.867, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000127476_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: pizza: [0.125, 0.070, 0.867, 0.961]\nGiven the above layout, shift the pizza to the left by 0.039."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.086, 0.070, 0.828, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000127987",
    "conversations": [
      {
        "from": "human",
        "value": "Two TVs are side by side in the background, and a keyboard is in the foreground to the right."
      },
      {
        "from": "gpt",
        "value": "tv: [0.039, 0.164, 0.539, 0.531]\ntv: [0.484, 0.227, 0.828, 0.531]\nkeyboard: [0.539, 0.570, 0.992, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000127987_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two TVs are side by side in the background, and a keyboard is in the foreground to the right.\nObjects: [tv, tv, keyboard]"
      },
      {
        "from": "gpt",
        "value": "tv: [0.039, 0.164, 0.539, 0.531]\ntv: [0.484, 0.227, 0.828, 0.531]\nkeyboard: [0.539, 0.570, 0.992, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000128372",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left of a bus, another person is walking towards the bus from the right, and a third person is further to the right, walking away from the bus."
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.281, 0.648, 0.750]\nperson: [0.586, 0.477, 0.695, 0.758]\nperson: [0.836, 0.492, 0.898, 0.688]\nperson: [0.688, 0.508, 0.742, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000128372_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left of a bus, another person is walking towards the bus from the right, and a third person is further to the right, walking away from the bus.\nObjects: [bus, person, person, person]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.281, 0.648, 0.750]\nperson: [0.586, 0.477, 0.695, 0.758]\nperson: [0.836, 0.492, 0.898, 0.688]\nperson: [0.688, 0.508, 0.742, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000128699",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in mid-air to the right above the skateboard during a jump."
      },
      {
        "from": "gpt",
        "value": "person: [0.391, 0.102, 0.672, 0.422]\nskateboard: [0.367, 0.391, 0.516, 0.469]"
      }
    ]
  },
  {
    "id": "coco_000000128699_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in mid-air to the right above the skateboard during a jump.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.391, 0.102, 0.672, 0.422]\nskateboard: [0.367, 0.391, 0.516, 0.469]"
      }
    ]
  },
  {
    "id": "coco_000000128699_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a red red skateboarder is in mid-air to the right above the red skateboard during a jump."
      },
      {
        "from": "gpt",
        "value": "a red skateboarder: [0.391, 0.102, 0.672, 0.422]\nred skateboard: [0.367, 0.391, 0.516, 0.469]"
      }
    ]
  },
  {
    "id": "coco_000000128699_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a red red skateboarder is in mid-air to the right above the red skateboard during a jump.\nObjects: [a red skateboarder, red skateboard]"
      },
      {
        "from": "gpt",
        "value": "a red skateboarder: [0.391, 0.102, 0.672, 0.422]\nred skateboard: [0.367, 0.391, 0.516, 0.469]"
      }
    ]
  },
  {
    "id": "coco_000000128699_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.391, 0.102, 0.672, 0.422]\nskateboard: [0.367, 0.391, 0.516, 0.469]\nGiven the above layout, shift the skateboard downwards by 0.211."
      },
      {
        "from": "gpt",
        "value": "person: [0.391, 0.102, 0.672, 0.422]\nskateboard: [0.367, 0.602, 0.516, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000130579",
    "conversations": [
      {
        "from": "human",
        "value": "A person in a white baseball uniform and cap, standing on a pitcher's mound."
      },
      {
        "from": "gpt",
        "value": "person: [0.469, 0.109, 0.711, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000130579_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in a white baseball uniform and cap, standing on a pitchers mound.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.469, 0.109, 0.711, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000130579_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a professional basketball player in a white baseball uniform and cap, standing on a pitcher's mound."
      },
      {
        "from": "gpt",
        "value": "professional basketball player: [0.469, 0.109, 0.711, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000130579_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a professional basketball player in a white baseball uniform and cap, standing on a pitchers mound.\nObjects: [professional basketball player]"
      },
      {
        "from": "gpt",
        "value": "professional basketball player: [0.469, 0.109, 0.711, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000130579_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.469, 0.109, 0.711, 0.859]\nGiven the above layout, shift the person to the left by 0.172."
      },
      {
        "from": "gpt",
        "value": "person: [0.297, 0.109, 0.539, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000130599",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left of a giraffe, wearing a red cap and a black t-shirt."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.297, 0.719, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000130599_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left of a giraffe, wearing a red cap and a black t-shirt.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.297, 0.719, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000130599_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young man is standing to the left of a giraffe, wearing a red cap and a black t-shirt."
      },
      {
        "from": "gpt",
        "value": "young man: [0.000, 0.297, 0.719, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000130599_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young man is standing to the left of a giraffe, wearing a red cap and a black t-shirt.\nObjects: [young man]"
      },
      {
        "from": "gpt",
        "value": "young man: [0.000, 0.297, 0.719, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000130599_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.000, 0.297, 0.719, 0.859]\nGiven the above layout, shift the person upwards by 0.281."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.016, 0.719, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000131556",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skiing, with one ski on each side of a rail, sliding down it."
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.297, 0.938, 0.633]\nskis: [0.203, 0.586, 0.695, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000131556_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skiing, with one ski on each side of a rail, sliding down it.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.297, 0.938, 0.633]\nskis: [0.203, 0.586, 0.695, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000131556_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a person is skiing, with one ski on each side of a rail, sliding down it."
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.297, 0.938, 0.633]\nskis: [0.203, 0.586, 0.695, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000131556_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a person is skiing, with one ski on each side of a rail, sliding down it.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.297, 0.938, 0.633]\nskis: [0.203, 0.586, 0.695, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000131556_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.352, 0.297, 0.938, 0.633]\nskis: [0.203, 0.586, 0.695, 0.656]\nGiven the above layout, shift the skis downwards by 0.117."
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.297, 0.938, 0.633]\nskis: [0.203, 0.703, 0.695, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000134722",
    "conversations": [
      {
        "from": "human",
        "value": "A train on the tracks to the right, with the front of the train facing towards the left."
      },
      {
        "from": "gpt",
        "value": "train: [0.305, 0.422, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000134722_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train on the tracks to the right, with the front of the train facing towards the left.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.305, 0.422, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000134722_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a blue cargo train on the tracks to the right, with the front of the blue cargo train facing towards the left."
      },
      {
        "from": "gpt",
        "value": "blue cargo train: [0.305, 0.422, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000134722_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a blue cargo train on the tracks to the right, with the front of the blue cargo train facing towards the left.\nObjects: [blue cargo train]"
      },
      {
        "from": "gpt",
        "value": "blue cargo train: [0.305, 0.422, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000134722_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.305, 0.422, 0.992, 0.727]\nGiven the above layout, shift the train upwards by 0.141."
      },
      {
        "from": "gpt",
        "value": "train: [0.305, 0.281, 0.992, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000135561",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is on the right side of the image, partially covered with various papers and magnets."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.383, 0.555, 0.633, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000135561_key",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is on the right side of the image, partially covered with various papers and magnets.\nObjects: [refrigerator]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.383, 0.555, 0.633, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000135561_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the cluttered white refrigerator is on the right side of the image, partially covered with various papers and magnets."
      },
      {
        "from": "gpt",
        "value": "cluttered white refrigerator: [0.383, 0.555, 0.633, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000135561_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the cluttered white refrigerator is on the right side of the image, partially covered with various papers and magnets.\nObjects: [cluttered white refrigerator]"
      },
      {
        "from": "gpt",
        "value": "cluttered white refrigerator: [0.383, 0.555, 0.633, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000135561_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: refrigerator: [0.383, 0.555, 0.633, 0.859]\nGiven the above layout, shift the refrigerator upwards by 0.320."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.383, 0.234, 0.633, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000135902",
    "conversations": [
      {
        "from": "human",
        "value": "A train is at the center of the image, facing towards the right side."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.328, 0.844, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000135902_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is at the center of the image, facing towards the right side.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.328, 0.844, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000135902_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a colorful toy train is at the center of the image, facing towards the right side."
      },
      {
        "from": "gpt",
        "value": "colorful toy train: [0.000, 0.328, 0.844, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000135902_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a colorful toy train is at the center of the image, facing towards the right side.\nObjects: [colorful toy train]"
      },
      {
        "from": "gpt",
        "value": "colorful toy train: [0.000, 0.328, 0.844, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000135902_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.328, 0.844, 0.727]\nGiven the above layout, shift the train upwards by 0.156."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.172, 0.844, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000151662",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe is standing behind a black fence to the right of the image, with its head turned towards the left."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.109, 0.359, 0.727, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000151662_key",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe is standing behind a black fence to the right of the image, with its head turned towards the left.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.109, 0.359, 0.727, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000151662_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a long-necked camel is standing behind a black fence to the right of the image, with its head turned towards the left."
      },
      {
        "from": "gpt",
        "value": "long-necked camel: [0.109, 0.359, 0.727, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000151662_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a long-necked camel is standing behind a black fence to the right of the image, with its head turned towards the left.\nObjects: [long-necked camel]"
      },
      {
        "from": "gpt",
        "value": "long-necked camel: [0.109, 0.359, 0.727, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000151662_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.109, 0.359, 0.727, 0.859]\nGiven the above layout, shift the giraffe upwards by 0.148."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.109, 0.211, 0.727, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000162581",
    "conversations": [
      {
        "from": "human",
        "value": "The person is at the center, playing tennis with a racket in an overhead position."
      },
      {
        "from": "gpt",
        "value": "person: [0.359, 0.219, 0.633, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000162581_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is at the center, playing tennis with a racket in an overhead position.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.359, 0.219, 0.633, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000162581_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the teenage male tennis player is at the center, playing tennis with a racket in an overhead position."
      },
      {
        "from": "gpt",
        "value": "teenage male tennis player: [0.359, 0.219, 0.633, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000162581_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the teenage male tennis player is at the center, playing tennis with a racket in an overhead position.\nObjects: [teenage male tennis player]"
      },
      {
        "from": "gpt",
        "value": "teenage male tennis player: [0.359, 0.219, 0.633, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000162581_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.359, 0.219, 0.633, 0.797]\nGiven the above layout, shift the person to the left by 0.023."
      },
      {
        "from": "gpt",
        "value": "person: [0.336, 0.219, 0.609, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000163951",
    "conversations": [
      {
        "from": "human",
        "value": "A banana is on the right of the chair."
      },
      {
        "from": "gpt",
        "value": "banana: [0.367, 0.336, 0.711, 0.680]\nchair: [0.453, 0.641, 0.625, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000163951_key",
    "conversations": [
      {
        "from": "human",
        "value": "A banana is on the right of the chair.\nObjects: [banana, chair]"
      },
      {
        "from": "gpt",
        "value": "banana: [0.367, 0.336, 0.711, 0.680]\nchair: [0.453, 0.641, 0.625, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000163951_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a ripe banana is on the right of the leather armchair."
      },
      {
        "from": "gpt",
        "value": "ripe banana: [0.367, 0.336, 0.711, 0.680]\nleather armchair: [0.453, 0.641, 0.625, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000163951_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a ripe banana is on the right of the leather armchair.\nObjects: [ripe banana, leather armchair]"
      },
      {
        "from": "gpt",
        "value": "ripe banana: [0.367, 0.336, 0.711, 0.680]\nleather armchair: [0.453, 0.641, 0.625, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000163951_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: banana: [0.367, 0.336, 0.711, 0.680]\nchair: [0.453, 0.641, 0.625, 0.805]\nGiven the above layout, shift the banana to the left by 0.094."
      },
      {
        "from": "gpt",
        "value": "banana: [0.273, 0.336, 0.617, 0.680]\nchair: [0.453, 0.641, 0.625, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000165039",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is in the foreground on the left, and a car is in the background to the right of the bus."
      },
      {
        "from": "gpt",
        "value": "bus: [0.141, 0.242, 0.625, 0.695]\ncar: [0.594, 0.414, 0.875, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000165039_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is in the foreground on the left, and a car is in the background to the right of the bus.\nObjects: [bus, car]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.141, 0.242, 0.625, 0.695]\ncar: [0.594, 0.414, 0.875, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000165039_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a double-decker bus is in the foreground on the left, and a sporty sedan is in the background to the right of the double-decker bus."
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.141, 0.242, 0.625, 0.695]\nsporty sedan: [0.594, 0.414, 0.875, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000165039_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a double-decker bus is in the foreground on the left, and a sporty sedan is in the background to the right of the double-decker bus.\nObjects: [double-decker bus, sporty sedan]"
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.141, 0.242, 0.625, 0.695]\nsporty sedan: [0.594, 0.414, 0.875, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000165039_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.141, 0.242, 0.625, 0.695]\ncar: [0.594, 0.414, 0.875, 0.539]\nGiven the above layout, shift the bus downwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "bus: [0.141, 0.312, 0.625, 0.766]\ncar: [0.594, 0.414, 0.875, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000165713",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is on the right side of the image, tilted slightly to the left."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.328, 0.219, 0.578, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000165713_key",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is on the right side of the image, tilted slightly to the left.\nObjects: [fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.328, 0.219, 0.578, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000165713_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red fire hydrant is on the right side of the image, tilted slightly to the left."
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.328, 0.219, 0.578, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000165713_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red fire hydrant is on the right side of the image, tilted slightly to the left.\nObjects: [red fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.328, 0.219, 0.578, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000165713_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: fire hydrant: [0.328, 0.219, 0.578, 0.891]\nGiven the above layout, shift the fire hydrant to the right by 0.031."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.359, 0.219, 0.609, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000166563",
    "conversations": [
      {
        "from": "human",
        "value": "The elephant statue is mounted on top of a vertical signpost."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.125, 0.250, 0.812, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000166563_key",
    "conversations": [
      {
        "from": "human",
        "value": "The elephant statue is mounted on top of a vertical signpost.\nObjects: [elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.125, 0.250, 0.812, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000166563_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the bronze elephant statue statue is mounted on top of a vertical signpost."
      },
      {
        "from": "gpt",
        "value": "bronze elephant statue: [0.125, 0.250, 0.812, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000166563_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the bronze elephant statue statue is mounted on top of a vertical signpost.\nObjects: [bronze elephant statue]"
      },
      {
        "from": "gpt",
        "value": "bronze elephant statue: [0.125, 0.250, 0.812, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000166563_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: elephant: [0.125, 0.250, 0.812, 0.758]\nGiven the above layout, shift the elephant upwards by 0.172."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.125, 0.078, 0.812, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000167067",
    "conversations": [
      {
        "from": "human",
        "value": "A person is wearing a bow tie at the center of the collar area."
      },
      {
        "from": "gpt",
        "value": "person: [0.133, 0.000, 0.867, 0.977]\ntie: [0.492, 0.547, 0.773, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000167067_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is wearing a bow tie at the center of the collar area.\nObjects: [person, tie]"
      },
      {
        "from": "gpt",
        "value": "person: [0.133, 0.000, 0.867, 0.977]\ntie: [0.492, 0.547, 0.773, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000167353",
    "conversations": [
      {
        "from": "human",
        "value": "An antique clock with a round face at the top and a decorative body beneath is mounted on the wall."
      },
      {
        "from": "gpt",
        "value": "clock: [0.125, 0.055, 0.609, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000167353_key",
    "conversations": [
      {
        "from": "human",
        "value": "An antique clock with a round face at the top and a decorative body beneath is mounted on the wall.\nObjects: [clock]"
      },
      {
        "from": "gpt",
        "value": "clock: [0.125, 0.055, 0.609, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000167353_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an antique ornate grandfather clock with a round face at the top and a decorative body beneath is mounted on the wall."
      },
      {
        "from": "gpt",
        "value": "ornate grandfather clock: [0.125, 0.055, 0.609, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000167353_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an antique ornate grandfather clock with a round face at the top and a decorative body beneath is mounted on the wall.\nObjects: [ornate grandfather clock]"
      },
      {
        "from": "gpt",
        "value": "ornate grandfather clock: [0.125, 0.055, 0.609, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000167353_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: clock: [0.125, 0.055, 0.609, 0.992]\nGiven the above layout, shift the clock to the right by 0.375."
      },
      {
        "from": "gpt",
        "value": "clock: [0.500, 0.055, 0.984, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000167540",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying in the center of the image against a blue sky background."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.258, 0.281, 0.758, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000167540_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying in the center of the image against a blue sky background.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.258, 0.281, 0.758, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000167540_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an wide-bodied jetliner is flying in the center of the image against a blue sky background."
      },
      {
        "from": "gpt",
        "value": "wide-bodied jetliner: [0.258, 0.281, 0.758, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000167540_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an wide-bodied jetliner is flying in the center of the image against a blue sky background.\nObjects: [wide-bodied jetliner]"
      },
      {
        "from": "gpt",
        "value": "wide-bodied jetliner: [0.258, 0.281, 0.758, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000167540_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.258, 0.281, 0.758, 0.680]\nGiven the above layout, shift the airplane downwards by 0.250."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.258, 0.531, 0.758, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000167902",
    "conversations": [
      {
        "from": "human",
        "value": "The bird is perched on a branch in the center of the image."
      },
      {
        "from": "gpt",
        "value": "bird: [0.211, 0.242, 0.672, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000167902_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bird is perched on a branch in the center of the image.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.211, 0.242, 0.672, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000167902_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the small sparrow is perched on a branch in the center of the image."
      },
      {
        "from": "gpt",
        "value": "small sparrow: [0.211, 0.242, 0.672, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000167902_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the small sparrow is perched on a branch in the center of the image.\nObjects: [small sparrow]"
      },
      {
        "from": "gpt",
        "value": "small sparrow: [0.211, 0.242, 0.672, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000167902_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.211, 0.242, 0.672, 0.727]\nGiven the above layout, shift the bird to the right by 0.125."
      },
      {
        "from": "gpt",
        "value": "bird: [0.336, 0.242, 0.797, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000168593",
    "conversations": [
      {
        "from": "human",
        "value": "A green refrigerator is positioned in the left foreground, and a white refrigerator is to its right. A chair is situated to the right side of the space near the white refrigerator."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.000, 0.312, 0.422, 0.867]\nrefrigerator: [0.398, 0.297, 0.602, 0.812]\nchair: [0.797, 0.469, 0.992, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000168593_key",
    "conversations": [
      {
        "from": "human",
        "value": "A green refrigerator is positioned in the left foreground, and a white refrigerator is to its right. A chair is situated to the right side of the space near the white refrigerator.\nObjects: [refrigerator, refrigerator, chair]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.000, 0.312, 0.422, 0.867]\nrefrigerator: [0.398, 0.297, 0.602, 0.812]\nchair: [0.797, 0.469, 0.992, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000170116",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is in the center of the image, covered with various notes and magnets."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.125, 0.125, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000170116_key",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is in the center of the image, covered with various notes and magnets.\nObjects: [refrigerator]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.125, 0.125, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000170116_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the Stainless steel refrigerator is in the center of the image, covered with various notes and magnets."
      },
      {
        "from": "gpt",
        "value": "Stainless steel refrigerator: [0.125, 0.125, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000170116_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the Stainless steel refrigerator is in the center of the image, covered with various notes and magnets.\nObjects: [Stainless steel refrigerator]"
      },
      {
        "from": "gpt",
        "value": "Stainless steel refrigerator: [0.125, 0.125, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000170116_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: refrigerator: [0.125, 0.125, 0.992, 0.859]\nGiven the above layout, shift the refrigerator downwards by 0.031."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.125, 0.156, 0.992, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000171050",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is in the foreground on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.391, 0.391, 0.852, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000171050_key",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is in the foreground on the left side of the image.\nObjects: [fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.391, 0.391, 0.852, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000171050_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red fire hydrant is in the foreground on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.391, 0.391, 0.852, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000171050_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red fire hydrant is in the foreground on the left side of the image.\nObjects: [red fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.391, 0.391, 0.852, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000171050_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: fire hydrant: [0.391, 0.391, 0.852, 0.984]\nGiven the above layout, shift the fire hydrant to the left by 0.094."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.297, 0.391, 0.758, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000192191",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza is inside the oven with the door open, and the oven is below the stove where a pizza box rests on top."
      },
      {
        "from": "gpt",
        "value": "oven: [0.125, 0.070, 0.781, 0.977]\npizza: [0.320, 0.617, 0.586, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000192191_key",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza is inside the oven with the door open, and the oven is below the stove where a pizza box rests on top.\nObjects: [oven, pizza]"
      },
      {
        "from": "gpt",
        "value": "oven: [0.125, 0.070, 0.781, 0.977]\npizza: [0.320, 0.617, 0.586, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000192191_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a large Margherita pizza is inside the black oven with the door open, and the black oven is below the stove where a large Margherita pizza box rests on top."
      },
      {
        "from": "gpt",
        "value": "black oven: [0.125, 0.070, 0.781, 0.977]\nlarge Margherita pizza: [0.320, 0.617, 0.586, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000192191_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a large Margherita pizza is inside the black oven with the door open, and the black oven is below the stove where a large Margherita pizza box rests on top.\nObjects: [black oven, large Margherita pizza]"
      },
      {
        "from": "gpt",
        "value": "black oven: [0.125, 0.070, 0.781, 0.977]\nlarge Margherita pizza: [0.320, 0.617, 0.586, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000192191_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: oven: [0.125, 0.070, 0.781, 0.977]\npizza: [0.320, 0.617, 0.586, 0.836]\nGiven the above layout, shift the oven to the right by 0.117."
      },
      {
        "from": "gpt",
        "value": "oven: [0.242, 0.070, 0.898, 0.977]\npizza: [0.320, 0.617, 0.586, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000199055",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a skateboard."
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.055, 0.734, 0.930]\nskateboard: [0.375, 0.758, 0.664, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000199055_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a skateboard.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.055, 0.734, 0.930]\nskateboard: [0.375, 0.758, 0.664, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000199055_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage boy is standing on a bright yellow skateboard."
      },
      {
        "from": "gpt",
        "value": "teenage boy: [0.344, 0.055, 0.734, 0.930]\nbright yellow skateboard: [0.375, 0.758, 0.664, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000199055_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage boy is standing on a bright yellow skateboard.\nObjects: [teenage boy, bright yellow skateboard]"
      },
      {
        "from": "gpt",
        "value": "teenage boy: [0.344, 0.055, 0.734, 0.930]\nbright yellow skateboard: [0.375, 0.758, 0.664, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000199055_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.344, 0.055, 0.734, 0.930]\nskateboard: [0.375, 0.758, 0.664, 0.945]\nGiven the above layout, shift the person to the left by 0.016."
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.055, 0.719, 0.930]\nskateboard: [0.375, 0.758, 0.664, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000201934",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is parked on the right side of the image, alongside a sidewalk."
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.242, 0.523, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000201934_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is parked on the right side of the image, alongside a sidewalk.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.242, 0.523, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000201934_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a double-decker bus is parked on the right side of the image, alongside a sidewalk."
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.000, 0.242, 0.523, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000201934_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a double-decker bus is parked on the right side of the image, alongside a sidewalk.\nObjects: [double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.000, 0.242, 0.523, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000201934_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.000, 0.242, 0.523, 0.711]\nGiven the above layout, shift the bus to the right by 0.445."
      },
      {
        "from": "gpt",
        "value": "bus: [0.445, 0.242, 0.969, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000203546",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is at the center of the image, partially submerged in water."
      },
      {
        "from": "gpt",
        "value": "bear: [0.359, 0.242, 0.812, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000203546_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is at the center of the image, partially submerged in water.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.359, 0.242, 0.812, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000203546_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the panda bear is at the center of the image, partially submerged in water."
      },
      {
        "from": "gpt",
        "value": "panda bear: [0.359, 0.242, 0.812, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000203546_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the panda bear is at the center of the image, partially submerged in water.\nObjects: [panda bear]"
      },
      {
        "from": "gpt",
        "value": "panda bear: [0.359, 0.242, 0.812, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000203546_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.359, 0.242, 0.812, 0.633]\nGiven the above layout, shift the bear to the left by 0.352."
      },
      {
        "from": "gpt",
        "value": "bear: [0.008, 0.242, 0.461, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000203639",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing slightly off-center to the right of the image, with sunlight coming from the left side."
      },
      {
        "from": "gpt",
        "value": "person: [0.242, 0.062, 0.617, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000203639_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing slightly off-center to the right of the image, with sunlight coming from the left side.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.242, 0.062, 0.617, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000203639_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman is standing slightly off-center to the right of the image, with sunlight coming from the left side."
      },
      {
        "from": "gpt",
        "value": "young woman: [0.242, 0.062, 0.617, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000203639_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman is standing slightly off-center to the right of the image, with sunlight coming from the left side.\nObjects: [young woman]"
      },
      {
        "from": "gpt",
        "value": "young woman: [0.242, 0.062, 0.617, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000203639_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.242, 0.062, 0.617, 0.961]\nGiven the above layout, shift the person to the right by 0.031."
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.062, 0.648, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000205647",
    "conversations": [
      {
        "from": "human",
        "value": "A FedEx truck is driving from left to right, pulling two trailers."
      },
      {
        "from": "gpt",
        "value": "truck: [0.070, 0.484, 0.812, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000205647_key",
    "conversations": [
      {
        "from": "human",
        "value": "A FedEx truck is driving from left to right, pulling two trailers.\nObjects: [truck]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.070, 0.484, 0.812, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000205647_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a fedex UPS delivery van is driving from left to right, pulling two trailers."
      },
      {
        "from": "gpt",
        "value": "UPS delivery van: [0.070, 0.484, 0.812, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000205647_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a fedex UPS delivery van is driving from left to right, pulling two trailers.\nObjects: [UPS delivery van]"
      },
      {
        "from": "gpt",
        "value": "UPS delivery van: [0.070, 0.484, 0.812, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000205647_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.070, 0.484, 0.812, 0.664]\nGiven the above layout, shift the truck upwards by 0.047."
      },
      {
        "from": "gpt",
        "value": "truck: [0.070, 0.438, 0.812, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000205776",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is positioned with its head through a large mechanical structure, facing towards the right."
      },
      {
        "from": "gpt",
        "value": "bear: [0.141, 0.211, 0.828, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000205776_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is positioned with its head through a large mechanical structure, facing towards the right.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.141, 0.211, 0.828, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000205776_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the grizzly bear is positioned with its head through a large mechanical structure, facing towards the right."
      },
      {
        "from": "gpt",
        "value": "grizzly bear: [0.141, 0.211, 0.828, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000205776_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the grizzly bear is positioned with its head through a large mechanical structure, facing towards the right.\nObjects: [grizzly bear]"
      },
      {
        "from": "gpt",
        "value": "grizzly bear: [0.141, 0.211, 0.828, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000205776_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.141, 0.211, 0.828, 0.586]\nGiven the above layout, shift the bear downwards by 0.086."
      },
      {
        "from": "gpt",
        "value": "bear: [0.141, 0.297, 0.828, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000206218",
    "conversations": [
      {
        "from": "human",
        "value": "A laptop with an integrated keyboard at the center of the image."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.555, 0.281, 0.977, 0.617]\nkeyboard: [0.609, 0.484, 0.883, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000206218_key",
    "conversations": [
      {
        "from": "human",
        "value": "A laptop with an integrated keyboard at the center of the image.\nObjects: [laptop, keyboard]"
      },
      {
        "from": "gpt",
        "value": "laptop: [0.555, 0.281, 0.977, 0.617]\nkeyboard: [0.609, 0.484, 0.883, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000206218_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a silver MacBook Pro with an integrated black laptop keyboard at the center of the image."
      },
      {
        "from": "gpt",
        "value": "silver MacBook Pro: [0.555, 0.281, 0.977, 0.617]\nblack laptop keyboard: [0.609, 0.484, 0.883, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000206218_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a silver MacBook Pro with an integrated black laptop keyboard at the center of the image.\nObjects: [silver MacBook Pro, black laptop keyboard]"
      },
      {
        "from": "gpt",
        "value": "silver MacBook Pro: [0.555, 0.281, 0.977, 0.617]\nblack laptop keyboard: [0.609, 0.484, 0.883, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000206218_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: laptop: [0.555, 0.281, 0.977, 0.617]\nkeyboard: [0.609, 0.484, 0.883, 0.555]\nGiven the above layout, shift the laptop to the left by 0.484."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.070, 0.281, 0.492, 0.617]\nkeyboard: [0.609, 0.484, 0.883, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000206994",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks to the right side of the image, parallel to a platform with a blue shelter on the left."
      },
      {
        "from": "gpt",
        "value": "train: [0.344, 0.469, 0.930, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000206994_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks to the right side of the image, parallel to a platform with a blue shelter on the left.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.344, 0.469, 0.930, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000206994_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red diesel locomotive is on the tracks to the right side of the image, parallel to a platform with a blue shelter on the left."
      },
      {
        "from": "gpt",
        "value": "red diesel locomotive: [0.344, 0.469, 0.930, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000206994_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red diesel locomotive is on the tracks to the right side of the image, parallel to a platform with a blue shelter on the left.\nObjects: [red diesel locomotive]"
      },
      {
        "from": "gpt",
        "value": "red diesel locomotive: [0.344, 0.469, 0.930, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000206994_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.344, 0.469, 0.930, 0.672]\nGiven the above layout, shift the train upwards by 0.141."
      },
      {
        "from": "gpt",
        "value": "train: [0.344, 0.328, 0.930, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000207306",
    "conversations": [
      {
        "from": "human",
        "value": "A teddy bear is sitting on top of a trash can at the center of the image."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.219, 0.297, 0.656, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000207306_key",
    "conversations": [
      {
        "from": "human",
        "value": "A teddy bear is sitting on top of a trash can at the center of the image.\nObjects: [teddy bear]"
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.219, 0.297, 0.656, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000207306_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a fluffy white rabbit is sitting on top of a trash can at the center of the image."
      },
      {
        "from": "gpt",
        "value": "fluffy white rabbit: [0.219, 0.297, 0.656, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000207306_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a fluffy white rabbit is sitting on top of a trash can at the center of the image.\nObjects: [fluffy white rabbit]"
      },
      {
        "from": "gpt",
        "value": "fluffy white rabbit: [0.219, 0.297, 0.656, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000207306_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: teddy bear: [0.219, 0.297, 0.656, 0.703]\nGiven the above layout, shift the teddy bear to the right by 0.227."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.445, 0.297, 0.883, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000207538",
    "conversations": [
      {
        "from": "human",
        "value": "The microwave is mounted under the kitchen cabinets to the right side."
      },
      {
        "from": "gpt",
        "value": "microwave: [0.203, 0.430, 0.812, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000207538_key",
    "conversations": [
      {
        "from": "human",
        "value": "The microwave is mounted under the kitchen cabinets to the right side.\nObjects: [microwave]"
      },
      {
        "from": "gpt",
        "value": "microwave: [0.203, 0.430, 0.812, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000207538_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel microwave is mounted under the kitchen cabinets to the right side."
      },
      {
        "from": "gpt",
        "value": "stainless steel microwave: [0.203, 0.430, 0.812, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000207538_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel microwave is mounted under the kitchen cabinets to the right side.\nObjects: [stainless steel microwave]"
      },
      {
        "from": "gpt",
        "value": "stainless steel microwave: [0.203, 0.430, 0.812, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000207538_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: microwave: [0.203, 0.430, 0.812, 0.805]\nGiven the above layout, shift the microwave upwards by 0.266."
      },
      {
        "from": "gpt",
        "value": "microwave: [0.203, 0.164, 0.812, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000208208",
    "conversations": [
      {
        "from": "human",
        "value": "The wing of an airplane is visible in the foreground on the bottom right with a view of mountains below."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.414, 0.125, 0.992, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000208208_key",
    "conversations": [
      {
        "from": "human",
        "value": "The wing of an airplane is visible in the foreground on the bottom right with a view of mountains below.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.414, 0.125, 0.992, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000208208_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the wing of an airliner is visible in the foreground on the bottom right with a view of mountains below."
      },
      {
        "from": "gpt",
        "value": "airliner: [0.414, 0.125, 0.992, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000208208_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the wing of an airliner is visible in the foreground on the bottom right with a view of mountains below.\nObjects: [airliner]"
      },
      {
        "from": "gpt",
        "value": "airliner: [0.414, 0.125, 0.992, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000208208_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.414, 0.125, 0.992, 0.500]\nGiven the above layout, shift the airplane downwards by 0.492."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.414, 0.617, 0.992, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000209753",
    "conversations": [
      {
        "from": "human",
        "value": "The person is standing in the center of the image holding a phone, with a TV in the background slightly to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.195, 0.102, 0.797, 0.977]\ntv: [0.695, 0.539, 0.852, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000209753_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is standing in the center of the image holding a phone, with a TV in the background slightly to the right.\nObjects: [person, tv]"
      },
      {
        "from": "gpt",
        "value": "person: [0.195, 0.102, 0.797, 0.977]\ntv: [0.695, 0.539, 0.852, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000209753_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the young woman is standing in the center of the image holding a phone, with a flat-screen TV in the background slightly to the right."
      },
      {
        "from": "gpt",
        "value": "young woman: [0.195, 0.102, 0.797, 0.977]\nflat-screen TV: [0.695, 0.539, 0.852, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000209753_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the young woman is standing in the center of the image holding a phone, with a flat-screen TV in the background slightly to the right.\nObjects: [young woman, flat-screen TV]"
      },
      {
        "from": "gpt",
        "value": "young woman: [0.195, 0.102, 0.797, 0.977]\nflat-screen TV: [0.695, 0.539, 0.852, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000209753_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.195, 0.102, 0.797, 0.977]\ntv: [0.695, 0.539, 0.852, 0.711]\nGiven the above layout, shift the person to the left by 0.125."
      },
      {
        "from": "gpt",
        "value": "person: [0.070, 0.102, 0.672, 0.977]\ntv: [0.695, 0.539, 0.852, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000209972",
    "conversations": [
      {
        "from": "human",
        "value": "The sailboat is at the center of the image on the sandy shore with water in the background."
      },
      {
        "from": "gpt",
        "value": "boat: [0.516, 0.328, 0.695, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000209972_key",
    "conversations": [
      {
        "from": "human",
        "value": "The sailboat is at the center of the image on the sandy shore with water in the background.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.516, 0.328, 0.695, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000209972_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the sailvintage wooden yacht is at the center of the image on the sandy shore with water in the background."
      },
      {
        "from": "gpt",
        "value": "vintage wooden yacht: [0.516, 0.328, 0.695, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000209972_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the sailvintage wooden yacht is at the center of the image on the sandy shore with water in the background.\nObjects: [vintage wooden yacht]"
      },
      {
        "from": "gpt",
        "value": "vintage wooden yacht: [0.516, 0.328, 0.695, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000209972_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.516, 0.328, 0.695, 0.633]\nGiven the above layout, shift the boat to the left by 0.508."
      },
      {
        "from": "gpt",
        "value": "boat: [0.008, 0.328, 0.188, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000232244",
    "conversations": [
      {
        "from": "human",
        "value": "The elephant is at the center of the image, adorned with a colorful cloth."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.008, 0.188, 0.961, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000232244_key",
    "conversations": [
      {
        "from": "human",
        "value": "The elephant is at the center of the image, adorned with a colorful cloth.\nObjects: [elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.008, 0.188, 0.961, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000232244_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the decorated Indian elephant is at the center of the image, adorned with a colorful cloth."
      },
      {
        "from": "gpt",
        "value": "decorated Indian elephant: [0.008, 0.188, 0.961, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000232244_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the decorated Indian elephant is at the center of the image, adorned with a colorful cloth.\nObjects: [decorated Indian elephant]"
      },
      {
        "from": "gpt",
        "value": "decorated Indian elephant: [0.008, 0.188, 0.961, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000232244_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: elephant: [0.008, 0.188, 0.961, 0.867]\nGiven the above layout, shift the elephant upwards by 0.125."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.008, 0.062, 0.961, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000236426",
    "conversations": [
      {
        "from": "human",
        "value": "One person is playing tennis on the court, and another person is standing in the background to the left."
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.266, 0.625, 0.602]\nperson: [0.031, 0.312, 0.188, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000236426_key",
    "conversations": [
      {
        "from": "human",
        "value": "One person is playing tennis on the court, and another person is standing in the background to the left.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.266, 0.625, 0.602]\nperson: [0.031, 0.312, 0.188, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000236730",
    "conversations": [
      {
        "from": "human",
        "value": "The zebra's head is in the center of the image facing to the left."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.125, 0.023, 0.711, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000236730_key",
    "conversations": [
      {
        "from": "human",
        "value": "The zebras head is in the center of the image facing to the left.\nObjects: [zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.125, 0.023, 0.711, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000236730_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the circus horse's head is in the center of the image facing to the left."
      },
      {
        "from": "gpt",
        "value": "circus horse: [0.125, 0.023, 0.711, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000236730_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the circus horses head is in the center of the image facing to the left.\nObjects: [circus horse]"
      },
      {
        "from": "gpt",
        "value": "circus horse: [0.125, 0.023, 0.711, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000236730_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: zebra: [0.125, 0.023, 0.711, 0.984]\nGiven the above layout, shift the zebra to the right by 0.172."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.297, 0.023, 0.883, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000237864",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant is in the center of the image, walking to the right."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.102, 0.352, 0.516, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000237864_key",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant is in the center of the image, walking to the right.\nObjects: [elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.102, 0.352, 0.516, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000237864_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an enormous giraffe is in the center of the image, walking to the right."
      },
      {
        "from": "gpt",
        "value": "enormous giraffe: [0.102, 0.352, 0.516, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000237864_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an enormous giraffe is in the center of the image, walking to the right.\nObjects: [enormous giraffe]"
      },
      {
        "from": "gpt",
        "value": "enormous giraffe: [0.102, 0.352, 0.516, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000237864_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: elephant: [0.102, 0.352, 0.516, 0.641]\nGiven the above layout, shift the elephant to the right by 0.031."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.133, 0.352, 0.547, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000239274",
    "conversations": [
      {
        "from": "human",
        "value": "The boat is at the center of the image, floating near the rocky shore."
      },
      {
        "from": "gpt",
        "value": "boat: [0.156, 0.289, 0.672, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000239274_key",
    "conversations": [
      {
        "from": "human",
        "value": "The boat is at the center of the image, floating near the rocky shore.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.156, 0.289, 0.672, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000239274_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red sailboat is at the center of the image, floating near the rocky shore."
      },
      {
        "from": "gpt",
        "value": "red sailboat: [0.156, 0.289, 0.672, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000239274_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red sailboat is at the center of the image, floating near the rocky shore.\nObjects: [red sailboat]"
      },
      {
        "from": "gpt",
        "value": "red sailboat: [0.156, 0.289, 0.672, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000239274_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.156, 0.289, 0.672, 0.797]\nGiven the above layout, shift the boat to the right by 0.031."
      },
      {
        "from": "gpt",
        "value": "boat: [0.188, 0.289, 0.703, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000241297",
    "conversations": [
      {
        "from": "human",
        "value": "The train is coming toward the viewer on the tracks, slightly off to the left side of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.211, 0.375, 0.680, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000241297_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is coming toward the viewer on the tracks, slightly off to the left side of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.211, 0.375, 0.680, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000241297_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the big diesel locomotive is coming toward the viewer on the tracks, slightly off to the left side of the image."
      },
      {
        "from": "gpt",
        "value": "big diesel locomotive: [0.211, 0.375, 0.680, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000241297_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the big diesel locomotive is coming toward the viewer on the tracks, slightly off to the left side of the image.\nObjects: [big diesel locomotive]"
      },
      {
        "from": "gpt",
        "value": "big diesel locomotive: [0.211, 0.375, 0.680, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000241297_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.211, 0.375, 0.680, 0.758]\nGiven the above layout, shift the train upwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "train: [0.211, 0.336, 0.680, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000241319",
    "conversations": [
      {
        "from": "human",
        "value": "A toothbrush is to the left of the sink, another toothbrush is to the right of the sink, and a handbag is to the far left, adjacent to the sink."
      },
      {
        "from": "gpt",
        "value": "sink: [0.000, 0.625, 0.992, 0.734]\ntoothbrush: [0.711, 0.320, 0.883, 0.602]\nhandbag: [0.000, 0.398, 0.211, 0.633]\ntoothbrush: [0.203, 0.289, 0.312, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000241319_key",
    "conversations": [
      {
        "from": "human",
        "value": "A toothbrush is to the left of the sink, another toothbrush is to the right of the sink, and a handbag is to the far left, adjacent to the sink.\nObjects: [sink, toothbrush, handbag, toothbrush]"
      },
      {
        "from": "gpt",
        "value": "sink: [0.000, 0.625, 0.992, 0.734]\ntoothbrush: [0.711, 0.320, 0.883, 0.602]\nhandbag: [0.000, 0.398, 0.211, 0.633]\ntoothbrush: [0.203, 0.289, 0.312, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000242287",
    "conversations": [
      {
        "from": "human",
        "value": "The bicycle is leaning against a wall to the right of a wooden door."
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.195, 0.594, 0.680, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000242287_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bicycle is leaning against a wall to the right of a wooden door.\nObjects: [bicycle]"
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.195, 0.594, 0.680, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000242287_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the mountain bike is leaning against a wall to the right of a wooden door."
      },
      {
        "from": "gpt",
        "value": "mountain bike: [0.195, 0.594, 0.680, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000242287_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the mountain bike is leaning against a wall to the right of a wooden door.\nObjects: [mountain bike]"
      },
      {
        "from": "gpt",
        "value": "mountain bike: [0.195, 0.594, 0.680, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000242287_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bicycle: [0.195, 0.594, 0.680, 0.977]\nGiven the above layout, shift the bicycle upwards by 0.359."
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.195, 0.234, 0.680, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000243075",
    "conversations": [
      {
        "from": "human",
        "value": "A polar bear is at the center facing upwards."
      },
      {
        "from": "gpt",
        "value": "bear: [0.000, 0.180, 0.852, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000243075_key",
    "conversations": [
      {
        "from": "human",
        "value": "A polar bear is at the center facing upwards.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.000, 0.180, 0.852, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000243075_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a polar adult grizzly bear is at the center facing upwards."
      },
      {
        "from": "gpt",
        "value": "adult grizzly bear: [0.000, 0.180, 0.852, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000243075_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a polar adult grizzly bear is at the center facing upwards.\nObjects: [adult grizzly bear]"
      },
      {
        "from": "gpt",
        "value": "adult grizzly bear: [0.000, 0.180, 0.852, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000243075_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.000, 0.180, 0.852, 0.930]\nGiven the above layout, shift the bear upwards by 0.109."
      },
      {
        "from": "gpt",
        "value": "bear: [0.000, 0.070, 0.852, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000245026",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing behind a table with a cake in the center."
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.219, 0.656, 0.641]\ncake: [0.297, 0.586, 0.664, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000245026_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing behind a table with a cake in the center.\nObjects: [person, cake]"
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.219, 0.656, 0.641]\ncake: [0.297, 0.586, 0.664, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000245026_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a woman in a red dress is standing behind a table with a a two-tiered strawberry cake in the center."
      },
      {
        "from": "gpt",
        "value": "a woman in a red dress: [0.273, 0.219, 0.656, 0.641]\na two-tiered strawberry cake: [0.297, 0.586, 0.664, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000245026_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a woman in a red dress is standing behind a table with a a two-tiered strawberry cake in the center.\nObjects: [a woman in a red dress, a two-tiered strawberry cake]"
      },
      {
        "from": "gpt",
        "value": "a woman in a red dress: [0.273, 0.219, 0.656, 0.641]\na two-tiered strawberry cake: [0.297, 0.586, 0.664, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000245026_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.273, 0.219, 0.656, 0.641]\ncake: [0.297, 0.586, 0.664, 0.797]\nGiven the above layout, shift the cake to the right by 0.133."
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.219, 0.656, 0.641]\ncake: [0.430, 0.586, 0.797, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000245651",
    "conversations": [
      {
        "from": "human",
        "value": "A two-tiered cake with colorful star decorations is centered on a table with a grey surface."
      },
      {
        "from": "gpt",
        "value": "cake: [0.125, 0.070, 0.844, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000245651_key",
    "conversations": [
      {
        "from": "human",
        "value": "A two-tiered cake with colorful star decorations is centered on a table with a grey surface.\nObjects: [cake]"
      },
      {
        "from": "gpt",
        "value": "cake: [0.125, 0.070, 0.844, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000245651_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a two-tiered two-layered dessert with rainbow sprinkles with colorful star decorations is centered on a table with a grey surface."
      },
      {
        "from": "gpt",
        "value": "two-layered dessert with rainbow sprinkles: [0.125, 0.070, 0.844, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000245651_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a two-tiered two-layered dessert with rainbow sprinkles with colorful star decorations is centered on a table with a grey surface.\nObjects: [two-layered dessert with rainbow sprinkles]"
      },
      {
        "from": "gpt",
        "value": "two-layered dessert with rainbow sprinkles: [0.125, 0.070, 0.844, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000245651_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cake: [0.125, 0.070, 0.844, 0.734]\nGiven the above layout, shift the cake downwards by 0.016."
      },
      {
        "from": "gpt",
        "value": "cake: [0.125, 0.086, 0.844, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000248400",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the left is gesturing towards a pizza in an open box on a table with a potted plant to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.180, 0.391, 0.812]\npizza: [0.422, 0.742, 0.812, 0.820]\npotted plant: [0.305, 0.391, 0.367, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000248400_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the left is gesturing towards a pizza in an open box on a table with a potted plant to the right.\nObjects: [person, pizza, potted plant]"
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.180, 0.391, 0.812]\npizza: [0.422, 0.742, 0.812, 0.820]\npotted plant: [0.305, 0.391, 0.367, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000248400_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a person on the left is gesturing towards a pizza in an open box on a table with a potted plant to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.180, 0.391, 0.812]\npizza: [0.422, 0.742, 0.812, 0.820]\npotted plant: [0.305, 0.391, 0.367, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000248400_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a person on the left is gesturing towards a pizza in an open box on a table with a potted plant to the right.\nObjects: [person, pizza, potted plant]"
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.180, 0.391, 0.812]\npizza: [0.422, 0.742, 0.812, 0.820]\npotted plant: [0.305, 0.391, 0.367, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000248400_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.000, 0.180, 0.391, 0.812]\npizza: [0.422, 0.742, 0.812, 0.820]\npotted plant: [0.305, 0.391, 0.367, 0.578]\nGiven the above layout, shift the person upwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.141, 0.391, 0.773]\npizza: [0.422, 0.742, 0.812, 0.820]\npotted plant: [0.305, 0.391, 0.367, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000270244",
    "conversations": [
      {
        "from": "human",
        "value": "A zebra stands in the center of a grass field, facing left."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.156, 0.391, 0.555, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000270244_key",
    "conversations": [
      {
        "from": "human",
        "value": "A zebra stands in the center of a grass field, facing left.\nObjects: [zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.156, 0.391, 0.555, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000270244_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a striped wild horse stands in the center of a grass field, facing left."
      },
      {
        "from": "gpt",
        "value": "striped wild horse: [0.156, 0.391, 0.555, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000270244_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a striped wild horse stands in the center of a grass field, facing left.\nObjects: [striped wild horse]"
      },
      {
        "from": "gpt",
        "value": "striped wild horse: [0.156, 0.391, 0.555, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000270244_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: zebra: [0.156, 0.391, 0.555, 0.688]\nGiven the above layout, shift the zebra to the right by 0.438."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.594, 0.391, 0.992, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000281414",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on a wall with a backpack to their right side."
      },
      {
        "from": "gpt",
        "value": "person: [0.250, 0.164, 0.641, 0.898]\nbackpack: [0.594, 0.469, 0.836, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000281414_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on a wall with a backpack to their right side.\nObjects: [person, backpack]"
      },
      {
        "from": "gpt",
        "value": "person: [0.250, 0.164, 0.641, 0.898]\nbackpack: [0.594, 0.469, 0.836, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000281414_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a hiker is sitting on a wall with a a large hiking backpack to their right side."
      },
      {
        "from": "gpt",
        "value": "a hiker: [0.250, 0.164, 0.641, 0.898]\na large hiking backpack: [0.594, 0.469, 0.836, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000281414_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a hiker is sitting on a wall with a a large hiking backpack to their right side.\nObjects: [a hiker, a large hiking backpack]"
      },
      {
        "from": "gpt",
        "value": "a hiker: [0.250, 0.164, 0.641, 0.898]\na large hiking backpack: [0.594, 0.469, 0.836, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000281414_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.250, 0.164, 0.641, 0.898]\nbackpack: [0.594, 0.469, 0.836, 0.625]\nGiven the above layout, shift the person to the left by 0.109."
      },
      {
        "from": "gpt",
        "value": "person: [0.141, 0.164, 0.531, 0.898]\nbackpack: [0.594, 0.469, 0.836, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000283520",
    "conversations": [
      {
        "from": "human",
        "value": "One person is standing on the left side watching another person on the right side throwing a frisbee."
      },
      {
        "from": "gpt",
        "value": "person: [0.508, 0.359, 0.719, 0.758]\nperson: [0.266, 0.367, 0.375, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000283520_key",
    "conversations": [
      {
        "from": "human",
        "value": "One person is standing on the left side watching another person on the right side throwing a frisbee.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.508, 0.359, 0.719, 0.758]\nperson: [0.266, 0.367, 0.375, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000285349",
    "conversations": [
      {
        "from": "human",
        "value": "The heart-shaped vase is in the center, filled with colorful paper cranes."
      },
      {
        "from": "gpt",
        "value": "vase: [0.047, 0.188, 0.844, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000285349_key",
    "conversations": [
      {
        "from": "human",
        "value": "The heart-shaped vase is in the center, filled with colorful paper cranes.\nObjects: [vase]"
      },
      {
        "from": "gpt",
        "value": "vase: [0.047, 0.188, 0.844, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000285349_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the heart-shaped polka-dotted jug is in the center, filled with colorful paper cranes."
      },
      {
        "from": "gpt",
        "value": "polka-dotted jug: [0.047, 0.188, 0.844, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000285349_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the heart-shaped polka-dotted jug is in the center, filled with colorful paper cranes.\nObjects: [polka-dotted jug]"
      },
      {
        "from": "gpt",
        "value": "polka-dotted jug: [0.047, 0.188, 0.844, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000285349_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: vase: [0.047, 0.188, 0.844, 0.867]\nGiven the above layout, shift the vase upwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "vase: [0.047, 0.148, 0.844, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000289059",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the foreground is crouching with a tennis racket, and another person is standing in the background to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.008, 0.188, 0.609, 0.859]\nperson: [0.539, 0.125, 0.812, 0.695]\ntennis racket: [0.547, 0.555, 0.852, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000289059_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the foreground is crouching with a tennis racket, and another person is standing in the background to the right.\nObjects: [person, person, tennis racket]"
      },
      {
        "from": "gpt",
        "value": "person: [0.008, 0.188, 0.609, 0.859]\nperson: [0.539, 0.125, 0.812, 0.695]\ntennis racket: [0.547, 0.555, 0.852, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000289229",
    "conversations": [
      {
        "from": "human",
        "value": "A person wearing a white lab coat, with a stethoscope in their left hand, standing against a light background."
      },
      {
        "from": "gpt",
        "value": "person: [0.234, 0.031, 0.805, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000289229_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person wearing a white lab coat, with a stethoscope in their left hand, standing against a light background.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.234, 0.031, 0.805, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000289229_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a middle-aged healthcare professional wearing a white lab coat, with a stethoscope in their left hand, standing against a light background."
      },
      {
        "from": "gpt",
        "value": "a middle-aged healthcare professional: [0.234, 0.031, 0.805, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000289229_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a middle-aged healthcare professional wearing a white lab coat, with a stethoscope in their left hand, standing against a light background.\nObjects: [a middle-aged healthcare professional]"
      },
      {
        "from": "gpt",
        "value": "a middle-aged healthcare professional: [0.234, 0.031, 0.805, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000289229_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.234, 0.031, 0.805, 0.992]\nGiven the above layout, shift the person to the left by 0.133."
      },
      {
        "from": "gpt",
        "value": "person: [0.102, 0.031, 0.672, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000289586",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe's neck and head are at the center extending towards the top right corner of the image."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.312, 0.148, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000289586_key",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffes neck and head are at the center extending towards the top right corner of the image.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.312, 0.148, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000289586_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the tall flamingo's neck and head are at the center extending towards the top right corner of the image."
      },
      {
        "from": "gpt",
        "value": "tall flamingo: [0.312, 0.148, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000289586_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the tall flamingos neck and head are at the center extending towards the top right corner of the image.\nObjects: [tall flamingo]"
      },
      {
        "from": "gpt",
        "value": "tall flamingo: [0.312, 0.148, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000289586_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.312, 0.148, 0.828, 0.992]\nGiven the above layout, shift the giraffe to the left by 0.023."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.289, 0.148, 0.805, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000289992",
    "conversations": [
      {
        "from": "human",
        "value": "The sink is located in the bottom left corner of the image."
      },
      {
        "from": "gpt",
        "value": "sink: [0.047, 0.633, 0.438, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000289992_key",
    "conversations": [
      {
        "from": "human",
        "value": "The sink is located in the bottom left corner of the image.\nObjects: [sink]"
      },
      {
        "from": "gpt",
        "value": "sink: [0.047, 0.633, 0.438, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000289992_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel kitchen sink is located in the bottom left corner of the image."
      },
      {
        "from": "gpt",
        "value": "stainless steel kitchen sink: [0.047, 0.633, 0.438, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000289992_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel kitchen sink is located in the bottom left corner of the image.\nObjects: [stainless steel kitchen sink]"
      },
      {
        "from": "gpt",
        "value": "stainless steel kitchen sink: [0.047, 0.633, 0.438, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000289992_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sink: [0.047, 0.633, 0.438, 0.828]\nGiven the above layout, shift the sink upwards by 0.617."
      },
      {
        "from": "gpt",
        "value": "sink: [0.047, 0.016, 0.438, 0.211]"
      }
    ]
  },
  {
    "id": "coco_000000290293",
    "conversations": [
      {
        "from": "human",
        "value": "A train is on the right, moving through the station which has lights on the ceiling."
      },
      {
        "from": "gpt",
        "value": "train: [0.016, 0.336, 0.719, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000290293_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is on the right, moving through the station which has lights on the ceiling.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.016, 0.336, 0.719, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000290293_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a high-speed bullet train is on the right, moving through the station which has lights on the ceiling."
      },
      {
        "from": "gpt",
        "value": "high-speed bullet train: [0.016, 0.336, 0.719, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000290293_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a high-speed bullet train is on the right, moving through the station which has lights on the ceiling.\nObjects: [high-speed bullet train]"
      },
      {
        "from": "gpt",
        "value": "high-speed bullet train: [0.016, 0.336, 0.719, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000290293_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.016, 0.336, 0.719, 0.648]\nGiven the above layout, shift the train downwards by 0.062."
      },
      {
        "from": "gpt",
        "value": "train: [0.016, 0.398, 0.719, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000290619",
    "conversations": [
      {
        "from": "human",
        "value": "The banana is to the left of a blue container."
      },
      {
        "from": "gpt",
        "value": "banana: [0.078, 0.219, 0.438, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000290619_key",
    "conversations": [
      {
        "from": "human",
        "value": "The banana is to the left of a blue container.\nObjects: [banana]"
      },
      {
        "from": "gpt",
        "value": "banana: [0.078, 0.219, 0.438, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000290619_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the ripe banana is to the left of a blue container."
      },
      {
        "from": "gpt",
        "value": "ripe banana: [0.078, 0.219, 0.438, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000290619_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the ripe banana is to the left of a blue container.\nObjects: [ripe banana]"
      },
      {
        "from": "gpt",
        "value": "ripe banana: [0.078, 0.219, 0.438, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000290619_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: banana: [0.078, 0.219, 0.438, 0.820]\nGiven the above layout, shift the banana to the right by 0.531."
      },
      {
        "from": "gpt",
        "value": "banana: [0.609, 0.219, 0.969, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000290768",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is at the center, integrated into the kitchen unit that is positioned against the wall."
      },
      {
        "from": "gpt",
        "value": "oven: [0.344, 0.328, 0.609, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000290768_key",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is at the center, integrated into the kitchen unit that is positioned against the wall.\nObjects: [oven]"
      },
      {
        "from": "gpt",
        "value": "oven: [0.344, 0.328, 0.609, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000290768_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel oven is at the center, integrated into the kitchen unit that is positioned against the wall."
      },
      {
        "from": "gpt",
        "value": "stainless steel oven: [0.344, 0.328, 0.609, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000290768_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel oven is at the center, integrated into the kitchen unit that is positioned against the wall.\nObjects: [stainless steel oven]"
      },
      {
        "from": "gpt",
        "value": "stainless steel oven: [0.344, 0.328, 0.609, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000290768_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: oven: [0.344, 0.328, 0.609, 0.977]\nGiven the above layout, shift the oven to the right by 0.031."
      },
      {
        "from": "gpt",
        "value": "oven: [0.375, 0.328, 0.641, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000291551",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a skateboard at the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.391, 0.172, 0.797, 0.641]\nskateboard: [0.516, 0.609, 0.766, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000291551_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a skateboard at the center of the image.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.391, 0.172, 0.797, 0.641]\nskateboard: [0.516, 0.609, 0.766, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000291551_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a person is standing on a skateboard at the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.391, 0.172, 0.797, 0.641]\nskateboard: [0.516, 0.609, 0.766, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000291551_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a person is standing on a skateboard at the center of the image.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.391, 0.172, 0.797, 0.641]\nskateboard: [0.516, 0.609, 0.766, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000291551_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.391, 0.172, 0.797, 0.641]\nskateboard: [0.516, 0.609, 0.766, 0.867]\nGiven the above layout, shift the person to the left by 0.344."
      },
      {
        "from": "gpt",
        "value": "person: [0.047, 0.172, 0.453, 0.641]\nskateboard: [0.516, 0.609, 0.766, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000291861",
    "conversations": [
      {
        "from": "human",
        "value": "The zebra is in the center, standing behind a rock, facing to the left."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.148, 0.289, 0.984, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000291861_key",
    "conversations": [
      {
        "from": "human",
        "value": "The zebra is in the center, standing behind a rock, facing to the left.\nObjects: [zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.148, 0.289, 0.984, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000291861_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the white stallion is in the center, standing behind a rock, facing to the left."
      },
      {
        "from": "gpt",
        "value": "white stallion: [0.148, 0.289, 0.984, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000291861_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the white stallion is in the center, standing behind a rock, facing to the left.\nObjects: [white stallion]"
      },
      {
        "from": "gpt",
        "value": "white stallion: [0.148, 0.289, 0.984, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000291861_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: zebra: [0.148, 0.289, 0.984, 0.828]\nGiven the above layout, shift the zebra upwards by 0.102."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.148, 0.188, 0.984, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000292060",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is to the left, the sink is at the center, and the refrigerator is to the right."
      },
      {
        "from": "gpt",
        "value": "oven: [0.164, 0.547, 0.430, 0.992]\nrefrigerator: [0.781, 0.352, 0.828, 0.977]\nsink: [0.430, 0.594, 0.703, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000292060_key",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is to the left, the sink is at the center, and the refrigerator is to the right.\nObjects: [oven, refrigerator, sink]"
      },
      {
        "from": "gpt",
        "value": "oven: [0.164, 0.547, 0.430, 0.992]\nrefrigerator: [0.781, 0.352, 0.828, 0.977]\nsink: [0.430, 0.594, 0.703, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000292060_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel double oven is to the left, the square kitchen sink is at the center, and the large white refrigerator is to the right."
      },
      {
        "from": "gpt",
        "value": "stainless steel double oven: [0.164, 0.547, 0.430, 0.992]\nlarge white refrigerator: [0.781, 0.352, 0.828, 0.977]\nsquare kitchen sink: [0.430, 0.594, 0.703, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000292060_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel double oven is to the left, the square kitchen sink is at the center, and the large white refrigerator is to the right.\nObjects: [stainless steel double oven, large white refrigerator, square kitchen sink]"
      },
      {
        "from": "gpt",
        "value": "stainless steel double oven: [0.164, 0.547, 0.430, 0.992]\nlarge white refrigerator: [0.781, 0.352, 0.828, 0.977]\nsquare kitchen sink: [0.430, 0.594, 0.703, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000292060_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: oven: [0.164, 0.547, 0.430, 0.992]\nrefrigerator: [0.781, 0.352, 0.828, 0.977]\nsink: [0.430, 0.594, 0.703, 0.641]\nGiven the above layout, shift the refrigerator upwards by 0.141."
      },
      {
        "from": "gpt",
        "value": "oven: [0.164, 0.547, 0.430, 0.992]\nrefrigerator: [0.781, 0.211, 0.828, 0.836]\nsink: [0.430, 0.594, 0.703, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000320554",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is lying on the ground underneath the right side of a bench."
      },
      {
        "from": "gpt",
        "value": "bench: [0.078, 0.125, 0.961, 0.680]\ncat: [0.445, 0.516, 0.688, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000320554_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is lying on the ground underneath the right side of a bench.\nObjects: [bench, cat]"
      },
      {
        "from": "gpt",
        "value": "bench: [0.078, 0.125, 0.961, 0.680]\ncat: [0.445, 0.516, 0.688, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000320554_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a striped feline is lying on the ground underneath the right side of a wooden park bench."
      },
      {
        "from": "gpt",
        "value": "wooden park bench: [0.078, 0.125, 0.961, 0.680]\nstriped feline: [0.445, 0.516, 0.688, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000320554_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a striped feline is lying on the ground underneath the right side of a wooden park bench.\nObjects: [wooden park bench, striped feline]"
      },
      {
        "from": "gpt",
        "value": "wooden park bench: [0.078, 0.125, 0.961, 0.680]\nstriped feline: [0.445, 0.516, 0.688, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000320554_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bench: [0.078, 0.125, 0.961, 0.680]\ncat: [0.445, 0.516, 0.688, 0.711]\nGiven the above layout, shift the cat downwards by 0.016."
      },
      {
        "from": "gpt",
        "value": "bench: [0.078, 0.125, 0.961, 0.680]\ncat: [0.445, 0.531, 0.688, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000321557",
    "conversations": [
      {
        "from": "human",
        "value": "The motorcycle is positioned at a diagonal angle, facing to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.086, 0.039, 0.883, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000321557_key",
    "conversations": [
      {
        "from": "human",
        "value": "The motorcycle is positioned at a diagonal angle, facing to the right side of the image.\nObjects: [motorcycle]"
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.086, 0.039, 0.883, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000321557_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the crimson red chopper is positioned at a diagonal angle, facing to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "crimson red chopper: [0.086, 0.039, 0.883, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000321557_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the crimson red chopper is positioned at a diagonal angle, facing to the right side of the image.\nObjects: [crimson red chopper]"
      },
      {
        "from": "gpt",
        "value": "crimson red chopper: [0.086, 0.039, 0.883, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000321557_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: motorcycle: [0.086, 0.039, 0.883, 0.977]\nGiven the above layout, shift the motorcycle to the right by 0.039."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.125, 0.039, 0.922, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000322829",
    "conversations": [
      {
        "from": "human",
        "value": "A white ornate bench is centered on a grass lawn with a hedge in the background."
      },
      {
        "from": "gpt",
        "value": "bench: [0.125, 0.242, 0.836, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000322829_key",
    "conversations": [
      {
        "from": "human",
        "value": "A white ornate bench is centered on a grass lawn with a hedge in the background.\nObjects: [bench]"
      },
      {
        "from": "gpt",
        "value": "bench: [0.125, 0.242, 0.836, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000322829_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a white ornate white painted Victorian style bench is centered on a grass lawn with a hedge in the background."
      },
      {
        "from": "gpt",
        "value": "white painted Victorian style bench: [0.125, 0.242, 0.836, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000322829_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a white ornate white painted Victorian style bench is centered on a grass lawn with a hedge in the background.\nObjects: [white painted Victorian style bench]"
      },
      {
        "from": "gpt",
        "value": "white painted Victorian style bench: [0.125, 0.242, 0.836, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000322829_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bench: [0.125, 0.242, 0.836, 0.688]\nGiven the above layout, shift the bench downwards by 0.156."
      },
      {
        "from": "gpt",
        "value": "bench: [0.125, 0.398, 0.836, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000324715",
    "conversations": [
      {
        "from": "human",
        "value": "A closed laptop on the left and scissors to the right on a wooden surface."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.062, 0.305, 0.633, 0.820]\nscissors: [0.688, 0.539, 0.953, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000324715_key",
    "conversations": [
      {
        "from": "human",
        "value": "A closed laptop on the left and scissors to the right on a wooden surface.\nObjects: [laptop, scissors]"
      },
      {
        "from": "gpt",
        "value": "laptop: [0.062, 0.305, 0.633, 0.820]\nscissors: [0.688, 0.539, 0.953, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000324715_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a closed silver MacBook on the left and stainless steel scissors to the right on a wooden surface."
      },
      {
        "from": "gpt",
        "value": "silver MacBook: [0.062, 0.305, 0.633, 0.820]\nstainless steel scissors: [0.688, 0.539, 0.953, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000324715_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a closed silver MacBook on the left and stainless steel scissors to the right on a wooden surface.\nObjects: [silver MacBook, stainless steel scissors]"
      },
      {
        "from": "gpt",
        "value": "silver MacBook: [0.062, 0.305, 0.633, 0.820]\nstainless steel scissors: [0.688, 0.539, 0.953, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000324715_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: laptop: [0.062, 0.305, 0.633, 0.820]\nscissors: [0.688, 0.539, 0.953, 0.766]\nGiven the above layout, shift the laptop upwards by 0.148."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.062, 0.156, 0.633, 0.672]\nscissors: [0.688, 0.539, 0.953, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000325991",
    "conversations": [
      {
        "from": "human",
        "value": "A person in a red shirt is standing in a grassy area, extending their right arm out to throw a frisbee."
      },
      {
        "from": "gpt",
        "value": "person: [0.289, 0.250, 0.680, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000325991_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in a red shirt is standing in a grassy area, extending their right arm out to throw a frisbee.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.289, 0.250, 0.680, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000325991_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a man in a red t-shirt in a red shirt is standing in a grassy area, extending their right arm out to throw a frisbee."
      },
      {
        "from": "gpt",
        "value": "man in a red t-shirt: [0.289, 0.250, 0.680, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000325991_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a man in a red t-shirt in a red shirt is standing in a grassy area, extending their right arm out to throw a frisbee.\nObjects: [man in a red t-shirt]"
      },
      {
        "from": "gpt",
        "value": "man in a red t-shirt: [0.289, 0.250, 0.680, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000325991_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.289, 0.250, 0.680, 0.828]\nGiven the above layout, shift the person to the right by 0.219."
      },
      {
        "from": "gpt",
        "value": "person: [0.508, 0.250, 0.898, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000326462",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a donut with their right hand in the foreground."
      },
      {
        "from": "gpt",
        "value": "donut: [0.156, 0.203, 0.695, 0.719]\nperson: [0.039, 0.648, 0.648, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000326462_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a donut with their right hand in the foreground.\nObjects: [donut, person]"
      },
      {
        "from": "gpt",
        "value": "donut: [0.156, 0.203, 0.695, 0.719]\nperson: [0.039, 0.648, 0.648, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000326462_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in a blue sweater is holding a frosted sprinkle donut with their right hand in the foreground."
      },
      {
        "from": "gpt",
        "value": "frosted sprinkle donut: [0.156, 0.203, 0.695, 0.719]\nwoman in a blue sweater: [0.039, 0.648, 0.648, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000326462_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in a blue sweater is holding a frosted sprinkle donut with their right hand in the foreground.\nObjects: [frosted sprinkle donut, woman in a blue sweater]"
      },
      {
        "from": "gpt",
        "value": "frosted sprinkle donut: [0.156, 0.203, 0.695, 0.719]\nwoman in a blue sweater: [0.039, 0.648, 0.648, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000326462_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: donut: [0.156, 0.203, 0.695, 0.719]\nperson: [0.039, 0.648, 0.648, 0.953]\nGiven the above layout, shift the donut to the right by 0.148."
      },
      {
        "from": "gpt",
        "value": "donut: [0.305, 0.203, 0.844, 0.719]\nperson: [0.039, 0.648, 0.648, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000327605",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on skis at the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.242, 0.180, 0.398, 0.711]\nskis: [0.070, 0.656, 0.594, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000327605_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on skis at the center of the image.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.242, 0.180, 0.398, 0.711]\nskis: [0.070, 0.656, 0.594, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000327605_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in a snowsuit is standing on pair of white skis at the center of the image."
      },
      {
        "from": "gpt",
        "value": "woman in a snowsuit: [0.242, 0.180, 0.398, 0.711]\npair of white skis: [0.070, 0.656, 0.594, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000327605_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in a snowsuit is standing on pair of white skis at the center of the image.\nObjects: [woman in a snowsuit, pair of white skis]"
      },
      {
        "from": "gpt",
        "value": "woman in a snowsuit: [0.242, 0.180, 0.398, 0.711]\npair of white skis: [0.070, 0.656, 0.594, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000327605_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.242, 0.180, 0.398, 0.711]\nskis: [0.070, 0.656, 0.594, 0.727]\nGiven the above layout, shift the skis to the right by 0.172."
      },
      {
        "from": "gpt",
        "value": "person: [0.242, 0.180, 0.398, 0.711]\nskis: [0.242, 0.656, 0.766, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000328959",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is in the foreground on the left side of the image with a wall-mounted handrail above and to the left of it."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.227, 0.547, 0.578, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000328959_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is in the foreground on the left side of the image with a wall-mounted handrail above and to the left of it.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.227, 0.547, 0.578, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000328959_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the white porcelain toilet is in the foreground on the left side of the image with a wall-mounted handrail above and to the left of it."
      },
      {
        "from": "gpt",
        "value": "white porcelain toilet: [0.227, 0.547, 0.578, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000328959_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the white porcelain toilet is in the foreground on the left side of the image with a wall-mounted handrail above and to the left of it.\nObjects: [white porcelain toilet]"
      },
      {
        "from": "gpt",
        "value": "white porcelain toilet: [0.227, 0.547, 0.578, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000328959_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.227, 0.547, 0.578, 0.992]\nGiven the above layout, shift the toilet upwards by 0.125."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.227, 0.422, 0.578, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000329219",
    "conversations": [
      {
        "from": "human",
        "value": "A person stands at the center by the counter, and a dog is in front of them on the floor."
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.172, 0.500, 0.680]\ndog: [0.461, 0.555, 0.555, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000329219_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person stands at the center by the counter, and a dog is in front of them on the floor.\nObjects: [person, dog]"
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.172, 0.500, 0.680]\ndog: [0.461, 0.555, 0.555, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000329219_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a middle-aged man stands at the center by the counter, and a small poodle is in front of them on the floor."
      },
      {
        "from": "gpt",
        "value": "middle-aged man: [0.273, 0.172, 0.500, 0.680]\nsmall poodle: [0.461, 0.555, 0.555, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000329219_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a middle-aged man stands at the center by the counter, and a small poodle is in front of them on the floor.\nObjects: [middle-aged man, small poodle]"
      },
      {
        "from": "gpt",
        "value": "middle-aged man: [0.273, 0.172, 0.500, 0.680]\nsmall poodle: [0.461, 0.555, 0.555, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000329219_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.273, 0.172, 0.500, 0.680]\ndog: [0.461, 0.555, 0.555, 0.727]\nGiven the above layout, shift the dog to the right by 0.305."
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.172, 0.500, 0.680]\ndog: [0.766, 0.555, 0.859, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000330369",
    "conversations": [
      {
        "from": "human",
        "value": "The boat is in the center of the image, facing towards the right."
      },
      {
        "from": "gpt",
        "value": "boat: [0.164, 0.172, 0.844, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000330369_key",
    "conversations": [
      {
        "from": "human",
        "value": "The boat is in the center of the image, facing towards the right.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.164, 0.172, 0.844, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000330369_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the traditional sailboat is in the center of the image, facing towards the right."
      },
      {
        "from": "gpt",
        "value": "traditional sailboat: [0.164, 0.172, 0.844, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000330369_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the traditional sailboat is in the center of the image, facing towards the right.\nObjects: [traditional sailboat]"
      },
      {
        "from": "gpt",
        "value": "traditional sailboat: [0.164, 0.172, 0.844, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000330369_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.164, 0.172, 0.844, 0.773]\nGiven the above layout, shift the boat downwards by 0.117."
      },
      {
        "from": "gpt",
        "value": "boat: [0.164, 0.289, 0.844, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000330396",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left of another person on a beach, both facing towards the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.477, 0.258, 0.648, 0.859]\nperson: [0.625, 0.281, 0.734, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000330396_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left of another person on a beach, both facing towards the right.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.477, 0.258, 0.648, 0.859]\nperson: [0.625, 0.281, 0.734, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000331075",
    "conversations": [
      {
        "from": "human",
        "value": "A wet dog standing at the center of the image on a sandy beach."
      },
      {
        "from": "gpt",
        "value": "dog: [0.008, 0.195, 0.844, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000331075_key",
    "conversations": [
      {
        "from": "human",
        "value": "A wet dog standing at the center of the image on a sandy beach.\nObjects: [dog]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.008, 0.195, 0.844, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000331075_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a wet soaked golden retriever standing at the center of the image on a sandy beach."
      },
      {
        "from": "gpt",
        "value": "soaked golden retriever: [0.008, 0.195, 0.844, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000331075_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a wet soaked golden retriever standing at the center of the image on a sandy beach.\nObjects: [soaked golden retriever]"
      },
      {
        "from": "gpt",
        "value": "soaked golden retriever: [0.008, 0.195, 0.844, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000331075_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.008, 0.195, 0.844, 0.969]\nGiven the above layout, shift the dog upwards by 0.078."
      },
      {
        "from": "gpt",
        "value": "dog: [0.008, 0.117, 0.844, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000331317",
    "conversations": [
      {
        "from": "human",
        "value": "An ornate golden clock is at the center, mounted on a glass-paneled wall."
      },
      {
        "from": "gpt",
        "value": "clock: [0.367, 0.539, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000331317_key",
    "conversations": [
      {
        "from": "human",
        "value": "An ornate golden clock is at the center, mounted on a glass-paneled wall.\nObjects: [clock]"
      },
      {
        "from": "gpt",
        "value": "clock: [0.367, 0.539, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000331317_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an ornate golden antique bronze wall clock is at the center, mounted on a glass-paneled wall."
      },
      {
        "from": "gpt",
        "value": "antique bronze wall clock: [0.367, 0.539, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000331317_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an ornate golden antique bronze wall clock is at the center, mounted on a glass-paneled wall.\nObjects: [antique bronze wall clock]"
      },
      {
        "from": "gpt",
        "value": "antique bronze wall clock: [0.367, 0.539, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000331317_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: clock: [0.367, 0.539, 0.992, 0.867]\nGiven the above layout, shift the clock upwards by 0.414."
      },
      {
        "from": "gpt",
        "value": "clock: [0.367, 0.125, 0.992, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000354547",
    "conversations": [
      {
        "from": "human",
        "value": "A person dressed in a light-colored suit standing with one hand in the pocket."
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.094, 0.586, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000354547_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person dressed in a light-colored suit standing with one hand in the pocket.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.094, 0.586, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000354547_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man in a beige suit dressed in a light-colored suit standing with one hand in the pocket."
      },
      {
        "from": "gpt",
        "value": "tall man in a beige suit: [0.312, 0.094, 0.586, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000354547_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man in a beige suit dressed in a light-colored suit standing with one hand in the pocket.\nObjects: [tall man in a beige suit]"
      },
      {
        "from": "gpt",
        "value": "tall man in a beige suit: [0.312, 0.094, 0.586, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000354547_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.312, 0.094, 0.586, 0.977]\nGiven the above layout, shift the person to the right by 0.398."
      },
      {
        "from": "gpt",
        "value": "person: [0.711, 0.094, 0.984, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000360393",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza is at the center, with a bowl to the left and another bowl to the right in the background."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.102, 0.266, 0.953, 0.758]\nbowl: [0.781, 0.570, 0.992, 0.828]\nbowl: [0.898, 0.164, 0.992, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000360393_key",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza is at the center, with a bowl to the left and another bowl to the right in the background.\nObjects: [pizza, bowl, bowl]"
      },
      {
        "from": "gpt",
        "value": "pizza: [0.102, 0.266, 0.953, 0.758]\nbowl: [0.781, 0.570, 0.992, 0.828]\nbowl: [0.898, 0.164, 0.992, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000361180",
    "conversations": [
      {
        "from": "human",
        "value": "A bear is positioned in the center facing forward with visible front paws resting on a rock ledge."
      },
      {
        "from": "gpt",
        "value": "bear: [0.266, 0.219, 0.711, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000361180_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bear is positioned in the center facing forward with visible front paws resting on a rock ledge.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.266, 0.219, 0.711, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000361180_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a silverback gorilla is positioned in the center facing forward with visible front paws resting on a rock ledge."
      },
      {
        "from": "gpt",
        "value": "silverback gorilla: [0.266, 0.219, 0.711, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000361180_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a silverback gorilla is positioned in the center facing forward with visible front paws resting on a rock ledge.\nObjects: [silverback gorilla]"
      },
      {
        "from": "gpt",
        "value": "silverback gorilla: [0.266, 0.219, 0.711, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000361180_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.266, 0.219, 0.711, 0.758]\nGiven the above layout, shift the bear to the right by 0.062."
      },
      {
        "from": "gpt",
        "value": "bear: [0.328, 0.219, 0.773, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000361571",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is at the center, facing to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "dog: [0.398, 0.180, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000361571_key",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is at the center, facing to the right side of the image.\nObjects: [dog]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.398, 0.180, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000361571_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a brown poodle is at the center, facing to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "brown poodle: [0.398, 0.180, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000361571_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a brown poodle is at the center, facing to the right side of the image.\nObjects: [brown poodle]"
      },
      {
        "from": "gpt",
        "value": "brown poodle: [0.398, 0.180, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000361571_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.398, 0.180, 0.992, 0.820]\nGiven the above layout, shift the dog to the left by 0.219."
      },
      {
        "from": "gpt",
        "value": "dog: [0.180, 0.180, 0.773, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000365095",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center, slightly to the right, running towards the right side."
      },
      {
        "from": "gpt",
        "value": "person: [0.547, 0.281, 0.828, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000365095_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center, slightly to the right, running towards the right side.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.547, 0.281, 0.828, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000365095_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a woman with dark hair is in the center, slightly to the right, running towards the right side."
      },
      {
        "from": "gpt",
        "value": "woman with dark hair: [0.547, 0.281, 0.828, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000365095_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a woman with dark hair is in the center, slightly to the right, running towards the right side.\nObjects: [woman with dark hair]"
      },
      {
        "from": "gpt",
        "value": "woman with dark hair: [0.547, 0.281, 0.828, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000365095_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.547, 0.281, 0.828, 0.586]\nGiven the above layout, shift the person to the left by 0.289."
      },
      {
        "from": "gpt",
        "value": "person: [0.258, 0.281, 0.539, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000365098",
    "conversations": [
      {
        "from": "human",
        "value": "The boat is floating on water to the right of the image, partially obscured by leaves in the foreground."
      },
      {
        "from": "gpt",
        "value": "boat: [0.062, 0.305, 0.992, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000365098_key",
    "conversations": [
      {
        "from": "human",
        "value": "The boat is floating on water to the right of the image, partially obscured by leaves in the foreground.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.062, 0.305, 0.992, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000365098_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the white sailboat is floating on water to the right of the image, partially obscured by leaves in the foreground."
      },
      {
        "from": "gpt",
        "value": "white sailboat: [0.062, 0.305, 0.992, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000365098_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the white sailboat is floating on water to the right of the image, partially obscured by leaves in the foreground.\nObjects: [white sailboat]"
      },
      {
        "from": "gpt",
        "value": "white sailboat: [0.062, 0.305, 0.992, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000365098_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.062, 0.305, 0.992, 0.773]\nGiven the above layout, shift the boat upwards by 0.133."
      },
      {
        "from": "gpt",
        "value": "boat: [0.062, 0.172, 0.992, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000365521",
    "conversations": [
      {
        "from": "human",
        "value": "A person is on a skateboard, sliding down a ramp."
      },
      {
        "from": "gpt",
        "value": "person: [0.500, 0.055, 0.789, 0.391]\nskateboard: [0.500, 0.375, 0.672, 0.430]"
      }
    ]
  },
  {
    "id": "coco_000000365521_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is on a skateboard, sliding down a ramp.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.500, 0.055, 0.789, 0.391]\nskateboard: [0.500, 0.375, 0.672, 0.430]"
      }
    ]
  },
  {
    "id": "coco_000000365521_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a person is on a skateboard, sliding down a ramp."
      },
      {
        "from": "gpt",
        "value": "person: [0.500, 0.055, 0.789, 0.391]\nskateboard: [0.500, 0.375, 0.672, 0.430]"
      }
    ]
  },
  {
    "id": "coco_000000365521_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a person is on a skateboard, sliding down a ramp.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.500, 0.055, 0.789, 0.391]\nskateboard: [0.500, 0.375, 0.672, 0.430]"
      }
    ]
  },
  {
    "id": "coco_000000365521_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.500, 0.055, 0.789, 0.391]\nskateboard: [0.500, 0.375, 0.672, 0.430]\nGiven the above layout, shift the skateboard downwards by 0.352."
      },
      {
        "from": "gpt",
        "value": "person: [0.500, 0.055, 0.789, 0.391]\nskateboard: [0.500, 0.727, 0.672, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000365655",
    "conversations": [
      {
        "from": "human",
        "value": "A red and white bus parked on the left side of the image, with mountain scenery in the background."
      },
      {
        "from": "gpt",
        "value": "bus: [0.070, 0.414, 0.711, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000365655_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red and white bus parked on the left side of the image, with mountain scenery in the background.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.070, 0.414, 0.711, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000365655_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red and white bicolor school bus parked on the left side of the image, with mountain scenery in the background."
      },
      {
        "from": "gpt",
        "value": "bicolor school bus: [0.070, 0.414, 0.711, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000365655_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red and white bicolor school bus parked on the left side of the image, with mountain scenery in the background.\nObjects: [bicolor school bus]"
      },
      {
        "from": "gpt",
        "value": "bicolor school bus: [0.070, 0.414, 0.711, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000365655_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.070, 0.414, 0.711, 0.656]\nGiven the above layout, shift the bus upwards by 0.281."
      },
      {
        "from": "gpt",
        "value": "bus: [0.070, 0.133, 0.711, 0.375]"
      }
    ]
  },
  {
    "id": "coco_000000366711",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing behind a fruit stand, slicing an orange."
      },
      {
        "from": "gpt",
        "value": "person: [0.211, 0.156, 0.539, 0.508]"
      }
    ]
  },
  {
    "id": "coco_000000366711_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing behind a fruit stand, slicing an orange.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.211, 0.156, 0.539, 0.508]"
      }
    ]
  },
  {
    "id": "coco_000000366711_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a fruit vendor is standing behind a fruit stand, slicing an orange."
      },
      {
        "from": "gpt",
        "value": "fruit vendor: [0.211, 0.156, 0.539, 0.508]"
      }
    ]
  },
  {
    "id": "coco_000000366711_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a fruit vendor is standing behind a fruit stand, slicing an orange.\nObjects: [fruit vendor]"
      },
      {
        "from": "gpt",
        "value": "fruit vendor: [0.211, 0.156, 0.539, 0.508]"
      }
    ]
  },
  {
    "id": "coco_000000366711_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.211, 0.156, 0.539, 0.508]\nGiven the above layout, shift the person downwards by 0.195."
      },
      {
        "from": "gpt",
        "value": "person: [0.211, 0.352, 0.539, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000368038",
    "conversations": [
      {
        "from": "human",
        "value": "A train with colorful cars arranged in a line from left to right on the tracks."
      },
      {
        "from": "gpt",
        "value": "train: [0.109, 0.273, 0.984, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000368038_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train with colorful cars arranged in a line from left to right on the tracks.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.109, 0.273, 0.984, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000368038_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a vintage steam engine with colorful cars arranged in a line from left to right on the tracks."
      },
      {
        "from": "gpt",
        "value": "vintage steam engine: [0.109, 0.273, 0.984, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000368038_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a vintage steam engine with colorful cars arranged in a line from left to right on the tracks.\nObjects: [vintage steam engine]"
      },
      {
        "from": "gpt",
        "value": "vintage steam engine: [0.109, 0.273, 0.984, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000368038_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.109, 0.273, 0.984, 0.719]\nGiven the above layout, shift the train upwards by 0.164."
      },
      {
        "from": "gpt",
        "value": "train: [0.109, 0.109, 0.984, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000368940",
    "conversations": [
      {
        "from": "human",
        "value": "The sink is at the center against the wall."
      },
      {
        "from": "gpt",
        "value": "sink: [0.000, 0.273, 0.516, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000368940_key",
    "conversations": [
      {
        "from": "human",
        "value": "The sink is at the center against the wall.\nObjects: [sink]"
      },
      {
        "from": "gpt",
        "value": "sink: [0.000, 0.273, 0.516, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000368940_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel basin is at the center against the wall."
      },
      {
        "from": "gpt",
        "value": "stainless steel basin: [0.000, 0.273, 0.516, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000368940_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel basin is at the center against the wall.\nObjects: [stainless steel basin]"
      },
      {
        "from": "gpt",
        "value": "stainless steel basin: [0.000, 0.273, 0.516, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000368940_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sink: [0.000, 0.273, 0.516, 0.523]\nGiven the above layout, shift the sink to the right by 0.461."
      },
      {
        "from": "gpt",
        "value": "sink: [0.461, 0.273, 0.977, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000368982",
    "conversations": [
      {
        "from": "human",
        "value": "The scissors are at the center of the image on a wooden surface, handles to the left."
      },
      {
        "from": "gpt",
        "value": "scissors: [0.023, 0.406, 0.844, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000368982_key",
    "conversations": [
      {
        "from": "human",
        "value": "The scissors are at the center of the image on a wooden surface, handles to the left.\nObjects: [scissors]"
      },
      {
        "from": "gpt",
        "value": "scissors: [0.023, 0.406, 0.844, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000368982_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel scissors are at the center of the image on a wooden surface, handles to the left."
      },
      {
        "from": "gpt",
        "value": "stainless steel scissors: [0.023, 0.406, 0.844, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000368982_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel scissors are at the center of the image on a wooden surface, handles to the left.\nObjects: [stainless steel scissors]"
      },
      {
        "from": "gpt",
        "value": "stainless steel scissors: [0.023, 0.406, 0.844, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000368982_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: scissors: [0.023, 0.406, 0.844, 0.805]\nGiven the above layout, shift the scissors upwards by 0.016."
      },
      {
        "from": "gpt",
        "value": "scissors: [0.023, 0.391, 0.844, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000369081",
    "conversations": [
      {
        "from": "human",
        "value": "Two horses are standing close together on the left, while a third horse is apart to the right, all facing the left side of the image."
      },
      {
        "from": "gpt",
        "value": "horse: [0.180, 0.438, 0.391, 0.750]\nhorse: [0.398, 0.430, 0.562, 0.734]\nhorse: [0.734, 0.461, 0.828, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000369081_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two horses are standing close together on the left, while a third horse is apart to the right, all facing the left side of the image.\nObjects: [horse, horse, horse]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.180, 0.438, 0.391, 0.750]\nhorse: [0.398, 0.430, 0.562, 0.734]\nhorse: [0.734, 0.461, 0.828, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000394328",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center of the image against a red wall."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.367, 0.578, 0.680, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000394328_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center of the image against a red wall.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.367, 0.578, 0.680, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000394328_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the white ceramic toilet is at the center of the image against a red wall."
      },
      {
        "from": "gpt",
        "value": "white ceramic toilet: [0.367, 0.578, 0.680, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000394328_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the white ceramic toilet is at the center of the image against a red wall.\nObjects: [white ceramic toilet]"
      },
      {
        "from": "gpt",
        "value": "white ceramic toilet: [0.367, 0.578, 0.680, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000394328_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.367, 0.578, 0.680, 0.977]\nGiven the above layout, shift the toilet upwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.367, 0.555, 0.680, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000407960",
    "conversations": [
      {
        "from": "human",
        "value": "A cat sitting on the floor to the left of an oven."
      },
      {
        "from": "gpt",
        "value": "oven: [0.578, 0.164, 0.992, 0.820]\ncat: [0.086, 0.414, 0.547, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000407960_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat sitting on the floor to the left of an oven.\nObjects: [oven, cat]"
      },
      {
        "from": "gpt",
        "value": "oven: [0.578, 0.164, 0.992, 0.820]\ncat: [0.086, 0.414, 0.547, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000409268",
    "conversations": [
      {
        "from": "human",
        "value": "A teddy bear is lying on its back at the center of the image."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.164, 0.023, 0.781, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000409268_key",
    "conversations": [
      {
        "from": "human",
        "value": "A teddy bear is lying on its back at the center of the image.\nObjects: [teddy bear]"
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.164, 0.023, 0.781, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000409268_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a fluffy stuffed bunny is lying on its back at the center of the image."
      },
      {
        "from": "gpt",
        "value": "fluffy stuffed bunny: [0.164, 0.023, 0.781, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000409268_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a fluffy stuffed bunny is lying on its back at the center of the image.\nObjects: [fluffy stuffed bunny]"
      },
      {
        "from": "gpt",
        "value": "fluffy stuffed bunny: [0.164, 0.023, 0.781, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000409268_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: teddy bear: [0.164, 0.023, 0.781, 0.953]\nGiven the above layout, shift the teddy bear to the right by 0.102."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.266, 0.023, 0.883, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000409630",
    "conversations": [
      {
        "from": "human",
        "value": "A keyboard is in front of a laptop's keyboard, and a mouse is to the right of the external keyboard."
      },
      {
        "from": "gpt",
        "value": "keyboard: [0.055, 0.398, 0.766, 0.695]\nkeyboard: [0.102, 0.125, 0.789, 0.367]\nmouse: [0.766, 0.414, 0.930, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000409630_key",
    "conversations": [
      {
        "from": "human",
        "value": "A keyboard is in front of a laptops keyboard, and a mouse is to the right of the external keyboard.\nObjects: [keyboard, keyboard, mouse]"
      },
      {
        "from": "gpt",
        "value": "keyboard: [0.055, 0.398, 0.766, 0.695]\nkeyboard: [0.102, 0.125, 0.789, 0.367]\nmouse: [0.766, 0.414, 0.930, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000416269",
    "conversations": [
      {
        "from": "human",
        "value": "The train is at the center of the image, positioned horizontally on the tracks."
      },
      {
        "from": "gpt",
        "value": "train: [0.086, 0.328, 0.852, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000416269_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is at the center of the image, positioned horizontally on the tracks.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.086, 0.328, 0.852, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000416269_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the vintage steam locomotive is at the center of the image, positioned horizontally on the tracks."
      },
      {
        "from": "gpt",
        "value": "vintage steam locomotive: [0.086, 0.328, 0.852, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000416269_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the vintage steam locomotive is at the center of the image, positioned horizontally on the tracks.\nObjects: [vintage steam locomotive]"
      },
      {
        "from": "gpt",
        "value": "vintage steam locomotive: [0.086, 0.328, 0.852, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000416269_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.086, 0.328, 0.852, 0.680]\nGiven the above layout, shift the train upwards by 0.117."
      },
      {
        "from": "gpt",
        "value": "train: [0.086, 0.211, 0.852, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000417043",
    "conversations": [
      {
        "from": "human",
        "value": "The bench is on the left side of the image, facing a pathway that extends to the right."
      },
      {
        "from": "gpt",
        "value": "bench: [0.000, 0.469, 0.391, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000417043_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bench is on the left side of the image, facing a pathway that extends to the right.\nObjects: [bench]"
      },
      {
        "from": "gpt",
        "value": "bench: [0.000, 0.469, 0.391, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000417043_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the wooden park bench is on the left side of the image, facing a pathway that extends to the right."
      },
      {
        "from": "gpt",
        "value": "wooden park bench: [0.000, 0.469, 0.391, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000417043_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the wooden park bench is on the left side of the image, facing a pathway that extends to the right.\nObjects: [wooden park bench]"
      },
      {
        "from": "gpt",
        "value": "wooden park bench: [0.000, 0.469, 0.391, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000417043_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bench: [0.000, 0.469, 0.391, 0.859]\nGiven the above layout, shift the bench to the right by 0.398."
      },
      {
        "from": "gpt",
        "value": "bench: [0.398, 0.469, 0.789, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000417249",
    "conversations": [
      {
        "from": "human",
        "value": "In the image, one person is to the left moving away, one person is in the center facing away, and another person is to the right side, also facing away."
      },
      {
        "from": "gpt",
        "value": "person: [0.625, 0.336, 0.852, 0.844]\nperson: [0.406, 0.391, 0.609, 0.766]\nperson: [0.133, 0.328, 0.312, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000417249_key",
    "conversations": [
      {
        "from": "human",
        "value": "In the image, one person is to the left moving away, one person is in the center facing away, and another person is to the right side, also facing away.\nObjects: [person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.625, 0.336, 0.852, 0.844]\nperson: [0.406, 0.391, 0.609, 0.766]\nperson: [0.133, 0.328, 0.312, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000417465",
    "conversations": [
      {
        "from": "human",
        "value": "A bear is lying on a flat surface with its head raised and mouth open."
      },
      {
        "from": "gpt",
        "value": "bear: [0.094, 0.195, 0.906, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000417465_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bear is lying on a flat surface with its head raised and mouth open.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.094, 0.195, 0.906, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000417465_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a grizzly bear is lying on a flat surface with its head raised and mouth open."
      },
      {
        "from": "gpt",
        "value": "grizzly bear: [0.094, 0.195, 0.906, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000417465_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a grizzly bear is lying on a flat surface with its head raised and mouth open.\nObjects: [grizzly bear]"
      },
      {
        "from": "gpt",
        "value": "grizzly bear: [0.094, 0.195, 0.906, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000417465_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.094, 0.195, 0.906, 0.812]\nGiven the above layout, shift the bear upwards by 0.031."
      },
      {
        "from": "gpt",
        "value": "bear: [0.094, 0.164, 0.906, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000423519",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is on the right side of the image, oriented diagonally and facing towards the left side of the frame."
      },
      {
        "from": "gpt",
        "value": "bus: [0.164, 0.352, 0.836, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000423519_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is on the right side of the image, oriented diagonally and facing towards the left side of the frame.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.164, 0.352, 0.836, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000423519_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker bus is on the right side of the image, oriented diagonally and facing towards the left side of the frame."
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.164, 0.352, 0.836, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000423519_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker bus is on the right side of the image, oriented diagonally and facing towards the left side of the frame.\nObjects: [double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.164, 0.352, 0.836, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000423519_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.164, 0.352, 0.836, 0.820]\nGiven the above layout, shift the bus upwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "bus: [0.164, 0.328, 0.836, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000426268",
    "conversations": [
      {
        "from": "human",
        "value": "A black and red train on display on rails, positioned at an angle with the front facing to the left of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.016, 0.234, 0.930, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000426268_key",
    "conversations": [
      {
        "from": "human",
        "value": "A black and red train on display on rails, positioned at an angle with the front facing to the left of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.016, 0.234, 0.930, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000426268_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a black and red black and red steam engine on display on rails, positioned at an angle with the front facing to the left of the image."
      },
      {
        "from": "gpt",
        "value": "black and red steam engine: [0.016, 0.234, 0.930, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000426268_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a black and red black and red steam engine on display on rails, positioned at an angle with the front facing to the left of the image.\nObjects: [black and red steam engine]"
      },
      {
        "from": "gpt",
        "value": "black and red steam engine: [0.016, 0.234, 0.930, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000426268_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.016, 0.234, 0.930, 0.594]\nGiven the above layout, shift the train downwards by 0.359."
      },
      {
        "from": "gpt",
        "value": "train: [0.016, 0.594, 0.930, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000426297",
    "conversations": [
      {
        "from": "human",
        "value": "The zebra is at the center facing left, with only the head and part of its body visible."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.195, 0.195, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000426297_key",
    "conversations": [
      {
        "from": "human",
        "value": "The zebra is at the center facing left, with only the head and part of its body visible.\nObjects: [zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.195, 0.195, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000426297_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the black and white-striped gelding is at the center facing left, with only the head and part of its body visible."
      },
      {
        "from": "gpt",
        "value": "black and white-striped gelding: [0.195, 0.195, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000426297_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the black and white-striped gelding is at the center facing left, with only the head and part of its body visible.\nObjects: [black and white-striped gelding]"
      },
      {
        "from": "gpt",
        "value": "black and white-striped gelding: [0.195, 0.195, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000426297_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: zebra: [0.195, 0.195, 0.992, 0.820]\nGiven the above layout, shift the zebra to the left by 0.047."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.148, 0.195, 0.945, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000426795",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on a chair."
      },
      {
        "from": "gpt",
        "value": "person: [0.086, 0.156, 0.727, 0.859]\nchair: [0.586, 0.602, 0.898, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000426795_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on a chair.\nObjects: [person, chair]"
      },
      {
        "from": "gpt",
        "value": "person: [0.086, 0.156, 0.727, 0.859]\nchair: [0.586, 0.602, 0.898, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000426795_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a man in a business suit is sitting on a red leather chair."
      },
      {
        "from": "gpt",
        "value": "a man in a business suit: [0.086, 0.156, 0.727, 0.859]\nred leather chair: [0.586, 0.602, 0.898, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000426795_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a man in a business suit is sitting on a red leather chair.\nObjects: [a man in a business suit, red leather chair]"
      },
      {
        "from": "gpt",
        "value": "a man in a business suit: [0.086, 0.156, 0.727, 0.859]\nred leather chair: [0.586, 0.602, 0.898, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000426795_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.086, 0.156, 0.727, 0.859]\nchair: [0.586, 0.602, 0.898, 0.859]\nGiven the above layout, shift the person upwards by 0.078."
      },
      {
        "from": "gpt",
        "value": "person: [0.086, 0.078, 0.727, 0.781]\nchair: [0.586, 0.602, 0.898, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000427500",
    "conversations": [
      {
        "from": "human",
        "value": "A fire hydrant is on the right side of the image, in the foreground, and a car is visible in the background on the left side."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.430, 0.461, 0.695, 0.711]\ncar: [0.164, 0.008, 0.234, 0.211]"
      }
    ]
  },
  {
    "id": "coco_000000427500_key",
    "conversations": [
      {
        "from": "human",
        "value": "A fire hydrant is on the right side of the image, in the foreground, and a car is visible in the background on the left side.\nObjects: [fire hydrant, car]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.430, 0.461, 0.695, 0.711]\ncar: [0.164, 0.008, 0.234, 0.211]"
      }
    ]
  },
  {
    "id": "coco_000000427655",
    "conversations": [
      {
        "from": "human",
        "value": "A horse is harnessed to a carriage at the center of the image, facing to the right."
      },
      {
        "from": "gpt",
        "value": "horse: [0.242, 0.359, 0.570, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000427655_key",
    "conversations": [
      {
        "from": "human",
        "value": "A horse is harnessed to a carriage at the center of the image, facing to the right.\nObjects: [horse]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.242, 0.359, 0.570, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000427655_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a brown mare is harnessed to a carriage at the center of the image, facing to the right."
      },
      {
        "from": "gpt",
        "value": "brown mare: [0.242, 0.359, 0.570, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000427655_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a brown mare is harnessed to a carriage at the center of the image, facing to the right.\nObjects: [brown mare]"
      },
      {
        "from": "gpt",
        "value": "brown mare: [0.242, 0.359, 0.570, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000427655_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: horse: [0.242, 0.359, 0.570, 0.945]\nGiven the above layout, shift the horse to the right by 0.219."
      },
      {
        "from": "gpt",
        "value": "horse: [0.461, 0.359, 0.789, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000442463",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a skateboard in the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.445, 0.375, 0.711, 0.727]\nskateboard: [0.461, 0.695, 0.703, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000442463_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a skateboard in the center of the image.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.445, 0.375, 0.711, 0.727]\nskateboard: [0.461, 0.695, 0.703, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000442463_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young teen boy is standing on a red and black skateboard in the center of the image."
      },
      {
        "from": "gpt",
        "value": "young teen boy: [0.445, 0.375, 0.711, 0.727]\nred and black skateboard: [0.461, 0.695, 0.703, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000442463_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young teen boy is standing on a red and black skateboard in the center of the image.\nObjects: [young teen boy, red and black skateboard]"
      },
      {
        "from": "gpt",
        "value": "young teen boy: [0.445, 0.375, 0.711, 0.727]\nred and black skateboard: [0.461, 0.695, 0.703, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000442463_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.445, 0.375, 0.711, 0.727]\nskateboard: [0.461, 0.695, 0.703, 0.758]\nGiven the above layout, shift the person to the left by 0.031."
      },
      {
        "from": "gpt",
        "value": "person: [0.414, 0.375, 0.680, 0.727]\nskateboard: [0.461, 0.695, 0.703, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000452122",
    "conversations": [
      {
        "from": "human",
        "value": "Airplane flying towards the right in the sky."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.125, 0.367, 0.844, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000452122_key",
    "conversations": [
      {
        "from": "human",
        "value": "Airplane flying towards the right in the sky.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.125, 0.367, 0.844, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000452122_aug",
    "conversations": [
      {
        "from": "human",
        "value": "large passenger jet flying towards the right in the sky."
      },
      {
        "from": "gpt",
        "value": "large passenger jet: [0.125, 0.367, 0.844, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000452122_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "large passenger jet flying towards the right in the sky.\nObjects: [large passenger jet]"
      },
      {
        "from": "gpt",
        "value": "large passenger jet: [0.125, 0.367, 0.844, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000452122_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.125, 0.367, 0.844, 0.586]\nGiven the above layout, shift the airplane downwards by 0.406."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.125, 0.773, 0.844, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000456559",
    "conversations": [
      {
        "from": "human",
        "value": "A person is wearing a tie at the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.219, 0.133, 0.992, 0.867]\ntie: [0.492, 0.695, 0.664, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000456559_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is wearing a tie at the center of the image.\nObjects: [person, tie]"
      },
      {
        "from": "gpt",
        "value": "person: [0.219, 0.133, 0.992, 0.867]\ntie: [0.492, 0.695, 0.664, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000456559_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a businessman in a suit is wearing a navy blue tie at the center of the image."
      },
      {
        "from": "gpt",
        "value": "businessman in a suit: [0.219, 0.133, 0.992, 0.867]\nnavy blue tie: [0.492, 0.695, 0.664, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000456559_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a businessman in a suit is wearing a navy blue tie at the center of the image.\nObjects: [businessman in a suit, navy blue tie]"
      },
      {
        "from": "gpt",
        "value": "businessman in a suit: [0.219, 0.133, 0.992, 0.867]\nnavy blue tie: [0.492, 0.695, 0.664, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000456559_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.219, 0.133, 0.992, 0.867]\ntie: [0.492, 0.695, 0.664, 0.867]\nGiven the above layout, shift the person to the left by 0.156."
      },
      {
        "from": "gpt",
        "value": "person: [0.062, 0.133, 0.836, 0.867]\ntie: [0.492, 0.695, 0.664, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000463037",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is at the center of the image, positioned on the ground facing to the left."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.000, 0.320, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000463037_key",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is at the center of the image, positioned on the ground facing to the left.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.000, 0.320, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000463037_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the silver commercial jet is at the center of the image, positioned on the ground facing to the left."
      },
      {
        "from": "gpt",
        "value": "silver commercial jet: [0.000, 0.320, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000463037_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the silver commercial jet is at the center of the image, positioned on the ground facing to the left.\nObjects: [silver commercial jet]"
      },
      {
        "from": "gpt",
        "value": "silver commercial jet: [0.000, 0.320, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000463037_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.000, 0.320, 0.992, 0.766]\nGiven the above layout, shift the airplane upwards by 0.047."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.000, 0.273, 0.992, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000466085",
    "conversations": [
      {
        "from": "human",
        "value": "The sink is on the lower right side of the image, in front of a wooden wall panel and next to a mirrored medicine cabinet."
      },
      {
        "from": "gpt",
        "value": "sink: [0.477, 0.617, 0.781, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000466085_key",
    "conversations": [
      {
        "from": "human",
        "value": "The sink is on the lower right side of the image, in front of a wooden wall panel and next to a mirrored medicine cabinet.\nObjects: [sink]"
      },
      {
        "from": "gpt",
        "value": "sink: [0.477, 0.617, 0.781, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000466085_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain sink is on the lower right side of the image, in front of a wooden wall panel and next to a mirrored medicine cabinet."
      },
      {
        "from": "gpt",
        "value": "porcelain sink: [0.477, 0.617, 0.781, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000466085_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain sink is on the lower right side of the image, in front of a wooden wall panel and next to a mirrored medicine cabinet.\nObjects: [porcelain sink]"
      },
      {
        "from": "gpt",
        "value": "porcelain sink: [0.477, 0.617, 0.781, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000466085_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sink: [0.477, 0.617, 0.781, 0.875]\nGiven the above layout, shift the sink upwards by 0.242."
      },
      {
        "from": "gpt",
        "value": "sink: [0.477, 0.375, 0.781, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000466567",
    "conversations": [
      {
        "from": "human",
        "value": "A donut hanging by a red ribbon in the center of the image, surrounded by green pine needles."
      },
      {
        "from": "gpt",
        "value": "donut: [0.289, 0.352, 0.680, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000466567_key",
    "conversations": [
      {
        "from": "human",
        "value": "A donut hanging by a red ribbon in the center of the image, surrounded by green pine needles.\nObjects: [donut]"
      },
      {
        "from": "gpt",
        "value": "donut: [0.289, 0.352, 0.680, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000466567_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a iced sugar cookie hanging by a red ribbon hanging by a red ribbon in the center of the image, surrounded by green pine needles."
      },
      {
        "from": "gpt",
        "value": "iced sugar cookie hanging by a red ribbon: [0.289, 0.352, 0.680, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000466567_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a iced sugar cookie hanging by a red ribbon hanging by a red ribbon in the center of the image, surrounded by green pine needles.\nObjects: [iced sugar cookie hanging by a red ribbon]"
      },
      {
        "from": "gpt",
        "value": "iced sugar cookie hanging by a red ribbon: [0.289, 0.352, 0.680, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000466567_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: donut: [0.289, 0.352, 0.680, 0.719]\nGiven the above layout, shift the donut upwards by 0.234."
      },
      {
        "from": "gpt",
        "value": "donut: [0.289, 0.117, 0.680, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000468245",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is at the center between two windows, slightly skewed to the right."
      },
      {
        "from": "gpt",
        "value": "bed: [0.102, 0.508, 0.836, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000468245_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is at the center between two windows, slightly skewed to the right.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.102, 0.508, 0.836, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000468245_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the oak wood double bed is at the center between two windows, slightly skewed to the right."
      },
      {
        "from": "gpt",
        "value": "oak wood double bed: [0.102, 0.508, 0.836, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000468245_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the oak wood double bed is at the center between two windows, slightly skewed to the right.\nObjects: [oak wood double bed]"
      },
      {
        "from": "gpt",
        "value": "oak wood double bed: [0.102, 0.508, 0.836, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000468245_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.102, 0.508, 0.836, 0.820]\nGiven the above layout, shift the bed upwards by 0.156."
      },
      {
        "from": "gpt",
        "value": "bed: [0.102, 0.352, 0.836, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000469246",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks to the right of the platform."
      },
      {
        "from": "gpt",
        "value": "train: [0.180, 0.172, 0.992, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000469246_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks to the right of the platform.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.180, 0.172, 0.992, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000469246_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the speeding bullet train is on the tracks to the right of the platform."
      },
      {
        "from": "gpt",
        "value": "speeding bullet train: [0.180, 0.172, 0.992, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000469246_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the speeding bullet train is on the tracks to the right of the platform.\nObjects: [speeding bullet train]"
      },
      {
        "from": "gpt",
        "value": "speeding bullet train: [0.180, 0.172, 0.992, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000469246_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.180, 0.172, 0.992, 0.812]\nGiven the above layout, shift the train to the left by 0.164."
      },
      {
        "from": "gpt",
        "value": "train: [0.016, 0.172, 0.828, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000469652",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe's head is at the center right, angled downward."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.000, 0.203, 0.891, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000469652_key",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffes head is at the center right, angled downward.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.000, 0.203, 0.891, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000469652_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the tall giraffe with patchy fur's head is at the center right, angled downward."
      },
      {
        "from": "gpt",
        "value": "tall giraffe with patchy fur: [0.000, 0.203, 0.891, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000469652_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the tall giraffe with patchy furs head is at the center right, angled downward.\nObjects: [tall giraffe with patchy fur]"
      },
      {
        "from": "gpt",
        "value": "tall giraffe with patchy fur: [0.000, 0.203, 0.891, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000469652_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.000, 0.203, 0.891, 0.836]\nGiven the above layout, shift the giraffe upwards by 0.195."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.000, 0.008, 0.891, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000472298",
    "conversations": [
      {
        "from": "human",
        "value": "A red and white boat is in the center of the image, moving to the right on the water."
      },
      {
        "from": "gpt",
        "value": "boat: [0.117, 0.523, 0.953, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000472298_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red and white boat is in the center of the image, moving to the right on the water.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.117, 0.523, 0.953, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000472298_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red and white blue and yellow kayak is in the center of the image, moving to the right on the water."
      },
      {
        "from": "gpt",
        "value": "blue and yellow kayak: [0.117, 0.523, 0.953, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000472298_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red and white blue and yellow kayak is in the center of the image, moving to the right on the water.\nObjects: [blue and yellow kayak]"
      },
      {
        "from": "gpt",
        "value": "blue and yellow kayak: [0.117, 0.523, 0.953, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000472298_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.117, 0.523, 0.953, 0.609]\nGiven the above layout, shift the boat upwards by 0.383."
      },
      {
        "from": "gpt",
        "value": "boat: [0.117, 0.141, 0.953, 0.227]"
      }
    ]
  },
  {
    "id": "coco_000000473237",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on a chair in the center, holding a slice of pizza."
      },
      {
        "from": "gpt",
        "value": "person: [0.078, 0.164, 0.961, 0.820]\nchair: [0.648, 0.445, 0.898, 0.703]\npizza: [0.195, 0.578, 0.547, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000473237_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on a chair in the center, holding a slice of pizza.\nObjects: [person, chair, pizza]"
      },
      {
        "from": "gpt",
        "value": "person: [0.078, 0.164, 0.961, 0.820]\nchair: [0.648, 0.445, 0.898, 0.703]\npizza: [0.195, 0.578, 0.547, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000474095",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on a toilet with a cigarette in their right hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.047, 0.719, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000474095_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on a toilet with a cigarette in their right hand.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.047, 0.719, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000474095_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a adult with a goatee is sitting on a toilet with a cigarette in their right hand."
      },
      {
        "from": "gpt",
        "value": "adult with a goatee: [0.273, 0.047, 0.719, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000474095_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a adult with a goatee is sitting on a toilet with a cigarette in their right hand.\nObjects: [adult with a goatee]"
      },
      {
        "from": "gpt",
        "value": "adult with a goatee: [0.273, 0.047, 0.719, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000474095_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.273, 0.047, 0.719, 0.984]\nGiven the above layout, shift the person to the left by 0.211."
      },
      {
        "from": "gpt",
        "value": "person: [0.062, 0.047, 0.508, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000475150",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe's head and neck are at the center, tilted slightly to the right."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.219, 0.234, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000475150_key",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffes head and neck are at the center, tilted slightly to the right.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.219, 0.234, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000475150_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the long-necked camelopard's head and neck are at the center, tilted slightly to the right."
      },
      {
        "from": "gpt",
        "value": "long-necked camelopard: [0.219, 0.234, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000475150_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the long-necked camelopards head and neck are at the center, tilted slightly to the right.\nObjects: [long-necked camelopard]"
      },
      {
        "from": "gpt",
        "value": "long-necked camelopard: [0.219, 0.234, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000475150_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.219, 0.234, 0.992, 0.820]\nGiven the above layout, shift the giraffe upwards by 0.133."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.219, 0.102, 0.992, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000475191",
    "conversations": [
      {
        "from": "human",
        "value": "A person at the center holding a tennis racket above the head preparing to serve."
      },
      {
        "from": "gpt",
        "value": "person: [0.281, 0.266, 0.648, 0.766]\ntennis racket: [0.594, 0.164, 0.648, 0.344]"
      }
    ]
  },
  {
    "id": "coco_000000475191_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person at the center holding a tennis racket above the head preparing to serve.\nObjects: [person, tennis racket]"
      },
      {
        "from": "gpt",
        "value": "person: [0.281, 0.266, 0.648, 0.766]\ntennis racket: [0.594, 0.164, 0.648, 0.344]"
      }
    ]
  },
  {
    "id": "coco_000000498857",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe is standing to the right, facing left towards a fence."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.312, 0.297, 0.656, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000498857_key",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe is standing to the right, facing left towards a fence.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.312, 0.297, 0.656, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000498857_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the tall ostrich is standing to the right, facing left towards a fence."
      },
      {
        "from": "gpt",
        "value": "tall ostrich: [0.312, 0.297, 0.656, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000498857_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the tall ostrich is standing to the right, facing left towards a fence.\nObjects: [tall ostrich]"
      },
      {
        "from": "gpt",
        "value": "tall ostrich: [0.312, 0.297, 0.656, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000498857_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.312, 0.297, 0.656, 0.758]\nGiven the above layout, shift the giraffe to the right by 0.250."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.562, 0.297, 0.906, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000500613",
    "conversations": [
      {
        "from": "human",
        "value": "The fire truck is positioned in the center of the image facing slightly to the left."
      },
      {
        "from": "gpt",
        "value": "truck: [0.250, 0.320, 0.812, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000500613_key",
    "conversations": [
      {
        "from": "human",
        "value": "The fire truck is positioned in the center of the image facing slightly to the left.\nObjects: [truck]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.250, 0.320, 0.812, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000500613_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the fire bright red fire engine is positioned in the center of the image facing slightly to the left."
      },
      {
        "from": "gpt",
        "value": "bright red fire engine: [0.250, 0.320, 0.812, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000500613_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the fire bright red fire engine is positioned in the center of the image facing slightly to the left.\nObjects: [bright red fire engine]"
      },
      {
        "from": "gpt",
        "value": "bright red fire engine: [0.250, 0.320, 0.812, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000500613_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.250, 0.320, 0.812, 0.734]\nGiven the above layout, shift the truck upwards by 0.109."
      },
      {
        "from": "gpt",
        "value": "truck: [0.250, 0.211, 0.812, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000502599",
    "conversations": [
      {
        "from": "human",
        "value": "Three airplanes are suspended in the air: one at the center with a prominent yellow color, one to its left with red and white stripes, and another partially visible to the right with a blue and orange color scheme."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.594, 0.164, 0.992, 0.820]\nairplane: [0.000, 0.312, 0.734, 0.641]\nairplane: [0.195, 0.617, 0.586, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000502599_key",
    "conversations": [
      {
        "from": "human",
        "value": "Three airplanes are suspended in the air: one at the center with a prominent yellow color, one to its left with red and white stripes, and another partially visible to the right with a blue and orange color scheme.\nObjects: [airplane, airplane, airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.594, 0.164, 0.992, 0.820]\nairplane: [0.000, 0.312, 0.734, 0.641]\nairplane: [0.195, 0.617, 0.586, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000504580",
    "conversations": [
      {
        "from": "human",
        "value": "One giraffe stands in the background to the left while another giraffe is in the foreground on the right."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.094, 0.328, 0.391, 0.711]\ngiraffe: [0.805, 0.453, 0.945, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000504580_key",
    "conversations": [
      {
        "from": "human",
        "value": "One giraffe stands in the background to the left while another giraffe is in the foreground on the right.\nObjects: [giraffe, giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.094, 0.328, 0.391, 0.711]\ngiraffe: [0.805, 0.453, 0.945, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000506178",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on the left side of the bed, while another person is on the right side of the bed."
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.180, 0.719, 0.984]\nbed: [0.133, 0.852, 0.367, 0.977]\nperson: [0.742, 0.195, 0.867, 0.422]"
      }
    ]
  },
  {
    "id": "coco_000000506178_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on the left side of the bed, while another person is on the right side of the bed.\nObjects: [person, bed, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.180, 0.719, 0.984]\nbed: [0.133, 0.852, 0.367, 0.977]\nperson: [0.742, 0.195, 0.867, 0.422]"
      }
    ]
  },
  {
    "id": "coco_000000509131",
    "conversations": [
      {
        "from": "human",
        "value": "A bunch of bananas hanging above a bowl of oranges on a table, with a potted plant to the left in the background."
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.008, 0.180, 0.383, 0.789]\norange: [0.258, 0.695, 0.664, 0.812]\nbanana: [0.664, 0.398, 0.742, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000509131_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bunch of bananas hanging above a bowl of oranges on a table, with a potted plant to the left in the background.\nObjects: [potted plant, orange, banana]"
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.008, 0.180, 0.383, 0.789]\norange: [0.258, 0.695, 0.664, 0.812]\nbanana: [0.664, 0.398, 0.742, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000509131_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a bunch of cluster of grapess hanging above a bowl of bunch of appless on a table, with a Fern in a ceramic pot to the left in the background."
      },
      {
        "from": "gpt",
        "value": "Fern in a ceramic pot: [0.008, 0.180, 0.383, 0.789]\nbunch of apples: [0.258, 0.695, 0.664, 0.812]\ncluster of grapes: [0.664, 0.398, 0.742, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000509131_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a bunch of cluster of grapess hanging above a bowl of bunch of appless on a table, with a Fern in a ceramic pot to the left in the background.\nObjects: [Fern in a ceramic pot, bunch of apples, cluster of grapes]"
      },
      {
        "from": "gpt",
        "value": "Fern in a ceramic pot: [0.008, 0.180, 0.383, 0.789]\nbunch of apples: [0.258, 0.695, 0.664, 0.812]\ncluster of grapes: [0.664, 0.398, 0.742, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000509131_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: potted plant: [0.008, 0.180, 0.383, 0.789]\norange: [0.258, 0.695, 0.664, 0.812]\nbanana: [0.664, 0.398, 0.742, 0.562]\nGiven the above layout, shift the banana to the right by 0.109."
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.008, 0.180, 0.383, 0.789]\norange: [0.258, 0.695, 0.664, 0.812]\nbanana: [0.773, 0.398, 0.852, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000509260",
    "conversations": [
      {
        "from": "human",
        "value": "The television is in the lower left side of the image, in front of a bookshelf."
      },
      {
        "from": "gpt",
        "value": "tv: [0.062, 0.523, 0.469, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000509260_key",
    "conversations": [
      {
        "from": "human",
        "value": "The television is in the lower left side of the image, in front of a bookshelf.\nObjects: [tv]"
      },
      {
        "from": "gpt",
        "value": "tv: [0.062, 0.523, 0.469, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000509260_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the television is in the lower left side of the image, in front of a bookshelf."
      },
      {
        "from": "gpt",
        "value": "flat screen television: [0.062, 0.523, 0.469, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000509260_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the television is in the lower left side of the image, in front of a bookshelf.\nObjects: [flat screen television]"
      },
      {
        "from": "gpt",
        "value": "flat screen television: [0.062, 0.523, 0.469, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000509260_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: tv: [0.062, 0.523, 0.469, 0.859]\nGiven the above layout, shift the tv upwards by 0.477."
      },
      {
        "from": "gpt",
        "value": "tv: [0.062, 0.047, 0.469, 0.383]"
      }
    ]
  },
  {
    "id": "coco_000000509403",
    "conversations": [
      {
        "from": "human",
        "value": "From left to right: a child (person) holding a frisbee, another child (person) further back in the grass, a dog in mid-air catching a frisbee, and an adult (person) facing the dog with one arm extended."
      },
      {
        "from": "gpt",
        "value": "person: [0.555, 0.258, 0.742, 0.742]\ndog: [0.797, 0.492, 0.914, 0.703]\nperson: [0.062, 0.414, 0.148, 0.617]\nperson: [0.273, 0.359, 0.328, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000509403_key",
    "conversations": [
      {
        "from": "human",
        "value": "From left to right: a child (person) holding a frisbee, another child (person) further back in the grass, a dog in mid-air catching a frisbee, and an adult (person) facing the dog with one arm extended.\nObjects: [person, dog, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.555, 0.258, 0.742, 0.742]\ndog: [0.797, 0.492, 0.914, 0.703]\nperson: [0.062, 0.414, 0.148, 0.617]\nperson: [0.273, 0.359, 0.328, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000509699",
    "conversations": [
      {
        "from": "human",
        "value": "A chair is in the foreground with a person sitting on it, and a TV is positioned across the room to the right."
      },
      {
        "from": "gpt",
        "value": "chair: [0.227, 0.398, 0.539, 0.758]\ntv: [0.602, 0.508, 0.742, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000509699_key",
    "conversations": [
      {
        "from": "human",
        "value": "A chair is in the foreground with a person sitting on it, and a TV is positioned across the room to the right.\nObjects: [chair, tv]"
      },
      {
        "from": "gpt",
        "value": "chair: [0.227, 0.398, 0.539, 0.758]\ntv: [0.602, 0.508, 0.742, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000509699_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a comfortable armchair is in the foreground with a person sitting on it, and a flat-screen TV is positioned across the room to the right."
      },
      {
        "from": "gpt",
        "value": "comfortable armchair: [0.227, 0.398, 0.539, 0.758]\nflat-screen TV: [0.602, 0.508, 0.742, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000509699_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a comfortable armchair is in the foreground with a person sitting on it, and a flat-screen TV is positioned across the room to the right.\nObjects: [comfortable armchair, flat-screen TV]"
      },
      {
        "from": "gpt",
        "value": "comfortable armchair: [0.227, 0.398, 0.539, 0.758]\nflat-screen TV: [0.602, 0.508, 0.742, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000509699_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: chair: [0.227, 0.398, 0.539, 0.758]\ntv: [0.602, 0.508, 0.742, 0.719]\nGiven the above layout, shift the chair upwards by 0.164."
      },
      {
        "from": "gpt",
        "value": "chair: [0.227, 0.234, 0.539, 0.594]\ntv: [0.602, 0.508, 0.742, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000511398",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is lying down on the sand."
      },
      {
        "from": "gpt",
        "value": "dog: [0.016, 0.234, 0.820, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000511398_key",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is lying down on the sand.\nObjects: [dog]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.016, 0.234, 0.820, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000511398_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a golden retriever puppy is lying down on the sand."
      },
      {
        "from": "gpt",
        "value": "golden retriever puppy: [0.016, 0.234, 0.820, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000511398_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a golden retriever puppy is lying down on the sand.\nObjects: [golden retriever puppy]"
      },
      {
        "from": "gpt",
        "value": "golden retriever puppy: [0.016, 0.234, 0.820, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000511398_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.016, 0.234, 0.820, 0.789]\nGiven the above layout, shift the dog upwards by 0.055."
      },
      {
        "from": "gpt",
        "value": "dog: [0.016, 0.180, 0.820, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000513524",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a surfboard in the water."
      },
      {
        "from": "gpt",
        "value": "person: [0.453, 0.188, 0.781, 0.688]\nsurfboard: [0.227, 0.625, 0.711, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000513524_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a surfboard in the water.\nObjects: [person, surfboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.453, 0.188, 0.781, 0.688]\nsurfboard: [0.227, 0.625, 0.711, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000513524_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a surfer with a wetsuit is standing on a red and white striped surfboard in the water."
      },
      {
        "from": "gpt",
        "value": "surfer with a wetsuit: [0.453, 0.188, 0.781, 0.688]\nred and white striped surfboard: [0.227, 0.625, 0.711, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000513524_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a surfer with a wetsuit is standing on a red and white striped surfboard in the water.\nObjects: [surfer with a wetsuit, red and white striped surfboard]"
      },
      {
        "from": "gpt",
        "value": "surfer with a wetsuit: [0.453, 0.188, 0.781, 0.688]\nred and white striped surfboard: [0.227, 0.625, 0.711, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000513524_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.453, 0.188, 0.781, 0.688]\nsurfboard: [0.227, 0.625, 0.711, 0.758]\nGiven the above layout, shift the surfboard downwards by 0.211."
      },
      {
        "from": "gpt",
        "value": "person: [0.453, 0.188, 0.781, 0.688]\nsurfboard: [0.227, 0.836, 0.711, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000514914",
    "conversations": [
      {
        "from": "human",
        "value": "The sink is at the center against the wall between a bathtub on the left and a shower cabin on the right."
      },
      {
        "from": "gpt",
        "value": "sink: [0.000, 0.633, 0.508, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000514914_key",
    "conversations": [
      {
        "from": "human",
        "value": "The sink is at the center against the wall between a bathtub on the left and a shower cabin on the right.\nObjects: [sink]"
      },
      {
        "from": "gpt",
        "value": "sink: [0.000, 0.633, 0.508, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000514914_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel sink is at the center against the wall between a bathtub on the left and a shower cabin on the right."
      },
      {
        "from": "gpt",
        "value": "stainless steel sink: [0.000, 0.633, 0.508, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000514914_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel sink is at the center against the wall between a bathtub on the left and a shower cabin on the right.\nObjects: [stainless steel sink]"
      },
      {
        "from": "gpt",
        "value": "stainless steel sink: [0.000, 0.633, 0.508, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000514914_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sink: [0.000, 0.633, 0.508, 0.773]\nGiven the above layout, shift the sink upwards by 0.148."
      },
      {
        "from": "gpt",
        "value": "sink: [0.000, 0.484, 0.508, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000537053",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe standing in the center of the image facing forward."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.375, 0.070, 0.719, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000537053_key",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe standing in the center of the image facing forward.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.375, 0.070, 0.719, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000537053_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a Atlanta's zoo giraffe standing in the center of the image facing forward."
      },
      {
        "from": "gpt",
        "value": "Atlanta's zoo giraffe: [0.375, 0.070, 0.719, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000537053_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a Atlantas zoo giraffe standing in the center of the image facing forward.\nObjects: [\"Atlantas zoo giraffe\"]"
      },
      {
        "from": "gpt",
        "value": "Atlanta's zoo giraffe: [0.375, 0.070, 0.719, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000537053_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.375, 0.070, 0.719, 0.938]\nGiven the above layout, shift the giraffe to the left by 0.289."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.086, 0.070, 0.430, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000546826",
    "conversations": [
      {
        "from": "human",
        "value": "The red handle of a pair of scissors is to the right of the image."
      },
      {
        "from": "gpt",
        "value": "scissors: [0.508, 0.125, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000546826_key",
    "conversations": [
      {
        "from": "human",
        "value": "The red handle of a pair of scissors is to the right of the image.\nObjects: [scissors]"
      },
      {
        "from": "gpt",
        "value": "scissors: [0.508, 0.125, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000546826_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red handle of a pair of blue handled kitchen shears is to the right of the image."
      },
      {
        "from": "gpt",
        "value": "blue handled kitchen shears: [0.508, 0.125, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000546826_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red handle of a pair of blue handled kitchen shears is to the right of the image.\nObjects: [blue handled kitchen shears]"
      },
      {
        "from": "gpt",
        "value": "blue handled kitchen shears: [0.508, 0.125, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000546826_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: scissors: [0.508, 0.125, 0.992, 0.867]\nGiven the above layout, shift the scissors to the left by 0.078."
      },
      {
        "from": "gpt",
        "value": "scissors: [0.430, 0.125, 0.914, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000550426",
    "conversations": [
      {
        "from": "human",
        "value": "The vase is at the center, with flowers in it, placed on a transparent surface."
      },
      {
        "from": "gpt",
        "value": "vase: [0.398, 0.500, 0.664, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000550426_key",
    "conversations": [
      {
        "from": "human",
        "value": "The vase is at the center, with flowers in it, placed on a transparent surface.\nObjects: [vase]"
      },
      {
        "from": "gpt",
        "value": "vase: [0.398, 0.500, 0.664, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000550426_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the ceramic vase with floral patterns is at the center, with flowers in it, placed on a transparent surface."
      },
      {
        "from": "gpt",
        "value": "ceramic vase with floral patterns: [0.398, 0.500, 0.664, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000550426_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the ceramic vase with floral patterns is at the center, with flowers in it, placed on a transparent surface.\nObjects: [ceramic vase with floral patterns]"
      },
      {
        "from": "gpt",
        "value": "ceramic vase with floral patterns: [0.398, 0.500, 0.664, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000550426_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: vase: [0.398, 0.500, 0.664, 0.969]\nGiven the above layout, shift the vase upwards by 0.031."
      },
      {
        "from": "gpt",
        "value": "vase: [0.398, 0.469, 0.664, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000550797",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center with a closed lid, positioned against a wall with a tiled floor."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.297, 0.336, 0.688, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000550797_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center with a closed lid, positioned against a wall with a tiled floor.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.297, 0.336, 0.688, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000550797_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain toilet is at the center with a closed lid, positioned against a wall with a tiled floor."
      },
      {
        "from": "gpt",
        "value": "porcelain toilet: [0.297, 0.336, 0.688, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000550797_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain toilet is at the center with a closed lid, positioned against a wall with a tiled floor.\nObjects: [porcelain toilet]"
      },
      {
        "from": "gpt",
        "value": "porcelain toilet: [0.297, 0.336, 0.688, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000550797_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.297, 0.336, 0.688, 0.938]\nGiven the above layout, shift the toilet upwards by 0.102."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.297, 0.234, 0.688, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000551780",
    "conversations": [
      {
        "from": "human",
        "value": "A round clock is mounted on a dark surface to the left of some partially visible white lettering."
      },
      {
        "from": "gpt",
        "value": "clock: [0.375, 0.219, 0.680, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000551780_key",
    "conversations": [
      {
        "from": "human",
        "value": "A round clock is mounted on a dark surface to the left of some partially visible white lettering.\nObjects: [clock]"
      },
      {
        "from": "gpt",
        "value": "clock: [0.375, 0.219, 0.680, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000551780_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a round antique wooden clock is mounted on a dark surface to the left of some partially visible white lettering."
      },
      {
        "from": "gpt",
        "value": "antique wooden clock: [0.375, 0.219, 0.680, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000551780_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a round antique wooden clock is mounted on a dark surface to the left of some partially visible white lettering.\nObjects: [antique wooden clock]"
      },
      {
        "from": "gpt",
        "value": "antique wooden clock: [0.375, 0.219, 0.680, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000551780_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: clock: [0.375, 0.219, 0.680, 0.742]\nGiven the above layout, shift the clock to the left by 0.078."
      },
      {
        "from": "gpt",
        "value": "clock: [0.297, 0.219, 0.602, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000551804",
    "conversations": [
      {
        "from": "human",
        "value": "A person at the center holding a tennis racket in the right hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.289, 0.680, 0.727]\ntennis racket: [0.539, 0.258, 0.602, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000551804_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person at the center holding a tennis racket in the right hand.\nObjects: [person, tennis racket]"
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.289, 0.680, 0.727]\ntennis racket: [0.539, 0.258, 0.602, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000551804_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a man in a blue jersey at the center holding a red tennis racket in the right hand."
      },
      {
        "from": "gpt",
        "value": "man in a blue jersey: [0.344, 0.289, 0.680, 0.727]\nred tennis racket: [0.539, 0.258, 0.602, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000551804_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a man in a blue jersey at the center holding a red tennis racket in the right hand.\nObjects: [man in a blue jersey, red tennis racket]"
      },
      {
        "from": "gpt",
        "value": "man in a blue jersey: [0.344, 0.289, 0.680, 0.727]\nred tennis racket: [0.539, 0.258, 0.602, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000551804_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.344, 0.289, 0.680, 0.727]\ntennis racket: [0.539, 0.258, 0.602, 0.477]\nGiven the above layout, shift the person to the left by 0.133."
      },
      {
        "from": "gpt",
        "value": "person: [0.211, 0.289, 0.547, 0.727]\ntennis racket: [0.539, 0.258, 0.602, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000555412",
    "conversations": [
      {
        "from": "human",
        "value": "The pizza is at the center of the image, topped with green leaves and slices of meat."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.000, 0.172, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000555412_key",
    "conversations": [
      {
        "from": "human",
        "value": "The pizza is at the center of the image, topped with green leaves and slices of meat.\nObjects: [pizza]"
      },
      {
        "from": "gpt",
        "value": "pizza: [0.000, 0.172, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000555412_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the Margherita pizza topped with basil leaves and slices of pepperoni is at the center of the image, topped with green leaves and slices of meat."
      },
      {
        "from": "gpt",
        "value": "Margherita pizza topped with basil leaves and slices of pepperoni: [0.000, 0.172, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000555412_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the Margherita pizza topped with basil leaves and slices of pepperoni is at the center of the image, topped with green leaves and slices of meat.\nObjects: [Margherita pizza topped with basil leaves and slices of pepperoni]"
      },
      {
        "from": "gpt",
        "value": "Margherita pizza topped with basil leaves and slices of pepperoni: [0.000, 0.172, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000555412_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: pizza: [0.000, 0.172, 0.992, 0.820]\nGiven the above layout, shift the pizza upwards by 0.055."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.000, 0.117, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000555705",
    "conversations": [
      {
        "from": "human",
        "value": "An orange cat on the left and a grey cat on the right sitting closely together."
      },
      {
        "from": "gpt",
        "value": "cat: [0.500, 0.242, 0.992, 0.688]\ncat: [0.000, 0.289, 0.516, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000555705_key",
    "conversations": [
      {
        "from": "human",
        "value": "An orange cat on the left and a grey cat on the right sitting closely together.\nObjects: [cat, cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.500, 0.242, 0.992, 0.688]\ncat: [0.000, 0.289, 0.516, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000557258",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center with the lid down, and a flush tank is mounted on the wall above it."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.211, 0.359, 0.758, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000557258_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center with the lid down, and a flush tank is mounted on the wall above it.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.211, 0.359, 0.758, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000557258_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain bowl is at the center with the lid down, and a flush tank is mounted on the wall above it."
      },
      {
        "from": "gpt",
        "value": "porcelain bowl: [0.211, 0.359, 0.758, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000557258_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain bowl is at the center with the lid down, and a flush tank is mounted on the wall above it.\nObjects: [porcelain bowl]"
      },
      {
        "from": "gpt",
        "value": "porcelain bowl: [0.211, 0.359, 0.758, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000557258_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.211, 0.359, 0.758, 0.977]\nGiven the above layout, shift the toilet upwards by 0.141."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.211, 0.219, 0.758, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000557884",
    "conversations": [
      {
        "from": "human",
        "value": "A vase is mounted on the wall, slightly towards the right side of the image."
      },
      {
        "from": "gpt",
        "value": "vase: [0.445, 0.219, 0.734, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000557884_key",
    "conversations": [
      {
        "from": "human",
        "value": "A vase is mounted on the wall, slightly towards the right side of the image.\nObjects: [vase]"
      },
      {
        "from": "gpt",
        "value": "vase: [0.445, 0.219, 0.734, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000557884_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a small ceramic vase is mounted on the wall, slightly towards the right side of the image."
      },
      {
        "from": "gpt",
        "value": "small ceramic vase: [0.445, 0.219, 0.734, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000557884_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a small ceramic vase is mounted on the wall, slightly towards the right side of the image.\nObjects: [small ceramic vase]"
      },
      {
        "from": "gpt",
        "value": "small ceramic vase: [0.445, 0.219, 0.734, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000557884_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: vase: [0.445, 0.219, 0.734, 0.820]\nGiven the above layout, shift the vase to the left by 0.438."
      },
      {
        "from": "gpt",
        "value": "vase: [0.008, 0.219, 0.297, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000560279",
    "conversations": [
      {
        "from": "human",
        "value": "A bottle is on top of a toilet tank, against the wall."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.297, 0.242, 0.703, 0.984]\nbottle: [0.523, 0.078, 0.602, 0.281]"
      }
    ]
  },
  {
    "id": "coco_000000560279_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bottle is on top of a toilet tank, against the wall.\nObjects: [toilet, bottle]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.297, 0.242, 0.703, 0.984]\nbottle: [0.523, 0.078, 0.602, 0.281]"
      }
    ]
  },
  {
    "id": "coco_000000560279_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a glass water bottle is on top of a porcelain toilet tank, against the wall."
      },
      {
        "from": "gpt",
        "value": "porcelain toilet: [0.297, 0.242, 0.703, 0.984]\nglass water bottle: [0.523, 0.078, 0.602, 0.281]"
      }
    ]
  },
  {
    "id": "coco_000000560279_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a glass water bottle is on top of a porcelain toilet tank, against the wall.\nObjects: [porcelain toilet, glass water bottle]"
      },
      {
        "from": "gpt",
        "value": "porcelain toilet: [0.297, 0.242, 0.703, 0.984]\nglass water bottle: [0.523, 0.078, 0.602, 0.281]"
      }
    ]
  },
  {
    "id": "coco_000000560279_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.297, 0.242, 0.703, 0.984]\nbottle: [0.523, 0.078, 0.602, 0.281]\nGiven the above layout, shift the toilet to the left by 0.133."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.164, 0.242, 0.570, 0.984]\nbottle: [0.523, 0.078, 0.602, 0.281]"
      }
    ]
  },
  {
    "id": "coco_000000561009",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is perched on a branch near the center of the image, surrounded by foliage."
      },
      {
        "from": "gpt",
        "value": "bird: [0.375, 0.406, 0.617, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000561009_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is perched on a branch near the center of the image, surrounded by foliage.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.375, 0.406, 0.617, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000561009_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a colorful parrot is perched on a branch near the center of the image, surrounded by foliage."
      },
      {
        "from": "gpt",
        "value": "colorful parrot: [0.375, 0.406, 0.617, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000561009_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a colorful parrot is perched on a branch near the center of the image, surrounded by foliage.\nObjects: [colorful parrot]"
      },
      {
        "from": "gpt",
        "value": "colorful parrot: [0.375, 0.406, 0.617, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000561009_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.375, 0.406, 0.617, 0.820]\nGiven the above layout, shift the bird upwards by 0.195."
      },
      {
        "from": "gpt",
        "value": "bird: [0.375, 0.211, 0.617, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000562229",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing on a skateboard in the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.430, 0.195, 0.703, 0.883]\nskateboard: [0.391, 0.773, 0.648, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000562229_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing on a skateboard in the center of the image.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.430, 0.195, 0.703, 0.883]\nskateboard: [0.391, 0.773, 0.648, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000562229_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a skater in a green hoodie standing on a sleek black skateboard in the center of the image."
      },
      {
        "from": "gpt",
        "value": "a skater in a green hoodie: [0.430, 0.195, 0.703, 0.883]\nsleek black skateboard: [0.391, 0.773, 0.648, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000562229_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a skater in a green hoodie standing on a sleek black skateboard in the center of the image.\nObjects: [a skater in a green hoodie, sleek black skateboard]"
      },
      {
        "from": "gpt",
        "value": "a skater in a green hoodie: [0.430, 0.195, 0.703, 0.883]\nsleek black skateboard: [0.391, 0.773, 0.648, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000562229_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.430, 0.195, 0.703, 0.883]\nskateboard: [0.391, 0.773, 0.648, 0.914]\nGiven the above layout, shift the skateboard to the left by 0.336."
      },
      {
        "from": "gpt",
        "value": "person: [0.430, 0.195, 0.703, 0.883]\nskateboard: [0.055, 0.773, 0.312, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000580410",
    "conversations": [
      {
        "from": "human",
        "value": "A couch is placed on the left side of the image, with a handbag on the floor in front of it, and a chair is positioned to the right, towards the back of the room."
      },
      {
        "from": "gpt",
        "value": "couch: [0.164, 0.383, 0.375, 0.781]\nchair: [0.531, 0.312, 0.656, 0.523]\nhandbag: [0.336, 0.672, 0.523, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000580410_key",
    "conversations": [
      {
        "from": "human",
        "value": "A couch is placed on the left side of the image, with a handbag on the floor in front of it, and a chair is positioned to the right, towards the back of the room.\nObjects: [couch, chair, handbag]"
      },
      {
        "from": "gpt",
        "value": "couch: [0.164, 0.383, 0.375, 0.781]\nchair: [0.531, 0.312, 0.656, 0.523]\nhandbag: [0.336, 0.672, 0.523, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000580410_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a brown leather couch is placed on the left side of the image, with a blue designer handbag on the floor in front of it, and a tall wooden chair is positioned to the right, towards the back of the room."
      },
      {
        "from": "gpt",
        "value": "brown leather couch: [0.164, 0.383, 0.375, 0.781]\ntall wooden chair: [0.531, 0.312, 0.656, 0.523]\nblue designer handbag: [0.336, 0.672, 0.523, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000580410_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a brown leather couch is placed on the left side of the image, with a blue designer handbag on the floor in front of it, and a tall wooden chair is positioned to the right, towards the back of the room.\nObjects: [brown leather couch, tall wooden chair, blue designer handbag]"
      },
      {
        "from": "gpt",
        "value": "brown leather couch: [0.164, 0.383, 0.375, 0.781]\ntall wooden chair: [0.531, 0.312, 0.656, 0.523]\nblue designer handbag: [0.336, 0.672, 0.523, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000580410_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: couch: [0.164, 0.383, 0.375, 0.781]\nchair: [0.531, 0.312, 0.656, 0.523]\nhandbag: [0.336, 0.672, 0.523, 0.773]\nGiven the above layout, shift the chair to the right by 0.312."
      },
      {
        "from": "gpt",
        "value": "couch: [0.164, 0.383, 0.375, 0.781]\nchair: [0.844, 0.312, 0.969, 0.523]\nhandbag: [0.336, 0.672, 0.523, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000017905",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left of a traffic light."
      },
      {
        "from": "gpt",
        "value": "person: [0.250, 0.352, 0.438, 0.922]\ntraffic light: [0.484, 0.203, 0.578, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000017905_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left of a traffic light.\nObjects: [person, traffic light]"
      },
      {
        "from": "gpt",
        "value": "person: [0.250, 0.352, 0.438, 0.922]\ntraffic light: [0.484, 0.203, 0.578, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000017905_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a adult pedestrian is standing to the left of a red traffic signal."
      },
      {
        "from": "gpt",
        "value": "adult pedestrian: [0.250, 0.352, 0.438, 0.922]\nred traffic signal: [0.484, 0.203, 0.578, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000017905_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a adult pedestrian is standing to the left of a red traffic signal.\nObjects: [adult pedestrian, red traffic signal]"
      },
      {
        "from": "gpt",
        "value": "adult pedestrian: [0.250, 0.352, 0.438, 0.922]\nred traffic signal: [0.484, 0.203, 0.578, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000017905_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.250, 0.352, 0.438, 0.922]\ntraffic light: [0.484, 0.203, 0.578, 0.438]\nGiven the above layout, shift the traffic light to the right by 0.117."
      },
      {
        "from": "gpt",
        "value": "person: [0.250, 0.352, 0.438, 0.922]\ntraffic light: [0.602, 0.203, 0.695, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000019742",
    "conversations": [
      {
        "from": "human",
        "value": "The vase is at the center, on a glass plate."
      },
      {
        "from": "gpt",
        "value": "vase: [0.344, 0.266, 0.672, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000019742_key",
    "conversations": [
      {
        "from": "human",
        "value": "The vase is at the center, on a glass plate.\nObjects: [vase]"
      },
      {
        "from": "gpt",
        "value": "vase: [0.344, 0.266, 0.672, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000019742_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the ornate porcelain vase is at the center, on a glass plate."
      },
      {
        "from": "gpt",
        "value": "ornate porcelain vase: [0.344, 0.266, 0.672, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000019742_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the ornate porcelain vase is at the center, on a glass plate.\nObjects: [ornate porcelain vase]"
      },
      {
        "from": "gpt",
        "value": "ornate porcelain vase: [0.344, 0.266, 0.672, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000019742_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: vase: [0.344, 0.266, 0.672, 0.812]\nGiven the above layout, shift the vase to the left by 0.297."
      },
      {
        "from": "gpt",
        "value": "vase: [0.047, 0.266, 0.375, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000020247",
    "conversations": [
      {
        "from": "human",
        "value": "One bear is in the foreground facing forward, and another bear is behind it to the left, partially obscured."
      },
      {
        "from": "gpt",
        "value": "bear: [0.516, 0.414, 0.789, 0.820]\nbear: [0.000, 0.164, 0.133, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000020247_key",
    "conversations": [
      {
        "from": "human",
        "value": "One bear is in the foreground facing forward, and another bear is behind it to the left, partially obscured.\nObjects: [bear, bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.516, 0.414, 0.789, 0.820]\nbear: [0.000, 0.164, 0.133, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000023023",
    "conversations": [
      {
        "from": "human",
        "value": "A suitcase is at the center with a handbag to its right."
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.336, 0.273, 0.664, 0.688]\nhandbag: [0.656, 0.375, 0.930, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000023023_key",
    "conversations": [
      {
        "from": "human",
        "value": "A suitcase is at the center with a handbag to its right.\nObjects: [suitcase, handbag]"
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.336, 0.273, 0.664, 0.688]\nhandbag: [0.656, 0.375, 0.930, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000023023_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a large brown suitcase is at the center with a small black clutch bag to its right."
      },
      {
        "from": "gpt",
        "value": "large brown suitcase: [0.336, 0.273, 0.664, 0.688]\nsmall black clutch bag: [0.656, 0.375, 0.930, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000023023_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a large brown suitcase is at the center with a small black clutch bag to its right.\nObjects: [large brown suitcase, small black clutch bag]"
      },
      {
        "from": "gpt",
        "value": "large brown suitcase: [0.336, 0.273, 0.664, 0.688]\nsmall black clutch bag: [0.656, 0.375, 0.930, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000023023_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: suitcase: [0.336, 0.273, 0.664, 0.688]\nhandbag: [0.656, 0.375, 0.930, 0.672]\nGiven the above layout, shift the suitcase to the left by 0.188."
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.148, 0.273, 0.477, 0.688]\nhandbag: [0.656, 0.375, 0.930, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000025057",
    "conversations": [
      {
        "from": "human",
        "value": "A shirtless person is standing in a field holding a frisbee in their left hand, extended out to the side."
      },
      {
        "from": "gpt",
        "value": "person: [0.195, 0.172, 0.664, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000025057_key",
    "conversations": [
      {
        "from": "human",
        "value": "A shirtless person is standing in a field holding a frisbee in their left hand, extended out to the side.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.195, 0.172, 0.664, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000025057_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a shirtless athletic man is standing in a field holding a frisbee in their left hand, extended out to the side."
      },
      {
        "from": "gpt",
        "value": "athletic man: [0.195, 0.172, 0.664, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000025057_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a shirtless athletic man is standing in a field holding a frisbee in their left hand, extended out to the side.\nObjects: [athletic man]"
      },
      {
        "from": "gpt",
        "value": "athletic man: [0.195, 0.172, 0.664, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000025057_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.195, 0.172, 0.664, 0.820]\nGiven the above layout, shift the person to the right by 0.109."
      },
      {
        "from": "gpt",
        "value": "person: [0.305, 0.172, 0.773, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000034257",
    "conversations": [
      {
        "from": "human",
        "value": "A pile of carrots is in the center, flanked by broccoli on both sides."
      },
      {
        "from": "gpt",
        "value": "carrot: [0.250, 0.516, 0.742, 0.742]\nbroccoli: [0.055, 0.195, 0.469, 0.367]\nbroccoli: [0.555, 0.211, 0.820, 0.359]"
      }
    ]
  },
  {
    "id": "coco_000000034257_key",
    "conversations": [
      {
        "from": "human",
        "value": "A pile of carrots is in the center, flanked by broccoli on both sides.\nObjects: [carrot, broccoli, broccoli]"
      },
      {
        "from": "gpt",
        "value": "carrot: [0.250, 0.516, 0.742, 0.742]\nbroccoli: [0.055, 0.195, 0.469, 0.367]\nbroccoli: [0.555, 0.211, 0.820, 0.359]"
      }
    ]
  },
  {
    "id": "coco_000000036494",
    "conversations": [
      {
        "from": "human",
        "value": "A large clock at the center of the image on the wall, with a person standing below it to the right."
      },
      {
        "from": "gpt",
        "value": "clock: [0.602, 0.219, 0.883, 0.547]\nperson: [0.625, 0.664, 0.711, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000036494_key",
    "conversations": [
      {
        "from": "human",
        "value": "A large clock at the center of the image on the wall, with a person standing below it to the right.\nObjects: [clock, person]"
      },
      {
        "from": "gpt",
        "value": "clock: [0.602, 0.219, 0.883, 0.547]\nperson: [0.625, 0.664, 0.711, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000036494_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a large enormous grandfather clock at the center of the image on the wall, with a bearded man standing below it to the right."
      },
      {
        "from": "gpt",
        "value": "enormous grandfather clock: [0.602, 0.219, 0.883, 0.547]\nbearded man: [0.625, 0.664, 0.711, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000036494_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a large enormous grandfather clock at the center of the image on the wall, with a bearded man standing below it to the right.\nObjects: [enormous grandfather clock, bearded man]"
      },
      {
        "from": "gpt",
        "value": "enormous grandfather clock: [0.602, 0.219, 0.883, 0.547]\nbearded man: [0.625, 0.664, 0.711, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000036494_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: clock: [0.602, 0.219, 0.883, 0.547]\nperson: [0.625, 0.664, 0.711, 0.812]\nGiven the above layout, shift the clock to the left by 0.023."
      },
      {
        "from": "gpt",
        "value": "clock: [0.578, 0.219, 0.859, 0.547]\nperson: [0.625, 0.664, 0.711, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000037740",
    "conversations": [
      {
        "from": "human",
        "value": "A chair is in front of a table on the left, a couch is to the left of the chair, and a potted plant is to the right of the table."
      },
      {
        "from": "gpt",
        "value": "chair: [0.328, 0.484, 0.602, 0.820]\npotted plant: [0.695, 0.414, 0.977, 0.703]\ncouch: [0.000, 0.641, 0.219, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000037740_key",
    "conversations": [
      {
        "from": "human",
        "value": "A chair is in front of a table on the left, a couch is to the left of the chair, and a potted plant is to the right of the table.\nObjects: [chair, potted plant, couch]"
      },
      {
        "from": "gpt",
        "value": "chair: [0.328, 0.484, 0.602, 0.820]\npotted plant: [0.695, 0.414, 0.977, 0.703]\ncouch: [0.000, 0.641, 0.219, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000037740_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a wooden dining chair is in front of a table on the left, a plush beige sofa is to the left of the wooden dining chair, and a large fern in a terracotta pot is to the right of the table."
      },
      {
        "from": "gpt",
        "value": "wooden dining chair: [0.328, 0.484, 0.602, 0.820]\nlarge fern in a terracotta pot: [0.695, 0.414, 0.977, 0.703]\nplush beige sofa: [0.000, 0.641, 0.219, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000037740_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a wooden dining chair is in front of a table on the left, a plush beige sofa is to the left of the wooden dining chair, and a large fern in a terracotta pot is to the right of the table.\nObjects: [wooden dining chair, large fern in a terracotta pot, plush beige sofa]"
      },
      {
        "from": "gpt",
        "value": "wooden dining chair: [0.328, 0.484, 0.602, 0.820]\nlarge fern in a terracotta pot: [0.695, 0.414, 0.977, 0.703]\nplush beige sofa: [0.000, 0.641, 0.219, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000037740_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: chair: [0.328, 0.484, 0.602, 0.820]\npotted plant: [0.695, 0.414, 0.977, 0.703]\ncouch: [0.000, 0.641, 0.219, 0.859]\nGiven the above layout, shift the potted plant upwards by 0.211."
      },
      {
        "from": "gpt",
        "value": "chair: [0.328, 0.484, 0.602, 0.820]\npotted plant: [0.695, 0.203, 0.977, 0.492]\ncouch: [0.000, 0.641, 0.219, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000038070",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center with the tank directly above the bowl."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.328, 0.195, 0.719, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000038070_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center with the tank directly above the bowl.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.328, 0.195, 0.719, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000038070_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the ceramic bidet is at the center with the tank directly above the bowl."
      },
      {
        "from": "gpt",
        "value": "ceramic bidet: [0.328, 0.195, 0.719, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000038070_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the ceramic bidet is at the center with the tank directly above the bowl.\nObjects: [ceramic bidet]"
      },
      {
        "from": "gpt",
        "value": "ceramic bidet: [0.328, 0.195, 0.719, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000038070_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.328, 0.195, 0.719, 0.828]\nGiven the above layout, shift the toilet to the left by 0.180."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.148, 0.195, 0.539, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000038210",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center, wearing skis which are on the snow-covered ground."
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.414, 0.484, 0.836]\nskis: [0.344, 0.836, 0.656, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000038210_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center, wearing skis which are on the snow-covered ground.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.414, 0.484, 0.836]\nskis: [0.344, 0.836, 0.656, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000038210_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man with a parka is in the center, wearing two polished skis which are on the snow-covered ground."
      },
      {
        "from": "gpt",
        "value": "tall man with a parka: [0.273, 0.414, 0.484, 0.836]\ntwo polished skis: [0.344, 0.836, 0.656, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000038210_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man with a parka is in the center, wearing two polished skis which are on the snow-covered ground.\nObjects: [tall man with a parka, two polished skis]"
      },
      {
        "from": "gpt",
        "value": "tall man with a parka: [0.273, 0.414, 0.484, 0.836]\ntwo polished skis: [0.344, 0.836, 0.656, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000038210_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.273, 0.414, 0.484, 0.836]\nskis: [0.344, 0.836, 0.656, 0.867]\nGiven the above layout, shift the person upwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.375, 0.484, 0.797]\nskis: [0.344, 0.836, 0.656, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000039551",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center, oriented towards the right while swinging a tennis racket."
      },
      {
        "from": "gpt",
        "value": "person: [0.188, 0.250, 0.492, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000039551_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center, oriented towards the right while swinging a tennis racket.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.188, 0.250, 0.492, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000039551_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a sports enthusiast is standing at the center, oriented towards the right while swinging a tennis racket."
      },
      {
        "from": "gpt",
        "value": "sports enthusiast: [0.188, 0.250, 0.492, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000039551_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a sports enthusiast is standing at the center, oriented towards the right while swinging a tennis racket.\nObjects: [sports enthusiast]"
      },
      {
        "from": "gpt",
        "value": "sports enthusiast: [0.188, 0.250, 0.492, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000039551_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.188, 0.250, 0.492, 0.688]\nGiven the above layout, shift the person to the right by 0.375."
      },
      {
        "from": "gpt",
        "value": "person: [0.562, 0.250, 0.867, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000039670",
    "conversations": [
      {
        "from": "human",
        "value": "A train coming forward on curving tracks, surrounded by greenery."
      },
      {
        "from": "gpt",
        "value": "train: [0.078, 0.156, 0.891, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000039670_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train coming forward on curving tracks, surrounded by greenery.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.078, 0.156, 0.891, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000039670_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a vintage steam engine coming forward on curving tracks, surrounded by greenery."
      },
      {
        "from": "gpt",
        "value": "vintage steam engine: [0.078, 0.156, 0.891, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000039670_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a vintage steam engine coming forward on curving tracks, surrounded by greenery.\nObjects: [vintage steam engine]"
      },
      {
        "from": "gpt",
        "value": "vintage steam engine: [0.078, 0.156, 0.891, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000039670_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.078, 0.156, 0.891, 0.703]\nGiven the above layout, shift the train downwards by 0.219."
      },
      {
        "from": "gpt",
        "value": "train: [0.078, 0.375, 0.891, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000043816",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the left swinging a bat, facing another person on the right crouching in catcher's gear."
      },
      {
        "from": "gpt",
        "value": "person: [0.391, 0.289, 0.703, 0.703]\nperson: [0.742, 0.469, 0.992, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000043816_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the left swinging a bat, facing another person on the right crouching in catchers gear.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.391, 0.289, 0.703, 0.703]\nperson: [0.742, 0.469, 0.992, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000066886",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a pink hairbrush in the right hand and is reaching towards the front."
      },
      {
        "from": "gpt",
        "value": "person: [0.188, 0.219, 0.930, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000066886_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a pink hairbrush in the right hand and is reaching towards the front.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.188, 0.219, 0.930, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000066886_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a lady with long brown hair is holding a pink hairbrush in the right hand and is reaching towards the front."
      },
      {
        "from": "gpt",
        "value": "a lady with long brown hair: [0.188, 0.219, 0.930, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000066886_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a lady with long brown hair is holding a pink hairbrush in the right hand and is reaching towards the front.\nObjects: [a lady with long brown hair]"
      },
      {
        "from": "gpt",
        "value": "a lady with long brown hair: [0.188, 0.219, 0.930, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000066886_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.188, 0.219, 0.930, 0.828]\nGiven the above layout, shift the person upwards by 0.211."
      },
      {
        "from": "gpt",
        "value": "person: [0.188, 0.008, 0.930, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000084170",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is at the center of the image, driving on a wet road towards the viewer."
      },
      {
        "from": "gpt",
        "value": "bus: [0.312, 0.312, 0.688, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000084170_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is at the center of the image, driving on a wet road towards the viewer.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.312, 0.312, 0.688, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000084170_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a blue double-decker bus is at the center of the image, driving on a wet road towards the viewer."
      },
      {
        "from": "gpt",
        "value": "blue double-decker bus: [0.312, 0.312, 0.688, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000084170_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a blue double-decker bus is at the center of the image, driving on a wet road towards the viewer.\nObjects: [blue double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "blue double-decker bus: [0.312, 0.312, 0.688, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000084170_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.312, 0.312, 0.688, 0.688]\nGiven the above layout, shift the bus to the left by 0.086."
      },
      {
        "from": "gpt",
        "value": "bus: [0.227, 0.312, 0.602, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000096001",
    "conversations": [
      {
        "from": "human",
        "value": "The umbrella is at the bottom, partially visible, with the handle to the left. The book is in the upper right corner, open, with pages facing upwards. The bowl is to the left of the book, closer to the top edge."
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.000, 0.469, 0.992, 0.750]\nbook: [0.461, 0.164, 0.906, 0.445]\nbowl: [0.062, 0.258, 0.281, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000096001_key",
    "conversations": [
      {
        "from": "human",
        "value": "The umbrella is at the bottom, partially visible, with the handle to the left. The book is in the upper right corner, open, with pages facing upwards. The bowl is to the left of the book, closer to the top edge.\nObjects: [umbrella, book, bowl]"
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.000, 0.469, 0.992, 0.750]\nbook: [0.461, 0.164, 0.906, 0.445]\nbowl: [0.062, 0.258, 0.281, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000096001_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the clear plastic umbrella is at the bottom, partially visible, with the handle to the left. the hardcover novel is in the upper right corner, open, with pages facing upwards. the ceramic salad bowl is to the left of the hardcover novel, closer to the top edge."
      },
      {
        "from": "gpt",
        "value": "clear plastic umbrella: [0.000, 0.469, 0.992, 0.750]\nhardcover novel: [0.461, 0.164, 0.906, 0.445]\nceramic salad bowl: [0.062, 0.258, 0.281, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000096001_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the clear plastic umbrella is at the bottom, partially visible, with the handle to the left. the hardcover novel is in the upper right corner, open, with pages facing upwards. the ceramic salad bowl is to the left of the hardcover novel, closer to the top edge.\nObjects: [clear plastic umbrella, hardcover novel, ceramic salad bowl]"
      },
      {
        "from": "gpt",
        "value": "clear plastic umbrella: [0.000, 0.469, 0.992, 0.750]\nhardcover novel: [0.461, 0.164, 0.906, 0.445]\nceramic salad bowl: [0.062, 0.258, 0.281, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000096001_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: umbrella: [0.000, 0.469, 0.992, 0.750]\nbook: [0.461, 0.164, 0.906, 0.445]\nbowl: [0.062, 0.258, 0.281, 0.406]\nGiven the above layout, shift the umbrella downwards by 0.102."
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.000, 0.570, 0.992, 0.852]\nbook: [0.461, 0.164, 0.906, 0.445]\nbowl: [0.062, 0.258, 0.281, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000096549",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is at the center of the image, positioned on the ground facing to the right."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.094, 0.352, 0.977, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000096549_key",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is at the center of the image, positioned on the ground facing to the right.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.094, 0.352, 0.977, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000096549_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red jet plane is at the center of the image, positioned on the ground facing to the right."
      },
      {
        "from": "gpt",
        "value": "red jet plane: [0.094, 0.352, 0.977, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000096549_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red jet plane is at the center of the image, positioned on the ground facing to the right.\nObjects: [red jet plane]"
      },
      {
        "from": "gpt",
        "value": "red jet plane: [0.094, 0.352, 0.977, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000096549_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.094, 0.352, 0.977, 0.594]\nGiven the above layout, shift the airplane downwards by 0.258."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.094, 0.609, 0.977, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000097230",
    "conversations": [
      {
        "from": "human",
        "value": "One elephant stands on the left side of the dirt path, while the other elephant is to the right of the path, partially obscured by bushes."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.133, 0.383, 0.508, 0.656]\nelephant: [0.570, 0.430, 0.914, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000097230_key",
    "conversations": [
      {
        "from": "human",
        "value": "One elephant stands on the left side of the dirt path, while the other elephant is to the right of the path, partially obscured by bushes.\nObjects: [elephant, elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.133, 0.383, 0.508, 0.656]\nelephant: [0.570, 0.430, 0.914, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000098853",
    "conversations": [
      {
        "from": "human",
        "value": "The person is at the center, playing tennis."
      },
      {
        "from": "gpt",
        "value": "person: [0.297, 0.289, 0.625, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000098853_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is at the center, playing tennis.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.297, 0.289, 0.625, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000098853_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the male athlete is at the center, playing tennis."
      },
      {
        "from": "gpt",
        "value": "male athlete: [0.297, 0.289, 0.625, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000098853_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the male athlete is at the center, playing tennis.\nObjects: [male athlete]"
      },
      {
        "from": "gpt",
        "value": "male athlete: [0.297, 0.289, 0.625, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000098853_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.297, 0.289, 0.625, 0.789]\nGiven the above layout, shift the person to the right by 0.109."
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.289, 0.734, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000100283",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is in the center foreground of the image."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.320, 0.172, 0.727, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000100283_key",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is in the center foreground of the image.\nObjects: [stop sign]"
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.320, 0.172, 0.727, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000100283_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the vivid red stop sign is in the center foreground of the image."
      },
      {
        "from": "gpt",
        "value": "vivid red stop sign: [0.320, 0.172, 0.727, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000100283_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the vivid red stop sign is in the center foreground of the image.\nObjects: [vivid red stop sign]"
      },
      {
        "from": "gpt",
        "value": "vivid red stop sign: [0.320, 0.172, 0.727, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000100283_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: stop sign: [0.320, 0.172, 0.727, 0.602]\nGiven the above layout, shift the stop sign downwards by 0.102."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.320, 0.273, 0.727, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000101762",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is to the right of a bicycle that is leaning against a wall."
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.062, 0.125, 0.797, 0.656]\ncat: [0.648, 0.234, 0.984, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000101762_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is to the right of a bicycle that is leaning against a wall.\nObjects: [bicycle, cat]"
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.062, 0.125, 0.797, 0.656]\ncat: [0.648, 0.234, 0.984, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000101762_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a fluffy Persian cat is to the right of a mountain bike that is leaning against a wall."
      },
      {
        "from": "gpt",
        "value": "mountain bike: [0.062, 0.125, 0.797, 0.656]\nfluffy Persian cat: [0.648, 0.234, 0.984, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000101762_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a fluffy Persian cat is to the right of a mountain bike that is leaning against a wall.\nObjects: [mountain bike, fluffy Persian cat]"
      },
      {
        "from": "gpt",
        "value": "mountain bike: [0.062, 0.125, 0.797, 0.656]\nfluffy Persian cat: [0.648, 0.234, 0.984, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000101762_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bicycle: [0.062, 0.125, 0.797, 0.656]\ncat: [0.648, 0.234, 0.984, 0.648]\nGiven the above layout, shift the bicycle downwards by 0.328."
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.062, 0.453, 0.797, 0.984]\ncat: [0.648, 0.234, 0.984, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000103723",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the right of an elephant."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.367, 0.344, 0.727, 0.883]\nperson: [0.656, 0.523, 0.867, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000103723_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the right of an elephant.\nObjects: [elephant, person]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.367, 0.344, 0.727, 0.883]\nperson: [0.656, 0.523, 0.867, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000103723_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man in a black jacket is standing to the right of an large African elephant."
      },
      {
        "from": "gpt",
        "value": "large African elephant: [0.367, 0.344, 0.727, 0.883]\ntall man in a black jacket: [0.656, 0.523, 0.867, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000103723_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man in a black jacket is standing to the right of an large African elephant.\nObjects: [large African elephant, tall man in a black jacket]"
      },
      {
        "from": "gpt",
        "value": "large African elephant: [0.367, 0.344, 0.727, 0.883]\ntall man in a black jacket: [0.656, 0.523, 0.867, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000103723_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: elephant: [0.367, 0.344, 0.727, 0.883]\nperson: [0.656, 0.523, 0.867, 0.992]\nGiven the above layout, shift the elephant to the left by 0.258."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.109, 0.344, 0.469, 0.883]\nperson: [0.656, 0.523, 0.867, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000104119",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is in the foreground slightly to the left, facing left, with another bird partially visible in the background to the right."
      },
      {
        "from": "gpt",
        "value": "bird: [0.211, 0.125, 0.664, 0.828]\nbird: [0.742, 0.484, 0.961, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000104119_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is in the foreground slightly to the left, facing left, with another bird partially visible in the background to the right.\nObjects: [bird, bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.211, 0.125, 0.664, 0.828]\nbird: [0.742, 0.484, 0.961, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000104198",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is on the right side of the image, attached to a pole."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.570, 0.359, 0.984, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000104198_key",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is on the right side of the image, attached to a pole.\nObjects: [stop sign]"
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.570, 0.359, 0.984, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000104198_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red and white stop sign is on the right side of the image, attached to a pole."
      },
      {
        "from": "gpt",
        "value": "red and white stop sign: [0.570, 0.359, 0.984, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000104198_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red and white stop sign is on the right side of the image, attached to a pole.\nObjects: [red and white stop sign]"
      },
      {
        "from": "gpt",
        "value": "red and white stop sign: [0.570, 0.359, 0.984, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000104198_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: stop sign: [0.570, 0.359, 0.984, 0.750]\nGiven the above layout, shift the stop sign to the left by 0.570."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.000, 0.359, 0.414, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000104619",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe stands in the center facing slightly to the left."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.211, 0.234, 0.500, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000104619_key",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe stands in the center facing slightly to the left.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.211, 0.234, 0.500, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000104619_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall ostrich stands in the center facing slightly to the left."
      },
      {
        "from": "gpt",
        "value": "tall ostrich: [0.211, 0.234, 0.500, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000104619_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall ostrich stands in the center facing slightly to the left.\nObjects: [tall ostrich]"
      },
      {
        "from": "gpt",
        "value": "tall ostrich: [0.211, 0.234, 0.500, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000104619_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.211, 0.234, 0.500, 0.844]\nGiven the above layout, shift the giraffe to the right by 0.148."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.359, 0.234, 0.648, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000104782",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is in the center of the image, mounted on a pole."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.500, 0.266, 0.633, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000104782_key",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is in the center of the image, mounted on a pole.\nObjects: [stop sign]"
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.500, 0.266, 0.633, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000104782_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the traffic light is in the center of the image, mounted on a pole."
      },
      {
        "from": "gpt",
        "value": "traffic light: [0.500, 0.266, 0.633, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000104782_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the traffic light is in the center of the image, mounted on a pole.\nObjects: [traffic light]"
      },
      {
        "from": "gpt",
        "value": "traffic light: [0.500, 0.266, 0.633, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000104782_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: stop sign: [0.500, 0.266, 0.633, 0.859]\nGiven the above layout, shift the stop sign to the left by 0.227."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.273, 0.266, 0.406, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000137727",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the right side of the image, aligned horizontally."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.359, 0.891, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000137727_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the right side of the image, aligned horizontally.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.359, 0.891, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000137727_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the blue freight train is on the right side of the image, aligned horizontally."
      },
      {
        "from": "gpt",
        "value": "blue freight train: [0.000, 0.359, 0.891, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000137727_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the blue freight train is on the right side of the image, aligned horizontally.\nObjects: [blue freight train]"
      },
      {
        "from": "gpt",
        "value": "blue freight train: [0.000, 0.359, 0.891, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000137727_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.359, 0.891, 0.625]\nGiven the above layout, shift the train downwards by 0.055."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.414, 0.891, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000146825",
    "conversations": [
      {
        "from": "human",
        "value": "The train is situated horizontally across the center of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.078, 0.383, 0.992, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000146825_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is situated horizontally across the center of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.078, 0.383, 0.992, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000146825_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the steam engine locomotive is situated horizontally across the center of the image."
      },
      {
        "from": "gpt",
        "value": "steam engine locomotive: [0.078, 0.383, 0.992, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000146825_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the steam engine locomotive is situated horizontally across the center of the image.\nObjects: [steam engine locomotive]"
      },
      {
        "from": "gpt",
        "value": "steam engine locomotive: [0.078, 0.383, 0.992, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000146825_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.078, 0.383, 0.992, 0.688]\nGiven the above layout, shift the train upwards by 0.250."
      },
      {
        "from": "gpt",
        "value": "train: [0.078, 0.133, 0.992, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000149406",
    "conversations": [
      {
        "from": "human",
        "value": "A red motorcycle is parked on the left side in front of a green wooden door with glass panes."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.133, 0.562, 0.758, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000149406_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red motorcycle is parked on the left side in front of a green wooden door with glass panes.\nObjects: [motorcycle]"
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.133, 0.562, 0.758, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000149406_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red blue scooter is parked on the left side in front of a green wooden door with glass panes."
      },
      {
        "from": "gpt",
        "value": "blue scooter: [0.133, 0.562, 0.758, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000149406_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red blue scooter is parked on the left side in front of a green wooden door with glass panes.\nObjects: [blue scooter]"
      },
      {
        "from": "gpt",
        "value": "blue scooter: [0.133, 0.562, 0.758, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000149406_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: motorcycle: [0.133, 0.562, 0.758, 0.930]\nGiven the above layout, shift the motorcycle upwards by 0.125."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.133, 0.438, 0.758, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000150265",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the background standing to the left and a person in the foreground walking towards the bottom right corner."
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.578, 0.625, 0.977]\nperson: [0.141, 0.125, 0.375, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000150265_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the background standing to the left and a person in the foreground walking towards the bottom right corner.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.578, 0.625, 0.977]\nperson: [0.141, 0.125, 0.375, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000151962",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is visible through the rearview mirror of the car."
      },
      {
        "from": "gpt",
        "value": "car: [0.102, 0.273, 0.727, 0.859]\ndog: [0.531, 0.500, 0.695, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000151962_key",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is visible through the rearview mirror of the car.\nObjects: [car, dog]"
      },
      {
        "from": "gpt",
        "value": "car: [0.102, 0.273, 0.727, 0.859]\ndog: [0.531, 0.500, 0.695, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000151962_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a dog is visible through the rearview mirror of the car."
      },
      {
        "from": "gpt",
        "value": "car: [0.102, 0.273, 0.727, 0.859]\ndog: [0.531, 0.500, 0.695, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000151962_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a dog is visible through the rearview mirror of the car.\nObjects: [car, dog]"
      },
      {
        "from": "gpt",
        "value": "car: [0.102, 0.273, 0.727, 0.859]\ndog: [0.531, 0.500, 0.695, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000151962_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: car: [0.102, 0.273, 0.727, 0.859]\ndog: [0.531, 0.500, 0.695, 0.680]\nGiven the above layout, shift the car upwards by 0.219."
      },
      {
        "from": "gpt",
        "value": "car: [0.102, 0.055, 0.727, 0.641]\ndog: [0.531, 0.500, 0.695, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000152686",
    "conversations": [
      {
        "from": "human",
        "value": "A person playing tennis is in the foreground on the right side, while another person is standing in the background on the left side."
      },
      {
        "from": "gpt",
        "value": "person: [0.359, 0.219, 0.633, 0.789]\nperson: [0.000, 0.359, 0.055, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000152686_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person playing tennis is in the foreground on the right side, while another person is standing in the background on the left side.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.359, 0.219, 0.633, 0.789]\nperson: [0.000, 0.359, 0.055, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000152870",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe centered in the image, amidst a background of trees and shrubs."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.422, 0.039, 0.750, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000152870_key",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe centered in the image, amidst a background of trees and shrubs.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.422, 0.039, 0.750, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000152870_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a long-necked ostrich centered in the image, amidst a background of trees and shrubs."
      },
      {
        "from": "gpt",
        "value": "long-necked ostrich: [0.422, 0.039, 0.750, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000152870_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a long-necked ostrich centered in the image, amidst a background of trees and shrubs.\nObjects: [long-necked ostrich]"
      },
      {
        "from": "gpt",
        "value": "long-necked ostrich: [0.422, 0.039, 0.750, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000152870_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.422, 0.039, 0.750, 0.961]\nGiven the above layout, shift the giraffe to the left by 0.242."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.180, 0.039, 0.508, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000161861",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center of the image, wearing a white outfit, and holding a tennis racket."
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.281, 0.547, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000161861_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center of the image, wearing a white outfit, and holding a tennis racket.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.281, 0.547, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000161861_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a yoga enthusiast wearing a white outfit is standing at the center of the image, wearing a white outfit, and holding a tennis racket."
      },
      {
        "from": "gpt",
        "value": "yoga enthusiast wearing a white outfit: [0.352, 0.281, 0.547, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000161861_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a yoga enthusiast wearing a white outfit is standing at the center of the image, wearing a white outfit, and holding a tennis racket.\nObjects: [yoga enthusiast wearing a white outfit]"
      },
      {
        "from": "gpt",
        "value": "yoga enthusiast wearing a white outfit: [0.352, 0.281, 0.547, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000161861_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.352, 0.281, 0.547, 0.750]\nGiven the above layout, shift the person to the right by 0.383."
      },
      {
        "from": "gpt",
        "value": "person: [0.734, 0.281, 0.930, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000161925",
    "conversations": [
      {
        "from": "human",
        "value": "One person stands to the left facing the back of another person on the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.125, 0.156, 0.406, 0.984]\nperson: [0.508, 0.141, 0.773, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000161925_key",
    "conversations": [
      {
        "from": "human",
        "value": "One person stands to the left facing the back of another person on the right.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.125, 0.156, 0.406, 0.984]\nperson: [0.508, 0.141, 0.773, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000163562",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing holding a frisbee in their right hand down by their side."
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.164, 0.898, 0.828]\nfrisbee: [0.172, 0.609, 0.391, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000163562_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing holding a frisbee in their right hand down by their side.\nObjects: [person, frisbee]"
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.164, 0.898, 0.828]\nfrisbee: [0.172, 0.609, 0.391, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000163562_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a lady wearing sunglasses standing holding a blue frisbee in their right hand down by their side."
      },
      {
        "from": "gpt",
        "value": "a lady wearing sunglasses: [0.266, 0.164, 0.898, 0.828]\nblue frisbee: [0.172, 0.609, 0.391, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000163562_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a lady wearing sunglasses standing holding a blue frisbee in their right hand down by their side.\nObjects: [a lady wearing sunglasses, blue frisbee]"
      },
      {
        "from": "gpt",
        "value": "a lady wearing sunglasses: [0.266, 0.164, 0.898, 0.828]\nblue frisbee: [0.172, 0.609, 0.391, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000163562_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.266, 0.164, 0.898, 0.828]\nfrisbee: [0.172, 0.609, 0.391, 0.758]\nGiven the above layout, shift the frisbee to the left by 0.023."
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.164, 0.898, 0.828]\nfrisbee: [0.148, 0.609, 0.367, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000164363",
    "conversations": [
      {
        "from": "human",
        "value": "The clock is at the center of the image, with roman numerals and set within a square wooden frame."
      },
      {
        "from": "gpt",
        "value": "clock: [0.094, 0.039, 0.883, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000164363_key",
    "conversations": [
      {
        "from": "human",
        "value": "The clock is at the center of the image, with roman numerals and set within a square wooden frame.\nObjects: [clock]"
      },
      {
        "from": "gpt",
        "value": "clock: [0.094, 0.039, 0.883, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000164363_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the vintage mantel clock is at the center of the image, with roman numerals and set within a square wooden frame."
      },
      {
        "from": "gpt",
        "value": "vintage mantel clock: [0.094, 0.039, 0.883, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000164363_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the vintage mantel clock is at the center of the image, with roman numerals and set within a square wooden frame.\nObjects: [vintage mantel clock]"
      },
      {
        "from": "gpt",
        "value": "vintage mantel clock: [0.094, 0.039, 0.883, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000164363_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: clock: [0.094, 0.039, 0.883, 0.820]\nGiven the above layout, shift the clock downwards by 0.102."
      },
      {
        "from": "gpt",
        "value": "clock: [0.094, 0.141, 0.883, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000179765",
    "conversations": [
      {
        "from": "human",
        "value": "The motorcycle is at the center of the image, angled slightly to the right."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.148, 0.133, 0.938, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000179765_key",
    "conversations": [
      {
        "from": "human",
        "value": "The motorcycle is at the center of the image, angled slightly to the right.\nObjects: [motorcycle]"
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.148, 0.133, 0.938, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000179765_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the classic Harley Davidson is at the center of the image, angled slightly to the right."
      },
      {
        "from": "gpt",
        "value": "classic Harley Davidson: [0.148, 0.133, 0.938, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000179765_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the classic Harley Davidson is at the center of the image, angled slightly to the right.\nObjects: [classic Harley Davidson]"
      },
      {
        "from": "gpt",
        "value": "classic Harley Davidson: [0.148, 0.133, 0.938, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000179765_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: motorcycle: [0.148, 0.133, 0.938, 0.727]\nGiven the above layout, shift the motorcycle downwards by 0.164."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.148, 0.297, 0.938, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000193743",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the foreground holding a tennis racket, with another person visible in the background."
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.070, 0.781, 0.977]\nperson: [0.508, 0.938, 0.656, 0.984]\ntennis racket: [0.750, 0.594, 0.773, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000193743_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the foreground holding a tennis racket, with another person visible in the background.\nObjects: [person, person, tennis racket]"
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.070, 0.781, 0.977]\nperson: [0.508, 0.938, 0.656, 0.984]\ntennis racket: [0.750, 0.594, 0.773, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000195842",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the right of a couch that is positioned against a wall in the room."
      },
      {
        "from": "gpt",
        "value": "person: [0.641, 0.195, 0.875, 0.859]\ncouch: [0.438, 0.570, 0.703, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000195842_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the right of a couch that is positioned against a wall in the room.\nObjects: [person, couch]"
      },
      {
        "from": "gpt",
        "value": "person: [0.641, 0.195, 0.875, 0.859]\ncouch: [0.438, 0.570, 0.703, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000195842_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a blonde woman is standing to the right of a green loveseat that is positioned against a wall in the room."
      },
      {
        "from": "gpt",
        "value": "blonde woman: [0.641, 0.195, 0.875, 0.859]\ngreen loveseat: [0.438, 0.570, 0.703, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000195842_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a blonde woman is standing to the right of a green loveseat that is positioned against a wall in the room.\nObjects: [blonde woman, green loveseat]"
      },
      {
        "from": "gpt",
        "value": "blonde woman: [0.641, 0.195, 0.875, 0.859]\ngreen loveseat: [0.438, 0.570, 0.703, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000195842_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.641, 0.195, 0.875, 0.859]\ncouch: [0.438, 0.570, 0.703, 0.719]\nGiven the above layout, shift the couch to the left by 0.039."
      },
      {
        "from": "gpt",
        "value": "person: [0.641, 0.195, 0.875, 0.859]\ncouch: [0.398, 0.570, 0.664, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000196759",
    "conversations": [
      {
        "from": "human",
        "value": "The truck is parked diagonally in a parking lot, facing to the right of the image."
      },
      {
        "from": "gpt",
        "value": "truck: [0.070, 0.383, 0.961, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000196759_key",
    "conversations": [
      {
        "from": "human",
        "value": "The truck is parked diagonally in a parking lot, facing to the right of the image.\nObjects: [truck]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.070, 0.383, 0.961, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000196759_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red pickup truck is parked diagonally in a parking lot, facing to the right of the image."
      },
      {
        "from": "gpt",
        "value": "red pickup truck: [0.070, 0.383, 0.961, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000196759_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red pickup truck is parked diagonally in a parking lot, facing to the right of the image.\nObjects: [red pickup truck]"
      },
      {
        "from": "gpt",
        "value": "red pickup truck: [0.070, 0.383, 0.961, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000196759_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.070, 0.383, 0.961, 0.781]\nGiven the above layout, shift the truck upwards by 0.125."
      },
      {
        "from": "gpt",
        "value": "truck: [0.070, 0.258, 0.961, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000199442",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a surfboard, riding a wave."
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.281, 0.688, 0.531]\nsurfboard: [0.258, 0.477, 0.633, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000199442_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a surfboard, riding a wave.\nObjects: [person, surfboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.281, 0.688, 0.531]\nsurfboard: [0.258, 0.477, 0.633, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000199442_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a surfer in a wetsuit is standing on a brightly colored surfboard, riding a wave."
      },
      {
        "from": "gpt",
        "value": "surfer in a wetsuit: [0.406, 0.281, 0.688, 0.531]\nbrightly colored surfboard: [0.258, 0.477, 0.633, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000199442_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a surfer in a wetsuit is standing on a brightly colored surfboard, riding a wave.\nObjects: [surfer in a wetsuit, brightly colored surfboard]"
      },
      {
        "from": "gpt",
        "value": "surfer in a wetsuit: [0.406, 0.281, 0.688, 0.531]\nbrightly colored surfboard: [0.258, 0.477, 0.633, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000199442_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.406, 0.281, 0.688, 0.531]\nsurfboard: [0.258, 0.477, 0.633, 0.570]\nGiven the above layout, shift the surfboard downwards by 0.242."
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.281, 0.688, 0.531]\nsurfboard: [0.258, 0.719, 0.633, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000203317",
    "conversations": [
      {
        "from": "human",
        "value": "A red bicycle is parked on the right side of the image, leaning against a brown-shuttered window."
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.422, 0.492, 0.930, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000203317_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red bicycle is parked on the right side of the image, leaning against a brown-shuttered window.\nObjects: [bicycle]"
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.422, 0.492, 0.930, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000203317_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red blue mountain bike is parked on the right side of the image, leaning against a brown-shuttered window."
      },
      {
        "from": "gpt",
        "value": "blue mountain bike: [0.422, 0.492, 0.930, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000203317_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red blue mountain bike is parked on the right side of the image, leaning against a brown-shuttered window.\nObjects: [blue mountain bike]"
      },
      {
        "from": "gpt",
        "value": "blue mountain bike: [0.422, 0.492, 0.930, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000203317_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bicycle: [0.422, 0.492, 0.930, 0.898]\nGiven the above layout, shift the bicycle upwards by 0.328."
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.422, 0.164, 0.930, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000209757",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding on top of a skateboard, balancing in the center."
      },
      {
        "from": "gpt",
        "value": "person: [0.359, 0.039, 0.703, 0.508]\nskateboard: [0.438, 0.477, 0.656, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000209757_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding on top of a skateboard, balancing in the center.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.359, 0.039, 0.703, 0.508]\nskateboard: [0.438, 0.477, 0.656, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000209757_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager practicing stunts is graffiti covered skateboarding on top of a graffiti covered skateboard, balancing in the center."
      },
      {
        "from": "gpt",
        "value": "teenager practicing stunts: [0.359, 0.039, 0.703, 0.508]\ngraffiti covered skateboard: [0.438, 0.477, 0.656, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000209757_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager practicing stunts is graffiti covered skateboarding on top of a graffiti covered skateboard, balancing in the center.\nObjects: [teenager practicing stunts, graffiti covered skateboard]"
      },
      {
        "from": "gpt",
        "value": "teenager practicing stunts: [0.359, 0.039, 0.703, 0.508]\ngraffiti covered skateboard: [0.438, 0.477, 0.656, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000209757_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.359, 0.039, 0.703, 0.508]\nskateboard: [0.438, 0.477, 0.656, 0.531]\nGiven the above layout, shift the skateboard downwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "person: [0.359, 0.039, 0.703, 0.508]\nskateboard: [0.438, 0.547, 0.656, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000210502",
    "conversations": [
      {
        "from": "human",
        "value": "The side of a train with a door at the center, featuring a reflective window with a diagonal striped pattern."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.172, 0.992, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000210502_key",
    "conversations": [
      {
        "from": "human",
        "value": "The side of a train with a door at the center, featuring a reflective window with a diagonal striped pattern.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.172, 0.992, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000210502_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the side of a red locomotive with a door at the center, featuring a reflective window with a diagonal striped pattern."
      },
      {
        "from": "gpt",
        "value": "red locomotive: [0.000, 0.172, 0.992, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000210502_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the side of a red locomotive with a door at the center, featuring a reflective window with a diagonal striped pattern.\nObjects: [red locomotive]"
      },
      {
        "from": "gpt",
        "value": "red locomotive: [0.000, 0.172, 0.992, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000210502_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.172, 0.992, 0.812]\nGiven the above layout, shift the train downwards by 0.148."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.320, 0.992, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000211069",
    "conversations": [
      {
        "from": "human",
        "value": "One giraffe is positioned on the left side facing left, while another giraffe is to the right facing right, both in front of greenery."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.391, 0.430, 0.695, 0.750]\ngiraffe: [0.000, 0.477, 0.203, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000211069_key",
    "conversations": [
      {
        "from": "human",
        "value": "One giraffe is positioned on the left side facing left, while another giraffe is to the right facing right, both in front of greenery.\nObjects: [giraffe, giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.391, 0.430, 0.695, 0.750]\ngiraffe: [0.000, 0.477, 0.203, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000212072",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is on the right side of the image, positioned at the forefront on a pole."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.617, 0.180, 0.914, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000212072_key",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is on the right side of the image, positioned at the forefront on a pole.\nObjects: [stop sign]"
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.617, 0.180, 0.914, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000212072_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red triangle sign is on the right side of the image, positioned at the forefront on a pole."
      },
      {
        "from": "gpt",
        "value": "red triangle sign: [0.617, 0.180, 0.914, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000212072_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red triangle sign is on the right side of the image, positioned at the forefront on a pole.\nObjects: [red triangle sign]"
      },
      {
        "from": "gpt",
        "value": "red triangle sign: [0.617, 0.180, 0.914, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000212072_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: stop sign: [0.617, 0.180, 0.914, 0.477]\nGiven the above layout, shift the stop sign to the left by 0.352."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.266, 0.180, 0.562, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000212166",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting in front of a plate of food, with their left hand holding a fork near the plate."
      },
      {
        "from": "gpt",
        "value": "person: [0.141, 0.023, 0.867, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000212166_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting in front of a plate of food, with their left hand holding a fork near the plate.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.141, 0.023, 0.867, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000212166_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a young woman is sitting in front of a plate of food, with their left hand holding a fork near the plate."
      },
      {
        "from": "gpt",
        "value": "a young woman: [0.141, 0.023, 0.867, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000212166_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a young woman is sitting in front of a plate of food, with their left hand holding a fork near the plate.\nObjects: [a young woman]"
      },
      {
        "from": "gpt",
        "value": "a young woman: [0.141, 0.023, 0.867, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000212166_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.141, 0.023, 0.867, 0.664]\nGiven the above layout, shift the person downwards by 0.141."
      },
      {
        "from": "gpt",
        "value": "person: [0.141, 0.164, 0.867, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000212453",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is centered against a wall with a patterned wallpaper."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.430, 0.484, 0.844, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000212453_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is centered against a wall with a patterned wallpaper.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.430, 0.484, 0.844, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000212453_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the ceramic toilet is centered against a wall with a patterned wallpaper."
      },
      {
        "from": "gpt",
        "value": "ceramic toilet: [0.430, 0.484, 0.844, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000212453_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the ceramic toilet is centered against a wall with a patterned wallpaper.\nObjects: [ceramic toilet]"
      },
      {
        "from": "gpt",
        "value": "ceramic toilet: [0.430, 0.484, 0.844, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000212453_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.430, 0.484, 0.844, 0.992]\nGiven the above layout, shift the toilet upwards by 0.047."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.430, 0.438, 0.844, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000212800",
    "conversations": [
      {
        "from": "human",
        "value": "A boat is at the center, moving towards the right of the image."
      },
      {
        "from": "gpt",
        "value": "boat: [0.062, 0.492, 0.875, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000212800_key",
    "conversations": [
      {
        "from": "human",
        "value": "A boat is at the center, moving towards the right of the image.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.062, 0.492, 0.875, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000212800_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a white sailboat is at the center, moving towards the right of the image."
      },
      {
        "from": "gpt",
        "value": "white sailboat: [0.062, 0.492, 0.875, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000212800_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a white sailboat is at the center, moving towards the right of the image.\nObjects: [white sailboat]"
      },
      {
        "from": "gpt",
        "value": "white sailboat: [0.062, 0.492, 0.875, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000212800_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.062, 0.492, 0.875, 0.711]\nGiven the above layout, shift the boat upwards by 0.047."
      },
      {
        "from": "gpt",
        "value": "boat: [0.062, 0.445, 0.875, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000213171",
    "conversations": [
      {
        "from": "human",
        "value": "The person is standing in the center of the image, in a field, wearing a baseball uniform and holding a glove."
      },
      {
        "from": "gpt",
        "value": "person: [0.398, 0.289, 0.633, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000213171_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is standing in the center of the image, in a field, wearing a baseball uniform and holding a glove.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.398, 0.289, 0.633, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000213171_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the baseball player in a striking red uniform is standing in the center of the image, in a field, wearing a baseball uniform and holding a glove."
      },
      {
        "from": "gpt",
        "value": "baseball player in a striking red uniform: [0.398, 0.289, 0.633, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000213171_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the baseball player in a striking red uniform is standing in the center of the image, in a field, wearing a baseball uniform and holding a glove.\nObjects: [baseball player in a striking red uniform]"
      },
      {
        "from": "gpt",
        "value": "baseball player in a striking red uniform: [0.398, 0.289, 0.633, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000213171_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.398, 0.289, 0.633, 0.883]\nGiven the above layout, shift the person to the left by 0.086."
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.289, 0.547, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000232538",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the right side, partially under a bridge."
      },
      {
        "from": "gpt",
        "value": "train: [0.133, 0.430, 0.773, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000232538_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the right side, partially under a bridge.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.133, 0.430, 0.773, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000232538_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red locomotive is on the right side, partially under a bridge."
      },
      {
        "from": "gpt",
        "value": "red locomotive: [0.133, 0.430, 0.773, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000232538_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red locomotive is on the right side, partially under a bridge.\nObjects: [red locomotive]"
      },
      {
        "from": "gpt",
        "value": "red locomotive: [0.133, 0.430, 0.773, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000232538_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.133, 0.430, 0.773, 0.688]\nGiven the above layout, shift the train upwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "train: [0.133, 0.359, 0.773, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000256407",
    "conversations": [
      {
        "from": "human",
        "value": "The clock is at the center of the image, with its hands indicating the time."
      },
      {
        "from": "gpt",
        "value": "clock: [0.281, 0.281, 0.719, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000256407_key",
    "conversations": [
      {
        "from": "human",
        "value": "The clock is at the center of the image, with its hands indicating the time.\nObjects: [clock]"
      },
      {
        "from": "gpt",
        "value": "clock: [0.281, 0.281, 0.719, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000256407_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the antique wall clock is at the center of the image, with its hands indicating the time."
      },
      {
        "from": "gpt",
        "value": "antique wall clock: [0.281, 0.281, 0.719, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000256407_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the antique wall clock is at the center of the image, with its hands indicating the time.\nObjects: [antique wall clock]"
      },
      {
        "from": "gpt",
        "value": "antique wall clock: [0.281, 0.281, 0.719, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000256407_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: clock: [0.281, 0.281, 0.719, 0.711]\nGiven the above layout, shift the clock to the left by 0.250."
      },
      {
        "from": "gpt",
        "value": "clock: [0.031, 0.281, 0.469, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000261061",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left of a potted plant in the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.516, 0.250, 0.734, 0.828]\npotted plant: [0.008, 0.414, 0.219, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000261061_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left of a potted plant in the image.\nObjects: [person, potted plant]"
      },
      {
        "from": "gpt",
        "value": "person: [0.516, 0.250, 0.734, 0.828]\npotted plant: [0.008, 0.414, 0.219, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000261061_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a man in a red shirt is standing to the left of a tall ficus tree in a terracotta pot in the image."
      },
      {
        "from": "gpt",
        "value": "a man in a red shirt: [0.516, 0.250, 0.734, 0.828]\ntall ficus tree in a terracotta pot: [0.008, 0.414, 0.219, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000261061_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a man in a red shirt is standing to the left of a tall ficus tree in a terracotta pot in the image.\nObjects: [a man in a red shirt, tall ficus tree in a terracotta pot]"
      },
      {
        "from": "gpt",
        "value": "a man in a red shirt: [0.516, 0.250, 0.734, 0.828]\ntall ficus tree in a terracotta pot: [0.008, 0.414, 0.219, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000261061_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.516, 0.250, 0.734, 0.828]\npotted plant: [0.008, 0.414, 0.219, 0.539]\nGiven the above layout, shift the person to the right by 0.250."
      },
      {
        "from": "gpt",
        "value": "person: [0.766, 0.250, 0.984, 0.828]\npotted plant: [0.008, 0.414, 0.219, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000261732",
    "conversations": [
      {
        "from": "human",
        "value": "The person is on the left side of the image playing tennis."
      },
      {
        "from": "gpt",
        "value": "person: [0.227, 0.227, 0.484, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000261732_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is on the left side of the image playing tennis.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.227, 0.227, 0.484, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000261732_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the young man playing tennis is on the left side of the image playing tennis."
      },
      {
        "from": "gpt",
        "value": "young man playing tennis: [0.227, 0.227, 0.484, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000261732_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the young man playing tennis is on the left side of the image playing tennis.\nObjects: [young man playing tennis]"
      },
      {
        "from": "gpt",
        "value": "young man playing tennis: [0.227, 0.227, 0.484, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000261732_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.227, 0.227, 0.484, 0.711]\nGiven the above layout, shift the person to the right by 0.414."
      },
      {
        "from": "gpt",
        "value": "person: [0.641, 0.227, 0.898, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000263299",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the left, moving towards the right through a wooded area."
      },
      {
        "from": "gpt",
        "value": "train: [0.016, 0.172, 0.594, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000263299_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the left, moving towards the right through a wooded area.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.016, 0.172, 0.594, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000263299_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the green steam locomotive is on the left, moving towards the right through a wooded area."
      },
      {
        "from": "gpt",
        "value": "green steam locomotive: [0.016, 0.172, 0.594, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000263299_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the green steam locomotive is on the left, moving towards the right through a wooded area.\nObjects: [green steam locomotive]"
      },
      {
        "from": "gpt",
        "value": "green steam locomotive: [0.016, 0.172, 0.594, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000263299_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.016, 0.172, 0.594, 0.805]\nGiven the above layout, shift the train to the right by 0.398."
      },
      {
        "from": "gpt",
        "value": "train: [0.414, 0.172, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000263796",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the bottom center of the image, surrounded by various mechanical components."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.406, 0.406, 0.672, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000263796_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the bottom center of the image, surrounded by various mechanical components.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.406, 0.406, 0.672, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000263796_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the pristine white ceramic toilet is at the bottom center of the image, surrounded by various mechanical components."
      },
      {
        "from": "gpt",
        "value": "pristine white ceramic toilet: [0.406, 0.406, 0.672, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000263796_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the pristine white ceramic toilet is at the bottom center of the image, surrounded by various mechanical components.\nObjects: [pristine white ceramic toilet]"
      },
      {
        "from": "gpt",
        "value": "pristine white ceramic toilet: [0.406, 0.406, 0.672, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000263796_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.406, 0.406, 0.672, 0.922]\nGiven the above layout, shift the toilet to the left by 0.164."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.242, 0.406, 0.508, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000263966",
    "conversations": [
      {
        "from": "human",
        "value": "A person's hand is visible on the left, a horse is in the center, and a sheep is to the right of the horse in the background."
      },
      {
        "from": "gpt",
        "value": "horse: [0.305, 0.219, 0.641, 0.805]\nsheep: [0.695, 0.438, 0.906, 0.750]\nperson: [0.148, 0.680, 0.297, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000263966_key",
    "conversations": [
      {
        "from": "human",
        "value": "A persons hand is visible on the left, a horse is in the center, and a sheep is to the right of the horse in the background.\nObjects: [horse, sheep, person]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.305, 0.219, 0.641, 0.805]\nsheep: [0.695, 0.438, 0.906, 0.750]\nperson: [0.148, 0.680, 0.297, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000264335",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is in flight in the center of the image, against a clear blue sky."
      },
      {
        "from": "gpt",
        "value": "bird: [0.219, 0.070, 0.664, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000264335_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is in flight in the center of the image, against a clear blue sky.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.219, 0.070, 0.664, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000264335_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a soaring seagull is in flight in the center of the image, against a clear blue sky."
      },
      {
        "from": "gpt",
        "value": "soaring seagull: [0.219, 0.070, 0.664, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000264335_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a soaring seagull is in flight in the center of the image, against a clear blue sky.\nObjects: [soaring seagull]"
      },
      {
        "from": "gpt",
        "value": "soaring seagull: [0.219, 0.070, 0.664, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000264335_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.219, 0.070, 0.664, 0.922]\nGiven the above layout, shift the bird to the right by 0.094."
      },
      {
        "from": "gpt",
        "value": "bird: [0.312, 0.070, 0.758, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000264535",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on the right side of a bench."
      },
      {
        "from": "gpt",
        "value": "bench: [0.078, 0.406, 0.703, 0.938]\nperson: [0.609, 0.258, 0.961, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000264535_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on the right side of a bench.\nObjects: [bench, person]"
      },
      {
        "from": "gpt",
        "value": "bench: [0.078, 0.406, 0.703, 0.938]\nperson: [0.609, 0.258, 0.961, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000264535_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a person is sitting on the right side of a bench."
      },
      {
        "from": "gpt",
        "value": "bench: [0.078, 0.406, 0.703, 0.938]\nperson: [0.609, 0.258, 0.961, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000264535_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a person is sitting on the right side of a bench.\nObjects: [bench, person]"
      },
      {
        "from": "gpt",
        "value": "bench: [0.078, 0.406, 0.703, 0.938]\nperson: [0.609, 0.258, 0.961, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000264535_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bench: [0.078, 0.406, 0.703, 0.938]\nperson: [0.609, 0.258, 0.961, 0.797]\nGiven the above layout, shift the person upwards by 0.109."
      },
      {
        "from": "gpt",
        "value": "bench: [0.078, 0.406, 0.703, 0.938]\nperson: [0.609, 0.148, 0.961, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000266409",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center of the image with snowshoes on snow, surrounded by trees."
      },
      {
        "from": "gpt",
        "value": "person: [0.508, 0.359, 0.703, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000266409_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center of the image with snowshoes on snow, surrounded by trees.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.508, 0.359, 0.703, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000266409_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a man bundled in winter attire is in the center of the image with snowshoes on snow, surrounded by trees."
      },
      {
        "from": "gpt",
        "value": "a man bundled in winter attire: [0.508, 0.359, 0.703, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000266409_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a man bundled in winter attire is in the center of the image with snowshoes on snow, surrounded by trees.\nObjects: [a man bundled in winter attire]"
      },
      {
        "from": "gpt",
        "value": "a man bundled in winter attire: [0.508, 0.359, 0.703, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000266409_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.508, 0.359, 0.703, 0.828]\nGiven the above layout, shift the person to the left by 0.414."
      },
      {
        "from": "gpt",
        "value": "person: [0.094, 0.359, 0.289, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000267903",
    "conversations": [
      {
        "from": "human",
        "value": "A sink is mounted on the wall to the left of a toilet."
      },
      {
        "from": "gpt",
        "value": "sink: [0.117, 0.188, 0.516, 0.453]\ntoilet: [0.547, 0.547, 0.812, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000267903_key",
    "conversations": [
      {
        "from": "human",
        "value": "A sink is mounted on the wall to the left of a toilet.\nObjects: [sink, toilet]"
      },
      {
        "from": "gpt",
        "value": "sink: [0.117, 0.188, 0.516, 0.453]\ntoilet: [0.547, 0.547, 0.812, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000267903_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a porcelain sink is mounted on the wall to the left of a white ceramic toilet."
      },
      {
        "from": "gpt",
        "value": "porcelain sink: [0.117, 0.188, 0.516, 0.453]\nwhite ceramic toilet: [0.547, 0.547, 0.812, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000267903_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a porcelain sink is mounted on the wall to the left of a white ceramic toilet.\nObjects: [porcelain sink, white ceramic toilet]"
      },
      {
        "from": "gpt",
        "value": "porcelain sink: [0.117, 0.188, 0.516, 0.453]\nwhite ceramic toilet: [0.547, 0.547, 0.812, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000267903_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sink: [0.117, 0.188, 0.516, 0.453]\ntoilet: [0.547, 0.547, 0.812, 0.828]\nGiven the above layout, shift the sink upwards by 0.117."
      },
      {
        "from": "gpt",
        "value": "sink: [0.117, 0.070, 0.516, 0.336]\ntoilet: [0.547, 0.547, 0.812, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000267940",
    "conversations": [
      {
        "from": "human",
        "value": "A boat docked on the right side of the image, with its reflection visible in the water."
      },
      {
        "from": "gpt",
        "value": "boat: [0.273, 0.352, 0.844, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000267940_key",
    "conversations": [
      {
        "from": "human",
        "value": "A boat docked on the right side of the image, with its reflection visible in the water.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.273, 0.352, 0.844, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000267940_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a yellow speedboat docked on the right side of the image, with its reflection visible in the water."
      },
      {
        "from": "gpt",
        "value": "yellow speedboat: [0.273, 0.352, 0.844, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000267940_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a yellow speedboat docked on the right side of the image, with its reflection visible in the water.\nObjects: [yellow speedboat]"
      },
      {
        "from": "gpt",
        "value": "yellow speedboat: [0.273, 0.352, 0.844, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000267940_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.273, 0.352, 0.844, 0.570]\nGiven the above layout, shift the boat downwards by 0.078."
      },
      {
        "from": "gpt",
        "value": "boat: [0.273, 0.430, 0.844, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000269121",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing with a tennis racket raised above their head in the act of serving."
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.047, 0.680, 0.922]\ntennis racket: [0.633, 0.328, 0.797, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000269121_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing with a tennis racket raised above their head in the act of serving.\nObjects: [person, tennis racket]"
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.047, 0.680, 0.922]\ntennis racket: [0.633, 0.328, 0.797, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000269121_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tennis player is standing with a professional tennis racket raised above their head in the act of serving."
      },
      {
        "from": "gpt",
        "value": "tennis player: [0.352, 0.047, 0.680, 0.922]\nprofessional tennis racket: [0.633, 0.328, 0.797, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000269121_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tennis player is standing with a professional tennis racket raised above their head in the act of serving.\nObjects: [tennis player, professional tennis racket]"
      },
      {
        "from": "gpt",
        "value": "tennis player: [0.352, 0.047, 0.680, 0.922]\nprofessional tennis racket: [0.633, 0.328, 0.797, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000269121_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.352, 0.047, 0.680, 0.922]\ntennis racket: [0.633, 0.328, 0.797, 0.523]\nGiven the above layout, shift the person to the left by 0.258."
      },
      {
        "from": "gpt",
        "value": "person: [0.094, 0.047, 0.422, 0.922]\ntennis racket: [0.633, 0.328, 0.797, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000269314",
    "conversations": [
      {
        "from": "human",
        "value": "A cluster of bananas hanging from a tree branch at the top right of the image."
      },
      {
        "from": "gpt",
        "value": "banana: [0.141, 0.531, 0.438, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000269314_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cluster of bananas hanging from a tree branch at the top right of the image.\nObjects: [banana]"
      },
      {
        "from": "gpt",
        "value": "banana: [0.141, 0.531, 0.438, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000269314_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a cluster of bunch of ripe bananass hanging from a tree branch at the top right of the image."
      },
      {
        "from": "gpt",
        "value": "bunch of ripe bananas: [0.141, 0.531, 0.438, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000269314_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a cluster of bunch of ripe bananass hanging from a tree branch at the top right of the image.\nObjects: [bunch of ripe bananas]"
      },
      {
        "from": "gpt",
        "value": "bunch of ripe bananas: [0.141, 0.531, 0.438, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000269314_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: banana: [0.141, 0.531, 0.438, 0.797]\nGiven the above layout, shift the banana to the right by 0.391."
      },
      {
        "from": "gpt",
        "value": "banana: [0.531, 0.531, 0.828, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000286907",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is located in the center of the image, against a blue wall in the corner of the room."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.484, 0.531, 0.719, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000286907_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is located in the center of the image, against a blue wall in the corner of the room.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.484, 0.531, 0.719, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000286907_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the white porcelain pedestal toilet is located in the center of the image, against a blue wall in the corner of the room."
      },
      {
        "from": "gpt",
        "value": "white porcelain pedestal toilet: [0.484, 0.531, 0.719, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000286907_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the white porcelain pedestal toilet is located in the center of the image, against a blue wall in the corner of the room.\nObjects: [white porcelain pedestal toilet]"
      },
      {
        "from": "gpt",
        "value": "white porcelain pedestal toilet: [0.484, 0.531, 0.719, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000286907_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.484, 0.531, 0.719, 0.875]\nGiven the above layout, shift the toilet upwards by 0.180."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.484, 0.352, 0.719, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000300341",
    "conversations": [
      {
        "from": "human",
        "value": "Two people are standing in the foreground facing each other, each holding a game controller. A third person is sitting in the background, slightly to the right, watching them."
      },
      {
        "from": "gpt",
        "value": "person: [0.625, 0.164, 0.930, 0.828]\nperson: [0.070, 0.289, 0.391, 0.820]\nperson: [0.445, 0.688, 0.555, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000300341_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two people are standing in the foreground facing each other, each holding a game controller. A third person is sitting in the background, slightly to the right, watching them.\nObjects: [person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.625, 0.164, 0.930, 0.828]\nperson: [0.070, 0.289, 0.391, 0.820]\nperson: [0.445, 0.688, 0.555, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000303818",
    "conversations": [
      {
        "from": "human",
        "value": "A car is in front of a bus on the road."
      },
      {
        "from": "gpt",
        "value": "bus: [0.609, 0.102, 0.867, 0.484]\ncar: [0.133, 0.305, 0.336, 0.430]"
      }
    ]
  },
  {
    "id": "coco_000000303818_key",
    "conversations": [
      {
        "from": "human",
        "value": "A car is in front of a bus on the road.\nObjects: [bus, car]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.609, 0.102, 0.867, 0.484]\ncar: [0.133, 0.305, 0.336, 0.430]"
      }
    ]
  },
  {
    "id": "coco_000000303818_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red sedan is in front of a city bus on the road."
      },
      {
        "from": "gpt",
        "value": "city bus: [0.609, 0.102, 0.867, 0.484]\nred sedan: [0.133, 0.305, 0.336, 0.430]"
      }
    ]
  },
  {
    "id": "coco_000000303818_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red sedan is in front of a city bus on the road.\nObjects: [city bus, red sedan]"
      },
      {
        "from": "gpt",
        "value": "city bus: [0.609, 0.102, 0.867, 0.484]\nred sedan: [0.133, 0.305, 0.336, 0.430]"
      }
    ]
  },
  {
    "id": "coco_000000303818_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.609, 0.102, 0.867, 0.484]\ncar: [0.133, 0.305, 0.336, 0.430]\nGiven the above layout, shift the bus downwards by 0.297."
      },
      {
        "from": "gpt",
        "value": "bus: [0.609, 0.398, 0.867, 0.781]\ncar: [0.133, 0.305, 0.336, 0.430]"
      }
    ]
  },
  {
    "id": "coco_000000304291",
    "conversations": [
      {
        "from": "human",
        "value": "A horse is walking towards the camera, positioned at the center of the image."
      },
      {
        "from": "gpt",
        "value": "horse: [0.422, 0.320, 0.648, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000304291_key",
    "conversations": [
      {
        "from": "human",
        "value": "A horse is walking towards the camera, positioned at the center of the image.\nObjects: [horse]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.422, 0.320, 0.648, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000304291_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a gray stallion is walking towards the camera, positioned at the center of the image."
      },
      {
        "from": "gpt",
        "value": "gray stallion: [0.422, 0.320, 0.648, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000304291_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a gray stallion is walking towards the camera, positioned at the center of the image.\nObjects: [gray stallion]"
      },
      {
        "from": "gpt",
        "value": "gray stallion: [0.422, 0.320, 0.648, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000304291_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: horse: [0.422, 0.320, 0.648, 0.750]\nGiven the above layout, shift the horse to the left by 0.148."
      },
      {
        "from": "gpt",
        "value": "horse: [0.273, 0.320, 0.500, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000304404",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the center swinging a bat, a person to the left crouching, and a group of people in the background observing."
      },
      {
        "from": "gpt",
        "value": "person: [0.258, 0.305, 0.531, 0.648]\nperson: [0.000, 0.422, 0.156, 0.664]\nperson: [0.617, 0.352, 0.680, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000304404_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the center swinging a bat, a person to the left crouching, and a group of people in the background observing.\nObjects: [person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.258, 0.305, 0.531, 0.648]\nperson: [0.000, 0.422, 0.156, 0.664]\nperson: [0.617, 0.352, 0.680, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000304817",
    "conversations": [
      {
        "from": "human",
        "value": "The snowboard is leaning against a dark fence, placed vertically with the front side facing towards the right."
      },
      {
        "from": "gpt",
        "value": "snowboard: [0.055, 0.453, 0.914, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000304817_key",
    "conversations": [
      {
        "from": "human",
        "value": "The snowboard is leaning against a dark fence, placed vertically with the front side facing towards the right.\nObjects: [snowboard]"
      },
      {
        "from": "gpt",
        "value": "snowboard: [0.055, 0.453, 0.914, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000304817_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the bright red snowboard is leaning against a dark fence, placed vertically with the front side facing towards the right."
      },
      {
        "from": "gpt",
        "value": "bright red snowboard: [0.055, 0.453, 0.914, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000304817_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the bright red snowboard is leaning against a dark fence, placed vertically with the front side facing towards the right.\nObjects: [bright red snowboard]"
      },
      {
        "from": "gpt",
        "value": "bright red snowboard: [0.055, 0.453, 0.914, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000304817_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: snowboard: [0.055, 0.453, 0.914, 0.812]\nGiven the above layout, shift the snowboard upwards by 0.406."
      },
      {
        "from": "gpt",
        "value": "snowboard: [0.055, 0.047, 0.914, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000307658",
    "conversations": [
      {
        "from": "human",
        "value": "A bear's face is at the center of the image, facing forward."
      },
      {
        "from": "gpt",
        "value": "bear: [0.047, 0.086, 0.859, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000307658_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bears face is at the center of the image, facing forward.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.047, 0.086, 0.859, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000307658_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a grizzly bear's face is at the center of the image, facing forward."
      },
      {
        "from": "gpt",
        "value": "grizzly bear: [0.047, 0.086, 0.859, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000307658_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a grizzly bears face is at the center of the image, facing forward.\nObjects: [grizzly bear]"
      },
      {
        "from": "gpt",
        "value": "grizzly bear: [0.047, 0.086, 0.859, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000307658_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.047, 0.086, 0.859, 0.977]\nGiven the above layout, shift the bear to the right by 0.031."
      },
      {
        "from": "gpt",
        "value": "bear: [0.078, 0.086, 0.891, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000309452",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is perched on a branch slightly to the right of the center of the image."
      },
      {
        "from": "gpt",
        "value": "bird: [0.383, 0.336, 0.602, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000309452_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is perched on a branch slightly to the right of the center of the image.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.383, 0.336, 0.602, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000309452_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a small sparrow is perched on a branch slightly to the right of the center of the image."
      },
      {
        "from": "gpt",
        "value": "small sparrow: [0.383, 0.336, 0.602, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000309452_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a small sparrow is perched on a branch slightly to the right of the center of the image.\nObjects: [small sparrow]"
      },
      {
        "from": "gpt",
        "value": "small sparrow: [0.383, 0.336, 0.602, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000309452_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.383, 0.336, 0.602, 0.859]\nGiven the above layout, shift the bird to the right by 0.094."
      },
      {
        "from": "gpt",
        "value": "bird: [0.477, 0.336, 0.695, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000312278",
    "conversations": [
      {
        "from": "human",
        "value": "Two suitcases are stacked on top of each other; the bottom one has travel stickers and is on the left, and the top one is plain and to the right."
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.094, 0.305, 0.578, 0.633]\nsuitcase: [0.578, 0.367, 0.953, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000312278_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two suitcases are stacked on top of each other; the bottom one has travel stickers and is on the left, and the top one is plain and to the right.\nObjects: [suitcase, suitcase]"
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.094, 0.305, 0.578, 0.633]\nsuitcase: [0.578, 0.367, 0.953, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000312586",
    "conversations": [
      {
        "from": "human",
        "value": "A bear is at the center of the image, with its head facing to the right."
      },
      {
        "from": "gpt",
        "value": "bear: [0.281, 0.539, 0.680, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000312586_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bear is at the center of the image, with its head facing to the right.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.281, 0.539, 0.680, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000312586_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a brown grizzly bear is at the center of the image, with its head facing to the right."
      },
      {
        "from": "gpt",
        "value": "brown grizzly bear: [0.281, 0.539, 0.680, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000312586_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a brown grizzly bear is at the center of the image, with its head facing to the right.\nObjects: [brown grizzly bear]"
      },
      {
        "from": "gpt",
        "value": "brown grizzly bear: [0.281, 0.539, 0.680, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000312586_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.281, 0.539, 0.680, 0.758]\nGiven the above layout, shift the bear upwards by 0.523."
      },
      {
        "from": "gpt",
        "value": "bear: [0.281, 0.016, 0.680, 0.234]"
      }
    ]
  },
  {
    "id": "coco_000000315450",
    "conversations": [
      {
        "from": "human",
        "value": "One bus is in the center facing left; another bus is to the right of the first bus, also facing left."
      },
      {
        "from": "gpt",
        "value": "bus: [0.250, 0.336, 0.672, 0.633]\nbus: [0.656, 0.352, 0.992, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000315450_key",
    "conversations": [
      {
        "from": "human",
        "value": "One bus is in the center facing left; another bus is to the right of the first bus, also facing left.\nObjects: [bus, bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.250, 0.336, 0.672, 0.633]\nbus: [0.656, 0.352, 0.992, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000317433",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the right guiding two horses that are to the left of the person."
      },
      {
        "from": "gpt",
        "value": "horse: [0.383, 0.203, 0.719, 0.781]\nhorse: [0.695, 0.266, 0.984, 0.781]\nperson: [0.047, 0.383, 0.195, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000317433_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the right guiding two horses that are to the left of the person.\nObjects: [horse, horse, person]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.383, 0.203, 0.719, 0.781]\nhorse: [0.695, 0.266, 0.984, 0.781]\nperson: [0.047, 0.383, 0.195, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000319696",
    "conversations": [
      {
        "from": "human",
        "value": "A red microwave is on the left side, a clear bottle is in the center, and a potted plant is to the right of the bottle, all on a countertop."
      },
      {
        "from": "gpt",
        "value": "microwave: [0.031, 0.305, 0.602, 0.656]\nbottle: [0.719, 0.344, 0.820, 0.609]\npotted plant: [0.867, 0.164, 0.992, 0.375]"
      }
    ]
  },
  {
    "id": "coco_000000319696_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red microwave is on the left side, a clear bottle is in the center, and a potted plant is to the right of the bottle, all on a countertop.\nObjects: [microwave, bottle, potted plant]"
      },
      {
        "from": "gpt",
        "value": "microwave: [0.031, 0.305, 0.602, 0.656]\nbottle: [0.719, 0.344, 0.820, 0.609]\npotted plant: [0.867, 0.164, 0.992, 0.375]"
      }
    ]
  },
  {
    "id": "coco_000000337987",
    "conversations": [
      {
        "from": "human",
        "value": "A bird perched on a branch at the center of the image."
      },
      {
        "from": "gpt",
        "value": "bird: [0.242, 0.211, 0.648, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000337987_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bird perched on a branch at the center of the image.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.242, 0.211, 0.648, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000337987_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a petite red breasted robin perched on a branch at the center of the image."
      },
      {
        "from": "gpt",
        "value": "petite red breasted robin: [0.242, 0.211, 0.648, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000337987_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a petite red breasted robin perched on a branch at the center of the image.\nObjects: [petite red breasted robin]"
      },
      {
        "from": "gpt",
        "value": "petite red breasted robin: [0.242, 0.211, 0.648, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000337987_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.242, 0.211, 0.648, 0.867]\nGiven the above layout, shift the bird to the right by 0.148."
      },
      {
        "from": "gpt",
        "value": "bird: [0.391, 0.211, 0.797, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000357567",
    "conversations": [
      {
        "from": "human",
        "value": "A toilet is visible to the right of a closed shower curtain with striped patterns, partially obscured by a wall corner in the foreground."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.562, 0.562, 0.867, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000357567_key",
    "conversations": [
      {
        "from": "human",
        "value": "A toilet is visible to the right of a closed shower curtain with striped patterns, partially obscured by a wall corner in the foreground.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.562, 0.562, 0.867, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000357567_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a porcelain sink is visible to the right of a closed shower curtain with striped patterns, partially obscured by a wall corner in the foreground."
      },
      {
        "from": "gpt",
        "value": "porcelain sink: [0.562, 0.562, 0.867, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000357567_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a porcelain sink is visible to the right of a closed shower curtain with striped patterns, partially obscured by a wall corner in the foreground.\nObjects: [porcelain sink]"
      },
      {
        "from": "gpt",
        "value": "porcelain sink: [0.562, 0.562, 0.867, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000357567_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.562, 0.562, 0.867, 0.961]\nGiven the above layout, shift the toilet to the left by 0.219."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.344, 0.562, 0.648, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000359781",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe stands in the center of the image facing to the right."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.180, 0.133, 0.836, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000359781_key",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe stands in the center of the image facing to the right.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.180, 0.133, 0.836, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000359781_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a long-necked camel stands in the center of the image facing to the right."
      },
      {
        "from": "gpt",
        "value": "long-necked camel: [0.180, 0.133, 0.836, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000359781_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a long-necked camel stands in the center of the image facing to the right.\nObjects: [long-necked camel]"
      },
      {
        "from": "gpt",
        "value": "long-necked camel: [0.180, 0.133, 0.836, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000359781_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.180, 0.133, 0.836, 0.852]\nGiven the above layout, shift the giraffe to the left by 0.164."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.016, 0.133, 0.672, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000359855",
    "conversations": [
      {
        "from": "human",
        "value": "The suitcase is lying on its side on the ground, partially covered by green plants."
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.219, 0.133, 0.867, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000359855_key",
    "conversations": [
      {
        "from": "human",
        "value": "The suitcase is lying on its side on the ground, partially covered by green plants.\nObjects: [suitcase]"
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.219, 0.133, 0.867, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000359855_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the blue leather suitcase is lying on its side on the ground, partially covered by green plants."
      },
      {
        "from": "gpt",
        "value": "blue leather suitcase: [0.219, 0.133, 0.867, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000359855_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the blue leather suitcase is lying on its side on the ground, partially covered by green plants.\nObjects: [blue leather suitcase]"
      },
      {
        "from": "gpt",
        "value": "blue leather suitcase: [0.219, 0.133, 0.867, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000359855_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: suitcase: [0.219, 0.133, 0.867, 0.609]\nGiven the above layout, shift the suitcase downwards by 0.227."
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.219, 0.359, 0.867, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000361103",
    "conversations": [
      {
        "from": "human",
        "value": "A traffic light is on the left side of the image with a person standing underneath it, facing away. Another traffic light is visible in the distance towards the center-right with a person crossing the street underneath it."
      },
      {
        "from": "gpt",
        "value": "traffic light: [0.000, 0.266, 0.258, 0.789]\ntraffic light: [0.273, 0.508, 0.406, 0.805]\nperson: [0.422, 0.625, 0.516, 0.812]\nperson: [0.766, 0.641, 0.828, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000361103_key",
    "conversations": [
      {
        "from": "human",
        "value": "A traffic light is on the left side of the image with a person standing underneath it, facing away. Another traffic light is visible in the distance towards the center-right with a person crossing the street underneath it.\nObjects: [traffic light, traffic light, person, person]"
      },
      {
        "from": "gpt",
        "value": "traffic light: [0.000, 0.266, 0.258, 0.789]\ntraffic light: [0.273, 0.508, 0.406, 0.805]\nperson: [0.422, 0.625, 0.516, 0.812]\nperson: [0.766, 0.641, 0.828, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000364587",
    "conversations": [
      {
        "from": "human",
        "value": "The train is at the center of the image moving towards the left side."
      },
      {
        "from": "gpt",
        "value": "train: [0.273, 0.352, 0.672, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000364587_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is at the center of the image moving towards the left side.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.273, 0.352, 0.672, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000364587_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the streamlined locomotive is at the center of the image moving towards the left side."
      },
      {
        "from": "gpt",
        "value": "streamlined locomotive: [0.273, 0.352, 0.672, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000364587_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the streamlined locomotive is at the center of the image moving towards the left side.\nObjects: [streamlined locomotive]"
      },
      {
        "from": "gpt",
        "value": "streamlined locomotive: [0.273, 0.352, 0.672, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000364587_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.273, 0.352, 0.672, 0.711]\nGiven the above layout, shift the train upwards by 0.156."
      },
      {
        "from": "gpt",
        "value": "train: [0.273, 0.195, 0.672, 0.555]"
      }
    ]
  },
  {
    "id": "coco_000000366611",
    "conversations": [
      {
        "from": "human",
        "value": "The dog is at the center left of the image, lying on the ground with a ball between its paws."
      },
      {
        "from": "gpt",
        "value": "dog: [0.000, 0.383, 0.266, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000366611_key",
    "conversations": [
      {
        "from": "human",
        "value": "The dog is at the center left of the image, lying on the ground with a ball between its paws.\nObjects: [dog]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.000, 0.383, 0.266, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000366611_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the Labrador retriever is at the center left of the image, lying on the ground with a ball between its paws."
      },
      {
        "from": "gpt",
        "value": "Labrador retriever: [0.000, 0.383, 0.266, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000366611_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the Labrador retriever is at the center left of the image, lying on the ground with a ball between its paws.\nObjects: [Labrador retriever]"
      },
      {
        "from": "gpt",
        "value": "Labrador retriever: [0.000, 0.383, 0.266, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000366611_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.000, 0.383, 0.266, 0.711]\nGiven the above layout, shift the dog to the right by 0.039."
      },
      {
        "from": "gpt",
        "value": "dog: [0.039, 0.383, 0.305, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000368456",
    "conversations": [
      {
        "from": "human",
        "value": "The train is at the center of the image, parallel to the bottom edge."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.141, 0.984, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000368456_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is at the center of the image, parallel to the bottom edge.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.141, 0.984, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000368456_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the blue freight train is at the center of the image, parallel to the bottom edge."
      },
      {
        "from": "gpt",
        "value": "blue freight train: [0.000, 0.141, 0.984, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000368456_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the blue freight train is at the center of the image, parallel to the bottom edge.\nObjects: [blue freight train]"
      },
      {
        "from": "gpt",
        "value": "blue freight train: [0.000, 0.141, 0.984, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000368456_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.141, 0.984, 0.648]\nGiven the above layout, shift the train downwards by 0.102."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.242, 0.984, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000369675",
    "conversations": [
      {
        "from": "human",
        "value": "The train is positioned horizontally in the center of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.305, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000369675_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is positioned horizontally in the center of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.305, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000369675_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the blue passenger train is positioned horizontally in the center of the image."
      },
      {
        "from": "gpt",
        "value": "blue passenger train: [0.008, 0.305, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000369675_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the blue passenger train is positioned horizontally in the center of the image.\nObjects: [blue passenger train]"
      },
      {
        "from": "gpt",
        "value": "blue passenger train: [0.008, 0.305, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000369675_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.008, 0.305, 0.992, 0.805]\nGiven the above layout, shift the train upwards by 0.125."
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.180, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000374369",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing with skis on snow at the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.172, 0.594, 0.688]\nskis: [0.297, 0.625, 0.727, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000374369_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing with skis on snow at the center of the image.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.172, 0.594, 0.688]\nskis: [0.297, 0.625, 0.727, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000374369_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in blue ski suit is standing with red racing skis on snow at the center of the image."
      },
      {
        "from": "gpt",
        "value": "woman in blue ski suit: [0.352, 0.172, 0.594, 0.688]\nred racing skis: [0.297, 0.625, 0.727, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000374369_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in blue ski suit is standing with red racing skis on snow at the center of the image.\nObjects: [woman in blue ski suit, red racing skis]"
      },
      {
        "from": "gpt",
        "value": "woman in blue ski suit: [0.352, 0.172, 0.594, 0.688]\nred racing skis: [0.297, 0.625, 0.727, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000374369_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.352, 0.172, 0.594, 0.688]\nskis: [0.297, 0.625, 0.727, 0.719]\nGiven the above layout, shift the skis to the left by 0.086."
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.172, 0.594, 0.688]\nskis: [0.211, 0.625, 0.641, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000378139",
    "conversations": [
      {
        "from": "human",
        "value": "The boat is in the center of the canal, moving towards the foreground of the image."
      },
      {
        "from": "gpt",
        "value": "boat: [0.180, 0.516, 0.758, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000378139_key",
    "conversations": [
      {
        "from": "human",
        "value": "The boat is in the center of the canal, moving towards the foreground of the image.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.180, 0.516, 0.758, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000378139_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red and white sailboat is in the center of the canal, moving towards the foreground of the image."
      },
      {
        "from": "gpt",
        "value": "red and white sailboat: [0.180, 0.516, 0.758, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000378139_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red and white sailboat is in the center of the canal, moving towards the foreground of the image.\nObjects: [red and white sailboat]"
      },
      {
        "from": "gpt",
        "value": "red and white sailboat: [0.180, 0.516, 0.758, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000378139_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.180, 0.516, 0.758, 0.664]\nGiven the above layout, shift the boat upwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "boat: [0.180, 0.492, 0.758, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000379800",
    "conversations": [
      {
        "from": "human",
        "value": "The train is approaching from the right, moving towards the left side of the image on train tracks."
      },
      {
        "from": "gpt",
        "value": "train: [0.336, 0.281, 0.805, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000379800_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is approaching from the right, moving towards the left side of the image on train tracks.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.336, 0.281, 0.805, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000379800_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the royal blue freight train is approaching from the right, moving towards the left side of the image on royal blue freight train tracks."
      },
      {
        "from": "gpt",
        "value": "royal blue freight train: [0.336, 0.281, 0.805, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000379800_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the royal blue freight train is approaching from the right, moving towards the left side of the image on royal blue freight train tracks.\nObjects: [royal blue freight train]"
      },
      {
        "from": "gpt",
        "value": "royal blue freight train: [0.336, 0.281, 0.805, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000379800_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.336, 0.281, 0.805, 0.766]\nGiven the above layout, shift the train to the left by 0.320."
      },
      {
        "from": "gpt",
        "value": "train: [0.016, 0.281, 0.484, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000397279",
    "conversations": [
      {
        "from": "human",
        "value": "The person is on the right, bending forward slightly in preparation to play a shot on the tennis court."
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.305, 0.789, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000397279_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is on the right, bending forward slightly in preparation to play a shot on the tennis court.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.305, 0.789, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000397279_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the male tennis player is on the right, bending forward slightly in preparation to play a shot on the tennis court."
      },
      {
        "from": "gpt",
        "value": "male tennis player: [0.406, 0.305, 0.789, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000397279_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the male tennis player is on the right, bending forward slightly in preparation to play a shot on the tennis court.\nObjects: [male tennis player]"
      },
      {
        "from": "gpt",
        "value": "male tennis player: [0.406, 0.305, 0.789, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000397279_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.406, 0.305, 0.789, 0.680]\nGiven the above layout, shift the person to the left by 0.148."
      },
      {
        "from": "gpt",
        "value": "person: [0.258, 0.305, 0.641, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000424545",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is lying at the center of the image near a window."
      },
      {
        "from": "gpt",
        "value": "cat: [0.289, 0.211, 0.992, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000424545_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is lying at the center of the image near a window.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.289, 0.211, 0.992, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000424545_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a Siamese kitten is lying at the center of the image near a window."
      },
      {
        "from": "gpt",
        "value": "Siamese kitten: [0.289, 0.211, 0.992, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000424545_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a Siamese kitten is lying at the center of the image near a window.\nObjects: [Siamese kitten]"
      },
      {
        "from": "gpt",
        "value": "Siamese kitten: [0.289, 0.211, 0.992, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000424545_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.289, 0.211, 0.992, 0.742]\nGiven the above layout, shift the cat to the left by 0.211."
      },
      {
        "from": "gpt",
        "value": "cat: [0.078, 0.211, 0.781, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000429598",
    "conversations": [
      {
        "from": "human",
        "value": "A refrigerator is to the left, an oven is in the center, and a sink is to the right."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.000, 0.289, 0.297, 0.859]\noven: [0.508, 0.406, 0.766, 0.617]\nsink: [0.766, 0.570, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000429598_key",
    "conversations": [
      {
        "from": "human",
        "value": "A refrigerator is to the left, an oven is in the center, and a sink is to the right.\nObjects: [refrigerator, oven, sink]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.000, 0.289, 0.297, 0.859]\noven: [0.508, 0.406, 0.766, 0.617]\nsink: [0.766, 0.570, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000429598_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a silver stainless steel refrigerator is to the left, an black modern oven is in the center, and a double-basin sink is to the right."
      },
      {
        "from": "gpt",
        "value": "silver stainless steel refrigerator: [0.000, 0.289, 0.297, 0.859]\nblack modern oven: [0.508, 0.406, 0.766, 0.617]\ndouble-basin sink: [0.766, 0.570, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000429598_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a silver stainless steel refrigerator is to the left, an black modern oven is in the center, and a double-basin sink is to the right.\nObjects: [silver stainless steel refrigerator, black modern oven, double-basin sink]"
      },
      {
        "from": "gpt",
        "value": "silver stainless steel refrigerator: [0.000, 0.289, 0.297, 0.859]\nblack modern oven: [0.508, 0.406, 0.766, 0.617]\ndouble-basin sink: [0.766, 0.570, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000429598_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: refrigerator: [0.000, 0.289, 0.297, 0.859]\noven: [0.508, 0.406, 0.766, 0.617]\nsink: [0.766, 0.570, 0.992, 0.680]\nGiven the above layout, shift the refrigerator upwards by 0.258."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.000, 0.031, 0.297, 0.602]\noven: [0.508, 0.406, 0.766, 0.617]\nsink: [0.766, 0.570, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000430377",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing with skis on snow."
      },
      {
        "from": "gpt",
        "value": "person: [0.281, 0.070, 0.570, 0.867]\nskis: [0.180, 0.859, 0.773, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000430377_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing with skis on snow.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.281, 0.070, 0.570, 0.867]\nskis: [0.180, 0.859, 0.773, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000430377_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a man in a snowsuit is standing with pair of professional ski equipment on snow."
      },
      {
        "from": "gpt",
        "value": "man in a snowsuit: [0.281, 0.070, 0.570, 0.867]\npair of professional ski equipment: [0.180, 0.859, 0.773, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000430377_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a man in a snowsuit is standing with pair of professional ski equipment on snow.\nObjects: [man in a snowsuit, pair of professional ski equipment]"
      },
      {
        "from": "gpt",
        "value": "man in a snowsuit: [0.281, 0.070, 0.570, 0.867]\npair of professional ski equipment: [0.180, 0.859, 0.773, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000430377_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.281, 0.070, 0.570, 0.867]\nskis: [0.180, 0.859, 0.773, 0.961]\nGiven the above layout, shift the skis to the right by 0.188."
      },
      {
        "from": "gpt",
        "value": "person: [0.281, 0.070, 0.570, 0.867]\nskis: [0.367, 0.859, 0.961, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000430973",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza is placed at the center on a wooden pizza peel."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.055, 0.211, 0.945, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000430973_key",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza is placed at the center on a wooden pizza peel.\nObjects: [pizza]"
      },
      {
        "from": "gpt",
        "value": "pizza: [0.055, 0.211, 0.945, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000430973_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a margherita pizza is placed at the center on a wooden margherita pizza peel."
      },
      {
        "from": "gpt",
        "value": "margherita pizza: [0.055, 0.211, 0.945, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000430973_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a margherita pizza is placed at the center on a wooden margherita pizza peel.\nObjects: [margherita pizza]"
      },
      {
        "from": "gpt",
        "value": "margherita pizza: [0.055, 0.211, 0.945, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000430973_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: pizza: [0.055, 0.211, 0.945, 0.773]\nGiven the above layout, shift the pizza downwards by 0.195."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.055, 0.406, 0.945, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000431896",
    "conversations": [
      {
        "from": "human",
        "value": "A train on the right, parallel to the platform on the left, under a twilight sky."
      },
      {
        "from": "gpt",
        "value": "train: [0.164, 0.250, 0.891, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000431896_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train on the right, parallel to the platform on the left, under a twilight sky.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.164, 0.250, 0.891, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000431896_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek high-speed train on the right, parallel to the platform on the left, under a twilight sky."
      },
      {
        "from": "gpt",
        "value": "sleek high-speed train: [0.164, 0.250, 0.891, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000431896_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek high-speed train on the right, parallel to the platform on the left, under a twilight sky.\nObjects: [sleek high-speed train]"
      },
      {
        "from": "gpt",
        "value": "sleek high-speed train: [0.164, 0.250, 0.891, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000431896_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.164, 0.250, 0.891, 0.789]\nGiven the above layout, shift the train upwards by 0.047."
      },
      {
        "from": "gpt",
        "value": "train: [0.164, 0.203, 0.891, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000434548",
    "conversations": [
      {
        "from": "human",
        "value": "A person is positioned at the center of the image, throwing a baseball with their right arm."
      },
      {
        "from": "gpt",
        "value": "person: [0.281, 0.320, 0.547, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000434548_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is positioned at the center of the image, throwing a baseball with their right arm.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.281, 0.320, 0.547, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000434548_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a adult man in sports attire is positioned at the center of the image, throwing a baseball with their right arm."
      },
      {
        "from": "gpt",
        "value": "adult man in sports attire: [0.281, 0.320, 0.547, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000434548_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a adult man in sports attire is positioned at the center of the image, throwing a baseball with their right arm.\nObjects: [adult man in sports attire]"
      },
      {
        "from": "gpt",
        "value": "adult man in sports attire: [0.281, 0.320, 0.547, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000434548_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.281, 0.320, 0.547, 0.797]\nGiven the above layout, shift the person to the right by 0.344."
      },
      {
        "from": "gpt",
        "value": "person: [0.625, 0.320, 0.891, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000437514",
    "conversations": [
      {
        "from": "human",
        "value": "A potted plant is to the right of a bench."
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.586, 0.070, 0.977, 0.891]\nbench: [0.039, 0.375, 0.672, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000437514_key",
    "conversations": [
      {
        "from": "human",
        "value": "A potted plant is to the right of a bench.\nObjects: [potted plant, bench]"
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.586, 0.070, 0.977, 0.891]\nbench: [0.039, 0.375, 0.672, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000437514_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a bonsai tree is to the right of a a wooden park bench."
      },
      {
        "from": "gpt",
        "value": "a bonsai tree: [0.586, 0.070, 0.977, 0.891]\na wooden park bench: [0.039, 0.375, 0.672, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000437514_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a bonsai tree is to the right of a a wooden park bench.\nObjects: [a bonsai tree, a wooden park bench]"
      },
      {
        "from": "gpt",
        "value": "a bonsai tree: [0.586, 0.070, 0.977, 0.891]\na wooden park bench: [0.039, 0.375, 0.672, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000437514_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: potted plant: [0.586, 0.070, 0.977, 0.891]\nbench: [0.039, 0.375, 0.672, 0.852]\nGiven the above layout, shift the potted plant downwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.586, 0.141, 0.977, 0.961]\nbench: [0.039, 0.375, 0.672, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000440336",
    "conversations": [
      {
        "from": "human",
        "value": "Four people playing a game outside; one person in the foreground on the right, one in the center, and two people in the background on the left."
      },
      {
        "from": "gpt",
        "value": "person: [0.195, 0.391, 0.453, 0.727]\nperson: [0.531, 0.383, 0.688, 0.672]\nperson: [0.867, 0.352, 0.992, 0.688]\nperson: [0.375, 0.422, 0.469, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000440336_key",
    "conversations": [
      {
        "from": "human",
        "value": "Four people playing a game outside; one person in the foreground on the right, one in the center, and two people in the background on the left.\nObjects: [person, person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.195, 0.391, 0.453, 0.727]\nperson: [0.531, 0.383, 0.688, 0.672]\nperson: [0.867, 0.352, 0.992, 0.688]\nperson: [0.375, 0.422, 0.469, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000440508",
    "conversations": [
      {
        "from": "human",
        "value": "A train is moving from left to right through a wooded area, with the locomotive at the front."
      },
      {
        "from": "gpt",
        "value": "train: [0.328, 0.406, 0.812, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000440508_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is moving from left to right through a wooded area, with the locomotive at the front.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.328, 0.406, 0.812, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000440508_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a vintage passenger train is moving from left to right through a wooded area, with the locomotive at the front."
      },
      {
        "from": "gpt",
        "value": "vintage passenger train: [0.328, 0.406, 0.812, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000440508_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a vintage passenger train is moving from left to right through a wooded area, with the locomotive at the front.\nObjects: [vintage passenger train]"
      },
      {
        "from": "gpt",
        "value": "vintage passenger train: [0.328, 0.406, 0.812, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000440508_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.328, 0.406, 0.812, 0.797]\nGiven the above layout, shift the train upwards by 0.180."
      },
      {
        "from": "gpt",
        "value": "train: [0.328, 0.227, 0.812, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000442661",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe standing in front of a window, with its head near the top of the frame."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.172, 0.320, 0.562, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000442661_key",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe standing in front of a window, with its head near the top of the frame.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.172, 0.320, 0.562, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000442661_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a long-necked elephant standing in front of a window, with its head near the top of the frame."
      },
      {
        "from": "gpt",
        "value": "long-necked elephant: [0.172, 0.320, 0.562, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000442661_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a long-necked elephant standing in front of a window, with its head near the top of the frame.\nObjects: [long-necked elephant]"
      },
      {
        "from": "gpt",
        "value": "long-necked elephant: [0.172, 0.320, 0.562, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000442661_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.172, 0.320, 0.562, 0.867]\nGiven the above layout, shift the giraffe to the right by 0.047."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.219, 0.320, 0.609, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000446005",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is to the right of the sink, both embedded in kitchen counters."
      },
      {
        "from": "gpt",
        "value": "oven: [0.602, 0.500, 0.812, 0.820]\nsink: [0.102, 0.562, 0.344, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000446005_key",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is to the right of the sink, both embedded in kitchen counters.\nObjects: [oven, sink]"
      },
      {
        "from": "gpt",
        "value": "oven: [0.602, 0.500, 0.812, 0.820]\nsink: [0.102, 0.562, 0.344, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000446005_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel oven is to the right of the modern kitchen sink, both embedded in kitchen counters."
      },
      {
        "from": "gpt",
        "value": "stainless steel oven: [0.602, 0.500, 0.812, 0.820]\nmodern kitchen sink: [0.102, 0.562, 0.344, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000446005_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel oven is to the right of the modern kitchen sink, both embedded in kitchen counters.\nObjects: [stainless steel oven, modern kitchen sink]"
      },
      {
        "from": "gpt",
        "value": "stainless steel oven: [0.602, 0.500, 0.812, 0.820]\nmodern kitchen sink: [0.102, 0.562, 0.344, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000446005_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: oven: [0.602, 0.500, 0.812, 0.820]\nsink: [0.102, 0.562, 0.344, 0.609]\nGiven the above layout, shift the oven upwards by 0.438."
      },
      {
        "from": "gpt",
        "value": "oven: [0.602, 0.062, 0.812, 0.383]\nsink: [0.102, 0.562, 0.344, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000446206",
    "conversations": [
      {
        "from": "human",
        "value": "There is a train on elevated tracks above and to the right of a bus on the road."
      },
      {
        "from": "gpt",
        "value": "train: [0.188, 0.438, 0.984, 0.547]\nbus: [0.023, 0.625, 0.289, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000446206_key",
    "conversations": [
      {
        "from": "human",
        "value": "There is a train on elevated tracks above and to the right of a bus on the road.\nObjects: [train, bus]"
      },
      {
        "from": "gpt",
        "value": "train: [0.188, 0.438, 0.984, 0.547]\nbus: [0.023, 0.625, 0.289, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000446206_aug",
    "conversations": [
      {
        "from": "human",
        "value": "there is a fast moving express train on elevated tracks above and to the right of a city transit bus on the road."
      },
      {
        "from": "gpt",
        "value": "fast moving express train: [0.188, 0.438, 0.984, 0.547]\ncity transit bus: [0.023, 0.625, 0.289, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000446206_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "there is a fast moving express train on elevated tracks above and to the right of a city transit bus on the road.\nObjects: [fast moving express train, city transit bus]"
      },
      {
        "from": "gpt",
        "value": "fast moving express train: [0.188, 0.438, 0.984, 0.547]\ncity transit bus: [0.023, 0.625, 0.289, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000446206_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.188, 0.438, 0.984, 0.547]\nbus: [0.023, 0.625, 0.289, 0.773]\nGiven the above layout, shift the train upwards by 0.320."
      },
      {
        "from": "gpt",
        "value": "train: [0.188, 0.117, 0.984, 0.227]\nbus: [0.023, 0.625, 0.289, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000446703",
    "conversations": [
      {
        "from": "human",
        "value": "The teddy bear is lying on its side at the bottom left inside a wooden cupboard."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.180, 0.375, 0.805, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000446703_key",
    "conversations": [
      {
        "from": "human",
        "value": "The teddy bear is lying on its side at the bottom left inside a wooden cupboard.\nObjects: [teddy bear]"
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.180, 0.375, 0.805, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000446703_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the fluffy stuffed rabbit is lying on its side at the bottom left inside a wooden cupboard."
      },
      {
        "from": "gpt",
        "value": "fluffy stuffed rabbit: [0.180, 0.375, 0.805, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000446703_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the fluffy stuffed rabbit is lying on its side at the bottom left inside a wooden cupboard.\nObjects: [fluffy stuffed rabbit]"
      },
      {
        "from": "gpt",
        "value": "fluffy stuffed rabbit: [0.180, 0.375, 0.805, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000446703_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: teddy bear: [0.180, 0.375, 0.805, 0.695]\nGiven the above layout, shift the teddy bear upwards by 0.281."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.180, 0.094, 0.805, 0.414]"
      }
    ]
  },
  {
    "id": "coco_000000471567",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe's head is at the center of the image, with trees and a building in the background."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.250, 0.305, 0.688, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000471567_key",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffes head is at the center of the image, with trees and a building in the background.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.250, 0.305, 0.688, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000471567_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall dinosaur with a long neck's head is at the center of the image, with trees and a building in the background."
      },
      {
        "from": "gpt",
        "value": "tall dinosaur with a long neck: [0.250, 0.305, 0.688, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000471567_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall dinosaur with a long necks head is at the center of the image, with trees and a building in the background.\nObjects: [tall dinosaur with a long neck]"
      },
      {
        "from": "gpt",
        "value": "tall dinosaur with a long neck: [0.250, 0.305, 0.688, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000471567_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.250, 0.305, 0.688, 0.648]\nGiven the above layout, shift the giraffe downwards by 0.273."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.250, 0.578, 0.688, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000481573",
    "conversations": [
      {
        "from": "human",
        "value": "A skateboard is in the foreground with a person standing behind it."
      },
      {
        "from": "gpt",
        "value": "skateboard: [0.000, 0.234, 0.688, 0.992]\nperson: [0.586, 0.133, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000481573_key",
    "conversations": [
      {
        "from": "human",
        "value": "A skateboard is in the foreground with a person standing behind it.\nObjects: [skateboard, person]"
      },
      {
        "from": "gpt",
        "value": "skateboard: [0.000, 0.234, 0.688, 0.992]\nperson: [0.586, 0.133, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000481573_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a bright yellow skateboard is in the foreground with a young man standing behind it."
      },
      {
        "from": "gpt",
        "value": "bright yellow skateboard: [0.000, 0.234, 0.688, 0.992]\nyoung man: [0.586, 0.133, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000481573_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a bright yellow skateboard is in the foreground with a young man standing behind it.\nObjects: [bright yellow skateboard, young man]"
      },
      {
        "from": "gpt",
        "value": "bright yellow skateboard: [0.000, 0.234, 0.688, 0.992]\nyoung man: [0.586, 0.133, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000481573_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: skateboard: [0.000, 0.234, 0.688, 0.992]\nperson: [0.586, 0.133, 0.867, 0.977]\nGiven the above layout, shift the person upwards by 0.031."
      },
      {
        "from": "gpt",
        "value": "skateboard: [0.000, 0.234, 0.688, 0.992]\nperson: [0.586, 0.102, 0.867, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000483531",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is positioned in the center of the image, with the headboard against the wall."
      },
      {
        "from": "gpt",
        "value": "bed: [0.172, 0.531, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000483531_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is positioned in the center of the image, with the headboard against the wall.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.172, 0.531, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000483531_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the white double bed is positioned in the center of the image, with the headboard against the wall."
      },
      {
        "from": "gpt",
        "value": "white double bed: [0.172, 0.531, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000483531_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the white double bed is positioned in the center of the image, with the headboard against the wall.\nObjects: [white double bed]"
      },
      {
        "from": "gpt",
        "value": "white double bed: [0.172, 0.531, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000483531_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.172, 0.531, 0.992, 0.867]\nGiven the above layout, shift the bed upwards by 0.164."
      },
      {
        "from": "gpt",
        "value": "bed: [0.172, 0.367, 0.992, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000486046",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe is in the foreground on the right, and a zebra is in the background on the left."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.305, 0.164, 0.891, 0.859]\nzebra: [0.117, 0.703, 0.258, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000486046_key",
    "conversations": [
      {
        "from": "human",
        "value": "A giraffe is in the foreground on the right, and a zebra is in the background on the left.\nObjects: [giraffe, zebra]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.305, 0.164, 0.891, 0.859]\nzebra: [0.117, 0.703, 0.258, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000486046_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall giraffe with spotted patterns is in the foreground on the right, and a black and white striped zebra is in the background on the left."
      },
      {
        "from": "gpt",
        "value": "tall giraffe with spotted patterns: [0.305, 0.164, 0.891, 0.859]\nblack and white striped zebra: [0.117, 0.703, 0.258, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000486046_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall giraffe with spotted patterns is in the foreground on the right, and a black and white striped zebra is in the background on the left.\nObjects: [tall giraffe with spotted patterns, black and white striped zebra]"
      },
      {
        "from": "gpt",
        "value": "tall giraffe with spotted patterns: [0.305, 0.164, 0.891, 0.859]\nblack and white striped zebra: [0.117, 0.703, 0.258, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000486046_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.305, 0.164, 0.891, 0.859]\nzebra: [0.117, 0.703, 0.258, 0.867]\nGiven the above layout, shift the giraffe upwards by 0.086."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.305, 0.078, 0.891, 0.773]\nzebra: [0.117, 0.703, 0.258, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000488075",
    "conversations": [
      {
        "from": "human",
        "value": "Two chairs facing each other in the foreground, with a refrigerator visible in the background to the right."
      },
      {
        "from": "gpt",
        "value": "chair: [0.641, 0.516, 0.930, 0.820]\nchair: [0.898, 0.625, 0.992, 0.812]\nrefrigerator: [0.367, 0.305, 0.414, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000488075_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two chairs facing each other in the foreground, with a refrigerator visible in the background to the right.\nObjects: [chair, chair, refrigerator]"
      },
      {
        "from": "gpt",
        "value": "chair: [0.641, 0.516, 0.930, 0.820]\nchair: [0.898, 0.625, 0.992, 0.812]\nrefrigerator: [0.367, 0.305, 0.414, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000491613",
    "conversations": [
      {
        "from": "human",
        "value": "A zebra stands on the right side of the image, next to a reflective water body on the left where the zebra's reflection is visible."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.188, 0.047, 0.531, 0.398]"
      }
    ]
  },
  {
    "id": "coco_000000491613_key",
    "conversations": [
      {
        "from": "human",
        "value": "A zebra stands on the right side of the image, next to a reflective water body on the left where the zebras reflection is visible.\nObjects: [zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.188, 0.047, 0.531, 0.398]"
      }
    ]
  },
  {
    "id": "coco_000000491613_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a striped horse stands on the right side of the image, next to a reflective water body on the left where the striped horse's reflection is visible."
      },
      {
        "from": "gpt",
        "value": "striped horse: [0.188, 0.047, 0.531, 0.398]"
      }
    ]
  },
  {
    "id": "coco_000000491613_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a striped horse stands on the right side of the image, next to a reflective water body on the left where the striped horses reflection is visible.\nObjects: [striped horse]"
      },
      {
        "from": "gpt",
        "value": "striped horse: [0.188, 0.047, 0.531, 0.398]"
      }
    ]
  },
  {
    "id": "coco_000000491613_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: zebra: [0.188, 0.047, 0.531, 0.398]\nGiven the above layout, shift the zebra downwards by 0.312."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.188, 0.359, 0.531, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000493613",
    "conversations": [
      {
        "from": "human",
        "value": "A skateboard is in the center of the image, with its front end lifted slightly off the ground."
      },
      {
        "from": "gpt",
        "value": "skateboard: [0.359, 0.445, 0.883, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000493613_key",
    "conversations": [
      {
        "from": "human",
        "value": "A skateboard is in the center of the image, with its front end lifted slightly off the ground.\nObjects: [skateboard]"
      },
      {
        "from": "gpt",
        "value": "skateboard: [0.359, 0.445, 0.883, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000493613_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a light purple skateboard is in the center of the image, with its front end lifted slightly off the ground."
      },
      {
        "from": "gpt",
        "value": "light purple skateboard: [0.359, 0.445, 0.883, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000493613_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a light purple skateboard is in the center of the image, with its front end lifted slightly off the ground.\nObjects: [light purple skateboard]"
      },
      {
        "from": "gpt",
        "value": "light purple skateboard: [0.359, 0.445, 0.883, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000493613_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: skateboard: [0.359, 0.445, 0.883, 0.594]\nGiven the above layout, shift the skateboard upwards by 0.203."
      },
      {
        "from": "gpt",
        "value": "skateboard: [0.359, 0.242, 0.883, 0.391]"
      }
    ]
  },
  {
    "id": "coco_000000497568",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is parked on the tarmac in the center of the image, with the terminal building behind it."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.000, 0.281, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000497568_key",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is parked on the tarmac in the center of the image, with the terminal building behind it.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.000, 0.281, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000497568_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the blue commercial jet is parked on the tarmac in the center of the image, with the terminal building behind it."
      },
      {
        "from": "gpt",
        "value": "blue commercial jet: [0.000, 0.281, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000497568_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the blue commercial jet is parked on the tarmac in the center of the image, with the terminal building behind it.\nObjects: [blue commercial jet]"
      },
      {
        "from": "gpt",
        "value": "blue commercial jet: [0.000, 0.281, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000497568_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.000, 0.281, 0.992, 0.766]\nGiven the above layout, shift the airplane upwards by 0.227."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.000, 0.055, 0.992, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000498709",
    "conversations": [
      {
        "from": "human",
        "value": "A close-up view of the front part of a green motorcycle with its round headlight at the center."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.000, 0.227, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000498709_key",
    "conversations": [
      {
        "from": "human",
        "value": "A close-up view of the front part of a green motorcycle with its round headlight at the center.\nObjects: [motorcycle]"
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.000, 0.227, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000498709_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a close-up view of the front part of a green vintage green motorcycle with its round headlight at the center."
      },
      {
        "from": "gpt",
        "value": "vintage green motorcycle: [0.000, 0.227, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000498709_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a close-up view of the front part of a green vintage green motorcycle with its round headlight at the center.\nObjects: [vintage green motorcycle]"
      },
      {
        "from": "gpt",
        "value": "vintage green motorcycle: [0.000, 0.227, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000498709_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: motorcycle: [0.000, 0.227, 0.992, 0.820]\nGiven the above layout, shift the motorcycle upwards by 0.055."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.000, 0.172, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000499031",
    "conversations": [
      {
        "from": "human",
        "value": "Three people standing side by side in front of a Chiquita Banana backdrop."
      },
      {
        "from": "gpt",
        "value": "person: [0.609, 0.227, 0.828, 0.891]\nperson: [0.352, 0.305, 0.531, 0.891]\nperson: [0.172, 0.273, 0.336, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000499031_key",
    "conversations": [
      {
        "from": "human",
        "value": "Three people standing side by side in front of a Chiquita Banana backdrop.\nObjects: [person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.609, 0.227, 0.828, 0.891]\nperson: [0.352, 0.305, 0.531, 0.891]\nperson: [0.172, 0.273, 0.336, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000500423",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks positioned horizontally across the image, with the side facing the viewer."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.180, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000500423_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks positioned horizontally across the image, with the side facing the viewer.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.180, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000500423_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the steam-powered train is on the tracks positioned horizontally across the image, with the side facing the viewer."
      },
      {
        "from": "gpt",
        "value": "steam-powered train: [0.000, 0.180, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000500423_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the steam-powered train is on the tracks positioned horizontally across the image, with the side facing the viewer.\nObjects: [steam-powered train]"
      },
      {
        "from": "gpt",
        "value": "steam-powered train: [0.000, 0.180, 0.992, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000500423_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.180, 0.992, 0.680]\nGiven the above layout, shift the train downwards by 0.297."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.477, 0.992, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000504439",
    "conversations": [
      {
        "from": "human",
        "value": "One zebra is facing the camera at the center, and another zebra is facing away to the right."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.000, 0.258, 0.375, 0.734]\nzebra: [0.578, 0.422, 0.969, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000504439_key",
    "conversations": [
      {
        "from": "human",
        "value": "One zebra is facing the camera at the center, and another zebra is facing away to the right.\nObjects: [zebra, zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.000, 0.258, 0.375, 0.734]\nzebra: [0.578, 0.422, 0.969, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000506454",
    "conversations": [
      {
        "from": "human",
        "value": "A bench is at the center, surrounded by grass with a tree directly behind it."
      },
      {
        "from": "gpt",
        "value": "bench: [0.320, 0.367, 0.703, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000506454_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bench is at the center, surrounded by grass with a tree directly behind it.\nObjects: [bench]"
      },
      {
        "from": "gpt",
        "value": "bench: [0.320, 0.367, 0.703, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000506454_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a wooden bench is at the center, surrounded by grass with a tree directly behind it."
      },
      {
        "from": "gpt",
        "value": "wooden bench: [0.320, 0.367, 0.703, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000506454_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a wooden bench is at the center, surrounded by grass with a tree directly behind it.\nObjects: [wooden bench]"
      },
      {
        "from": "gpt",
        "value": "wooden bench: [0.320, 0.367, 0.703, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000506454_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bench: [0.320, 0.367, 0.703, 0.562]\nGiven the above layout, shift the bench downwards by 0.031."
      },
      {
        "from": "gpt",
        "value": "bench: [0.320, 0.398, 0.703, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000522940",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is at the center of the image on a post."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.117, 0.023, 0.672, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000522940_key",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is at the center of the image on a post.\nObjects: [stop sign]"
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.117, 0.023, 0.672, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000522940_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red hexagonal traffic sign is at the center of the image on a post."
      },
      {
        "from": "gpt",
        "value": "red hexagonal traffic sign: [0.117, 0.023, 0.672, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000522940_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red hexagonal traffic sign is at the center of the image on a post.\nObjects: [red hexagonal traffic sign]"
      },
      {
        "from": "gpt",
        "value": "red hexagonal traffic sign: [0.117, 0.023, 0.672, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000522940_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: stop sign: [0.117, 0.023, 0.672, 0.594]\nGiven the above layout, shift the stop sign downwards by 0.352."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.117, 0.375, 0.672, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000545100",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on the right side of the image, looking out towards the cityscape."
      },
      {
        "from": "gpt",
        "value": "person: [0.602, 0.352, 0.875, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000545100_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on the right side of the image, looking out towards the cityscape.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.602, 0.352, 0.875, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000545100_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman is standing on the right side of the image, looking out towards the cityscape."
      },
      {
        "from": "gpt",
        "value": "young woman: [0.602, 0.352, 0.875, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000545100_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman is standing on the right side of the image, looking out towards the cityscape.\nObjects: [young woman]"
      },
      {
        "from": "gpt",
        "value": "young woman: [0.602, 0.352, 0.875, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000545100_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.602, 0.352, 0.875, 0.828]\nGiven the above layout, shift the person to the left by 0.570."
      },
      {
        "from": "gpt",
        "value": "person: [0.031, 0.352, 0.305, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000546659",
    "conversations": [
      {
        "from": "human",
        "value": "A black steam train is on the tracks moving from right to left with buildings in the background."
      },
      {
        "from": "gpt",
        "value": "train: [0.242, 0.562, 0.820, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000546659_key",
    "conversations": [
      {
        "from": "human",
        "value": "A black steam train is on the tracks moving from right to left with buildings in the background.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.242, 0.562, 0.820, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000546659_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a black steam vintage black steam engine is on the tracks moving from right to left with buildings in the background."
      },
      {
        "from": "gpt",
        "value": "vintage black steam engine: [0.242, 0.562, 0.820, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000546659_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a black steam vintage black steam engine is on the tracks moving from right to left with buildings in the background.\nObjects: [vintage black steam engine]"
      },
      {
        "from": "gpt",
        "value": "vintage black steam engine: [0.242, 0.562, 0.820, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000546659_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.242, 0.562, 0.820, 0.852]\nGiven the above layout, shift the train upwards by 0.531."
      },
      {
        "from": "gpt",
        "value": "train: [0.242, 0.031, 0.820, 0.320]"
      }
    ]
  },
  {
    "id": "coco_000000549738",
    "conversations": [
      {
        "from": "human",
        "value": "A colorful kite flying in the sky at the center of the image."
      },
      {
        "from": "gpt",
        "value": "kite: [0.148, 0.406, 0.469, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000549738_key",
    "conversations": [
      {
        "from": "human",
        "value": "A colorful kite flying in the sky at the center of the image.\nObjects: [kite]"
      },
      {
        "from": "gpt",
        "value": "kite: [0.148, 0.406, 0.469, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000549738_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a colorful large red and blue kite flying in the sky at the center of the image."
      },
      {
        "from": "gpt",
        "value": "large red and blue kite: [0.148, 0.406, 0.469, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000549738_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a colorful large red and blue kite flying in the sky at the center of the image.\nObjects: [large red and blue kite]"
      },
      {
        "from": "gpt",
        "value": "large red and blue kite: [0.148, 0.406, 0.469, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000549738_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: kite: [0.148, 0.406, 0.469, 0.703]\nGiven the above layout, shift the kite to the right by 0.273."
      },
      {
        "from": "gpt",
        "value": "kite: [0.422, 0.406, 0.742, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000551215",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a tennis court, appearing to be in motion as if either hitting a ball or preparing to do so."
      },
      {
        "from": "gpt",
        "value": "person: [0.234, 0.109, 0.617, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000551215_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a tennis court, appearing to be in motion as if either hitting a ball or preparing to do so.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.234, 0.109, 0.617, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000551215_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a professional tennis player is standing on a tennis court, appearing to be in motion as if either hitting a ball or preparing to do so."
      },
      {
        "from": "gpt",
        "value": "professional tennis player: [0.234, 0.109, 0.617, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000551215_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a professional tennis player is standing on a tennis court, appearing to be in motion as if either hitting a ball or preparing to do so.\nObjects: [professional tennis player]"
      },
      {
        "from": "gpt",
        "value": "professional tennis player: [0.234, 0.109, 0.617, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000551215_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.234, 0.109, 0.617, 0.789]\nGiven the above layout, shift the person to the right by 0.320."
      },
      {
        "from": "gpt",
        "value": "person: [0.555, 0.109, 0.938, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000553664",
    "conversations": [
      {
        "from": "human",
        "value": "The laptop is open and positioned in the center of the image on a table."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.422, 0.391, 0.859, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000553664_key",
    "conversations": [
      {
        "from": "human",
        "value": "The laptop is open and positioned in the center of the image on a table.\nObjects: [laptop]"
      },
      {
        "from": "gpt",
        "value": "laptop: [0.422, 0.391, 0.859, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000553664_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the silver MacBook is open and positioned in the center of the image on a table."
      },
      {
        "from": "gpt",
        "value": "silver MacBook: [0.422, 0.391, 0.859, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000553664_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the silver MacBook is open and positioned in the center of the image on a table.\nObjects: [silver MacBook]"
      },
      {
        "from": "gpt",
        "value": "silver MacBook: [0.422, 0.391, 0.859, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000553664_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: laptop: [0.422, 0.391, 0.859, 0.680]\nGiven the above layout, shift the laptop to the left by 0.422."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.000, 0.391, 0.438, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000555050",
    "conversations": [
      {
        "from": "human",
        "value": "A car is in the bottom left corner of the image, and a traffic light is visible in the upper left corner."
      },
      {
        "from": "gpt",
        "value": "car: [0.000, 0.531, 0.469, 0.711]\ntraffic light: [0.008, 0.273, 0.070, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000555050_key",
    "conversations": [
      {
        "from": "human",
        "value": "A car is in the bottom left corner of the image, and a traffic light is visible in the upper left corner.\nObjects: [car, traffic light]"
      },
      {
        "from": "gpt",
        "value": "car: [0.000, 0.531, 0.469, 0.711]\ntraffic light: [0.008, 0.273, 0.070, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000555050_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red sports car is in the bottom left corner of the image, and a standard three-color traffic light is visible in the upper left corner."
      },
      {
        "from": "gpt",
        "value": "red sports car: [0.000, 0.531, 0.469, 0.711]\nstandard three-color traffic light: [0.008, 0.273, 0.070, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000555050_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red sports car is in the bottom left corner of the image, and a standard three-color traffic light is visible in the upper left corner.\nObjects: [red sports car, standard three-color traffic light]"
      },
      {
        "from": "gpt",
        "value": "red sports car: [0.000, 0.531, 0.469, 0.711]\nstandard three-color traffic light: [0.008, 0.273, 0.070, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000555050_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: car: [0.000, 0.531, 0.469, 0.711]\ntraffic light: [0.008, 0.273, 0.070, 0.438]\nGiven the above layout, shift the car to the right by 0.250."
      },
      {
        "from": "gpt",
        "value": "car: [0.250, 0.531, 0.719, 0.711]\ntraffic light: [0.008, 0.273, 0.070, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000556765",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant standing in the center of the image in a river."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.359, 0.320, 0.859, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000556765_key",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant standing in the center of the image in a river.\nObjects: [elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.359, 0.320, 0.859, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000556765_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an majestic gray elephant with large tusks standing in the center of the image in a river."
      },
      {
        "from": "gpt",
        "value": "majestic gray elephant with large tusks: [0.359, 0.320, 0.859, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000556765_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an majestic gray elephant with large tusks standing in the center of the image in a river.\nObjects: [majestic gray elephant with large tusks]"
      },
      {
        "from": "gpt",
        "value": "majestic gray elephant with large tusks: [0.359, 0.320, 0.859, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000556765_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: elephant: [0.359, 0.320, 0.859, 0.758]\nGiven the above layout, shift the elephant to the left by 0.242."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.117, 0.320, 0.617, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000569273",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is in the center-right of the image, in focus and in the foreground."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.625, 0.297, 0.891, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000569273_key",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is in the center-right of the image, in focus and in the foreground.\nObjects: [fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.625, 0.297, 0.891, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000569273_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red fire hydrant is in the center-right of the image, in focus and in the foreground."
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.625, 0.297, 0.891, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000569273_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red fire hydrant is in the center-right of the image, in focus and in the foreground.\nObjects: [red fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.625, 0.297, 0.891, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000569273_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: fire hydrant: [0.625, 0.297, 0.891, 0.859]\nGiven the above layout, shift the fire hydrant to the left by 0.453."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.172, 0.297, 0.438, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000572462",
    "conversations": [
      {
        "from": "human",
        "value": "The image is a collage with four segments. On the top left, a train is pictured from the outside. On the top right, there is one person visible looking at a digital display. On the bottom right, inside a train car, there are two people standing and one sitting."
      },
      {
        "from": "gpt",
        "value": "train: [0.023, 0.016, 0.586, 0.477]\nperson: [0.359, 0.609, 0.500, 0.969]\nperson: [0.555, 0.711, 0.703, 0.977]\nperson: [0.688, 0.617, 0.773, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000572462_key",
    "conversations": [
      {
        "from": "human",
        "value": "The image is a collage with four segments. On the top left, a train is pictured from the outside. On the top right, there is one person visible looking at a digital display. On the bottom right, inside a train car, there are two people standing and one sitting.\nObjects: [train, person, person, person]"
      },
      {
        "from": "gpt",
        "value": "train: [0.023, 0.016, 0.586, 0.477]\nperson: [0.359, 0.609, 0.500, 0.969]\nperson: [0.555, 0.711, 0.703, 0.977]\nperson: [0.688, 0.617, 0.773, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000572555",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks positioned to the right side of the image, facing to the left."
      },
      {
        "from": "gpt",
        "value": "train: [0.227, 0.250, 0.906, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000572555_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks positioned to the right side of the image, facing to the left.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.227, 0.250, 0.906, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000572555_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red locomotive is on the tracks positioned to the right side of the image, facing to the left."
      },
      {
        "from": "gpt",
        "value": "red locomotive: [0.227, 0.250, 0.906, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000572555_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red locomotive is on the tracks positioned to the right side of the image, facing to the left.\nObjects: [red locomotive]"
      },
      {
        "from": "gpt",
        "value": "red locomotive: [0.227, 0.250, 0.906, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000572555_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.227, 0.250, 0.906, 0.719]\nGiven the above layout, shift the train downwards by 0.133."
      },
      {
        "from": "gpt",
        "value": "train: [0.227, 0.383, 0.906, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000575081",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left of the TV, facing it and raising one arm towards it."
      },
      {
        "from": "gpt",
        "value": "tv: [0.734, 0.195, 0.992, 0.578]\nperson: [0.336, 0.180, 0.500, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000575081_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left of the TV, facing it and raising one arm towards it.\nObjects: [tv, person]"
      },
      {
        "from": "gpt",
        "value": "tv: [0.734, 0.195, 0.992, 0.578]\nperson: [0.336, 0.180, 0.500, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000575081_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in jeans is standing to the left of the tv, facing it and raising one arm towards it."
      },
      {
        "from": "gpt",
        "value": "tv: [0.734, 0.195, 0.992, 0.578]\nwoman in jeans: [0.336, 0.180, 0.500, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000575081_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in jeans is standing to the left of the tv, facing it and raising one arm towards it.\nObjects: [tv, woman in jeans]"
      },
      {
        "from": "gpt",
        "value": "tv: [0.734, 0.195, 0.992, 0.578]\nwoman in jeans: [0.336, 0.180, 0.500, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000575081_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: tv: [0.734, 0.195, 0.992, 0.578]\nperson: [0.336, 0.180, 0.500, 0.773]\nGiven the above layout, shift the person to the left by 0.117."
      },
      {
        "from": "gpt",
        "value": "tv: [0.734, 0.195, 0.992, 0.578]\nperson: [0.219, 0.180, 0.383, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000575187",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the left is reaching out to touch a giraffe on the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.445, 0.508, 0.812]\ngiraffe: [0.539, 0.227, 0.984, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000575187_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the left is reaching out to touch a giraffe on the right.\nObjects: [person, giraffe]"
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.445, 0.508, 0.812]\ngiraffe: [0.539, 0.227, 0.984, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000575187_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a smiling child on the left is reaching out to touch a tall yellow giraffe on the right."
      },
      {
        "from": "gpt",
        "value": "smiling child: [0.000, 0.445, 0.508, 0.812]\ntall yellow giraffe: [0.539, 0.227, 0.984, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000575187_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a smiling child on the left is reaching out to touch a tall yellow giraffe on the right.\nObjects: [smiling child, tall yellow giraffe]"
      },
      {
        "from": "gpt",
        "value": "smiling child: [0.000, 0.445, 0.508, 0.812]\ntall yellow giraffe: [0.539, 0.227, 0.984, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000575187_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.000, 0.445, 0.508, 0.812]\ngiraffe: [0.539, 0.227, 0.984, 0.453]\nGiven the above layout, shift the giraffe upwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.445, 0.508, 0.812]\ngiraffe: [0.539, 0.188, 0.984, 0.414]"
      }
    ]
  },
  {
    "id": "coco_000000575205",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is in the center of the image, taking off with the nose angled upward from a runway."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.195, 0.484, 0.727, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000575205_key",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is in the center of the image, taking off with the nose angled upward from a runway.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.195, 0.484, 0.727, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000575205_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red passenger jet is in the center of the image, taking off with the nose angled upward from a runway."
      },
      {
        "from": "gpt",
        "value": "red passenger jet: [0.195, 0.484, 0.727, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000575205_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red passenger jet is in the center of the image, taking off with the nose angled upward from a runway.\nObjects: [red passenger jet]"
      },
      {
        "from": "gpt",
        "value": "red passenger jet: [0.195, 0.484, 0.727, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000575205_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.195, 0.484, 0.727, 0.664]\nGiven the above layout, shift the airplane upwards by 0.297."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.195, 0.188, 0.727, 0.367]"
      }
    ]
  },
  {
    "id": "coco_000000581615",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is centered at the bottom of the image with walls on either side."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.344, 0.602, 0.641, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000581615_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is centered at the bottom of the image with walls on either side.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.344, 0.602, 0.641, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000581615_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the modern white toilet is centered at the bottom of the image with walls on either side."
      },
      {
        "from": "gpt",
        "value": "modern white toilet: [0.344, 0.602, 0.641, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000581615_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the modern white toilet is centered at the bottom of the image with walls on either side.\nObjects: [modern white toilet]"
      },
      {
        "from": "gpt",
        "value": "modern white toilet: [0.344, 0.602, 0.641, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000581615_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.344, 0.602, 0.641, 0.961]\nGiven the above layout, shift the toilet upwards by 0.391."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.344, 0.211, 0.641, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000033368",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing at the center of the image on a tennis court, facing away."
      },
      {
        "from": "gpt",
        "value": "person: [0.414, 0.062, 0.570, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000033368_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing at the center of the image on a tennis court, facing away.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.414, 0.062, 0.570, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000033368_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman playing tennis standing at the center of the image on a tennis court, facing away."
      },
      {
        "from": "gpt",
        "value": "young woman playing tennis: [0.414, 0.062, 0.570, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000033368_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman playing tennis standing at the center of the image on a tennis court, facing away.\nObjects: [young woman playing tennis]"
      },
      {
        "from": "gpt",
        "value": "young woman playing tennis: [0.414, 0.062, 0.570, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000033368_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.414, 0.062, 0.570, 0.672]\nGiven the above layout, shift the person to the right by 0.289."
      },
      {
        "from": "gpt",
        "value": "person: [0.703, 0.062, 0.859, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000050811",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting at a dining table with two bottles in front of them."
      },
      {
        "from": "gpt",
        "value": "person: [0.109, 0.133, 0.719, 0.789]\ndining table: [0.008, 0.727, 0.992, 0.953]\nbottle: [0.812, 0.516, 0.922, 0.945]\nbottle: [0.695, 0.516, 0.812, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000050811_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting at a dining table with two bottles in front of them.\nObjects: [person, dining table, bottle, bottle]"
      },
      {
        "from": "gpt",
        "value": "person: [0.109, 0.133, 0.719, 0.789]\ndining table: [0.008, 0.727, 0.992, 0.953]\nbottle: [0.812, 0.516, 0.922, 0.945]\nbottle: [0.695, 0.516, 0.812, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000052017",
    "conversations": [
      {
        "from": "human",
        "value": "A yellow and blue airplane is flying in the center, slightly towards the right of the image against a cloudy sky."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.078, 0.297, 0.750, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000052017_key",
    "conversations": [
      {
        "from": "human",
        "value": "A yellow and blue airplane is flying in the center, slightly towards the right of the image against a cloudy sky.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.078, 0.297, 0.750, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000052017_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a yellow and blue turquoise and white helicopter is flying in the center, slightly towards the right of the image against a cloudy sky."
      },
      {
        "from": "gpt",
        "value": "turquoise and white helicopter: [0.078, 0.297, 0.750, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000052017_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a yellow and blue turquoise and white helicopter is flying in the center, slightly towards the right of the image against a cloudy sky.\nObjects: [turquoise and white helicopter]"
      },
      {
        "from": "gpt",
        "value": "turquoise and white helicopter: [0.078, 0.297, 0.750, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000052017_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.078, 0.297, 0.750, 0.609]\nGiven the above layout, shift the airplane downwards by 0.016."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.078, 0.312, 0.750, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000052412",
    "conversations": [
      {
        "from": "human",
        "value": "The wing of an airplane is visible in the upper left corner of the image."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.000, 0.258, 0.461, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000052412_key",
    "conversations": [
      {
        "from": "human",
        "value": "The wing of an airplane is visible in the upper left corner of the image.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.000, 0.258, 0.461, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000052412_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the wing of an commercial airliner is visible in the upper left corner of the image."
      },
      {
        "from": "gpt",
        "value": "commercial airliner: [0.000, 0.258, 0.461, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000052412_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the wing of an commercial airliner is visible in the upper left corner of the image.\nObjects: [commercial airliner]"
      },
      {
        "from": "gpt",
        "value": "commercial airliner: [0.000, 0.258, 0.461, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000052412_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.000, 0.258, 0.461, 0.484]\nGiven the above layout, shift the airplane to the right by 0.312."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.312, 0.258, 0.773, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000052591",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing with a pair of skis to their right side."
      },
      {
        "from": "gpt",
        "value": "person: [0.234, 0.141, 0.656, 0.977]\nskis: [0.539, 0.000, 0.648, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000052591_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing with a pair of skis to their right side.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.234, 0.141, 0.656, 0.977]\nskis: [0.539, 0.000, 0.648, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000052591_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a adult skier with winter gear is standing with a pair of pair of red racing skis to their right side."
      },
      {
        "from": "gpt",
        "value": "adult skier with winter gear: [0.234, 0.141, 0.656, 0.977]\npair of red racing skis: [0.539, 0.000, 0.648, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000052591_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a adult skier with winter gear is standing with a pair of pair of red racing skis to their right side.\nObjects: [adult skier with winter gear, pair of red racing skis]"
      },
      {
        "from": "gpt",
        "value": "adult skier with winter gear: [0.234, 0.141, 0.656, 0.977]\npair of red racing skis: [0.539, 0.000, 0.648, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000052591_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.234, 0.141, 0.656, 0.977]\nskis: [0.539, 0.000, 0.648, 0.945]\nGiven the above layout, shift the person to the right by 0.320."
      },
      {
        "from": "gpt",
        "value": "person: [0.555, 0.141, 0.977, 0.977]\nskis: [0.539, 0.000, 0.648, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000056127",
    "conversations": [
      {
        "from": "human",
        "value": "A bench is at the center of the image with an oven to the left and a refrigerator to the right."
      },
      {
        "from": "gpt",
        "value": "bench: [0.562, 0.641, 0.945, 0.898]\noven: [0.242, 0.461, 0.430, 0.734]\nrefrigerator: [0.594, 0.375, 0.797, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000056127_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bench is at the center of the image with an oven to the left and a refrigerator to the right.\nObjects: [bench, oven, refrigerator]"
      },
      {
        "from": "gpt",
        "value": "bench: [0.562, 0.641, 0.945, 0.898]\noven: [0.242, 0.461, 0.430, 0.734]\nrefrigerator: [0.594, 0.375, 0.797, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000056127_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a park bench is at the center of the image with an steel oven to the left and a two-door refrigerator to the right."
      },
      {
        "from": "gpt",
        "value": "park bench: [0.562, 0.641, 0.945, 0.898]\nsteel oven: [0.242, 0.461, 0.430, 0.734]\ntwo-door refrigerator: [0.594, 0.375, 0.797, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000056127_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a park bench is at the center of the image with an steel oven to the left and a two-door refrigerator to the right.\nObjects: [park bench, steel oven, two-door refrigerator]"
      },
      {
        "from": "gpt",
        "value": "park bench: [0.562, 0.641, 0.945, 0.898]\nsteel oven: [0.242, 0.461, 0.430, 0.734]\ntwo-door refrigerator: [0.594, 0.375, 0.797, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000056127_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bench: [0.562, 0.641, 0.945, 0.898]\noven: [0.242, 0.461, 0.430, 0.734]\nrefrigerator: [0.594, 0.375, 0.797, 0.500]\nGiven the above layout, shift the refrigerator upwards by 0.289."
      },
      {
        "from": "gpt",
        "value": "bench: [0.562, 0.641, 0.945, 0.898]\noven: [0.242, 0.461, 0.430, 0.734]\nrefrigerator: [0.594, 0.086, 0.797, 0.211]"
      }
    ]
  },
  {
    "id": "coco_000000065074",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is situated at the center of the image with disheveled blankets and pillows."
      },
      {
        "from": "gpt",
        "value": "bed: [0.172, 0.352, 0.828, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000065074_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is situated at the center of the image with disheveled blankets and pillows.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.172, 0.352, 0.828, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000065074_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the king-size bed with fluffy blankets and plush pillows is situated at the center of the image with disheveled blankets and pillows."
      },
      {
        "from": "gpt",
        "value": "king-size bed with fluffy blankets and plush pillows: [0.172, 0.352, 0.828, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000065074_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the king-size bed with fluffy blankets and plush pillows is situated at the center of the image with disheveled blankets and pillows.\nObjects: [king-size bed with fluffy blankets and plush pillows]"
      },
      {
        "from": "gpt",
        "value": "king-size bed with fluffy blankets and plush pillows: [0.172, 0.352, 0.828, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000065074_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.172, 0.352, 0.828, 0.953]\nGiven the above layout, shift the bed upwards by 0.180."
      },
      {
        "from": "gpt",
        "value": "bed: [0.172, 0.172, 0.828, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000065736",
    "conversations": [
      {
        "from": "human",
        "value": "The person is at the center of the image, playing tennis."
      },
      {
        "from": "gpt",
        "value": "person: [0.289, 0.172, 0.586, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000065736_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is at the center of the image, playing tennis.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.289, 0.172, 0.586, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000065736_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the young man is at the center of the image, playing tennis."
      },
      {
        "from": "gpt",
        "value": "young man: [0.289, 0.172, 0.586, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000065736_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the young man is at the center of the image, playing tennis.\nObjects: [young man]"
      },
      {
        "from": "gpt",
        "value": "young man: [0.289, 0.172, 0.586, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000065736_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.289, 0.172, 0.586, 0.797]\nGiven the above layout, shift the person to the right by 0.188."
      },
      {
        "from": "gpt",
        "value": "person: [0.477, 0.172, 0.773, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000066135",
    "conversations": [
      {
        "from": "human",
        "value": "The train is positioned horizontally on the tracks, with the front facing to the right."
      },
      {
        "from": "gpt",
        "value": "train: [0.016, 0.195, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000066135_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is positioned horizontally on the tracks, with the front facing to the right.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.016, 0.195, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000066135_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the a blue locomotive is positioned horizontally on the tracks, with the front facing to the right."
      },
      {
        "from": "gpt",
        "value": "a blue locomotive: [0.016, 0.195, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000066135_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the a blue locomotive is positioned horizontally on the tracks, with the front facing to the right.\nObjects: [a blue locomotive]"
      },
      {
        "from": "gpt",
        "value": "a blue locomotive: [0.016, 0.195, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000066135_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.016, 0.195, 0.992, 0.820]\nGiven the above layout, shift the train upwards by 0.102."
      },
      {
        "from": "gpt",
        "value": "train: [0.016, 0.094, 0.992, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000067213",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is leaping in the air in front of a row of cars parked in the background."
      },
      {
        "from": "gpt",
        "value": "dog: [0.625, 0.211, 0.930, 0.523]\ncar: [0.000, 0.594, 0.305, 0.758]\ncar: [0.344, 0.633, 0.711, 0.758]\ncar: [0.688, 0.648, 0.961, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000067213_key",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is leaping in the air in front of a row of cars parked in the background.\nObjects: [dog, car, car, car]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.625, 0.211, 0.930, 0.523]\ncar: [0.000, 0.594, 0.305, 0.758]\ncar: [0.344, 0.633, 0.711, 0.758]\ncar: [0.688, 0.648, 0.961, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000067896",
    "conversations": [
      {
        "from": "human",
        "value": "The clock is hanging from a metal structure in the upper right corner of the image."
      },
      {
        "from": "gpt",
        "value": "clock: [0.281, 0.219, 0.742, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000067896_key",
    "conversations": [
      {
        "from": "human",
        "value": "The clock is hanging from a metal structure in the upper right corner of the image.\nObjects: [clock]"
      },
      {
        "from": "gpt",
        "value": "clock: [0.281, 0.219, 0.742, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000067896_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the antique wall clock is hanging from a metal structure in the upper right corner of the image."
      },
      {
        "from": "gpt",
        "value": "antique wall clock: [0.281, 0.219, 0.742, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000067896_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the antique wall clock is hanging from a metal structure in the upper right corner of the image.\nObjects: [antique wall clock]"
      },
      {
        "from": "gpt",
        "value": "antique wall clock: [0.281, 0.219, 0.742, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000067896_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: clock: [0.281, 0.219, 0.742, 0.664]\nGiven the above layout, shift the clock downwards by 0.227."
      },
      {
        "from": "gpt",
        "value": "clock: [0.281, 0.445, 0.742, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000068628",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the air above a skateboard, which is also in mid-air on the left side."
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.164, 0.758, 0.508]\nskateboard: [0.438, 0.469, 0.617, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000068628_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the air above a skateboard, which is also in mid-air on the left side.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.164, 0.758, 0.508]\nskateboard: [0.438, 0.469, 0.617, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000068628_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage red red skateboarder is in the air above a red skateboard, which is also in mid-air on the left side."
      },
      {
        "from": "gpt",
        "value": "teenage red skateboarder: [0.367, 0.164, 0.758, 0.508]\nred skateboard: [0.438, 0.469, 0.617, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000068628_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage red red skateboarder is in the air above a red skateboard, which is also in mid-air on the left side.\nObjects: [teenage red skateboarder, red skateboard]"
      },
      {
        "from": "gpt",
        "value": "teenage red skateboarder: [0.367, 0.164, 0.758, 0.508]\nred skateboard: [0.438, 0.469, 0.617, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000068628_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.367, 0.164, 0.758, 0.508]\nskateboard: [0.438, 0.469, 0.617, 0.641]\nGiven the above layout, shift the person to the left by 0.078."
      },
      {
        "from": "gpt",
        "value": "person: [0.289, 0.164, 0.680, 0.508]\nskateboard: [0.438, 0.469, 0.617, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000069356",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the left side of the image standing behind a fruit stand, a person on the right side facing the fruit stand, and another person in the background walking away to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.117, 0.273, 0.281, 0.859]\nperson: [0.648, 0.305, 0.820, 0.812]\nperson: [0.883, 0.281, 0.977, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000069356_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the left side of the image standing behind a fruit stand, a person on the right side facing the fruit stand, and another person in the background walking away to the right.\nObjects: [person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.117, 0.273, 0.281, 0.859]\nperson: [0.648, 0.305, 0.820, 0.812]\nperson: [0.883, 0.281, 0.977, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000100274",
    "conversations": [
      {
        "from": "human",
        "value": "A train is on the tracks towards the right side of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.414, 0.320, 0.586, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000100274_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is on the tracks towards the right side of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.414, 0.320, 0.586, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000100274_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red cargo train is on the tracks towards the right side of the image."
      },
      {
        "from": "gpt",
        "value": "red cargo train: [0.414, 0.320, 0.586, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000100274_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red cargo train is on the tracks towards the right side of the image.\nObjects: [red cargo train]"
      },
      {
        "from": "gpt",
        "value": "red cargo train: [0.414, 0.320, 0.586, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000100274_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.414, 0.320, 0.586, 0.828]\nGiven the above layout, shift the train to the left by 0.078."
      },
      {
        "from": "gpt",
        "value": "train: [0.336, 0.320, 0.508, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000110359",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is centered in the image flying against a clear blue sky."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.344, 0.398, 0.664, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000110359_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is centered in the image flying against a clear blue sky.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.344, 0.398, 0.664, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000110359_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an silver jet plane is centered in the image flying against a clear blue sky."
      },
      {
        "from": "gpt",
        "value": "silver jet plane: [0.344, 0.398, 0.664, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000110359_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an silver jet plane is centered in the image flying against a clear blue sky.\nObjects: [silver jet plane]"
      },
      {
        "from": "gpt",
        "value": "silver jet plane: [0.344, 0.398, 0.664, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000110359_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.344, 0.398, 0.664, 0.750]\nGiven the above layout, shift the airplane upwards by 0.133."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.344, 0.266, 0.664, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000121673",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a surfboard at the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.305, 0.289, 0.664, 0.602]\nsurfboard: [0.352, 0.602, 0.883, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000121673_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a surfboard at the center of the image.\nObjects: [person, surfboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.305, 0.289, 0.664, 0.602]\nsurfboard: [0.352, 0.602, 0.883, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000121673_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a man in a wetsuit is standing on a blue surfboard at the center of the image."
      },
      {
        "from": "gpt",
        "value": "a man in a wetsuit: [0.305, 0.289, 0.664, 0.602]\nblue surfboard: [0.352, 0.602, 0.883, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000121673_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a man in a wetsuit is standing on a blue surfboard at the center of the image.\nObjects: [a man in a wetsuit, blue surfboard]"
      },
      {
        "from": "gpt",
        "value": "a man in a wetsuit: [0.305, 0.289, 0.664, 0.602]\nblue surfboard: [0.352, 0.602, 0.883, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000121673_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.305, 0.289, 0.664, 0.602]\nsurfboard: [0.352, 0.602, 0.883, 0.695]\nGiven the above layout, shift the person to the left by 0.281."
      },
      {
        "from": "gpt",
        "value": "person: [0.023, 0.289, 0.383, 0.602]\nsurfboard: [0.352, 0.602, 0.883, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000135604",
    "conversations": [
      {
        "from": "human",
        "value": "The person is at the center right of the image, playing soccer on a field."
      },
      {
        "from": "gpt",
        "value": "person: [0.703, 0.227, 0.859, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000135604_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is at the center right of the image, playing soccer on a field.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.703, 0.227, 0.859, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000135604_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the soccer player is at the center right of the image, playing soccer on a field."
      },
      {
        "from": "gpt",
        "value": "soccer player: [0.703, 0.227, 0.859, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000135604_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the soccer player is at the center right of the image, playing soccer on a field.\nObjects: [soccer player]"
      },
      {
        "from": "gpt",
        "value": "soccer player: [0.703, 0.227, 0.859, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000135604_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.703, 0.227, 0.859, 0.688]\nGiven the above layout, shift the person to the left by 0.539."
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.227, 0.320, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000138819",
    "conversations": [
      {
        "from": "human",
        "value": "A sink is mounted on the wall to the left, and a toilet is positioned to the right of the sink."
      },
      {
        "from": "gpt",
        "value": "sink: [0.188, 0.156, 0.727, 0.477]\ntoilet: [0.734, 0.695, 0.961, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000138819_key",
    "conversations": [
      {
        "from": "human",
        "value": "A sink is mounted on the wall to the left, and a toilet is positioned to the right of the sink.\nObjects: [sink, toilet]"
      },
      {
        "from": "gpt",
        "value": "sink: [0.188, 0.156, 0.727, 0.477]\ntoilet: [0.734, 0.695, 0.961, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000138819_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a porcelain basin is mounted on the wall to the left, and a modern bidet is positioned to the right of the porcelain basin."
      },
      {
        "from": "gpt",
        "value": "porcelain basin: [0.188, 0.156, 0.727, 0.477]\nmodern bidet: [0.734, 0.695, 0.961, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000138819_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a porcelain basin is mounted on the wall to the left, and a modern bidet is positioned to the right of the porcelain basin.\nObjects: [porcelain basin, modern bidet]"
      },
      {
        "from": "gpt",
        "value": "porcelain basin: [0.188, 0.156, 0.727, 0.477]\nmodern bidet: [0.734, 0.695, 0.961, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000138819_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sink: [0.188, 0.156, 0.727, 0.477]\ntoilet: [0.734, 0.695, 0.961, 0.867]\nGiven the above layout, shift the sink to the left by 0.133."
      },
      {
        "from": "gpt",
        "value": "sink: [0.055, 0.156, 0.594, 0.477]\ntoilet: [0.734, 0.695, 0.961, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000139077",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left, facing and watching a television on the right."
      },
      {
        "from": "gpt",
        "value": "tv: [0.555, 0.125, 0.867, 0.430]\nperson: [0.258, 0.383, 0.375, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000139077_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left, facing and watching a television on the right.\nObjects: [tv, person]"
      },
      {
        "from": "gpt",
        "value": "tv: [0.555, 0.125, 0.867, 0.430]\nperson: [0.258, 0.383, 0.375, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000139077_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a middle-aged man is standing to the left, facing and watching a television on the right."
      },
      {
        "from": "gpt",
        "value": "sleek flat screen TV: [0.555, 0.125, 0.867, 0.430]\nmiddle-aged man: [0.258, 0.383, 0.375, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000139077_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a middle-aged man is standing to the left, facing and watching a television on the right.\nObjects: [sleek flat screen TV, middle-aged man]"
      },
      {
        "from": "gpt",
        "value": "sleek flat screen TV: [0.555, 0.125, 0.867, 0.430]\nmiddle-aged man: [0.258, 0.383, 0.375, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000139077_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: tv: [0.555, 0.125, 0.867, 0.430]\nperson: [0.258, 0.383, 0.375, 0.805]\nGiven the above layout, shift the person to the left by 0.203."
      },
      {
        "from": "gpt",
        "value": "tv: [0.555, 0.125, 0.867, 0.430]\nperson: [0.055, 0.383, 0.172, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000140286",
    "conversations": [
      {
        "from": "human",
        "value": "A horse harnessed to a carriage on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "horse: [0.148, 0.477, 0.414, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000140286_key",
    "conversations": [
      {
        "from": "human",
        "value": "A horse harnessed to a carriage on the left side of the image.\nObjects: [horse]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.148, 0.477, 0.414, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000140286_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a grey horse harnessed to a carriage on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "grey horse: [0.148, 0.477, 0.414, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000140286_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a grey horse harnessed to a carriage on the left side of the image.\nObjects: [grey horse]"
      },
      {
        "from": "gpt",
        "value": "grey horse: [0.148, 0.477, 0.414, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000140286_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: horse: [0.148, 0.477, 0.414, 0.781]\nGiven the above layout, shift the horse to the right by 0.406."
      },
      {
        "from": "gpt",
        "value": "horse: [0.555, 0.477, 0.820, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000141597",
    "conversations": [
      {
        "from": "human",
        "value": "A truck is parked to the left of a car, and another car is parked to the right of the first car, all aligned in a row on the street."
      },
      {
        "from": "gpt",
        "value": "truck: [0.062, 0.367, 0.617, 0.680]\ncar: [0.586, 0.531, 0.859, 0.711]\ncar: [0.844, 0.539, 0.953, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000141597_key",
    "conversations": [
      {
        "from": "human",
        "value": "A truck is parked to the left of a car, and another car is parked to the right of the first car, all aligned in a row on the street.\nObjects: [truck, car, car]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.062, 0.367, 0.617, 0.680]\ncar: [0.586, 0.531, 0.859, 0.711]\ncar: [0.844, 0.539, 0.953, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000142092",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza is at the center of the image on top of a baking stone."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.227, 0.227, 0.797, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000142092_key",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza is at the center of the image on top of a baking stone.\nObjects: [pizza]"
      },
      {
        "from": "gpt",
        "value": "pizza: [0.227, 0.227, 0.797, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000142092_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a margherita pizza on a wooden serving board is at the center of the image on top of a baking stone."
      },
      {
        "from": "gpt",
        "value": "margherita pizza on a wooden serving board: [0.227, 0.227, 0.797, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000142092_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a margherita pizza on a wooden serving board is at the center of the image on top of a baking stone.\nObjects: [margherita pizza on a wooden serving board]"
      },
      {
        "from": "gpt",
        "value": "margherita pizza on a wooden serving board: [0.227, 0.227, 0.797, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000142092_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: pizza: [0.227, 0.227, 0.797, 0.742]\nGiven the above layout, shift the pizza downwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.227, 0.266, 0.797, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000143572",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center, playing tennis."
      },
      {
        "from": "gpt",
        "value": "person: [0.359, 0.430, 0.641, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000143572_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center, playing tennis.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.359, 0.430, 0.641, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000143572_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a enthusiastic tennis player is standing at the center, playing tennis."
      },
      {
        "from": "gpt",
        "value": "enthusiastic tennis player: [0.359, 0.430, 0.641, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000143572_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a enthusiastic tennis player is standing at the center, playing tennis.\nObjects: [enthusiastic tennis player]"
      },
      {
        "from": "gpt",
        "value": "enthusiastic tennis player: [0.359, 0.430, 0.641, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000143572_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.359, 0.430, 0.641, 0.828]\nGiven the above layout, shift the person upwards by 0.234."
      },
      {
        "from": "gpt",
        "value": "person: [0.359, 0.195, 0.641, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000144114",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying in the center of the image against a cloudy sky."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.039, 0.477, 0.961, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000144114_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying in the center of the image against a cloudy sky.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.039, 0.477, 0.961, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000144114_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an twin-engine jet is flying in the center of the image against a cloudy sky."
      },
      {
        "from": "gpt",
        "value": "twin-engine jet: [0.039, 0.477, 0.961, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000144114_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an twin-engine jet is flying in the center of the image against a cloudy sky.\nObjects: [twin-engine jet]"
      },
      {
        "from": "gpt",
        "value": "twin-engine jet: [0.039, 0.477, 0.961, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000144114_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.039, 0.477, 0.961, 0.734]\nGiven the above layout, shift the airplane upwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.039, 0.453, 0.961, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000170191",
    "conversations": [
      {
        "from": "human",
        "value": "There is a bed in the background and a suitcase to the front right, with a person standing to the right side between them."
      },
      {
        "from": "gpt",
        "value": "bed: [0.000, 0.352, 0.742, 0.883]\nperson: [0.695, 0.102, 0.984, 0.891]\nsuitcase: [0.172, 0.828, 0.438, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000170191_key",
    "conversations": [
      {
        "from": "human",
        "value": "There is a bed in the background and a suitcase to the front right, with a person standing to the right side between them.\nObjects: [bed, person, suitcase]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.000, 0.352, 0.742, 0.883]\nperson: [0.695, 0.102, 0.984, 0.891]\nsuitcase: [0.172, 0.828, 0.438, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000170191_aug",
    "conversations": [
      {
        "from": "human",
        "value": "there is a cozy double bed in the background and a hard-shell travel suitcase to the front right, with a young man standing to the right side between them."
      },
      {
        "from": "gpt",
        "value": "cozy double bed: [0.000, 0.352, 0.742, 0.883]\nyoung man: [0.695, 0.102, 0.984, 0.891]\nhard-shell travel suitcase: [0.172, 0.828, 0.438, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000170191_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "there is a cozy double bed in the background and a hard-shell travel suitcase to the front right, with a young man standing to the right side between them.\nObjects: [cozy double bed, young man, hard-shell travel suitcase]"
      },
      {
        "from": "gpt",
        "value": "cozy double bed: [0.000, 0.352, 0.742, 0.883]\nyoung man: [0.695, 0.102, 0.984, 0.891]\nhard-shell travel suitcase: [0.172, 0.828, 0.438, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000170191_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.000, 0.352, 0.742, 0.883]\nperson: [0.695, 0.102, 0.984, 0.891]\nsuitcase: [0.172, 0.828, 0.438, 0.898]\nGiven the above layout, shift the person upwards by 0.086."
      },
      {
        "from": "gpt",
        "value": "bed: [0.000, 0.352, 0.742, 0.883]\nperson: [0.695, 0.016, 0.984, 0.805]\nsuitcase: [0.172, 0.828, 0.438, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000184762",
    "conversations": [
      {
        "from": "human",
        "value": "The clock is at the center of the image, tilted to the right."
      },
      {
        "from": "gpt",
        "value": "clock: [0.000, 0.125, 0.859, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000184762_key",
    "conversations": [
      {
        "from": "human",
        "value": "The clock is at the center of the image, tilted to the right.\nObjects: [clock]"
      },
      {
        "from": "gpt",
        "value": "clock: [0.000, 0.125, 0.859, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000184762_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the antique wall clock is at the center of the image, tilted to the right."
      },
      {
        "from": "gpt",
        "value": "antique wall clock: [0.000, 0.125, 0.859, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000184762_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the antique wall clock is at the center of the image, tilted to the right.\nObjects: [antique wall clock]"
      },
      {
        "from": "gpt",
        "value": "antique wall clock: [0.000, 0.125, 0.859, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000184762_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: clock: [0.000, 0.125, 0.859, 0.859]\nGiven the above layout, shift the clock to the right by 0.055."
      },
      {
        "from": "gpt",
        "value": "clock: [0.055, 0.125, 0.914, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000186296",
    "conversations": [
      {
        "from": "human",
        "value": "The cat is lying on the floor looking upward, with a blue shoe to its right side."
      },
      {
        "from": "gpt",
        "value": "cat: [0.062, 0.312, 0.898, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000186296_key",
    "conversations": [
      {
        "from": "human",
        "value": "The cat is lying on the floor looking upward, with a blue shoe to its right side.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.062, 0.312, 0.898, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000186296_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the fluffy Persian cat is lying on the floor looking upward, with a blue shoe to its right side."
      },
      {
        "from": "gpt",
        "value": "fluffy Persian cat: [0.062, 0.312, 0.898, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000186296_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the fluffy Persian cat is lying on the floor looking upward, with a blue shoe to its right side.\nObjects: [fluffy Persian cat]"
      },
      {
        "from": "gpt",
        "value": "fluffy Persian cat: [0.062, 0.312, 0.898, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000186296_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.062, 0.312, 0.898, 0.766]\nGiven the above layout, shift the cat upwards by 0.133."
      },
      {
        "from": "gpt",
        "value": "cat: [0.062, 0.180, 0.898, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000191471",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is at the center of the image, with trees and a partly cloudy sky in the background."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.188, 0.156, 0.789, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000191471_key",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is at the center of the image, with trees and a partly cloudy sky in the background.\nObjects: [stop sign]"
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.188, 0.156, 0.789, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000191471_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the yield sign is at the center of the image, with trees and a partly cloudy sky in the background."
      },
      {
        "from": "gpt",
        "value": "yield sign: [0.188, 0.156, 0.789, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000191471_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the yield sign is at the center of the image, with trees and a partly cloudy sky in the background.\nObjects: [yield sign]"
      },
      {
        "from": "gpt",
        "value": "yield sign: [0.188, 0.156, 0.789, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000191471_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: stop sign: [0.188, 0.156, 0.789, 0.773]\nGiven the above layout, shift the stop sign downwards by 0.203."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.188, 0.359, 0.789, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000193494",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is at the center of the image, with a blue motif surrounding it."
      },
      {
        "from": "gpt",
        "value": "bed: [0.273, 0.516, 0.680, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000193494_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is at the center of the image, with a blue motif surrounding it.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.273, 0.516, 0.680, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000193494_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the king-size bed is at the center of the image, with a blue motif surrounding it."
      },
      {
        "from": "gpt",
        "value": "king-size bed: [0.273, 0.516, 0.680, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000193494_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the king-size bed is at the center of the image, with a blue motif surrounding it.\nObjects: [king-size bed]"
      },
      {
        "from": "gpt",
        "value": "king-size bed: [0.273, 0.516, 0.680, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000193494_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.273, 0.516, 0.680, 0.906]\nGiven the above layout, shift the bed upwards by 0.211."
      },
      {
        "from": "gpt",
        "value": "bed: [0.273, 0.305, 0.680, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000194471",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding, with the skateboard under their feet at the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.297, 0.273, 0.633, 0.664]\nskateboard: [0.422, 0.617, 0.680, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000194471_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding, with the skateboard under their feet at the center of the image.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.297, 0.273, 0.633, 0.664]\nskateboard: [0.422, 0.617, 0.680, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000194471_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage boy is blue skateboarding, with the blue skateboard under their feet at the center of the image."
      },
      {
        "from": "gpt",
        "value": "teenage boy: [0.297, 0.273, 0.633, 0.664]\nblue skateboard: [0.422, 0.617, 0.680, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000194471_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage boy is blue skateboarding, with the blue skateboard under their feet at the center of the image.\nObjects: [teenage boy, blue skateboard]"
      },
      {
        "from": "gpt",
        "value": "teenage boy: [0.297, 0.273, 0.633, 0.664]\nblue skateboard: [0.422, 0.617, 0.680, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000194471_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.297, 0.273, 0.633, 0.664]\nskateboard: [0.422, 0.617, 0.680, 0.719]\nGiven the above layout, shift the skateboard to the right by 0.203."
      },
      {
        "from": "gpt",
        "value": "person: [0.297, 0.273, 0.633, 0.664]\nskateboard: [0.625, 0.617, 0.883, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000195918",
    "conversations": [
      {
        "from": "human",
        "value": "Two TVs are next to each other on a table, with the left one turned on and the right one turned off; a laptop is open on the right side of the table, and there is a chair in front of the table."
      },
      {
        "from": "gpt",
        "value": "tv: [0.055, 0.352, 0.375, 0.594]\ntv: [0.469, 0.352, 0.750, 0.555]\nlaptop: [0.820, 0.453, 0.992, 0.680]\nchair: [0.000, 0.750, 0.289, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000195918_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two TVs are next to each other on a table, with the left one turned on and the right one turned off; a laptop is open on the right side of the table, and there is a chair in front of the table.\nObjects: [tv, tv, laptop, chair]"
      },
      {
        "from": "gpt",
        "value": "tv: [0.055, 0.352, 0.375, 0.594]\ntv: [0.469, 0.352, 0.750, 0.555]\nlaptop: [0.820, 0.453, 0.992, 0.680]\nchair: [0.000, 0.750, 0.289, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000196185",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is in the center of the image, taking off above the runway."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.164, 0.406, 0.820, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000196185_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is in the center of the image, taking off above the runway.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.164, 0.406, 0.820, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000196185_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an blue jumbo jet is in the center of the image, taking off above the runway."
      },
      {
        "from": "gpt",
        "value": "blue jumbo jet: [0.164, 0.406, 0.820, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000196185_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an blue jumbo jet is in the center of the image, taking off above the runway.\nObjects: [blue jumbo jet]"
      },
      {
        "from": "gpt",
        "value": "blue jumbo jet: [0.164, 0.406, 0.820, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000196185_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.164, 0.406, 0.820, 0.594]\nGiven the above layout, shift the airplane upwards by 0.047."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.164, 0.359, 0.820, 0.547]"
      }
    ]
  },
  {
    "id": "coco_000000200839",
    "conversations": [
      {
        "from": "human",
        "value": "A colorful bus is parked on the right side of the image on a street, near a grassy area with trees."
      },
      {
        "from": "gpt",
        "value": "bus: [0.141, 0.383, 0.719, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000200839_key",
    "conversations": [
      {
        "from": "human",
        "value": "A colorful bus is parked on the right side of the image on a street, near a grassy area with trees.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.141, 0.383, 0.719, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000200839_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a colorful double-decker bus is parked on the right side of the image on a street, near a grassy area with trees."
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.141, 0.383, 0.719, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000200839_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a colorful double-decker bus is parked on the right side of the image on a street, near a grassy area with trees.\nObjects: [double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.141, 0.383, 0.719, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000200839_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.141, 0.383, 0.719, 0.617]\nGiven the above layout, shift the bus upwards by 0.141."
      },
      {
        "from": "gpt",
        "value": "bus: [0.141, 0.242, 0.719, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000205834",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is sitting behind a bowl to the right."
      },
      {
        "from": "gpt",
        "value": "dog: [0.203, 0.195, 0.836, 0.797]\nbowl: [0.219, 0.625, 0.578, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000205834_key",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is sitting behind a bowl to the right.\nObjects: [dog, bowl]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.203, 0.195, 0.836, 0.797]\nbowl: [0.219, 0.625, 0.578, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000205834_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a golden retriever is sitting behind a stainless steel pet bowl to the right."
      },
      {
        "from": "gpt",
        "value": "golden retriever: [0.203, 0.195, 0.836, 0.797]\nstainless steel pet bowl: [0.219, 0.625, 0.578, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000205834_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a golden retriever is sitting behind a stainless steel pet bowl to the right.\nObjects: [golden retriever, stainless steel pet bowl]"
      },
      {
        "from": "gpt",
        "value": "golden retriever: [0.203, 0.195, 0.836, 0.797]\nstainless steel pet bowl: [0.219, 0.625, 0.578, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000205834_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.203, 0.195, 0.836, 0.797]\nbowl: [0.219, 0.625, 0.578, 0.820]\nGiven the above layout, shift the dog to the left by 0.141."
      },
      {
        "from": "gpt",
        "value": "dog: [0.062, 0.195, 0.695, 0.797]\nbowl: [0.219, 0.625, 0.578, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000212895",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe is centered in the image, facing the camera with its back to the open landscape."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.406, 0.039, 0.586, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000212895_key",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe is centered in the image, facing the camera with its back to the open landscape.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.406, 0.039, 0.586, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000212895_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the tall ostrich is centered in the image, facing the camera with its back to the open landscape."
      },
      {
        "from": "gpt",
        "value": "tall ostrich: [0.406, 0.039, 0.586, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000212895_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the tall ostrich is centered in the image, facing the camera with its back to the open landscape.\nObjects: [tall ostrich]"
      },
      {
        "from": "gpt",
        "value": "tall ostrich: [0.406, 0.039, 0.586, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000212895_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.406, 0.039, 0.586, 0.977]\nGiven the above layout, shift the giraffe to the left by 0.195."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.211, 0.039, 0.391, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000213605",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is on the left side of the image, while a car is on the right side, both on a city street."
      },
      {
        "from": "gpt",
        "value": "bus: [0.148, 0.562, 0.719, 0.875]\ncar: [0.680, 0.688, 0.867, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000213605_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is on the left side of the image, while a car is on the right side, both on a city street.\nObjects: [bus, car]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.148, 0.562, 0.719, 0.875]\ncar: [0.680, 0.688, 0.867, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000213605_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a city double-decker bus is on the left side of the image, while a compact sedan car is on the right side, both on a city street."
      },
      {
        "from": "gpt",
        "value": "city double-decker bus: [0.148, 0.562, 0.719, 0.875]\ncompact sedan car: [0.680, 0.688, 0.867, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000213605_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a city double-decker bus is on the left side of the image, while a compact sedan car is on the right side, both on a city street.\nObjects: [city double-decker bus, compact sedan car]"
      },
      {
        "from": "gpt",
        "value": "city double-decker bus: [0.148, 0.562, 0.719, 0.875]\ncompact sedan car: [0.680, 0.688, 0.867, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000213605_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.148, 0.562, 0.719, 0.875]\ncar: [0.680, 0.688, 0.867, 0.922]\nGiven the above layout, shift the bus upwards by 0.492."
      },
      {
        "from": "gpt",
        "value": "bus: [0.148, 0.070, 0.719, 0.383]\ncar: [0.680, 0.688, 0.867, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000213816",
    "conversations": [
      {
        "from": "human",
        "value": "The train is stationary with its doors open in the center of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.133, 0.992, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000213816_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is stationary with its doors open in the center of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.133, 0.992, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000213816_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the Red and white passenger train is stationary with its doors open in the center of the image."
      },
      {
        "from": "gpt",
        "value": "Red and white passenger train: [0.000, 0.133, 0.992, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000213816_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the Red and white passenger train is stationary with its doors open in the center of the image.\nObjects: [Red and white passenger train]"
      },
      {
        "from": "gpt",
        "value": "Red and white passenger train: [0.000, 0.133, 0.992, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000213816_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.133, 0.992, 0.797]\nGiven the above layout, shift the train downwards by 0.094."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.227, 0.992, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000232489",
    "conversations": [
      {
        "from": "human",
        "value": "Two slices of pizza on a white plate with one slice partially on top of the other."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.000, 0.055, 0.969, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000232489_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two slices of pizza on a white plate with one slice partially on top of the other.\nObjects: [pizza]"
      },
      {
        "from": "gpt",
        "value": "pizza: [0.000, 0.055, 0.969, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000232489_aug",
    "conversations": [
      {
        "from": "human",
        "value": "two slices of two slices of Hawaiian pizza on a white plate with one slice partially on top of the other."
      },
      {
        "from": "gpt",
        "value": "two slices of Hawaiian pizza: [0.000, 0.055, 0.969, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000232489_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "two slices of two slices of Hawaiian pizza on a white plate with one slice partially on top of the other.\nObjects: [two slices of Hawaiian pizza]"
      },
      {
        "from": "gpt",
        "value": "two slices of Hawaiian pizza: [0.000, 0.055, 0.969, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000232489_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: pizza: [0.000, 0.055, 0.969, 0.961]\nGiven the above layout, shift the pizza upwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.000, 0.016, 0.969, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000258883",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the process of placing toppings on three pizzas that are laid out in front of them."
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.102, 0.602, 0.539]\npizza: [0.164, 0.719, 0.711, 0.930]\npizza: [0.195, 0.469, 0.641, 0.648]\npizza: [0.656, 0.531, 0.828, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000258883_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the process of placing toppings on three pizzas that are laid out in front of them.\nObjects: [person, pizza, pizza, pizza]"
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.102, 0.602, 0.539]\npizza: [0.164, 0.719, 0.711, 0.930]\npizza: [0.195, 0.469, 0.641, 0.648]\npizza: [0.656, 0.531, 0.828, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000261535",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing with their back to the camera, holding a tennis racket down in their right hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.469, 0.180, 0.672, 0.852]\ntennis racket: [0.633, 0.523, 0.742, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000261535_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing with their back to the camera, holding a tennis racket down in their right hand.\nObjects: [person, tennis racket]"
      },
      {
        "from": "gpt",
        "value": "person: [0.469, 0.180, 0.672, 0.852]\ntennis racket: [0.633, 0.523, 0.742, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000263644",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is at the center of the image, with elaborate wooden posts and a canopy top."
      },
      {
        "from": "gpt",
        "value": "bed: [0.234, 0.609, 0.789, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000263644_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is at the center of the image, with elaborate wooden posts and a canopy top.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.234, 0.609, 0.789, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000263644_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the mahogany poster bed is at the center of the image, with elaborate wooden posts and a canopy top."
      },
      {
        "from": "gpt",
        "value": "mahogany poster bed: [0.234, 0.609, 0.789, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000263644_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the mahogany poster bed is at the center of the image, with elaborate wooden posts and a canopy top.\nObjects: [mahogany poster bed]"
      },
      {
        "from": "gpt",
        "value": "mahogany poster bed: [0.234, 0.609, 0.789, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000263644_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.234, 0.609, 0.789, 0.953]\nGiven the above layout, shift the bed upwards by 0.297."
      },
      {
        "from": "gpt",
        "value": "bed: [0.234, 0.312, 0.789, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000269866",
    "conversations": [
      {
        "from": "human",
        "value": "The microwave is at the center on a kitchen countertop."
      },
      {
        "from": "gpt",
        "value": "microwave: [0.172, 0.242, 0.820, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000269866_key",
    "conversations": [
      {
        "from": "human",
        "value": "The microwave is at the center on a kitchen countertop.\nObjects: [microwave]"
      },
      {
        "from": "gpt",
        "value": "microwave: [0.172, 0.242, 0.820, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000269866_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel microwave is at the center on a kitchen countertop."
      },
      {
        "from": "gpt",
        "value": "stainless steel microwave: [0.172, 0.242, 0.820, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000269866_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel microwave is at the center on a kitchen countertop.\nObjects: [stainless steel microwave]"
      },
      {
        "from": "gpt",
        "value": "stainless steel microwave: [0.172, 0.242, 0.820, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000269866_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: microwave: [0.172, 0.242, 0.820, 0.773]\nGiven the above layout, shift the microwave upwards by 0.203."
      },
      {
        "from": "gpt",
        "value": "microwave: [0.172, 0.039, 0.820, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000270677",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center, holding a skateboard in their right hand by their side."
      },
      {
        "from": "gpt",
        "value": "person: [0.289, 0.141, 0.703, 0.992]\nskateboard: [0.656, 0.773, 0.773, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000270677_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center, holding a skateboard in their right hand by their side.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.289, 0.141, 0.703, 0.992]\nskateboard: [0.656, 0.773, 0.773, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000270677_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager in a hoodie is standing in the center, holding a neon green skateboard in their right hand by their side."
      },
      {
        "from": "gpt",
        "value": "teenager in a hoodie: [0.289, 0.141, 0.703, 0.992]\nneon green skateboard: [0.656, 0.773, 0.773, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000270677_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager in a hoodie is standing in the center, holding a neon green skateboard in their right hand by their side.\nObjects: [teenager in a hoodie, neon green skateboard]"
      },
      {
        "from": "gpt",
        "value": "teenager in a hoodie: [0.289, 0.141, 0.703, 0.992]\nneon green skateboard: [0.656, 0.773, 0.773, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000270677_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.289, 0.141, 0.703, 0.992]\nskateboard: [0.656, 0.773, 0.773, 0.992]\nGiven the above layout, shift the person to the left by 0.109."
      },
      {
        "from": "gpt",
        "value": "person: [0.180, 0.141, 0.594, 0.992]\nskateboard: [0.656, 0.773, 0.773, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000270908",
    "conversations": [
      {
        "from": "human",
        "value": "A person is lying on a tennis court with a tennis racket extended to the right hand side."
      },
      {
        "from": "gpt",
        "value": "person: [0.062, 0.258, 0.727, 0.609]\ntennis racket: [0.672, 0.500, 0.961, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000270908_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is lying on a tennis court with a tennis racket extended to the right hand side.\nObjects: [person, tennis racket]"
      },
      {
        "from": "gpt",
        "value": "person: [0.062, 0.258, 0.727, 0.609]\ntennis racket: [0.672, 0.500, 0.961, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000270908_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a sports player is lying on a tennis court with a neon green tennis racket extended to the right hand side."
      },
      {
        "from": "gpt",
        "value": "sports player: [0.062, 0.258, 0.727, 0.609]\nneon green tennis racket: [0.672, 0.500, 0.961, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000270908_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a sports player is lying on a tennis court with a neon green tennis racket extended to the right hand side.\nObjects: [sports player, neon green tennis racket]"
      },
      {
        "from": "gpt",
        "value": "sports player: [0.062, 0.258, 0.727, 0.609]\nneon green tennis racket: [0.672, 0.500, 0.961, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000270908_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.062, 0.258, 0.727, 0.609]\ntennis racket: [0.672, 0.500, 0.961, 0.742]\nGiven the above layout, shift the person upwards by 0.086."
      },
      {
        "from": "gpt",
        "value": "person: [0.062, 0.172, 0.727, 0.523]\ntennis racket: [0.672, 0.500, 0.961, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000272416",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center of the image, positioned on tiled flooring."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.438, 0.359, 0.922, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000272416_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center of the image, positioned on tiled flooring.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.438, 0.359, 0.922, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000272416_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the white porcelain toilet is at the center of the image, positioned on tiled flooring."
      },
      {
        "from": "gpt",
        "value": "white porcelain toilet: [0.438, 0.359, 0.922, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000272416_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the white porcelain toilet is at the center of the image, positioned on tiled flooring.\nObjects: [white porcelain toilet]"
      },
      {
        "from": "gpt",
        "value": "white porcelain toilet: [0.438, 0.359, 0.922, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000272416_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.438, 0.359, 0.922, 0.664]\nGiven the above layout, shift the toilet to the left by 0.227."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.211, 0.359, 0.695, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000274219",
    "conversations": [
      {
        "from": "human",
        "value": "A person wearing a dark jacket, white shirt, and bow tie, positioned at the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.141, 0.008, 0.859, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000274219_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person wearing a dark jacket, white shirt, and bow tie, positioned at the center of the image.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.141, 0.008, 0.859, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000274219_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a gentleman in formal attire wearing a dark jacket, white shirt, and bow tie, positioned at the center of the image."
      },
      {
        "from": "gpt",
        "value": "gentleman in formal attire: [0.141, 0.008, 0.859, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000274219_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a gentleman in formal attire wearing a dark jacket, white shirt, and bow tie, positioned at the center of the image.\nObjects: [gentleman in formal attire]"
      },
      {
        "from": "gpt",
        "value": "gentleman in formal attire: [0.141, 0.008, 0.859, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000274219_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.141, 0.008, 0.859, 0.977]\nGiven the above layout, shift the person to the left by 0.117."
      },
      {
        "from": "gpt",
        "value": "person: [0.023, 0.008, 0.742, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000278353",
    "conversations": [
      {
        "from": "human",
        "value": "A sheep is standing in the center of the image facing towards the camera."
      },
      {
        "from": "gpt",
        "value": "sheep: [0.164, 0.070, 0.859, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000278353_key",
    "conversations": [
      {
        "from": "human",
        "value": "A sheep is standing in the center of the image facing towards the camera.\nObjects: [sheep]"
      },
      {
        "from": "gpt",
        "value": "sheep: [0.164, 0.070, 0.859, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000278353_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a fluffy white alpaca is standing in the center of the image facing towards the camera."
      },
      {
        "from": "gpt",
        "value": "fluffy white alpaca: [0.164, 0.070, 0.859, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000278353_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a fluffy white alpaca is standing in the center of the image facing towards the camera.\nObjects: [fluffy white alpaca]"
      },
      {
        "from": "gpt",
        "value": "fluffy white alpaca: [0.164, 0.070, 0.859, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000278353_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sheep: [0.164, 0.070, 0.859, 0.945]\nGiven the above layout, shift the sheep to the left by 0.148."
      },
      {
        "from": "gpt",
        "value": "sheep: [0.016, 0.070, 0.711, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000280930",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in front of an oven to the left, with a refrigerator visible in the background to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.398, 0.172, 0.820, 0.820]\nrefrigerator: [0.758, 0.359, 0.992, 0.812]\noven: [0.000, 0.555, 0.375, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000280930_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in front of an oven to the left, with a refrigerator visible in the background to the right.\nObjects: [person, refrigerator, oven]"
      },
      {
        "from": "gpt",
        "value": "person: [0.398, 0.172, 0.820, 0.820]\nrefrigerator: [0.758, 0.359, 0.992, 0.812]\noven: [0.000, 0.555, 0.375, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000280930_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a chef is standing in front of an professional-grade oven to the left, with a large stainless steel refrigerator visible in the background to the right."
      },
      {
        "from": "gpt",
        "value": "a chef: [0.398, 0.172, 0.820, 0.820]\nlarge stainless steel refrigerator: [0.758, 0.359, 0.992, 0.812]\nprofessional-grade oven: [0.000, 0.555, 0.375, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000280930_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a chef is standing in front of an professional-grade oven to the left, with a large stainless steel refrigerator visible in the background to the right.\nObjects: [a chef, large stainless steel refrigerator, professional-grade oven]"
      },
      {
        "from": "gpt",
        "value": "a chef: [0.398, 0.172, 0.820, 0.820]\nlarge stainless steel refrigerator: [0.758, 0.359, 0.992, 0.812]\nprofessional-grade oven: [0.000, 0.555, 0.375, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000280930_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.398, 0.172, 0.820, 0.820]\nrefrigerator: [0.758, 0.359, 0.992, 0.812]\noven: [0.000, 0.555, 0.375, 0.820]\nGiven the above layout, shift the person upwards by 0.031."
      },
      {
        "from": "gpt",
        "value": "person: [0.398, 0.141, 0.820, 0.789]\nrefrigerator: [0.758, 0.359, 0.992, 0.812]\noven: [0.000, 0.555, 0.375, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000284279",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is perched on the right side of a bird feeder."
      },
      {
        "from": "gpt",
        "value": "bird: [0.539, 0.352, 0.906, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000284279_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is perched on the right side of a bird feeder.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.539, 0.352, 0.906, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000284279_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a small sparrow is perched on the right side of a small sparrow feeder."
      },
      {
        "from": "gpt",
        "value": "small sparrow: [0.539, 0.352, 0.906, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000284279_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a small sparrow is perched on the right side of a small sparrow feeder.\nObjects: [small sparrow]"
      },
      {
        "from": "gpt",
        "value": "small sparrow: [0.539, 0.352, 0.906, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000284279_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.539, 0.352, 0.906, 0.719]\nGiven the above layout, shift the bird to the left by 0.211."
      },
      {
        "from": "gpt",
        "value": "bird: [0.328, 0.352, 0.695, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000300276",
    "conversations": [
      {
        "from": "human",
        "value": "Three people standing behind a dining table, two persons are on the left and another person is on the right of the table."
      },
      {
        "from": "gpt",
        "value": "person: [0.477, 0.281, 0.727, 0.633]\nperson: [0.219, 0.305, 0.406, 0.633]\nperson: [0.008, 0.328, 0.180, 0.641]\ndining table: [0.383, 0.547, 0.867, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000300276_key",
    "conversations": [
      {
        "from": "human",
        "value": "Three people standing behind a dining table, two persons are on the left and another person is on the right of the table.\nObjects: [person, person, person, dining table]"
      },
      {
        "from": "gpt",
        "value": "person: [0.477, 0.281, 0.727, 0.633]\nperson: [0.219, 0.305, 0.406, 0.633]\nperson: [0.008, 0.328, 0.180, 0.641]\ndining table: [0.383, 0.547, 0.867, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000328238",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center of the image, reaching out to catch a frisbee."
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.352, 0.547, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000328238_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center of the image, reaching out to catch a frisbee.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.352, 0.547, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000328238_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man in a grey tracksuit is standing in the center of the image, reaching out to catch a frisbee."
      },
      {
        "from": "gpt",
        "value": "tall man in a grey tracksuit: [0.273, 0.352, 0.547, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000328238_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man in a grey tracksuit is standing in the center of the image, reaching out to catch a frisbee.\nObjects: [tall man in a grey tracksuit]"
      },
      {
        "from": "gpt",
        "value": "tall man in a grey tracksuit: [0.273, 0.352, 0.547, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000328238_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.273, 0.352, 0.547, 0.828]\nGiven the above layout, shift the person to the right by 0.102."
      },
      {
        "from": "gpt",
        "value": "person: [0.375, 0.352, 0.648, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000331569",
    "conversations": [
      {
        "from": "human",
        "value": "A cup is at the center of the image on a plate."
      },
      {
        "from": "gpt",
        "value": "cup: [0.383, 0.031, 0.992, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000331569_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cup is at the center of the image on a plate.\nObjects: [cup]"
      },
      {
        "from": "gpt",
        "value": "cup: [0.383, 0.031, 0.992, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000331569_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a small blue porcelain cup is at the center of the image on a plate."
      },
      {
        "from": "gpt",
        "value": "small blue porcelain cup: [0.383, 0.031, 0.992, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000331569_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a small blue porcelain cup is at the center of the image on a plate.\nObjects: [small blue porcelain cup]"
      },
      {
        "from": "gpt",
        "value": "small blue porcelain cup: [0.383, 0.031, 0.992, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000331569_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cup: [0.383, 0.031, 0.992, 0.914]\nGiven the above layout, shift the cup to the left by 0.195."
      },
      {
        "from": "gpt",
        "value": "cup: [0.188, 0.031, 0.797, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000332901",
    "conversations": [
      {
        "from": "human",
        "value": "Two sheep are inside a pen; one is leaning over the pen fence on the left, and the other is lying down behind it to the right."
      },
      {
        "from": "gpt",
        "value": "sheep: [0.000, 0.375, 0.531, 0.641]\nsheep: [0.539, 0.359, 0.992, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000332901_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two sheep are inside a pen; one is leaning over the pen fence on the left, and the other is lying down behind it to the right.\nObjects: [sheep, sheep]"
      },
      {
        "from": "gpt",
        "value": "sheep: [0.000, 0.375, 0.531, 0.641]\nsheep: [0.539, 0.359, 0.992, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000333237",
    "conversations": [
      {
        "from": "human",
        "value": "A bed is at the center of the image, and a chair is to the right of the bed."
      },
      {
        "from": "gpt",
        "value": "bed: [0.062, 0.445, 0.703, 0.781]\nchair: [0.617, 0.461, 0.727, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000333237_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bed is at the center of the image, and a chair is to the right of the bed.\nObjects: [bed, chair]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.062, 0.445, 0.703, 0.781]\nchair: [0.617, 0.461, 0.727, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000333237_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a king-size bed is at the center of the image, and a wooden rocking chair is to the right of the king-size bed."
      },
      {
        "from": "gpt",
        "value": "king-size bed: [0.062, 0.445, 0.703, 0.781]\nwooden rocking chair: [0.617, 0.461, 0.727, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000333237_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a king-size bed is at the center of the image, and a wooden rocking chair is to the right of the king-size bed.\nObjects: [king-size bed, wooden rocking chair]"
      },
      {
        "from": "gpt",
        "value": "king-size bed: [0.062, 0.445, 0.703, 0.781]\nwooden rocking chair: [0.617, 0.461, 0.727, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000333237_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.062, 0.445, 0.703, 0.781]\nchair: [0.617, 0.461, 0.727, 0.594]\nGiven the above layout, shift the bed upwards by 0.117."
      },
      {
        "from": "gpt",
        "value": "bed: [0.062, 0.328, 0.703, 0.664]\nchair: [0.617, 0.461, 0.727, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000335800",
    "conversations": [
      {
        "from": "human",
        "value": "A traffic light is mounted on a pole on the right side of the image, below a street sign."
      },
      {
        "from": "gpt",
        "value": "traffic light: [0.078, 0.562, 0.406, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000335800_key",
    "conversations": [
      {
        "from": "human",
        "value": "A traffic light is mounted on a pole on the right side of the image, below a street sign.\nObjects: [traffic light]"
      },
      {
        "from": "gpt",
        "value": "traffic light: [0.078, 0.562, 0.406, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000335800_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a city traffic signal. is mounted on a pole on the right side of the image, below a street sign."
      },
      {
        "from": "gpt",
        "value": "city traffic signal.: [0.078, 0.562, 0.406, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000335800_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a city traffic signal. is mounted on a pole on the right side of the image, below a street sign.\nObjects: [city traffic signal.]"
      },
      {
        "from": "gpt",
        "value": "city traffic signal.: [0.078, 0.562, 0.406, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000335800_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: traffic light: [0.078, 0.562, 0.406, 0.828]\nGiven the above layout, shift the traffic light to the right by 0.117."
      },
      {
        "from": "gpt",
        "value": "traffic light: [0.195, 0.562, 0.523, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000336209",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on top of a bench."
      },
      {
        "from": "gpt",
        "value": "bench: [0.508, 0.625, 0.906, 0.789]\nperson: [0.422, 0.352, 0.594, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000336209_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on top of a bench.\nObjects: [bench, person]"
      },
      {
        "from": "gpt",
        "value": "bench: [0.508, 0.625, 0.906, 0.789]\nperson: [0.422, 0.352, 0.594, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000336209_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man is standing on top of a oak wooden bench."
      },
      {
        "from": "gpt",
        "value": "oak wooden bench: [0.508, 0.625, 0.906, 0.789]\ntall man: [0.422, 0.352, 0.594, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000336209_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man is standing on top of a oak wooden bench.\nObjects: [oak wooden bench, tall man]"
      },
      {
        "from": "gpt",
        "value": "oak wooden bench: [0.508, 0.625, 0.906, 0.789]\ntall man: [0.422, 0.352, 0.594, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000336209_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bench: [0.508, 0.625, 0.906, 0.789]\nperson: [0.422, 0.352, 0.594, 0.609]\nGiven the above layout, shift the person to the left by 0.375."
      },
      {
        "from": "gpt",
        "value": "bench: [0.508, 0.625, 0.906, 0.789]\nperson: [0.047, 0.352, 0.219, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000338191",
    "conversations": [
      {
        "from": "human",
        "value": "The image shows multiple fire hydrants in different colors and designs arranged in a grid layout with no specific spatial relationship to each other since they are separated into individual frames within the image."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.297, 0.039, 0.703, 0.953]\nfire hydrant: [0.820, 0.062, 0.945, 0.281]\nfire hydrant: [0.023, 0.289, 0.156, 0.492]"
      }
    ]
  },
  {
    "id": "coco_000000338191_key",
    "conversations": [
      {
        "from": "human",
        "value": "The image shows multiple fire hydrants in different colors and designs arranged in a grid layout with no specific spatial relationship to each other since they are separated into individual frames within the image.\nObjects: [fire hydrant, fire hydrant, fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.297, 0.039, 0.703, 0.953]\nfire hydrant: [0.820, 0.062, 0.945, 0.281]\nfire hydrant: [0.023, 0.289, 0.156, 0.492]"
      }
    ]
  },
  {
    "id": "coco_000000338532",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe is standing at the center of the image."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.422, 0.242, 0.758, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000338532_key",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe is standing at the center of the image.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.422, 0.242, 0.758, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000338532_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the giraffe is standing at the center of the image."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.422, 0.242, 0.758, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000338532_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the giraffe is standing at the center of the image.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.422, 0.242, 0.758, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000338532_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.422, 0.242, 0.758, 0.852]\nGiven the above layout, shift the giraffe to the left by 0.281."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.141, 0.242, 0.477, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000338625",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is on the right side of the image, driving away on the street."
      },
      {
        "from": "gpt",
        "value": "bus: [0.211, 0.250, 0.758, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000338625_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is on the right side of the image, driving away on the street.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.211, 0.250, 0.758, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000338625_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker bus is on the right side of the image, driving away on the street."
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.211, 0.250, 0.758, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000338625_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker bus is on the right side of the image, driving away on the street.\nObjects: [double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.211, 0.250, 0.758, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000338625_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.211, 0.250, 0.758, 0.617]\nGiven the above layout, shift the bus downwards by 0.266."
      },
      {
        "from": "gpt",
        "value": "bus: [0.211, 0.516, 0.758, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000350607",
    "conversations": [
      {
        "from": "human",
        "value": "A colorful bench is at the center of the image."
      },
      {
        "from": "gpt",
        "value": "bench: [0.102, 0.320, 0.852, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000350607_key",
    "conversations": [
      {
        "from": "human",
        "value": "A colorful bench is at the center of the image.\nObjects: [bench]"
      },
      {
        "from": "gpt",
        "value": "bench: [0.102, 0.320, 0.852, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000350607_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a colorful rainbow-colored park bench is at the center of the image."
      },
      {
        "from": "gpt",
        "value": "rainbow-colored park bench: [0.102, 0.320, 0.852, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000350607_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a colorful rainbow-colored park bench is at the center of the image.\nObjects: [rainbow-colored park bench]"
      },
      {
        "from": "gpt",
        "value": "rainbow-colored park bench: [0.102, 0.320, 0.852, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000350607_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bench: [0.102, 0.320, 0.852, 0.648]\nGiven the above layout, shift the bench downwards by 0.078."
      },
      {
        "from": "gpt",
        "value": "bench: [0.102, 0.398, 0.852, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000354753",
    "conversations": [
      {
        "from": "human",
        "value": "There is no car visible in this image; only a street view with traffic lights is shown."
      },
      {
        "from": "gpt",
        "value": "car: [0.023, 0.727, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000354753_key",
    "conversations": [
      {
        "from": "human",
        "value": "There is no car visible in this image; only a street view with traffic lights is shown.\nObjects: [car]"
      },
      {
        "from": "gpt",
        "value": "car: [0.023, 0.727, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000354753_aug",
    "conversations": [
      {
        "from": "human",
        "value": "there is no red sedan visible in this image; only a street view with traffic lights is shown."
      },
      {
        "from": "gpt",
        "value": "red sedan: [0.023, 0.727, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000354753_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "there is no red sedan visible in this image; only a street view with traffic lights is shown.\nObjects: [red sedan]"
      },
      {
        "from": "gpt",
        "value": "red sedan: [0.023, 0.727, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000354753_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: car: [0.023, 0.727, 0.992, 0.867]\nGiven the above layout, shift the car upwards by 0.109."
      },
      {
        "from": "gpt",
        "value": "car: [0.023, 0.617, 0.992, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000356424",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting at the center of the dining table with another person seated at the table behind them. A chair is adjacent to the table."
      },
      {
        "from": "gpt",
        "value": "person: [0.180, 0.109, 0.648, 0.711]\ndining table: [0.125, 0.602, 0.867, 0.977]\nperson: [0.586, 0.180, 0.867, 0.531]\nchair: [0.648, 0.500, 0.867, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000356424_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting at the center of the dining table with another person seated at the table behind them. A chair is adjacent to the table.\nObjects: [person, dining table, person, chair]"
      },
      {
        "from": "gpt",
        "value": "person: [0.180, 0.109, 0.648, 0.711]\ndining table: [0.125, 0.602, 0.867, 0.977]\nperson: [0.586, 0.180, 0.867, 0.531]\nchair: [0.648, 0.500, 0.867, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000386134",
    "conversations": [
      {
        "from": "human",
        "value": "The broccoli is at the bottom center of the image."
      },
      {
        "from": "gpt",
        "value": "broccoli: [0.281, 0.477, 0.953, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000386134_key",
    "conversations": [
      {
        "from": "human",
        "value": "The broccoli is at the bottom center of the image.\nObjects: [broccoli]"
      },
      {
        "from": "gpt",
        "value": "broccoli: [0.281, 0.477, 0.953, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000386134_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the green cauliflower is at the bottom center of the image."
      },
      {
        "from": "gpt",
        "value": "green cauliflower: [0.281, 0.477, 0.953, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000386134_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the green cauliflower is at the bottom center of the image.\nObjects: [green cauliflower]"
      },
      {
        "from": "gpt",
        "value": "green cauliflower: [0.281, 0.477, 0.953, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000386134_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: broccoli: [0.281, 0.477, 0.953, 0.922]\nGiven the above layout, shift the broccoli upwards by 0.266."
      },
      {
        "from": "gpt",
        "value": "broccoli: [0.281, 0.211, 0.953, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000398810",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is at the center, sitting on a structure indoors, looking out the window where the reflection of another cat is visible."
      },
      {
        "from": "gpt",
        "value": "cat: [0.438, 0.297, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000398810_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is at the center, sitting on a structure indoors, looking out the window where the reflection of another cat is visible.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.438, 0.297, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000398810_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a Persian cat is at the center, sitting on a structure indoors, looking out the window where the reflection of another Persian cat is visible."
      },
      {
        "from": "gpt",
        "value": "Persian cat: [0.438, 0.297, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000398810_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a Persian cat is at the center, sitting on a structure indoors, looking out the window where the reflection of another Persian cat is visible.\nObjects: [Persian cat]"
      },
      {
        "from": "gpt",
        "value": "Persian cat: [0.438, 0.297, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000398810_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.438, 0.297, 0.992, 0.859]\nGiven the above layout, shift the cat to the left by 0.156."
      },
      {
        "from": "gpt",
        "value": "cat: [0.281, 0.297, 0.836, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000402118",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the air, centered above a snowboard, amidst a jump on a snowy slope."
      },
      {
        "from": "gpt",
        "value": "person: [0.289, 0.266, 0.750, 0.648]\nsnowboard: [0.312, 0.578, 0.828, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000402118_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the air, centered above a snowboard, amidst a jump on a snowy slope.\nObjects: [person, snowboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.289, 0.266, 0.750, 0.648]\nsnowboard: [0.312, 0.578, 0.828, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000402118_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a adventurous skier is in the air, centered above a fast-moving sled, amidst a jump on a snowy slope."
      },
      {
        "from": "gpt",
        "value": "adventurous skier: [0.289, 0.266, 0.750, 0.648]\nfast-moving sled: [0.312, 0.578, 0.828, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000402118_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a adventurous skier is in the air, centered above a fast-moving sled, amidst a jump on a snowy slope.\nObjects: [adventurous skier, fast-moving sled]"
      },
      {
        "from": "gpt",
        "value": "adventurous skier: [0.289, 0.266, 0.750, 0.648]\nfast-moving sled: [0.312, 0.578, 0.828, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000402118_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.289, 0.266, 0.750, 0.648]\nsnowboard: [0.312, 0.578, 0.828, 0.688]\nGiven the above layout, shift the snowboard downwards by 0.266."
      },
      {
        "from": "gpt",
        "value": "person: [0.289, 0.266, 0.750, 0.648]\nsnowboard: [0.312, 0.844, 0.828, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000404479",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is at the center of the image, on the ground, with mountains in the background."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.289, 0.523, 0.969, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000404479_key",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is at the center of the image, on the ground, with mountains in the background.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.289, 0.523, 0.969, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000404479_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the large commercial jet is at the center of the image, on the ground, with mountains in the background."
      },
      {
        "from": "gpt",
        "value": "large commercial jet: [0.289, 0.523, 0.969, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000404479_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the large commercial jet is at the center of the image, on the ground, with mountains in the background.\nObjects: [large commercial jet]"
      },
      {
        "from": "gpt",
        "value": "large commercial jet: [0.289, 0.523, 0.969, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000404479_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.289, 0.523, 0.969, 0.734]\nGiven the above layout, shift the airplane upwards by 0.062."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.289, 0.461, 0.969, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000406129",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center of the image, serving a tennis ball."
      },
      {
        "from": "gpt",
        "value": "person: [0.414, 0.242, 0.727, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000406129_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center of the image, serving a tennis ball.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.414, 0.242, 0.727, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000406129_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a fit woman in a white tennis outfit is in the center of the image, serving a tennis ball."
      },
      {
        "from": "gpt",
        "value": "fit woman in a white tennis outfit: [0.414, 0.242, 0.727, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000406129_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a fit woman in a white tennis outfit is in the center of the image, serving a tennis ball.\nObjects: [fit woman in a white tennis outfit]"
      },
      {
        "from": "gpt",
        "value": "fit woman in a white tennis outfit: [0.414, 0.242, 0.727, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000406129_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.414, 0.242, 0.727, 0.922]\nGiven the above layout, shift the person to the left by 0.195."
      },
      {
        "from": "gpt",
        "value": "person: [0.219, 0.242, 0.531, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000410878",
    "conversations": [
      {
        "from": "human",
        "value": "A motorcycle is parked in the center of the image, facing to the right."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.070, 0.219, 0.508, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000410878_key",
    "conversations": [
      {
        "from": "human",
        "value": "A motorcycle is parked in the center of the image, facing to the right.\nObjects: [motorcycle]"
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.070, 0.219, 0.508, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000410878_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a shiny red motorcycle is parked in the center of the image, facing to the right."
      },
      {
        "from": "gpt",
        "value": "shiny red motorcycle: [0.070, 0.219, 0.508, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000410878_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a shiny red motorcycle is parked in the center of the image, facing to the right.\nObjects: [shiny red motorcycle]"
      },
      {
        "from": "gpt",
        "value": "shiny red motorcycle: [0.070, 0.219, 0.508, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000410878_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: motorcycle: [0.070, 0.219, 0.508, 0.812]\nGiven the above layout, shift the motorcycle to the right by 0.094."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.164, 0.219, 0.602, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000423971",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center of the image with its lid open."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.344, 0.164, 0.617, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000423971_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center of the image with its lid open.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.344, 0.164, 0.617, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000423971_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the white porcelain toilet is at the center of the image with its lid open."
      },
      {
        "from": "gpt",
        "value": "white porcelain toilet: [0.344, 0.164, 0.617, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000423971_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the white porcelain toilet is at the center of the image with its lid open.\nObjects: [white porcelain toilet]"
      },
      {
        "from": "gpt",
        "value": "white porcelain toilet: [0.344, 0.164, 0.617, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000423971_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.344, 0.164, 0.617, 0.828]\nGiven the above layout, shift the toilet to the right by 0.086."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.430, 0.164, 0.703, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000428454",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the right is standing on a snowboard, with a kite flying in the air to the left of the person."
      },
      {
        "from": "gpt",
        "value": "person: [0.625, 0.414, 0.820, 0.789]\nkite: [0.383, 0.242, 0.523, 0.375]\nsnowboard: [0.539, 0.750, 0.852, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000428454_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the right is standing on a snowboard, with a kite flying in the air to the left of the person.\nObjects: [person, kite, snowboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.625, 0.414, 0.820, 0.789]\nkite: [0.383, 0.242, 0.523, 0.375]\nsnowboard: [0.539, 0.750, 0.852, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000428454_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek white sleek white snowboarder in a red jacket on the right is standing on a sleek white snowboard, with a rainbow-colored kite flying in the air to the left of the sleek white sleek white snowboarder in a red jacket."
      },
      {
        "from": "gpt",
        "value": "sleek white snowboarder in a red jacket: [0.625, 0.414, 0.820, 0.789]\nrainbow-colored kite: [0.383, 0.242, 0.523, 0.375]\nsleek white snowboard: [0.539, 0.750, 0.852, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000428454_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek white sleek white snowboarder in a red jacket on the right is standing on a sleek white snowboard, with a rainbow-colored kite flying in the air to the left of the sleek white sleek white snowboarder in a red jacket.\nObjects: [sleek white snowboarder in a red jacket, rainbow-colored kite, sleek white snowboard]"
      },
      {
        "from": "gpt",
        "value": "sleek white snowboarder in a red jacket: [0.625, 0.414, 0.820, 0.789]\nrainbow-colored kite: [0.383, 0.242, 0.523, 0.375]\nsleek white snowboard: [0.539, 0.750, 0.852, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000428454_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.625, 0.414, 0.820, 0.789]\nkite: [0.383, 0.242, 0.523, 0.375]\nsnowboard: [0.539, 0.750, 0.852, 0.789]\nGiven the above layout, shift the kite to the left by 0.297."
      },
      {
        "from": "gpt",
        "value": "person: [0.625, 0.414, 0.820, 0.789]\nkite: [0.086, 0.242, 0.227, 0.375]\nsnowboard: [0.539, 0.750, 0.852, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000429690",
    "conversations": [
      {
        "from": "human",
        "value": "In the foreground is a person holding a bat, in the midground to the right is a person pitching a softball, and in the background, there are two people seated watching."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.164, 0.352, 0.828]\nperson: [0.398, 0.328, 0.625, 0.734]\nperson: [0.773, 0.367, 0.906, 0.531]\nperson: [0.602, 0.359, 0.703, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000429690_key",
    "conversations": [
      {
        "from": "human",
        "value": "In the foreground is a person holding a bat, in the midground to the right is a person pitching a softball, and in the background, there are two people seated watching.\nObjects: [person, person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.164, 0.352, 0.828]\nperson: [0.398, 0.328, 0.625, 0.734]\nperson: [0.773, 0.367, 0.906, 0.531]\nperson: [0.602, 0.359, 0.703, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000430871",
    "conversations": [
      {
        "from": "human",
        "value": "The parking meter is on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.062, 0.234, 0.289, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000430871_key",
    "conversations": [
      {
        "from": "human",
        "value": "The parking meter is on the left side of the image.\nObjects: [parking meter]"
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.062, 0.234, 0.289, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000430871_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the digital parking meter is on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "digital parking meter: [0.062, 0.234, 0.289, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000430871_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the digital parking meter is on the left side of the image.\nObjects: [digital parking meter]"
      },
      {
        "from": "gpt",
        "value": "digital parking meter: [0.062, 0.234, 0.289, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000430871_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: parking meter: [0.062, 0.234, 0.289, 0.820]\nGiven the above layout, shift the parking meter to the right by 0.234."
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.297, 0.234, 0.523, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000431693",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center of the image playing tennis."
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.391, 0.727, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000431693_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center of the image playing tennis.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.391, 0.727, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000431693_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a professional tennis player is in the center of the image playing tennis."
      },
      {
        "from": "gpt",
        "value": "professional tennis player: [0.266, 0.391, 0.727, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000431693_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a professional tennis player is in the center of the image playing tennis.\nObjects: [professional tennis player]"
      },
      {
        "from": "gpt",
        "value": "professional tennis player: [0.266, 0.391, 0.727, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000431693_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.266, 0.391, 0.727, 0.742]\nGiven the above layout, shift the person upwards by 0.055."
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.336, 0.727, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000439522",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center of the image, cross-country skiing."
      },
      {
        "from": "gpt",
        "value": "person: [0.227, 0.039, 0.828, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000439522_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center of the image, cross-country skiing.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.227, 0.039, 0.828, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000439522_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a an adventurous skier is in the center of the image, cross-country skiing."
      },
      {
        "from": "gpt",
        "value": "an adventurous skier: [0.227, 0.039, 0.828, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000439522_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a an adventurous skier is in the center of the image, cross-country skiing.\nObjects: [an adventurous skier]"
      },
      {
        "from": "gpt",
        "value": "an adventurous skier: [0.227, 0.039, 0.828, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000439522_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.227, 0.039, 0.828, 0.938]\nGiven the above layout, shift the person to the left by 0.227."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.039, 0.602, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000445439",
    "conversations": [
      {
        "from": "human",
        "value": "The image is not visible to me, but based on our previous interactions, here is a caption assuming the image contains a zebra: \"A zebra positioned on the right side of the image, with its head bent down towards the ground.\""
      },
      {
        "from": "gpt",
        "value": "zebra: [0.000, 0.164, 0.781, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000445439_key",
    "conversations": [
      {
        "from": "human",
        "value": "The image is not visible to me, but based on our previous interactions, here is a caption assuming the image contains a zebra: \"A zebra positioned on the right side of the image, with its head bent down towards the ground.\"\nObjects: [zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.000, 0.164, 0.781, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000445439_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the image is not visible to me, but based on our previous interactions, here is a caption assuming the image contains a grazing giraffe: \"a grazing giraffe positioned on the right side of the image, with its head bent down towards the ground.\""
      },
      {
        "from": "gpt",
        "value": "grazing giraffe: [0.000, 0.164, 0.781, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000445439_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the image is not visible to me, but based on our previous interactions, here is a caption assuming the image contains a grazing giraffe: \"a grazing giraffe positioned on the right side of the image, with its head bent down towards the ground.\"\nObjects: [grazing giraffe]"
      },
      {
        "from": "gpt",
        "value": "grazing giraffe: [0.000, 0.164, 0.781, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000445439_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: zebra: [0.000, 0.164, 0.781, 0.828]\nGiven the above layout, shift the zebra to the right by 0.086."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.086, 0.164, 0.867, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000446574",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is to the left of the bathtub."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.164, 0.523, 0.484, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000446574_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is to the left of the bathtub.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.164, 0.523, 0.484, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000446574_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the white porcelain toilet is to the left of the bathtub."
      },
      {
        "from": "gpt",
        "value": "white porcelain toilet: [0.164, 0.523, 0.484, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000446574_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the white porcelain toilet is to the left of the bathtub.\nObjects: [white porcelain toilet]"
      },
      {
        "from": "gpt",
        "value": "white porcelain toilet: [0.164, 0.523, 0.484, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000446574_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.164, 0.523, 0.484, 0.977]\nGiven the above layout, shift the toilet upwards by 0.031."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.164, 0.492, 0.484, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000455085",
    "conversations": [
      {
        "from": "human",
        "value": "The rear side of the bus is in the center of the image, with the bus extending towards the left."
      },
      {
        "from": "gpt",
        "value": "bus: [0.172, 0.008, 0.805, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000455085_key",
    "conversations": [
      {
        "from": "human",
        "value": "The rear side of the bus is in the center of the image, with the bus extending towards the left.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.172, 0.008, 0.805, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000455085_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the rear side of the bright red double decker bus is in the center of the image, with the bright red double decker bus extending towards the left."
      },
      {
        "from": "gpt",
        "value": "bright red double decker bus: [0.172, 0.008, 0.805, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000455085_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the rear side of the bright red double decker bus is in the center of the image, with the bright red double decker bus extending towards the left.\nObjects: [bright red double decker bus]"
      },
      {
        "from": "gpt",
        "value": "bright red double decker bus: [0.172, 0.008, 0.805, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000455085_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.172, 0.008, 0.805, 0.859]\nGiven the above layout, shift the bus to the right by 0.070."
      },
      {
        "from": "gpt",
        "value": "bus: [0.242, 0.008, 0.875, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000478474",
    "conversations": [
      {
        "from": "human",
        "value": "The truck is on the left side of the image, moving towards the right."
      },
      {
        "from": "gpt",
        "value": "truck: [0.188, 0.359, 0.594, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000478474_key",
    "conversations": [
      {
        "from": "human",
        "value": "The truck is on the left side of the image, moving towards the right.\nObjects: [truck]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.188, 0.359, 0.594, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000478474_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red semi-truck is on the left side of the image, moving towards the right."
      },
      {
        "from": "gpt",
        "value": "red semi-truck: [0.188, 0.359, 0.594, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000478474_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red semi-truck is on the left side of the image, moving towards the right.\nObjects: [red semi-truck]"
      },
      {
        "from": "gpt",
        "value": "red semi-truck: [0.188, 0.359, 0.594, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000478474_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.188, 0.359, 0.594, 0.664]\nGiven the above layout, shift the truck to the right by 0.344."
      },
      {
        "from": "gpt",
        "value": "truck: [0.531, 0.359, 0.938, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000480985",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left of a motorcycle which is at the center of the image."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.156, 0.133, 0.805, 0.969]\nperson: [0.758, 0.547, 0.812, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000480985_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the left of a motorcycle which is at the center of the image.\nObjects: [motorcycle, person]"
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.156, 0.133, 0.805, 0.969]\nperson: [0.758, 0.547, 0.812, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000480985_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man in a leather jacket is standing to the left of a vintage Harley Davidson which is at the center of the image."
      },
      {
        "from": "gpt",
        "value": "vintage Harley Davidson: [0.156, 0.133, 0.805, 0.969]\ntall man in a leather jacket: [0.758, 0.547, 0.812, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000480985_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man in a leather jacket is standing to the left of a vintage Harley Davidson which is at the center of the image.\nObjects: [vintage Harley Davidson, tall man in a leather jacket]"
      },
      {
        "from": "gpt",
        "value": "vintage Harley Davidson: [0.156, 0.133, 0.805, 0.969]\ntall man in a leather jacket: [0.758, 0.547, 0.812, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000480985_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: motorcycle: [0.156, 0.133, 0.805, 0.969]\nperson: [0.758, 0.547, 0.812, 0.750]\nGiven the above layout, shift the person to the right by 0.023."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.156, 0.133, 0.805, 0.969]\nperson: [0.781, 0.547, 0.836, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000481159",
    "conversations": [
      {
        "from": "human",
        "value": "The horse is standing behind the fence, at the center of the image, with a snowy landscape in the background."
      },
      {
        "from": "gpt",
        "value": "horse: [0.289, 0.344, 0.688, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000481159_key",
    "conversations": [
      {
        "from": "human",
        "value": "The horse is standing behind the fence, at the center of the image, with a snowy landscape in the background.\nObjects: [horse]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.289, 0.344, 0.688, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000481159_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the brown mare is standing behind the fence, at the center of the image, with a snowy landscape in the background."
      },
      {
        "from": "gpt",
        "value": "brown mare: [0.289, 0.344, 0.688, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000481159_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the brown mare is standing behind the fence, at the center of the image, with a snowy landscape in the background.\nObjects: [brown mare]"
      },
      {
        "from": "gpt",
        "value": "brown mare: [0.289, 0.344, 0.688, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000481159_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: horse: [0.289, 0.344, 0.688, 0.828]\nGiven the above layout, shift the horse upwards by 0.062."
      },
      {
        "from": "gpt",
        "value": "horse: [0.289, 0.281, 0.688, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000481413",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on the beach facing the ocean, slightly to the right side of the image, holding a pink frisbee in their left hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.320, 0.516, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000481413_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on the beach facing the ocean, slightly to the right side of the image, holding a pink frisbee in their left hand.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.320, 0.516, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000481413_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager playing beach frisbee is standing on the beach facing the ocean, slightly to the right side of the image, holding a pink frisbee in their left hand."
      },
      {
        "from": "gpt",
        "value": "teenager playing beach frisbee: [0.312, 0.320, 0.516, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000481413_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager playing beach frisbee is standing on the beach facing the ocean, slightly to the right side of the image, holding a pink frisbee in their left hand.\nObjects: [teenager playing beach frisbee]"
      },
      {
        "from": "gpt",
        "value": "teenager playing beach frisbee: [0.312, 0.320, 0.516, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000481413_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.312, 0.320, 0.516, 0.688]\nGiven the above layout, shift the person to the right by 0.148."
      },
      {
        "from": "gpt",
        "value": "person: [0.461, 0.320, 0.664, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000488664",
    "conversations": [
      {
        "from": "human",
        "value": "A train extending from the left to the right side of the image with smoke rising from the locomotive on the left."
      },
      {
        "from": "gpt",
        "value": "train: [0.016, 0.578, 0.805, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000488664_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train extending from the left to the right side of the image with smoke rising from the locomotive on the left.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.016, 0.578, 0.805, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000488664_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a long cargo train extending from the left to the right side of the image with smoke rising from the locomotive on the left."
      },
      {
        "from": "gpt",
        "value": "long cargo train: [0.016, 0.578, 0.805, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000488664_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a long cargo train extending from the left to the right side of the image with smoke rising from the locomotive on the left.\nObjects: [long cargo train]"
      },
      {
        "from": "gpt",
        "value": "long cargo train: [0.016, 0.578, 0.805, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000488664_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.016, 0.578, 0.805, 0.766]\nGiven the above layout, shift the train upwards by 0.453."
      },
      {
        "from": "gpt",
        "value": "train: [0.016, 0.125, 0.805, 0.312]"
      }
    ]
  },
  {
    "id": "coco_000000490413",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is positioned behind a chain-link fence topped with barbed wire, centered in the background."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.016, 0.383, 0.984, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000490413_key",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is positioned behind a chain-link fence topped with barbed wire, centered in the background.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.016, 0.383, 0.984, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000490413_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the large commercial jet is positioned behind a chain-link fence topped with barbed wire, centered in the background."
      },
      {
        "from": "gpt",
        "value": "large commercial jet: [0.016, 0.383, 0.984, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000490413_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the large commercial jet is positioned behind a chain-link fence topped with barbed wire, centered in the background.\nObjects: [large commercial jet]"
      },
      {
        "from": "gpt",
        "value": "large commercial jet: [0.016, 0.383, 0.984, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000490413_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.016, 0.383, 0.984, 0.641]\nGiven the above layout, shift the airplane upwards by 0.289."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.016, 0.094, 0.984, 0.352]"
      }
    ]
  },
  {
    "id": "coco_000000493442",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skiing downhill with skis attached to their feet."
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.203, 0.750, 0.773]\nskis: [0.500, 0.719, 0.719, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000493442_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skiing downhill with skis attached to their feet.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.203, 0.750, 0.773]\nskis: [0.500, 0.719, 0.719, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000493442_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a an adventurous skier is skiing downhill with pair of high-speed skis attached to their feet."
      },
      {
        "from": "gpt",
        "value": "an adventurous skier: [0.367, 0.203, 0.750, 0.773]\npair of high-speed skis: [0.500, 0.719, 0.719, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000493442_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a an adventurous skier is skiing downhill with pair of high-speed skis attached to their feet.\nObjects: [an adventurous skier, pair of high-speed skis]"
      },
      {
        "from": "gpt",
        "value": "an adventurous skier: [0.367, 0.203, 0.750, 0.773]\npair of high-speed skis: [0.500, 0.719, 0.719, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000493442_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.367, 0.203, 0.750, 0.773]\nskis: [0.500, 0.719, 0.719, 0.773]\nGiven the above layout, shift the person to the left by 0.117."
      },
      {
        "from": "gpt",
        "value": "person: [0.250, 0.203, 0.633, 0.773]\nskis: [0.500, 0.719, 0.719, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000498032",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a remote control in their right hand, raised slightly above shoulder level."
      },
      {
        "from": "gpt",
        "value": "person: [0.219, 0.312, 0.695, 0.844]\nremote: [0.602, 0.289, 0.664, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000498032_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a remote control in their right hand, raised slightly above shoulder level.\nObjects: [person, remote]"
      },
      {
        "from": "gpt",
        "value": "person: [0.219, 0.312, 0.695, 0.844]\nremote: [0.602, 0.289, 0.664, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000498032_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a woman with curly hair is holding a sleek black remote control control in their right hand, raised slightly above shoulder level."
      },
      {
        "from": "gpt",
        "value": "woman with curly hair: [0.219, 0.312, 0.695, 0.844]\nsleek black remote control: [0.602, 0.289, 0.664, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000498032_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a woman with curly hair is holding a sleek black remote control control in their right hand, raised slightly above shoulder level.\nObjects: [woman with curly hair, sleek black remote control]"
      },
      {
        "from": "gpt",
        "value": "woman with curly hair: [0.219, 0.312, 0.695, 0.844]\nsleek black remote control: [0.602, 0.289, 0.664, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000498032_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.219, 0.312, 0.695, 0.844]\nremote: [0.602, 0.289, 0.664, 0.477]\nGiven the above layout, shift the person to the right by 0.125."
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.312, 0.820, 0.844]\nremote: [0.602, 0.289, 0.664, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000499109",
    "conversations": [
      {
        "from": "human",
        "value": "The sandwich is at the center of the image, slightly tilted to the left."
      },
      {
        "from": "gpt",
        "value": "sandwich: [0.156, 0.141, 0.727, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000499109_key",
    "conversations": [
      {
        "from": "human",
        "value": "The sandwich is at the center of the image, slightly tilted to the left.\nObjects: [sandwich]"
      },
      {
        "from": "gpt",
        "value": "sandwich: [0.156, 0.141, 0.727, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000499109_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the chicken sandwich is at the center of the image, slightly tilted to the left."
      },
      {
        "from": "gpt",
        "value": "chicken sandwich: [0.156, 0.141, 0.727, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000499109_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the chicken sandwich is at the center of the image, slightly tilted to the left.\nObjects: [chicken sandwich]"
      },
      {
        "from": "gpt",
        "value": "chicken sandwich: [0.156, 0.141, 0.727, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000499109_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sandwich: [0.156, 0.141, 0.727, 0.648]\nGiven the above layout, shift the sandwich downwards by 0.188."
      },
      {
        "from": "gpt",
        "value": "sandwich: [0.156, 0.328, 0.727, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000508639",
    "conversations": [
      {
        "from": "human",
        "value": "A horse is harnessed to a carriage on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "horse: [0.195, 0.539, 0.523, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000508639_key",
    "conversations": [
      {
        "from": "human",
        "value": "A horse is harnessed to a carriage on the left side of the image.\nObjects: [horse]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.195, 0.539, 0.523, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000508639_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a brown horse is harnessed to a carriage on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "brown horse: [0.195, 0.539, 0.523, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000508639_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a brown horse is harnessed to a carriage on the left side of the image.\nObjects: [brown horse]"
      },
      {
        "from": "gpt",
        "value": "brown horse: [0.195, 0.539, 0.523, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000508639_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: horse: [0.195, 0.539, 0.523, 0.836]\nGiven the above layout, shift the horse upwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "horse: [0.195, 0.516, 0.523, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000517523",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is in the center of the image, flying towards the left."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.094, 0.219, 0.953, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000517523_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is in the center of the image, flying towards the left.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.094, 0.219, 0.953, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000517523_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an private jet is in the center of the image, flying towards the left."
      },
      {
        "from": "gpt",
        "value": "private jet: [0.094, 0.219, 0.953, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000517523_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an private jet is in the center of the image, flying towards the left.\nObjects: [private jet]"
      },
      {
        "from": "gpt",
        "value": "private jet: [0.094, 0.219, 0.953, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000517523_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.094, 0.219, 0.953, 0.500]\nGiven the above layout, shift the airplane downwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.094, 0.289, 0.953, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000519338",
    "conversations": [
      {
        "from": "human",
        "value": "The train is positioned at the center of the image, facing slightly to the left."
      },
      {
        "from": "gpt",
        "value": "train: [0.250, 0.281, 0.750, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000519338_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is positioned at the center of the image, facing slightly to the left.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.250, 0.281, 0.750, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000519338_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the vintage steam engine is positioned at the center of the image, facing slightly to the left."
      },
      {
        "from": "gpt",
        "value": "vintage steam engine: [0.250, 0.281, 0.750, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000519338_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the vintage steam engine is positioned at the center of the image, facing slightly to the left.\nObjects: [vintage steam engine]"
      },
      {
        "from": "gpt",
        "value": "vintage steam engine: [0.250, 0.281, 0.750, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000519338_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.250, 0.281, 0.750, 0.750]\nGiven the above layout, shift the train upwards by 0.258."
      },
      {
        "from": "gpt",
        "value": "train: [0.250, 0.023, 0.750, 0.492]"
      }
    ]
  },
  {
    "id": "coco_000000521231",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is at the center, standing on a rock with water visible at the bottom edge of the image."
      },
      {
        "from": "gpt",
        "value": "bear: [0.312, 0.258, 0.688, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000521231_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is at the center, standing on a rock with water visible at the bottom edge of the image.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.312, 0.258, 0.688, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000521231_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the large grizzly bear is at the center, standing on a rock with water visible at the bottom edge of the image."
      },
      {
        "from": "gpt",
        "value": "large grizzly bear: [0.312, 0.258, 0.688, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000521231_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the large grizzly bear is at the center, standing on a rock with water visible at the bottom edge of the image.\nObjects: [large grizzly bear]"
      },
      {
        "from": "gpt",
        "value": "large grizzly bear: [0.312, 0.258, 0.688, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000521231_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.312, 0.258, 0.688, 0.711]\nGiven the above layout, shift the bear to the left by 0.250."
      },
      {
        "from": "gpt",
        "value": "bear: [0.062, 0.258, 0.438, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000537964",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is positioned to the left, amidst a bed of fallen leaves and surrounded by trees."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.078, 0.188, 0.336, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000537964_key",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is positioned to the left, amidst a bed of fallen leaves and surrounded by trees.\nObjects: [fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.078, 0.188, 0.336, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000537964_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red fire hydrant is positioned to the left, amidst a bed of fallen leaves and surrounded by trees."
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.078, 0.188, 0.336, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000537964_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red fire hydrant is positioned to the left, amidst a bed of fallen leaves and surrounded by trees.\nObjects: [red fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.078, 0.188, 0.336, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000537964_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: fire hydrant: [0.078, 0.188, 0.336, 0.781]\nGiven the above layout, shift the fire hydrant to the right by 0.180."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.258, 0.188, 0.516, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000564091",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting behind a display of various items spread out on the ground."
      },
      {
        "from": "gpt",
        "value": "person: [0.180, 0.000, 0.672, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000564091_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting behind a display of various items spread out on the ground.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.180, 0.000, 0.672, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000564091_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a elderly woman is sitting behind a display of various items spread out on the ground."
      },
      {
        "from": "gpt",
        "value": "elderly woman: [0.180, 0.000, 0.672, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000564091_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a elderly woman is sitting behind a display of various items spread out on the ground.\nObjects: [elderly woman]"
      },
      {
        "from": "gpt",
        "value": "elderly woman: [0.180, 0.000, 0.672, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000564091_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.180, 0.000, 0.672, 0.578]\nGiven the above layout, shift the person downwards by 0.055."
      },
      {
        "from": "gpt",
        "value": "person: [0.180, 0.055, 0.672, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000575357",
    "conversations": [
      {
        "from": "human",
        "value": "The dog is in mid-air, leaping towards the right side of the image."
      },
      {
        "from": "gpt",
        "value": "dog: [0.391, 0.391, 0.953, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000575357_key",
    "conversations": [
      {
        "from": "human",
        "value": "The dog is in mid-air, leaping towards the right side of the image.\nObjects: [dog]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.391, 0.391, 0.953, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000575357_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the eager black dog is in mid-air, leaping towards the right side of the image."
      },
      {
        "from": "gpt",
        "value": "eager black dog: [0.391, 0.391, 0.953, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000575357_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the eager black dog is in mid-air, leaping towards the right side of the image.\nObjects: [eager black dog]"
      },
      {
        "from": "gpt",
        "value": "eager black dog: [0.391, 0.391, 0.953, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000575357_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.391, 0.391, 0.953, 0.703]\nGiven the above layout, shift the dog to the left by 0.234."
      },
      {
        "from": "gpt",
        "value": "dog: [0.156, 0.391, 0.719, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000576566",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in mid-air above a skateboard that is at the center bottom of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.023, 0.641, 0.680]\nskateboard: [0.320, 0.484, 0.586, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000576566_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in mid-air above a skateboard that is at the center bottom of the image.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.023, 0.641, 0.680]\nskateboard: [0.320, 0.484, 0.586, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000576566_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young printed printed skateboarder is in mid-air above a printed skateboard that is at the center bottom of the image."
      },
      {
        "from": "gpt",
        "value": "young printed skateboarder: [0.352, 0.023, 0.641, 0.680]\nprinted skateboard: [0.320, 0.484, 0.586, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000576566_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young printed printed skateboarder is in mid-air above a printed skateboard that is at the center bottom of the image.\nObjects: [young printed skateboarder, printed skateboard]"
      },
      {
        "from": "gpt",
        "value": "young printed skateboarder: [0.352, 0.023, 0.641, 0.680]\nprinted skateboard: [0.320, 0.484, 0.586, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000576566_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.352, 0.023, 0.641, 0.680]\nskateboard: [0.320, 0.484, 0.586, 0.734]\nGiven the above layout, shift the person to the right by 0.273."
      },
      {
        "from": "gpt",
        "value": "person: [0.625, 0.023, 0.914, 0.680]\nskateboard: [0.320, 0.484, 0.586, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000577149",
    "conversations": [
      {
        "from": "human",
        "value": "Three zebras standing on the dirt path; one facing the camera in the foreground on the right, the other two facing away from the camera in the background on the left."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.531, 0.430, 0.875, 0.773]\nzebra: [0.164, 0.398, 0.289, 0.641]\nzebra: [0.297, 0.398, 0.391, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000577149_key",
    "conversations": [
      {
        "from": "human",
        "value": "Three zebras standing on the dirt path; one facing the camera in the foreground on the right, the other two facing away from the camera in the background on the left.\nObjects: [zebra, zebra, zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.531, 0.430, 0.875, 0.773]\nzebra: [0.164, 0.398, 0.289, 0.641]\nzebra: [0.297, 0.398, 0.391, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000578922",
    "conversations": [
      {
        "from": "human",
        "value": "A vase with flowers is at the center, with a cup to the right of it. There is no potted plant visible in the image."
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.031, 0.000, 0.852, 0.984]\nvase: [0.305, 0.703, 0.492, 0.977]\ncup: [0.523, 0.773, 0.695, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000578922_key",
    "conversations": [
      {
        "from": "human",
        "value": "A vase with flowers is at the center, with a cup to the right of it. There is no potted plant visible in the image.\nObjects: [potted plant, vase, cup]"
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.031, 0.000, 0.852, 0.984]\nvase: [0.305, 0.703, 0.492, 0.977]\ncup: [0.523, 0.773, 0.695, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000578922_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a blue glass vase with flowers is at the center, with a white coffee mug to the right of it. there is no cactus plant visible in the image."
      },
      {
        "from": "gpt",
        "value": "cactus plant: [0.031, 0.000, 0.852, 0.984]\nblue glass vase: [0.305, 0.703, 0.492, 0.977]\nwhite coffee mug: [0.523, 0.773, 0.695, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000578922_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a blue glass vase with flowers is at the center, with a white coffee mug to the right of it. there is no cactus plant visible in the image.\nObjects: [cactus plant, blue glass vase, white coffee mug]"
      },
      {
        "from": "gpt",
        "value": "cactus plant: [0.031, 0.000, 0.852, 0.984]\nblue glass vase: [0.305, 0.703, 0.492, 0.977]\nwhite coffee mug: [0.523, 0.773, 0.695, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000578922_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: potted plant: [0.031, 0.000, 0.852, 0.984]\nvase: [0.305, 0.703, 0.492, 0.977]\ncup: [0.523, 0.773, 0.695, 0.992]\nGiven the above layout, shift the potted plant to the right by 0.109."
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.141, 0.000, 0.961, 0.984]\nvase: [0.305, 0.703, 0.492, 0.977]\ncup: [0.523, 0.773, 0.695, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000578967",
    "conversations": [
      {
        "from": "human",
        "value": "The train is at the center, parallel to the bottom edge of the image, stretching from the left side towards the right side."
      },
      {
        "from": "gpt",
        "value": "train: [0.023, 0.352, 0.992, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000578967_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is at the center, parallel to the bottom edge of the image, stretching from the left side towards the right side.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.023, 0.352, 0.992, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000578967_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the green diesel locomotive is at the center, parallel to the bottom edge of the image, stretching from the left side towards the right side."
      },
      {
        "from": "gpt",
        "value": "green diesel locomotive: [0.023, 0.352, 0.992, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000578967_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the green diesel locomotive is at the center, parallel to the bottom edge of the image, stretching from the left side towards the right side.\nObjects: [green diesel locomotive]"
      },
      {
        "from": "gpt",
        "value": "green diesel locomotive: [0.023, 0.352, 0.992, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000578967_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.023, 0.352, 0.992, 0.852]\nGiven the above layout, shift the train upwards by 0.086."
      },
      {
        "from": "gpt",
        "value": "train: [0.023, 0.266, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000579818",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks elevated above the ground, moving from right to left with the front engine car leading."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.359, 0.812, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000579818_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks elevated above the ground, moving from right to left with the front engine car leading.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.359, 0.812, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000579818_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the express passenger train is on the tracks elevated above the ground, moving from right to left with the front engine car leading."
      },
      {
        "from": "gpt",
        "value": "express passenger train: [0.000, 0.359, 0.812, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000579818_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the express passenger train is on the tracks elevated above the ground, moving from right to left with the front engine car leading.\nObjects: [express passenger train]"
      },
      {
        "from": "gpt",
        "value": "express passenger train: [0.000, 0.359, 0.812, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000579818_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.359, 0.812, 0.562]\nGiven the above layout, shift the train downwards by 0.234."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.594, 0.812, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000579893",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is mounted on a pole to the right of the street sign."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.703, 0.414, 0.977, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000579893_key",
    "conversations": [
      {
        "from": "human",
        "value": "The stop sign is mounted on a pole to the right of the street sign.\nObjects: [stop sign]"
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.703, 0.414, 0.977, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000579893_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red octagonal street sign is mounted on a pole to the right of the street sign."
      },
      {
        "from": "gpt",
        "value": "red octagonal street sign: [0.703, 0.414, 0.977, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000579893_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red octagonal street sign is mounted on a pole to the right of the street sign.\nObjects: [red octagonal street sign]"
      },
      {
        "from": "gpt",
        "value": "red octagonal street sign: [0.703, 0.414, 0.977, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000579893_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: stop sign: [0.703, 0.414, 0.977, 0.820]\nGiven the above layout, shift the stop sign to the left by 0.273."
      },
      {
        "from": "gpt",
        "value": "stop sign: [0.430, 0.414, 0.703, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000579900",
    "conversations": [
      {
        "from": "human",
        "value": "The pizza is at the center on top of a yellow plate."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.125, 0.070, 0.867, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000579900_key",
    "conversations": [
      {
        "from": "human",
        "value": "The pizza is at the center on top of a yellow plate.\nObjects: [pizza]"
      },
      {
        "from": "gpt",
        "value": "pizza: [0.125, 0.070, 0.867, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000579900_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the freshly baked pepperoni pizza is at the center on top of a yellow plate."
      },
      {
        "from": "gpt",
        "value": "freshly baked pepperoni pizza: [0.125, 0.070, 0.867, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000579900_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the freshly baked pepperoni pizza is at the center on top of a yellow plate.\nObjects: [freshly baked pepperoni pizza]"
      },
      {
        "from": "gpt",
        "value": "freshly baked pepperoni pizza: [0.125, 0.070, 0.867, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000579900_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: pizza: [0.125, 0.070, 0.867, 0.891]\nGiven the above layout, shift the pizza to the left by 0.062."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.062, 0.070, 0.805, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000015956",
    "conversations": [
      {
        "from": "human",
        "value": "A person to the right, leading a horse to the left."
      },
      {
        "from": "gpt",
        "value": "horse: [0.203, 0.258, 0.570, 0.594]\nperson: [0.570, 0.336, 0.695, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000015956_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person to the right, leading a horse to the left.\nObjects: [horse, person]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.203, 0.258, 0.570, 0.594]\nperson: [0.570, 0.336, 0.695, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000015956_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a cowboy in a hat to the right, leading a brown stallion to the left."
      },
      {
        "from": "gpt",
        "value": "brown stallion: [0.203, 0.258, 0.570, 0.594]\ncowboy in a hat: [0.570, 0.336, 0.695, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000015956_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a cowboy in a hat to the right, leading a brown stallion to the left.\nObjects: [brown stallion, cowboy in a hat]"
      },
      {
        "from": "gpt",
        "value": "brown stallion: [0.203, 0.258, 0.570, 0.594]\ncowboy in a hat: [0.570, 0.336, 0.695, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000015956_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: horse: [0.203, 0.258, 0.570, 0.594]\nperson: [0.570, 0.336, 0.695, 0.648]\nGiven the above layout, shift the person downwards by 0.164."
      },
      {
        "from": "gpt",
        "value": "horse: [0.203, 0.258, 0.570, 0.594]\nperson: [0.570, 0.500, 0.695, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000017031",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe is in the center of the image with green foliage in the background."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.156, 0.234, 0.711, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000017031_key",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe is in the center of the image with green foliage in the background.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.156, 0.234, 0.711, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000017031_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the long-necked deer is in the center of the image with green foliage in the background."
      },
      {
        "from": "gpt",
        "value": "long-necked deer: [0.156, 0.234, 0.711, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000017031_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the long-necked deer is in the center of the image with green foliage in the background.\nObjects: [long-necked deer]"
      },
      {
        "from": "gpt",
        "value": "long-necked deer: [0.156, 0.234, 0.711, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000017031_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.156, 0.234, 0.711, 0.828]\nGiven the above layout, shift the giraffe to the right by 0.039."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.195, 0.234, 0.750, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000051712",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skiing down a slope to the right of a pair of fallen skis."
      },
      {
        "from": "gpt",
        "value": "person: [0.219, 0.289, 0.469, 0.672]\nskis: [0.125, 0.609, 0.516, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000051712_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skiing down a slope to the right of a pair of fallen skis.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.219, 0.289, 0.469, 0.672]\nskis: [0.125, 0.609, 0.516, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000051712_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a snowboarder is skiing down a slope to the right of a pair of fallen abandoned snowboard."
      },
      {
        "from": "gpt",
        "value": "snowboarder: [0.219, 0.289, 0.469, 0.672]\nabandoned snowboard: [0.125, 0.609, 0.516, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000051712_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a snowboarder is skiing down a slope to the right of a pair of fallen abandoned snowboard.\nObjects: [snowboarder, abandoned snowboard]"
      },
      {
        "from": "gpt",
        "value": "snowboarder: [0.219, 0.289, 0.469, 0.672]\nabandoned snowboard: [0.125, 0.609, 0.516, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000051712_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.219, 0.289, 0.469, 0.672]\nskis: [0.125, 0.609, 0.516, 0.727]\nGiven the above layout, shift the skis to the right by 0.016."
      },
      {
        "from": "gpt",
        "value": "person: [0.219, 0.289, 0.469, 0.672]\nskis: [0.141, 0.609, 0.531, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000076731",
    "conversations": [
      {
        "from": "human",
        "value": "The closed laptop is at the center of the image, on a wooden surface."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.078, 0.227, 0.930, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000076731_key",
    "conversations": [
      {
        "from": "human",
        "value": "The closed laptop is at the center of the image, on a wooden surface.\nObjects: [laptop]"
      },
      {
        "from": "gpt",
        "value": "laptop: [0.078, 0.227, 0.930, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000076731_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the closed MacBook Pro is at the center of the image, on a wooden surface."
      },
      {
        "from": "gpt",
        "value": "MacBook Pro: [0.078, 0.227, 0.930, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000076731_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the closed MacBook Pro is at the center of the image, on a wooden surface.\nObjects: [MacBook Pro]"
      },
      {
        "from": "gpt",
        "value": "MacBook Pro: [0.078, 0.227, 0.930, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000076731_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: laptop: [0.078, 0.227, 0.930, 0.719]\nGiven the above layout, shift the laptop downwards by 0.234."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.078, 0.461, 0.930, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000095843",
    "conversations": [
      {
        "from": "human",
        "value": "A double-decker bus is parked on the right side of the image facing leftwards."
      },
      {
        "from": "gpt",
        "value": "bus: [0.203, 0.266, 0.875, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000095843_key",
    "conversations": [
      {
        "from": "human",
        "value": "A double-decker bus is parked on the right side of the image facing leftwards.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.203, 0.266, 0.875, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000095843_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a double-decker red double-decker bus is parked on the right side of the image facing leftwards."
      },
      {
        "from": "gpt",
        "value": "red double-decker bus: [0.203, 0.266, 0.875, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000095843_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a double-decker red double-decker bus is parked on the right side of the image facing leftwards.\nObjects: [red double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "red double-decker bus: [0.203, 0.266, 0.875, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000095843_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.203, 0.266, 0.875, 0.781]\nGiven the above layout, shift the bus upwards by 0.203."
      },
      {
        "from": "gpt",
        "value": "bus: [0.203, 0.062, 0.875, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000096960",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is swimming underwater, oriented diagonally in the image with its head toward the top left and back legs toward the bottom right."
      },
      {
        "from": "gpt",
        "value": "bear: [0.039, 0.305, 0.672, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000096960_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is swimming underwater, oriented diagonally in the image with its head toward the top left and back legs toward the bottom right.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.039, 0.305, 0.672, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000096960_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the polar bear is swimming underwater, oriented diagonally in the image with its head toward the top left and back legs toward the bottom right."
      },
      {
        "from": "gpt",
        "value": "polar bear: [0.039, 0.305, 0.672, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000096960_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the polar bear is swimming underwater, oriented diagonally in the image with its head toward the top left and back legs toward the bottom right.\nObjects: [polar bear]"
      },
      {
        "from": "gpt",
        "value": "polar bear: [0.039, 0.305, 0.672, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000096960_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.039, 0.305, 0.672, 0.773]\nGiven the above layout, shift the bear to the right by 0.117."
      },
      {
        "from": "gpt",
        "value": "bear: [0.156, 0.305, 0.789, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000097278",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a snowboard."
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.117, 0.656, 0.891]\nsnowboard: [0.141, 0.844, 0.758, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000097278_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a snowboard.\nObjects: [person, snowboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.117, 0.656, 0.891]\nsnowboard: [0.141, 0.844, 0.758, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000097278_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a orange orange snowboard enthusiast is standing on a orange snowboard."
      },
      {
        "from": "gpt",
        "value": "orange snowboard enthusiast: [0.273, 0.117, 0.656, 0.891]\norange snowboard: [0.141, 0.844, 0.758, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000097278_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a orange orange snowboard enthusiast is standing on a orange snowboard.\nObjects: [orange snowboard enthusiast, orange snowboard]"
      },
      {
        "from": "gpt",
        "value": "orange snowboard enthusiast: [0.273, 0.117, 0.656, 0.891]\norange snowboard: [0.141, 0.844, 0.758, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000097278_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.273, 0.117, 0.656, 0.891]\nsnowboard: [0.141, 0.844, 0.758, 0.922]\nGiven the above layout, shift the snowboard to the right by 0.125."
      },
      {
        "from": "gpt",
        "value": "person: [0.273, 0.117, 0.656, 0.891]\nsnowboard: [0.266, 0.844, 0.883, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000102644",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is located to the left side of the image, in front of a bathtub."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.188, 0.477, 0.461, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000102644_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is located to the left side of the image, in front of a bathtub.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.188, 0.477, 0.461, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000102644_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the white porcelain toilet is located to the left side of the image, in front of a bathtub."
      },
      {
        "from": "gpt",
        "value": "white porcelain toilet: [0.188, 0.477, 0.461, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000102644_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the white porcelain toilet is located to the left side of the image, in front of a bathtub.\nObjects: [white porcelain toilet]"
      },
      {
        "from": "gpt",
        "value": "white porcelain toilet: [0.188, 0.477, 0.461, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000102644_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.188, 0.477, 0.461, 0.859]\nGiven the above layout, shift the toilet to the right by 0.273."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.461, 0.477, 0.734, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000105264",
    "conversations": [
      {
        "from": "human",
        "value": "A cow stands in the foreground on the left; in the background, three people are walking towards the right."
      },
      {
        "from": "gpt",
        "value": "cow: [0.094, 0.336, 0.555, 0.789]\nperson: [0.617, 0.336, 0.766, 0.664]\nperson: [0.492, 0.430, 0.562, 0.633]\nperson: [0.836, 0.445, 0.891, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000105264_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cow stands in the foreground on the left; in the background, three people are walking towards the right.\nObjects: [cow, person, person, person]"
      },
      {
        "from": "gpt",
        "value": "cow: [0.094, 0.336, 0.555, 0.789]\nperson: [0.617, 0.336, 0.766, 0.664]\nperson: [0.492, 0.430, 0.562, 0.633]\nperson: [0.836, 0.445, 0.891, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000107094",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the right of the skis, which are lying on snow-covered ground."
      },
      {
        "from": "gpt",
        "value": "person: [0.742, 0.289, 0.969, 0.820]\nskis: [0.562, 0.734, 0.812, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000107094_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the right of the skis, which are lying on snow-covered ground.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.742, 0.289, 0.969, 0.820]\nskis: [0.562, 0.734, 0.812, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000107094_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a skier in a red suit is standing to the right of the pair of professional-grade snow skis, which are lying on snow-covered ground."
      },
      {
        "from": "gpt",
        "value": "skier in a red suit: [0.742, 0.289, 0.969, 0.820]\npair of professional-grade snow skis: [0.562, 0.734, 0.812, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000107094_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a skier in a red suit is standing to the right of the pair of professional-grade snow skis, which are lying on snow-covered ground.\nObjects: [skier in a red suit, pair of professional-grade snow skis]"
      },
      {
        "from": "gpt",
        "value": "skier in a red suit: [0.742, 0.289, 0.969, 0.820]\npair of professional-grade snow skis: [0.562, 0.734, 0.812, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000107094_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.742, 0.289, 0.969, 0.820]\nskis: [0.562, 0.734, 0.812, 0.828]\nGiven the above layout, shift the skis to the left by 0.453."
      },
      {
        "from": "gpt",
        "value": "person: [0.742, 0.289, 0.969, 0.820]\nskis: [0.109, 0.734, 0.359, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000107554",
    "conversations": [
      {
        "from": "human",
        "value": "A blue surfboard is leaning against a clear glass table on the grass."
      },
      {
        "from": "gpt",
        "value": "surfboard: [0.000, 0.430, 0.859, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000107554_key",
    "conversations": [
      {
        "from": "human",
        "value": "A blue surfboard is leaning against a clear glass table on the grass.\nObjects: [surfboard]"
      },
      {
        "from": "gpt",
        "value": "surfboard: [0.000, 0.430, 0.859, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000107554_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a blue red skateboard is leaning against a clear glass table on the grass."
      },
      {
        "from": "gpt",
        "value": "red skateboard: [0.000, 0.430, 0.859, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000107554_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a blue red skateboard is leaning against a clear glass table on the grass.\nObjects: [red skateboard]"
      },
      {
        "from": "gpt",
        "value": "red skateboard: [0.000, 0.430, 0.859, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000107554_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: surfboard: [0.000, 0.430, 0.859, 0.633]\nGiven the above layout, shift the surfboard upwards by 0.414."
      },
      {
        "from": "gpt",
        "value": "surfboard: [0.000, 0.016, 0.859, 0.219]"
      }
    ]
  },
  {
    "id": "coco_000000108244",
    "conversations": [
      {
        "from": "human",
        "value": "A cat wearing a pirate hat is sitting inside a box at the center of the image."
      },
      {
        "from": "gpt",
        "value": "cat: [0.281, 0.367, 0.828, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000108244_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat wearing a pirate hat is sitting inside a box at the center of the image.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.281, 0.367, 0.828, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000108244_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a Sphynx cat wearing a tricorn pirate hat wearing a pirate hat is sitting inside a box at the center of the image."
      },
      {
        "from": "gpt",
        "value": "Sphynx cat wearing a tricorn pirate hat: [0.281, 0.367, 0.828, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000108244_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a Sphynx cat wearing a tricorn pirate hat wearing a pirate hat is sitting inside a box at the center of the image.\nObjects: [Sphynx cat wearing a tricorn pirate hat]"
      },
      {
        "from": "gpt",
        "value": "Sphynx cat wearing a tricorn pirate hat: [0.281, 0.367, 0.828, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000108244_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.281, 0.367, 0.828, 0.672]\nGiven the above layout, shift the cat upwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "cat: [0.281, 0.297, 0.828, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000110884",
    "conversations": [
      {
        "from": "human",
        "value": "A sink is mounted on the wall to the left, and a toilet is to the right of the sink."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.586, 0.695, 0.953, 0.969]\nsink: [0.047, 0.547, 0.484, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000110884_key",
    "conversations": [
      {
        "from": "human",
        "value": "A sink is mounted on the wall to the left, and a toilet is to the right of the sink.\nObjects: [toilet, sink]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.586, 0.695, 0.953, 0.969]\nsink: [0.047, 0.547, 0.484, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000110884_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a stainless steel sink is mounted on the wall to the left, and a porcelain toilet is to the right of the stainless steel sink."
      },
      {
        "from": "gpt",
        "value": "porcelain toilet: [0.586, 0.695, 0.953, 0.969]\nstainless steel sink: [0.047, 0.547, 0.484, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000110884_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a stainless steel sink is mounted on the wall to the left, and a porcelain toilet is to the right of the stainless steel sink.\nObjects: [porcelain toilet, stainless steel sink]"
      },
      {
        "from": "gpt",
        "value": "porcelain toilet: [0.586, 0.695, 0.953, 0.969]\nstainless steel sink: [0.047, 0.547, 0.484, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000110884_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.586, 0.695, 0.953, 0.969]\nsink: [0.047, 0.547, 0.484, 0.750]\nGiven the above layout, shift the sink upwards by 0.281."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.586, 0.695, 0.953, 0.969]\nsink: [0.047, 0.266, 0.484, 0.469]"
      }
    ]
  },
  {
    "id": "coco_000000113051",
    "conversations": [
      {
        "from": "human",
        "value": "The boat is docked under an archway to the left side of the image."
      },
      {
        "from": "gpt",
        "value": "boat: [0.055, 0.430, 0.695, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000113051_key",
    "conversations": [
      {
        "from": "human",
        "value": "The boat is docked under an archway to the left side of the image.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.055, 0.430, 0.695, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000113051_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the wooden canoe is docked under an archway to the left side of the image."
      },
      {
        "from": "gpt",
        "value": "wooden canoe: [0.055, 0.430, 0.695, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000113051_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the wooden canoe is docked under an archway to the left side of the image.\nObjects: [wooden canoe]"
      },
      {
        "from": "gpt",
        "value": "wooden canoe: [0.055, 0.430, 0.695, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000113051_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.055, 0.430, 0.695, 0.719]\nGiven the above layout, shift the boat upwards by 0.312."
      },
      {
        "from": "gpt",
        "value": "boat: [0.055, 0.117, 0.695, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000140929",
    "conversations": [
      {
        "from": "human",
        "value": "A clock is mounted on a black structure at the center of the image."
      },
      {
        "from": "gpt",
        "value": "clock: [0.328, 0.219, 0.992, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000140929_key",
    "conversations": [
      {
        "from": "human",
        "value": "A clock is mounted on a black structure at the center of the image.\nObjects: [clock]"
      },
      {
        "from": "gpt",
        "value": "clock: [0.328, 0.219, 0.992, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000140929_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a vintage wall clock is mounted on a black structure at the center of the image."
      },
      {
        "from": "gpt",
        "value": "vintage wall clock: [0.328, 0.219, 0.992, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000140929_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a vintage wall clock is mounted on a black structure at the center of the image.\nObjects: [vintage wall clock]"
      },
      {
        "from": "gpt",
        "value": "vintage wall clock: [0.328, 0.219, 0.992, 0.609]"
      }
    ]
  },
  {
    "id": "coco_000000140929_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: clock: [0.328, 0.219, 0.992, 0.609]\nGiven the above layout, shift the clock downwards by 0.016."
      },
      {
        "from": "gpt",
        "value": "clock: [0.328, 0.234, 0.992, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000155571",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant is walking away from the viewer, towards the right of the image."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.023, 0.180, 0.641, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000155571_key",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant is walking away from the viewer, towards the right of the image.\nObjects: [elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.023, 0.180, 0.641, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000155571_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an large mammoth is walking away from the viewer, towards the right of the image."
      },
      {
        "from": "gpt",
        "value": "large mammoth: [0.023, 0.180, 0.641, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000155571_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an large mammoth is walking away from the viewer, towards the right of the image.\nObjects: [large mammoth]"
      },
      {
        "from": "gpt",
        "value": "large mammoth: [0.023, 0.180, 0.641, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000155571_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: elephant: [0.023, 0.180, 0.641, 0.820]\nGiven the above layout, shift the elephant to the right by 0.039."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.062, 0.180, 0.680, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000178618",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant stands in the center with a cloud of dust in the foreground."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.516, 0.367, 0.789, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000178618_key",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant stands in the center with a cloud of dust in the foreground.\nObjects: [elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.516, 0.367, 0.789, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000178618_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an grown African elephant stands in the center with a cloud of dust in the foreground."
      },
      {
        "from": "gpt",
        "value": "grown African elephant: [0.516, 0.367, 0.789, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000178618_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an grown African elephant stands in the center with a cloud of dust in the foreground.\nObjects: [grown African elephant]"
      },
      {
        "from": "gpt",
        "value": "grown African elephant: [0.516, 0.367, 0.789, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000178618_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: elephant: [0.516, 0.367, 0.789, 0.664]\nGiven the above layout, shift the elephant to the left by 0.117."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.398, 0.367, 0.672, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000185157",
    "conversations": [
      {
        "from": "human",
        "value": "Multiple bicycles are parked haphazardly against a wall to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.188, 0.820, 0.625, 0.992]\nbicycle: [0.531, 0.859, 0.750, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000185157_key",
    "conversations": [
      {
        "from": "human",
        "value": "Multiple bicycles are parked haphazardly against a wall to the right side of the image.\nObjects: [bicycle, bicycle]"
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.188, 0.820, 0.625, 0.992]\nbicycle: [0.531, 0.859, 0.750, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000186422",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is on the right side, walking on rocks by the edge of a river."
      },
      {
        "from": "gpt",
        "value": "bear: [0.289, 0.328, 0.703, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000186422_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is on the right side, walking on rocks by the edge of a river.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.289, 0.328, 0.703, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000186422_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the grizzly bear is on the right side, walking on rocks by the edge of a river."
      },
      {
        "from": "gpt",
        "value": "grizzly bear: [0.289, 0.328, 0.703, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000186422_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the grizzly bear is on the right side, walking on rocks by the edge of a river.\nObjects: [grizzly bear]"
      },
      {
        "from": "gpt",
        "value": "grizzly bear: [0.289, 0.328, 0.703, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000186422_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.289, 0.328, 0.703, 0.641]\nGiven the above layout, shift the bear downwards by 0.305."
      },
      {
        "from": "gpt",
        "value": "bear: [0.289, 0.633, 0.703, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000193717",
    "conversations": [
      {
        "from": "human",
        "value": "A fire hydrant is on the right side of the image, and a person is walking in the background to the left of the fire hydrant."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.156, 0.047, 0.711, 0.945]\nperson: [0.711, 0.188, 0.867, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000193717_key",
    "conversations": [
      {
        "from": "human",
        "value": "A fire hydrant is on the right side of the image, and a person is walking in the background to the left of the fire hydrant.\nObjects: [fire hydrant, person]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.156, 0.047, 0.711, 0.945]\nperson: [0.711, 0.188, 0.867, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000193717_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red fire hydrant is on the right side of the image, and a teenager in a jacket is walking in the background to the left of the red fire hydrant."
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.156, 0.047, 0.711, 0.945]\nteenager in a jacket: [0.711, 0.188, 0.867, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000193717_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red fire hydrant is on the right side of the image, and a teenager in a jacket is walking in the background to the left of the red fire hydrant.\nObjects: [red fire hydrant, teenager in a jacket]"
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.156, 0.047, 0.711, 0.945]\nteenager in a jacket: [0.711, 0.188, 0.867, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000193717_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: fire hydrant: [0.156, 0.047, 0.711, 0.945]\nperson: [0.711, 0.188, 0.867, 0.477]\nGiven the above layout, shift the fire hydrant to the left by 0.062."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.094, 0.047, 0.648, 0.945]\nperson: [0.711, 0.188, 0.867, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000217219",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is centered in the image, partially covered with a yellow quilt, with newspapers on top of it to the right side."
      },
      {
        "from": "gpt",
        "value": "bed: [0.000, 0.219, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000217219_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is centered in the image, partially covered with a yellow quilt, with newspapers on top of it to the right side.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.000, 0.219, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000217219_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the king-size bed with a green blanket is centered in the image, partially covered with a yellow quilt, with newspapers on top of it to the right side."
      },
      {
        "from": "gpt",
        "value": "king-size bed with a green blanket: [0.000, 0.219, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000217219_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the king-size bed with a green blanket is centered in the image, partially covered with a yellow quilt, with newspapers on top of it to the right side.\nObjects: [king-size bed with a green blanket]"
      },
      {
        "from": "gpt",
        "value": "king-size bed with a green blanket: [0.000, 0.219, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000217219_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.000, 0.219, 0.992, 0.766]\nGiven the above layout, shift the bed downwards by 0.141."
      },
      {
        "from": "gpt",
        "value": "bed: [0.000, 0.359, 0.992, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000225757",
    "conversations": [
      {
        "from": "human",
        "value": "The keyboard is in front of the laptop, which is centered between two TVs."
      },
      {
        "from": "gpt",
        "value": "tv: [0.633, 0.211, 0.953, 0.516]\ntv: [0.250, 0.227, 0.586, 0.492]\nlaptop: [0.625, 0.594, 0.945, 0.836]\nkeyboard: [0.172, 0.594, 0.539, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000225757_key",
    "conversations": [
      {
        "from": "human",
        "value": "The keyboard is in front of the laptop, which is centered between two TVs.\nObjects: [tv, tv, laptop, keyboard]"
      },
      {
        "from": "gpt",
        "value": "tv: [0.633, 0.211, 0.953, 0.516]\ntv: [0.250, 0.227, 0.586, 0.492]\nlaptop: [0.625, 0.594, 0.945, 0.836]\nkeyboard: [0.172, 0.594, 0.539, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000226154",
    "conversations": [
      {
        "from": "human",
        "value": "A green bus is on the road, angled towards the left side of the image."
      },
      {
        "from": "gpt",
        "value": "bus: [0.227, 0.266, 0.820, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000226154_key",
    "conversations": [
      {
        "from": "human",
        "value": "A green bus is on the road, angled towards the left side of the image.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.227, 0.266, 0.820, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000226154_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a green city double-decker bus is on the road, angled towards the left side of the image."
      },
      {
        "from": "gpt",
        "value": "city double-decker bus: [0.227, 0.266, 0.820, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000226154_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a green city double-decker bus is on the road, angled towards the left side of the image.\nObjects: [city double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "city double-decker bus: [0.227, 0.266, 0.820, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000226154_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.227, 0.266, 0.820, 0.695]\nGiven the above layout, shift the bus downwards by 0.164."
      },
      {
        "from": "gpt",
        "value": "bus: [0.227, 0.430, 0.820, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000229311",
    "conversations": [
      {
        "from": "human",
        "value": "The sink is in the center of the image, beneath a window."
      },
      {
        "from": "gpt",
        "value": "sink: [0.258, 0.562, 0.797, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000229311_key",
    "conversations": [
      {
        "from": "human",
        "value": "The sink is in the center of the image, beneath a window.\nObjects: [sink]"
      },
      {
        "from": "gpt",
        "value": "sink: [0.258, 0.562, 0.797, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000229311_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the white porcelain sink is in the center of the image, beneath a window."
      },
      {
        "from": "gpt",
        "value": "white porcelain sink: [0.258, 0.562, 0.797, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000229311_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the white porcelain sink is in the center of the image, beneath a window.\nObjects: [white porcelain sink]"
      },
      {
        "from": "gpt",
        "value": "white porcelain sink: [0.258, 0.562, 0.797, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000229311_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sink: [0.258, 0.562, 0.797, 0.781]\nGiven the above layout, shift the sink upwards by 0.375."
      },
      {
        "from": "gpt",
        "value": "sink: [0.258, 0.188, 0.797, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000229997",
    "conversations": [
      {
        "from": "human",
        "value": "A bear is at the center, with one bird to the left, and two birds to the right."
      },
      {
        "from": "gpt",
        "value": "bear: [0.305, 0.344, 0.664, 0.641]\nbird: [0.422, 0.617, 0.594, 0.789]\nbird: [0.648, 0.648, 0.867, 0.773]\nbird: [0.000, 0.570, 0.148, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000229997_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bear is at the center, with one bird to the left, and two birds to the right.\nObjects: [bear, bird, bird, bird]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.305, 0.344, 0.664, 0.641]\nbird: [0.422, 0.617, 0.594, 0.789]\nbird: [0.648, 0.648, 0.867, 0.773]\nbird: [0.000, 0.570, 0.148, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000233139",
    "conversations": [
      {
        "from": "human",
        "value": "Two clocks are placed next to each other on a shelf; the one on the left has a black frame, and the one on the right has a white frame."
      },
      {
        "from": "gpt",
        "value": "clock: [0.078, 0.430, 0.352, 0.703]\nclock: [0.828, 0.484, 0.992, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000233139_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two clocks are placed next to each other on a shelf; the one on the left has a black frame, and the one on the right has a white frame.\nObjects: [clock, clock]"
      },
      {
        "from": "gpt",
        "value": "clock: [0.078, 0.430, 0.352, 0.703]\nclock: [0.828, 0.484, 0.992, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000237071",
    "conversations": [
      {
        "from": "human",
        "value": "A person wearing a blue shirt is playing tennis, swinging the racquet toward the ball at the center."
      },
      {
        "from": "gpt",
        "value": "person: [0.281, 0.328, 0.727, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000237071_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person wearing a blue shirt is playing tennis, swinging the racquet toward the ball at the center.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.281, 0.328, 0.727, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000237071_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a professional tennis player wearing a blue shirt is playing tennis, swinging the racquet toward the ball at the center."
      },
      {
        "from": "gpt",
        "value": "professional tennis player: [0.281, 0.328, 0.727, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000237071_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a professional tennis player wearing a blue shirt is playing tennis, swinging the racquet toward the ball at the center.\nObjects: [professional tennis player]"
      },
      {
        "from": "gpt",
        "value": "professional tennis player: [0.281, 0.328, 0.727, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000237071_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.281, 0.328, 0.727, 0.828]\nGiven the above layout, shift the person upwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "person: [0.281, 0.258, 0.727, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000280325",
    "conversations": [
      {
        "from": "human",
        "value": "The parking meter is on the right side of the image, against a wall with red graffiti."
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.672, 0.438, 0.977, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000280325_key",
    "conversations": [
      {
        "from": "human",
        "value": "The parking meter is on the right side of the image, against a wall with red graffiti.\nObjects: [parking meter]"
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.672, 0.438, 0.977, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000280325_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the digital parking meter is on the right side of the image, against a wall with red graffiti."
      },
      {
        "from": "gpt",
        "value": "digital parking meter: [0.672, 0.438, 0.977, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000280325_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the digital parking meter is on the right side of the image, against a wall with red graffiti.\nObjects: [digital parking meter]"
      },
      {
        "from": "gpt",
        "value": "digital parking meter: [0.672, 0.438, 0.977, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000280325_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: parking meter: [0.672, 0.438, 0.977, 0.836]\nGiven the above layout, shift the parking meter to the left by 0.477."
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.195, 0.438, 0.500, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000286422",
    "conversations": [
      {
        "from": "human",
        "value": "A sailboat is centered in the image, floating on water."
      },
      {
        "from": "gpt",
        "value": "boat: [0.148, 0.203, 0.844, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000286422_key",
    "conversations": [
      {
        "from": "human",
        "value": "A sailboat is centered in the image, floating on water.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.148, 0.203, 0.844, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000286422_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a sailsmall yacht is centered in the image, floating on water."
      },
      {
        "from": "gpt",
        "value": "small yacht: [0.148, 0.203, 0.844, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000286422_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a sailsmall yacht is centered in the image, floating on water.\nObjects: [small yacht]"
      },
      {
        "from": "gpt",
        "value": "small yacht: [0.148, 0.203, 0.844, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000286422_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.148, 0.203, 0.844, 0.742]\nGiven the above layout, shift the boat downwards by 0.156."
      },
      {
        "from": "gpt",
        "value": "boat: [0.148, 0.359, 0.844, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000292330",
    "conversations": [
      {
        "from": "human",
        "value": "A dog with its mouth on the handle of a baseball bat lying on the ground."
      },
      {
        "from": "gpt",
        "value": "dog: [0.273, 0.148, 0.984, 0.602]\nbaseball bat: [0.211, 0.531, 0.805, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000292330_key",
    "conversations": [
      {
        "from": "human",
        "value": "A dog with its mouth on the handle of a baseball bat lying on the ground.\nObjects: [dog, baseball bat]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.273, 0.148, 0.984, 0.602]\nbaseball bat: [0.211, 0.531, 0.805, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000292330_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a fluffy retriever with its mouth on the handle of a wooden baseball bat lying on the ground."
      },
      {
        "from": "gpt",
        "value": "fluffy retriever: [0.273, 0.148, 0.984, 0.602]\nwooden baseball bat: [0.211, 0.531, 0.805, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000292330_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a fluffy retriever with its mouth on the handle of a wooden baseball bat lying on the ground.\nObjects: [fluffy retriever, wooden baseball bat]"
      },
      {
        "from": "gpt",
        "value": "fluffy retriever: [0.273, 0.148, 0.984, 0.602]\nwooden baseball bat: [0.211, 0.531, 0.805, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000292330_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.273, 0.148, 0.984, 0.602]\nbaseball bat: [0.211, 0.531, 0.805, 0.578]\nGiven the above layout, shift the dog downwards by 0.133."
      },
      {
        "from": "gpt",
        "value": "dog: [0.273, 0.281, 0.984, 0.734]\nbaseball bat: [0.211, 0.531, 0.805, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000292415",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding on the left side of the image, silhouetted against the sky."
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.250, 0.602, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000292415_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding on the left side of the image, silhouetted against the sky.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.250, 0.602, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000292415_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager in hoodie is skateboarding on the left side of the image, silhouetted against the sky."
      },
      {
        "from": "gpt",
        "value": "teenager in hoodie: [0.312, 0.250, 0.602, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000292415_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager in hoodie is skateboarding on the left side of the image, silhouetted against the sky.\nObjects: [teenager in hoodie]"
      },
      {
        "from": "gpt",
        "value": "teenager in hoodie: [0.312, 0.250, 0.602, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000292415_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.312, 0.250, 0.602, 0.516]\nGiven the above layout, shift the person downwards by 0.062."
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.312, 0.602, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000295420",
    "conversations": [
      {
        "from": "human",
        "value": "A blue truck facing left is positioned in the center of the image on a road."
      },
      {
        "from": "gpt",
        "value": "truck: [0.250, 0.383, 0.680, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000295420_key",
    "conversations": [
      {
        "from": "human",
        "value": "A blue truck facing left is positioned in the center of the image on a road.\nObjects: [truck]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.250, 0.383, 0.680, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000295420_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a blue yellow tow truck facing left is positioned in the center of the image on a road."
      },
      {
        "from": "gpt",
        "value": "yellow tow truck: [0.250, 0.383, 0.680, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000295420_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a blue yellow tow truck facing left is positioned in the center of the image on a road.\nObjects: [yellow tow truck]"
      },
      {
        "from": "gpt",
        "value": "yellow tow truck: [0.250, 0.383, 0.680, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000295420_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.250, 0.383, 0.680, 0.719]\nGiven the above layout, shift the truck upwards by 0.047."
      },
      {
        "from": "gpt",
        "value": "truck: [0.250, 0.336, 0.680, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000297830",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is sitting on the left with a bottle placed to the right of the dog on the ground."
      },
      {
        "from": "gpt",
        "value": "dog: [0.352, 0.094, 0.836, 0.844]\nbottle: [0.281, 0.672, 0.359, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000297830_key",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is sitting on the left with a bottle placed to the right of the dog on the ground.\nObjects: [dog, bottle]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.352, 0.094, 0.836, 0.844]\nbottle: [0.281, 0.672, 0.359, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000297830_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a German Shepherd is sitting on the left with a green water bottle placed to the right of the German Shepherd on the ground."
      },
      {
        "from": "gpt",
        "value": "German Shepherd: [0.352, 0.094, 0.836, 0.844]\ngreen water bottle: [0.281, 0.672, 0.359, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000297830_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a German Shepherd is sitting on the left with a green water bottle placed to the right of the German Shepherd on the ground.\nObjects: [German Shepherd, green water bottle]"
      },
      {
        "from": "gpt",
        "value": "German Shepherd: [0.352, 0.094, 0.836, 0.844]\ngreen water bottle: [0.281, 0.672, 0.359, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000297830_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.352, 0.094, 0.836, 0.844]\nbottle: [0.281, 0.672, 0.359, 0.922]\nGiven the above layout, shift the bottle to the left by 0.148."
      },
      {
        "from": "gpt",
        "value": "dog: [0.352, 0.094, 0.836, 0.844]\nbottle: [0.133, 0.672, 0.211, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000299720",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe's head is peeking out from behind a post on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.492, 0.172, 0.805, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000299720_key",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffes head is peeking out from behind a post on the left side of the image.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.492, 0.172, 0.805, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000299720_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the long-necked ostrich's head is peeking out from behind a post on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "long-necked ostrich: [0.492, 0.172, 0.805, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000299720_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the long-necked ostrichs head is peeking out from behind a post on the left side of the image.\nObjects: [long-necked ostrich]"
      },
      {
        "from": "gpt",
        "value": "long-necked ostrich: [0.492, 0.172, 0.805, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000299720_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.492, 0.172, 0.805, 0.828]\nGiven the above layout, shift the giraffe to the left by 0.430."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.062, 0.172, 0.375, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000303863",
    "conversations": [
      {
        "from": "human",
        "value": "A train on the tracks is in the center, with a person on the left in the background, and another person on the right in the background."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.352, 0.906, 0.695]\nperson: [0.938, 0.477, 0.992, 0.625]\nperson: [0.875, 0.484, 0.930, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000303863_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train on the tracks is in the center, with a person on the left in the background, and another person on the right in the background.\nObjects: [train, person, person]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.352, 0.906, 0.695]\nperson: [0.938, 0.477, 0.992, 0.625]\nperson: [0.875, 0.484, 0.930, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000307598",
    "conversations": [
      {
        "from": "human",
        "value": "A train is coming towards the foreground, traveling from left to right under a signal bridge."
      },
      {
        "from": "gpt",
        "value": "train: [0.133, 0.516, 0.836, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000307598_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is coming towards the foreground, traveling from left to right under a signal bridge.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.133, 0.516, 0.836, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000307598_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a diesel locomotive is coming towards the foreground, traveling from left to right under a signal bridge."
      },
      {
        "from": "gpt",
        "value": "diesel locomotive: [0.133, 0.516, 0.836, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000307598_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a diesel locomotive is coming towards the foreground, traveling from left to right under a signal bridge.\nObjects: [diesel locomotive]"
      },
      {
        "from": "gpt",
        "value": "diesel locomotive: [0.133, 0.516, 0.836, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000307598_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.133, 0.516, 0.836, 0.766]\nGiven the above layout, shift the train upwards by 0.289."
      },
      {
        "from": "gpt",
        "value": "train: [0.133, 0.227, 0.836, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000311392",
    "conversations": [
      {
        "from": "human",
        "value": "A cow is in the foreground to the left, and a person stands in the background to the right, looking towards the cow."
      },
      {
        "from": "gpt",
        "value": "cow: [0.000, 0.281, 0.852, 0.828]\nperson: [0.758, 0.367, 0.867, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000311392_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cow is in the foreground to the left, and a person stands in the background to the right, looking towards the cow.\nObjects: [cow, person]"
      },
      {
        "from": "gpt",
        "value": "cow: [0.000, 0.281, 0.852, 0.828]\nperson: [0.758, 0.367, 0.867, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000311392_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a brown cow is in the foreground to the left, and a farmer in a hat stands in the background to the right, looking towards the brown cow."
      },
      {
        "from": "gpt",
        "value": "brown cow: [0.000, 0.281, 0.852, 0.828]\nfarmer in a hat: [0.758, 0.367, 0.867, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000311392_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a brown cow is in the foreground to the left, and a farmer in a hat stands in the background to the right, looking towards the brown cow.\nObjects: [brown cow, farmer in a hat]"
      },
      {
        "from": "gpt",
        "value": "brown cow: [0.000, 0.281, 0.852, 0.828]\nfarmer in a hat: [0.758, 0.367, 0.867, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000311392_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cow: [0.000, 0.281, 0.852, 0.828]\nperson: [0.758, 0.367, 0.867, 0.594]\nGiven the above layout, shift the cow upwards by 0.203."
      },
      {
        "from": "gpt",
        "value": "cow: [0.000, 0.078, 0.852, 0.625]\nperson: [0.758, 0.367, 0.867, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000323709",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is on the ground, centered in the image, with a clear sky above and grass below."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.102, 0.453, 0.727, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000323709_key",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is on the ground, centered in the image, with a clear sky above and grass below.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.102, 0.453, 0.727, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000323709_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the silver jumbo jet is on the ground, centered in the image, with a clear sky above and grass below."
      },
      {
        "from": "gpt",
        "value": "silver jumbo jet: [0.102, 0.453, 0.727, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000323709_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the silver jumbo jet is on the ground, centered in the image, with a clear sky above and grass below.\nObjects: [silver jumbo jet]"
      },
      {
        "from": "gpt",
        "value": "silver jumbo jet: [0.102, 0.453, 0.727, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000323709_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.102, 0.453, 0.727, 0.648]\nGiven the above layout, shift the airplane upwards by 0.227."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.102, 0.227, 0.727, 0.422]"
      }
    ]
  },
  {
    "id": "coco_000000350405",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center of the image riding a snowboard down a snowy slope."
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.336, 0.789, 0.656]\nsnowboard: [0.516, 0.625, 0.852, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000350405_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center of the image riding a snowboard down a snowy slope.\nObjects: [person, snowboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.336, 0.789, 0.656]\nsnowboard: [0.516, 0.625, 0.852, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000350405_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a white white snowboarder in a red jacket is in the center of the image riding a white snowboard down a snowy slope."
      },
      {
        "from": "gpt",
        "value": "white snowboarder in a red jacket: [0.367, 0.336, 0.789, 0.656]\nwhite snowboard: [0.516, 0.625, 0.852, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000350405_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a white white snowboarder in a red jacket is in the center of the image riding a white snowboard down a snowy slope.\nObjects: [white snowboarder in a red jacket, white snowboard]"
      },
      {
        "from": "gpt",
        "value": "white snowboarder in a red jacket: [0.367, 0.336, 0.789, 0.656]\nwhite snowboard: [0.516, 0.625, 0.852, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000350405_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.367, 0.336, 0.789, 0.656]\nsnowboard: [0.516, 0.625, 0.852, 0.695]\nGiven the above layout, shift the person to the left by 0.125."
      },
      {
        "from": "gpt",
        "value": "person: [0.242, 0.336, 0.664, 0.656]\nsnowboard: [0.516, 0.625, 0.852, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000375015",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is positioned at the center, facing to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "bear: [0.453, 0.180, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000375015_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is positioned at the center, facing to the right side of the image.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.453, 0.180, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000375015_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the brown bear is positioned at the center, facing to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "brown bear: [0.453, 0.180, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000375015_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the brown bear is positioned at the center, facing to the right side of the image.\nObjects: [brown bear]"
      },
      {
        "from": "gpt",
        "value": "brown bear: [0.453, 0.180, 0.992, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000375015_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.453, 0.180, 0.992, 0.805]\nGiven the above layout, shift the bear to the left by 0.078."
      },
      {
        "from": "gpt",
        "value": "bear: [0.375, 0.180, 0.914, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000385205",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is lying on the floor with a carrot to the right side, partially under the cat's paw."
      },
      {
        "from": "gpt",
        "value": "cat: [0.047, 0.133, 0.977, 0.750]\ncarrot: [0.047, 0.539, 0.266, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000385205_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is lying on the floor with a carrot to the right side, partially under the cats paw.\nObjects: [cat, carrot]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.047, 0.133, 0.977, 0.750]\ncarrot: [0.047, 0.539, 0.266, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000385205_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a cat is lying on the floor with a carrot to the right side, partially under the cat's paw."
      },
      {
        "from": "gpt",
        "value": "cat: [0.047, 0.133, 0.977, 0.750]\ncarrot: [0.047, 0.539, 0.266, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000385205_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a cat is lying on the floor with a carrot to the right side, partially under the cats paw.\nObjects: [cat, carrot]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.047, 0.133, 0.977, 0.750]\ncarrot: [0.047, 0.539, 0.266, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000385205_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.047, 0.133, 0.977, 0.750]\ncarrot: [0.047, 0.539, 0.266, 0.727]\nGiven the above layout, shift the cat downwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "cat: [0.047, 0.156, 0.977, 0.773]\ncarrot: [0.047, 0.539, 0.266, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000386457",
    "conversations": [
      {
        "from": "human",
        "value": "A cat peeking through a partially open wooden door at the center of the image."
      },
      {
        "from": "gpt",
        "value": "cat: [0.359, 0.203, 0.539, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000386457_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat peeking through a partially open wooden door at the center of the image.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.359, 0.203, 0.539, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000386457_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a calico kitten peeking through a partially open wooden door at the center of the image."
      },
      {
        "from": "gpt",
        "value": "calico kitten: [0.359, 0.203, 0.539, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000386457_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a calico kitten peeking through a partially open wooden door at the center of the image.\nObjects: [calico kitten]"
      },
      {
        "from": "gpt",
        "value": "calico kitten: [0.359, 0.203, 0.539, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000386457_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.359, 0.203, 0.539, 0.805]\nGiven the above layout, shift the cat to the right by 0.164."
      },
      {
        "from": "gpt",
        "value": "cat: [0.523, 0.203, 0.703, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000387387",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is positioned in the center of the image."
      },
      {
        "from": "gpt",
        "value": "bus: [0.062, 0.453, 0.945, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000387387_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is positioned in the center of the image.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.062, 0.453, 0.945, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000387387_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker bus is positioned in the center of the image."
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.062, 0.453, 0.945, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000387387_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker bus is positioned in the center of the image.\nObjects: [double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.062, 0.453, 0.945, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000387387_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.062, 0.453, 0.945, 0.711]\nGiven the above layout, shift the bus upwards by 0.344."
      },
      {
        "from": "gpt",
        "value": "bus: [0.062, 0.109, 0.945, 0.367]"
      }
    ]
  },
  {
    "id": "coco_000000391140",
    "conversations": [
      {
        "from": "human",
        "value": "A person wearing a blue shirt and khaki pants, standing with their right arm raised."
      },
      {
        "from": "gpt",
        "value": "person: [0.125, 0.258, 0.617, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000391140_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person wearing a blue shirt and khaki pants, standing with their right arm raised.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.125, 0.258, 0.617, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000391140_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a man in a business suit wearing a blue shirt and khaki pants, standing with their right arm raised."
      },
      {
        "from": "gpt",
        "value": "man in a business suit: [0.125, 0.258, 0.617, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000391140_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a man in a business suit wearing a blue shirt and khaki pants, standing with their right arm raised.\nObjects: [man in a business suit]"
      },
      {
        "from": "gpt",
        "value": "man in a business suit: [0.125, 0.258, 0.617, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000391140_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.125, 0.258, 0.617, 0.859]\nGiven the above layout, shift the person to the right by 0.359."
      },
      {
        "from": "gpt",
        "value": "person: [0.484, 0.258, 0.977, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000393282",
    "conversations": [
      {
        "from": "human",
        "value": "One giraffe stands in the center while a smaller giraffe is positioned to its left at a slight distance."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.500, 0.383, 0.734, 0.828]\ngiraffe: [0.195, 0.539, 0.367, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000393282_key",
    "conversations": [
      {
        "from": "human",
        "value": "One giraffe stands in the center while a smaller giraffe is positioned to its left at a slight distance.\nObjects: [giraffe, giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.500, 0.383, 0.734, 0.828]\ngiraffe: [0.195, 0.539, 0.367, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000396518",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting in the boat, which is in the lower right section of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.617, 0.297, 0.898, 0.695]\nboat: [0.734, 0.594, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000396518_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting in the boat, which is in the lower right section of the image.\nObjects: [person, boat]"
      },
      {
        "from": "gpt",
        "value": "person: [0.617, 0.297, 0.898, 0.695]\nboat: [0.734, 0.594, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000396518_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman is sitting in the blue sailing yacht, which is in the lower right section of the image."
      },
      {
        "from": "gpt",
        "value": "young woman: [0.617, 0.297, 0.898, 0.695]\nblue sailing yacht: [0.734, 0.594, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000396518_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman is sitting in the blue sailing yacht, which is in the lower right section of the image.\nObjects: [young woman, blue sailing yacht]"
      },
      {
        "from": "gpt",
        "value": "young woman: [0.617, 0.297, 0.898, 0.695]\nblue sailing yacht: [0.734, 0.594, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000396518_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.617, 0.297, 0.898, 0.695]\nboat: [0.734, 0.594, 0.992, 0.766]\nGiven the above layout, shift the person to the left by 0.375."
      },
      {
        "from": "gpt",
        "value": "person: [0.242, 0.297, 0.523, 0.695]\nboat: [0.734, 0.594, 0.992, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000396568",
    "conversations": [
      {
        "from": "human",
        "value": "A train on the tracks moving from the left to the right of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.125, 0.484, 0.641, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000396568_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train on the tracks moving from the left to the right of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.125, 0.484, 0.641, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000396568_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a red locomotive on the tracks moving from the left to the right of the image."
      },
      {
        "from": "gpt",
        "value": "a red locomotive: [0.125, 0.484, 0.641, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000396568_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a red locomotive on the tracks moving from the left to the right of the image.\nObjects: [a red locomotive]"
      },
      {
        "from": "gpt",
        "value": "a red locomotive: [0.125, 0.484, 0.641, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000396568_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.125, 0.484, 0.641, 0.719]\nGiven the above layout, shift the train upwards by 0.141."
      },
      {
        "from": "gpt",
        "value": "train: [0.125, 0.344, 0.641, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000397639",
    "conversations": [
      {
        "from": "human",
        "value": "A larger sheep stands to the left while a smaller sheep stands to its right."
      },
      {
        "from": "gpt",
        "value": "sheep: [0.359, 0.398, 0.594, 0.742]\nsheep: [0.594, 0.523, 0.742, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000397639_key",
    "conversations": [
      {
        "from": "human",
        "value": "A larger sheep stands to the left while a smaller sheep stands to its right.\nObjects: [sheep, sheep]"
      },
      {
        "from": "gpt",
        "value": "sheep: [0.359, 0.398, 0.594, 0.742]\nsheep: [0.594, 0.523, 0.742, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000400803",
    "conversations": [
      {
        "from": "human",
        "value": "A lifeboat is directly in the center of the image, floating on the water."
      },
      {
        "from": "gpt",
        "value": "boat: [0.172, 0.320, 0.562, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000400803_key",
    "conversations": [
      {
        "from": "human",
        "value": "A lifeboat is directly in the center of the image, floating on the water.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.172, 0.320, 0.562, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000400803_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a lifeinflatable raft is directly in the center of the image, floating on the water."
      },
      {
        "from": "gpt",
        "value": "inflatable raft: [0.172, 0.320, 0.562, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000400803_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a lifeinflatable raft is directly in the center of the image, floating on the water.\nObjects: [inflatable raft]"
      },
      {
        "from": "gpt",
        "value": "inflatable raft: [0.172, 0.320, 0.562, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000400803_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.172, 0.320, 0.562, 0.789]\nGiven the above layout, shift the boat to the right by 0.359."
      },
      {
        "from": "gpt",
        "value": "boat: [0.531, 0.320, 0.922, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000408112",
    "conversations": [
      {
        "from": "human",
        "value": "A silver airplane in the foreground on the left and another airplane in the background on the right."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.000, 0.281, 0.641, 0.633]\nairplane: [0.648, 0.375, 0.992, 0.492]"
      }
    ]
  },
  {
    "id": "coco_000000408112_key",
    "conversations": [
      {
        "from": "human",
        "value": "A silver airplane in the foreground on the left and another airplane in the background on the right.\nObjects: [airplane, airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.000, 0.281, 0.641, 0.633]\nairplane: [0.648, 0.375, 0.992, 0.492]"
      }
    ]
  },
  {
    "id": "coco_000000436315",
    "conversations": [
      {
        "from": "human",
        "value": "A freshly baked pizza is in the center of the image on a metal baking surface."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.156, 0.211, 0.805, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000436315_key",
    "conversations": [
      {
        "from": "human",
        "value": "A freshly baked pizza is in the center of the image on a metal baking surface.\nObjects: [pizza]"
      },
      {
        "from": "gpt",
        "value": "pizza: [0.156, 0.211, 0.805, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000436315_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a freshly baked pepperoni pizza with melting cheese is in the center of the image on a metal baking surface."
      },
      {
        "from": "gpt",
        "value": "pepperoni pizza with melting cheese: [0.156, 0.211, 0.805, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000436315_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a freshly baked pepperoni pizza with melting cheese is in the center of the image on a metal baking surface.\nObjects: [pepperoni pizza with melting cheese]"
      },
      {
        "from": "gpt",
        "value": "pepperoni pizza with melting cheese: [0.156, 0.211, 0.805, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000436315_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: pizza: [0.156, 0.211, 0.805, 0.758]\nGiven the above layout, shift the pizza downwards by 0.156."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.156, 0.367, 0.805, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000452515",
    "conversations": [
      {
        "from": "human",
        "value": "One person is standing on the tennis court in the foreground, while another person with a camera is standing on an elevated platform in the background to the left."
      },
      {
        "from": "gpt",
        "value": "person: [0.445, 0.617, 0.617, 0.938]\nperson: [0.609, 0.070, 0.695, 0.281]"
      }
    ]
  },
  {
    "id": "coco_000000452515_key",
    "conversations": [
      {
        "from": "human",
        "value": "One person is standing on the tennis court in the foreground, while another person with a camera is standing on an elevated platform in the background to the left.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.445, 0.617, 0.617, 0.938]\nperson: [0.609, 0.070, 0.695, 0.281]"
      }
    ]
  },
  {
    "id": "coco_000000477805",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting in front of an open laptop."
      },
      {
        "from": "gpt",
        "value": "person: [0.594, 0.188, 0.906, 0.766]\nlaptop: [0.109, 0.516, 0.391, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000477805_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting in front of an open laptop.\nObjects: [person, laptop]"
      },
      {
        "from": "gpt",
        "value": "person: [0.594, 0.188, 0.906, 0.766]\nlaptop: [0.109, 0.516, 0.391, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000477805_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a person is sitting in front of an open laptop."
      },
      {
        "from": "gpt",
        "value": "person: [0.594, 0.188, 0.906, 0.766]\nlaptop: [0.109, 0.516, 0.391, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000477805_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a person is sitting in front of an open laptop.\nObjects: [person, laptop]"
      },
      {
        "from": "gpt",
        "value": "person: [0.594, 0.188, 0.906, 0.766]\nlaptop: [0.109, 0.516, 0.391, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000477805_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.594, 0.188, 0.906, 0.766]\nlaptop: [0.109, 0.516, 0.391, 0.797]\nGiven the above layout, shift the laptop downwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "person: [0.594, 0.188, 0.906, 0.766]\nlaptop: [0.109, 0.555, 0.391, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000479953",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center of the image, kicking a soccer ball on a field."
      },
      {
        "from": "gpt",
        "value": "person: [0.133, 0.344, 0.422, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000479953_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center of the image, kicking a soccer ball on a field.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.133, 0.344, 0.422, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000479953_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a professional footballer is at the center of the image, kicking a soccer ball on a field."
      },
      {
        "from": "gpt",
        "value": "professional footballer: [0.133, 0.344, 0.422, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000479953_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a professional footballer is at the center of the image, kicking a soccer ball on a field.\nObjects: [professional footballer]"
      },
      {
        "from": "gpt",
        "value": "professional footballer: [0.133, 0.344, 0.422, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000479953_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.133, 0.344, 0.422, 0.594]\nGiven the above layout, shift the person to the right by 0.062."
      },
      {
        "from": "gpt",
        "value": "person: [0.195, 0.344, 0.484, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000484978",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting at a dining table with various items on it."
      },
      {
        "from": "gpt",
        "value": "dining table: [0.000, 0.570, 0.992, 0.875]\nperson: [0.133, 0.219, 0.500, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000484978_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting at a dining table with various items on it.\nObjects: [dining table, person]"
      },
      {
        "from": "gpt",
        "value": "dining table: [0.000, 0.570, 0.992, 0.875]\nperson: [0.133, 0.219, 0.500, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000484978_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a person is sitting at a dining table with various items on it."
      },
      {
        "from": "gpt",
        "value": "dining table: [0.000, 0.570, 0.992, 0.875]\nperson: [0.133, 0.219, 0.500, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000484978_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a person is sitting at a dining table with various items on it.\nObjects: [dining table, person]"
      },
      {
        "from": "gpt",
        "value": "dining table: [0.000, 0.570, 0.992, 0.875]\nperson: [0.133, 0.219, 0.500, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000484978_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dining table: [0.000, 0.570, 0.992, 0.875]\nperson: [0.133, 0.219, 0.500, 0.602]\nGiven the above layout, shift the person upwards by 0.203."
      },
      {
        "from": "gpt",
        "value": "dining table: [0.000, 0.570, 0.992, 0.875]\nperson: [0.133, 0.016, 0.500, 0.398]"
      }
    ]
  },
  {
    "id": "coco_000000485027",
    "conversations": [
      {
        "from": "human",
        "value": "A person at the center holding a tennis racket above his head with both hands."
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.281, 0.609, 0.961]\ntennis racket: [0.594, 0.383, 0.734, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000485027_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person at the center holding a tennis racket above his head with both hands.\nObjects: [person, tennis racket]"
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.281, 0.609, 0.961]\ntennis racket: [0.594, 0.383, 0.734, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000485027_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a sportsman at the center holding a professional tennis racket above his head with both hands."
      },
      {
        "from": "gpt",
        "value": "sportsman: [0.367, 0.281, 0.609, 0.961]\nprofessional tennis racket: [0.594, 0.383, 0.734, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000485027_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a sportsman at the center holding a professional tennis racket above his head with both hands.\nObjects: [sportsman, professional tennis racket]"
      },
      {
        "from": "gpt",
        "value": "sportsman: [0.367, 0.281, 0.609, 0.961]\nprofessional tennis racket: [0.594, 0.383, 0.734, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000485027_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.367, 0.281, 0.609, 0.961]\ntennis racket: [0.594, 0.383, 0.734, 0.500]\nGiven the above layout, shift the person to the left by 0.234."
      },
      {
        "from": "gpt",
        "value": "person: [0.133, 0.281, 0.375, 0.961]\ntennis racket: [0.594, 0.383, 0.734, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000497867",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is positioned in the center of the image, facing to the left."
      },
      {
        "from": "gpt",
        "value": "bus: [0.086, 0.281, 0.914, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000497867_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is positioned in the center of the image, facing to the left.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.086, 0.281, 0.914, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000497867_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red double-decker bus is positioned in the center of the image, facing to the left."
      },
      {
        "from": "gpt",
        "value": "red double-decker bus: [0.086, 0.281, 0.914, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000497867_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red double-decker bus is positioned in the center of the image, facing to the left.\nObjects: [red double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "red double-decker bus: [0.086, 0.281, 0.914, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000497867_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.086, 0.281, 0.914, 0.695]\nGiven the above layout, shift the bus downwards by 0.211."
      },
      {
        "from": "gpt",
        "value": "bus: [0.086, 0.492, 0.914, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000508917",
    "conversations": [
      {
        "from": "human",
        "value": "A train on the tracks to the left, with a person in front of it. Another person is standing to the far right."
      },
      {
        "from": "gpt",
        "value": "train: [0.281, 0.430, 0.711, 0.656]\nperson: [0.039, 0.484, 0.094, 0.625]\nperson: [0.812, 0.500, 0.859, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000508917_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train on the tracks to the left, with a person in front of it. Another person is standing to the far right.\nObjects: [train, person, person]"
      },
      {
        "from": "gpt",
        "value": "train: [0.281, 0.430, 0.711, 0.656]\nperson: [0.039, 0.484, 0.094, 0.625]\nperson: [0.812, 0.500, 0.859, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000516143",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is parked on the right side of the image, behind a signpost."
      },
      {
        "from": "gpt",
        "value": "bus: [0.102, 0.406, 0.852, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000516143_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is parked on the right side of the image, behind a signpost.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.102, 0.406, 0.852, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000516143_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the yellow school bus is parked on the right side of the image, behind a signpost."
      },
      {
        "from": "gpt",
        "value": "yellow school bus: [0.102, 0.406, 0.852, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000516143_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the yellow school bus is parked on the right side of the image, behind a signpost.\nObjects: [yellow school bus]"
      },
      {
        "from": "gpt",
        "value": "yellow school bus: [0.102, 0.406, 0.852, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000516143_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.102, 0.406, 0.852, 0.727]\nGiven the above layout, shift the bus upwards by 0.141."
      },
      {
        "from": "gpt",
        "value": "bus: [0.102, 0.266, 0.852, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000518213",
    "conversations": [
      {
        "from": "human",
        "value": "A cow is standing in the grass, turned slightly to the right with its head facing the camera."
      },
      {
        "from": "gpt",
        "value": "cow: [0.086, 0.305, 0.758, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000518213_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cow is standing in the grass, turned slightly to the right with its head facing the camera.\nObjects: [cow]"
      },
      {
        "from": "gpt",
        "value": "cow: [0.086, 0.305, 0.758, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000518213_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a black and white dairy cow is standing in the grass, turned slightly to the right with its head facing the camera."
      },
      {
        "from": "gpt",
        "value": "black and white dairy cow: [0.086, 0.305, 0.758, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000518213_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a black and white dairy cow is standing in the grass, turned slightly to the right with its head facing the camera.\nObjects: [black and white dairy cow]"
      },
      {
        "from": "gpt",
        "value": "black and white dairy cow: [0.086, 0.305, 0.758, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000518213_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cow: [0.086, 0.305, 0.758, 0.773]\nGiven the above layout, shift the cow upwards by 0.234."
      },
      {
        "from": "gpt",
        "value": "cow: [0.086, 0.070, 0.758, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000519611",
    "conversations": [
      {
        "from": "human",
        "value": "A polar bear is standing on a rock surface with its body facing to the right."
      },
      {
        "from": "gpt",
        "value": "bear: [0.227, 0.297, 0.789, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000519611_key",
    "conversations": [
      {
        "from": "human",
        "value": "A polar bear is standing on a rock surface with its body facing to the right.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.227, 0.297, 0.789, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000519611_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a polar snowy white bear is standing on a rock surface with its body facing to the right."
      },
      {
        "from": "gpt",
        "value": "snowy white bear: [0.227, 0.297, 0.789, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000519611_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a polar snowy white bear is standing on a rock surface with its body facing to the right.\nObjects: [snowy white bear]"
      },
      {
        "from": "gpt",
        "value": "snowy white bear: [0.227, 0.297, 0.789, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000519611_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.227, 0.297, 0.789, 0.719]\nGiven the above layout, shift the bear upwards by 0.094."
      },
      {
        "from": "gpt",
        "value": "bear: [0.227, 0.203, 0.789, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000521282",
    "conversations": [
      {
        "from": "human",
        "value": "The vase is at the center of the image filled with flowers."
      },
      {
        "from": "gpt",
        "value": "vase: [0.273, 0.461, 0.609, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000521282_key",
    "conversations": [
      {
        "from": "human",
        "value": "The vase is at the center of the image filled with flowers.\nObjects: [vase]"
      },
      {
        "from": "gpt",
        "value": "vase: [0.273, 0.461, 0.609, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000521282_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain vase filled with roses is at the center of the image filled with flowers."
      },
      {
        "from": "gpt",
        "value": "porcelain vase filled with roses: [0.273, 0.461, 0.609, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000521282_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain vase filled with roses is at the center of the image filled with flowers.\nObjects: [porcelain vase filled with roses]"
      },
      {
        "from": "gpt",
        "value": "porcelain vase filled with roses: [0.273, 0.461, 0.609, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000521282_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: vase: [0.273, 0.461, 0.609, 0.977]\nGiven the above layout, shift the vase upwards by 0.297."
      },
      {
        "from": "gpt",
        "value": "vase: [0.273, 0.164, 0.609, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000537812",
    "conversations": [
      {
        "from": "human",
        "value": "A chair to the right of the toilet, with a red bucket on top of it."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.062, 0.250, 0.375, 0.867]\nchair: [0.461, 0.523, 0.656, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000537812_key",
    "conversations": [
      {
        "from": "human",
        "value": "A chair to the right of the toilet, with a red bucket on top of it.\nObjects: [toilet, chair]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.062, 0.250, 0.375, 0.867]\nchair: [0.461, 0.523, 0.656, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000537812_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a white plastic chair to the right of the porcelain toilet, with a red bucket on top of it."
      },
      {
        "from": "gpt",
        "value": "porcelain toilet: [0.062, 0.250, 0.375, 0.867]\nwhite plastic chair: [0.461, 0.523, 0.656, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000537812_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a white plastic chair to the right of the porcelain toilet, with a red bucket on top of it.\nObjects: [porcelain toilet, white plastic chair]"
      },
      {
        "from": "gpt",
        "value": "porcelain toilet: [0.062, 0.250, 0.375, 0.867]\nwhite plastic chair: [0.461, 0.523, 0.656, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000537812_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.062, 0.250, 0.375, 0.867]\nchair: [0.461, 0.523, 0.656, 0.797]\nGiven the above layout, shift the chair to the right by 0.266."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.062, 0.250, 0.375, 0.867]\nchair: [0.727, 0.523, 0.922, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000547519",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is at the center of the image, walking towards the viewer."
      },
      {
        "from": "gpt",
        "value": "bear: [0.422, 0.375, 0.766, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000547519_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is at the center of the image, walking towards the viewer.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.422, 0.375, 0.766, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000547519_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the grizzly bear is at the center of the image, walking towards the viewer."
      },
      {
        "from": "gpt",
        "value": "grizzly bear: [0.422, 0.375, 0.766, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000547519_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the grizzly bear is at the center of the image, walking towards the viewer.\nObjects: [grizzly bear]"
      },
      {
        "from": "gpt",
        "value": "grizzly bear: [0.422, 0.375, 0.766, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000547519_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.422, 0.375, 0.766, 0.758]\nGiven the above layout, shift the bear to the left by 0.055."
      },
      {
        "from": "gpt",
        "value": "bear: [0.367, 0.375, 0.711, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000581317",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center of the image, looking at a mobile phone in their right hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.633, 0.305, 0.953, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000581317_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center of the image, looking at a mobile phone in their right hand.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.633, 0.305, 0.953, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000581317_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman is standing at the center of the image, looking at a mobile phone in their right hand."
      },
      {
        "from": "gpt",
        "value": "young woman: [0.633, 0.305, 0.953, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000581317_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman is standing at the center of the image, looking at a mobile phone in their right hand.\nObjects: [young woman]"
      },
      {
        "from": "gpt",
        "value": "young woman: [0.633, 0.305, 0.953, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000581317_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.633, 0.305, 0.953, 0.773]\nGiven the above layout, shift the person to the left by 0.562."
      },
      {
        "from": "gpt",
        "value": "person: [0.070, 0.305, 0.391, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000009769",
    "conversations": [
      {
        "from": "human",
        "value": "A red truck with a snowplow attached to the front is angled towards the left side of the image on a snowy road."
      },
      {
        "from": "gpt",
        "value": "truck: [0.133, 0.414, 0.719, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000009769_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red truck with a snowplow attached to the front is angled towards the left side of the image on a snowy road.\nObjects: [truck]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.133, 0.414, 0.719, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000009769_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red blue tractor with a snowplow attached to the front is angled towards the left side of the image on a snowy road."
      },
      {
        "from": "gpt",
        "value": "blue tractor: [0.133, 0.414, 0.719, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000009769_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red blue tractor with a snowplow attached to the front is angled towards the left side of the image on a snowy road.\nObjects: [blue tractor]"
      },
      {
        "from": "gpt",
        "value": "blue tractor: [0.133, 0.414, 0.719, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000009769_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.133, 0.414, 0.719, 0.711]\nGiven the above layout, shift the truck upwards by 0.195."
      },
      {
        "from": "gpt",
        "value": "truck: [0.133, 0.219, 0.719, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000017115",
    "conversations": [
      {
        "from": "human",
        "value": "Two zebras positioned next to each other facing away from the camera."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.156, 0.148, 0.477, 0.922]\nzebra: [0.531, 0.188, 0.836, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000017115_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two zebras positioned next to each other facing away from the camera.\nObjects: [zebra, zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.156, 0.148, 0.477, 0.922]\nzebra: [0.531, 0.188, 0.836, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000017627",
    "conversations": [
      {
        "from": "human",
        "value": "There is no bus visible in this image."
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.125, 0.242, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000017627_key",
    "conversations": [
      {
        "from": "human",
        "value": "There is no bus visible in this image.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.000, 0.125, 0.242, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000017627_aug",
    "conversations": [
      {
        "from": "human",
        "value": "there is no blue luxury coach visible in this image."
      },
      {
        "from": "gpt",
        "value": "blue luxury coach: [0.000, 0.125, 0.242, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000017627_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "there is no blue luxury coach visible in this image.\nObjects: [blue luxury coach]"
      },
      {
        "from": "gpt",
        "value": "blue luxury coach: [0.000, 0.125, 0.242, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000017627_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.000, 0.125, 0.242, 0.859]\nGiven the above layout, shift the bus to the right by 0.031."
      },
      {
        "from": "gpt",
        "value": "bus: [0.031, 0.125, 0.273, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000020107",
    "conversations": [
      {
        "from": "human",
        "value": "A fire hydrant stands to the left of the image."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.406, 0.172, 0.828, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000020107_key",
    "conversations": [
      {
        "from": "human",
        "value": "A fire hydrant stands to the left of the image.\nObjects: [fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.406, 0.172, 0.828, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000020107_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red fire hydrant stands to the left of the image."
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.406, 0.172, 0.828, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000020107_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red fire hydrant stands to the left of the image.\nObjects: [red fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.406, 0.172, 0.828, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000020107_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: fire hydrant: [0.406, 0.172, 0.828, 0.977]\nGiven the above layout, shift the fire hydrant to the left by 0.047."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.359, 0.172, 0.781, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000031050",
    "conversations": [
      {
        "from": "human",
        "value": "The vase is at the center on top of a white pedestal."
      },
      {
        "from": "gpt",
        "value": "vase: [0.414, 0.383, 0.594, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000031050_key",
    "conversations": [
      {
        "from": "human",
        "value": "The vase is at the center on top of a white pedestal.\nObjects: [vase]"
      },
      {
        "from": "gpt",
        "value": "vase: [0.414, 0.383, 0.594, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000031050_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the elegant ceramic vase is at the center on top of a white pedestal."
      },
      {
        "from": "gpt",
        "value": "elegant ceramic vase: [0.414, 0.383, 0.594, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000031050_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the elegant ceramic vase is at the center on top of a white pedestal.\nObjects: [elegant ceramic vase]"
      },
      {
        "from": "gpt",
        "value": "elegant ceramic vase: [0.414, 0.383, 0.594, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000031050_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: vase: [0.414, 0.383, 0.594, 0.883]\nGiven the above layout, shift the vase to the left by 0.094."
      },
      {
        "from": "gpt",
        "value": "vase: [0.320, 0.383, 0.500, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000038576",
    "conversations": [
      {
        "from": "human",
        "value": "A keyboard is centered in front of a TV, with a mouse to the right of the keyboard."
      },
      {
        "from": "gpt",
        "value": "tv: [0.266, 0.055, 0.594, 0.453]\nkeyboard: [0.219, 0.586, 0.820, 0.797]\nmouse: [0.492, 0.789, 0.672, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000038576_key",
    "conversations": [
      {
        "from": "human",
        "value": "A keyboard is centered in front of a TV, with a mouse to the right of the keyboard.\nObjects: [tv, keyboard, mouse]"
      },
      {
        "from": "gpt",
        "value": "tv: [0.266, 0.055, 0.594, 0.453]\nkeyboard: [0.219, 0.586, 0.820, 0.797]\nmouse: [0.492, 0.789, 0.672, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000038576_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a black gaming keyboard is centered in front of a large flat screen tv, with a wireless optical mouse to the right of the black gaming keyboard."
      },
      {
        "from": "gpt",
        "value": "large flat screen tv: [0.266, 0.055, 0.594, 0.453]\nblack gaming keyboard: [0.219, 0.586, 0.820, 0.797]\nwireless optical mouse: [0.492, 0.789, 0.672, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000038576_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a black gaming keyboard is centered in front of a large flat screen tv, with a wireless optical mouse to the right of the black gaming keyboard.\nObjects: [large flat screen tv, black gaming keyboard, wireless optical mouse]"
      },
      {
        "from": "gpt",
        "value": "large flat screen tv: [0.266, 0.055, 0.594, 0.453]\nblack gaming keyboard: [0.219, 0.586, 0.820, 0.797]\nwireless optical mouse: [0.492, 0.789, 0.672, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000038576_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: tv: [0.266, 0.055, 0.594, 0.453]\nkeyboard: [0.219, 0.586, 0.820, 0.797]\nmouse: [0.492, 0.789, 0.672, 0.953]\nGiven the above layout, shift the keyboard to the left by 0.172."
      },
      {
        "from": "gpt",
        "value": "tv: [0.266, 0.055, 0.594, 0.453]\nkeyboard: [0.047, 0.586, 0.648, 0.797]\nmouse: [0.492, 0.789, 0.672, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000051326",
    "conversations": [
      {
        "from": "human",
        "value": "The vase with pink flowers is placed on top of a carved pumpkin to the right of the image."
      },
      {
        "from": "gpt",
        "value": "vase: [0.539, 0.414, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000051326_key",
    "conversations": [
      {
        "from": "human",
        "value": "The vase with pink flowers is placed on top of a carved pumpkin to the right of the image.\nObjects: [vase]"
      },
      {
        "from": "gpt",
        "value": "vase: [0.539, 0.414, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000051326_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the crystal vase with pink tulips with pink flowers is placed on top of a carved pumpkin to the right of the image."
      },
      {
        "from": "gpt",
        "value": "crystal vase with pink tulips: [0.539, 0.414, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000051326_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the crystal vase with pink tulips with pink flowers is placed on top of a carved pumpkin to the right of the image.\nObjects: [crystal vase with pink tulips]"
      },
      {
        "from": "gpt",
        "value": "crystal vase with pink tulips: [0.539, 0.414, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000051326_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: vase: [0.539, 0.414, 0.992, 0.820]\nGiven the above layout, shift the vase to the left by 0.453."
      },
      {
        "from": "gpt",
        "value": "vase: [0.086, 0.414, 0.539, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000052462",
    "conversations": [
      {
        "from": "human",
        "value": "Two zebras standing side by side in dry grass, with the one on the left slightly in front of the other."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.219, 0.359, 0.453, 0.711]\nzebra: [0.625, 0.312, 0.820, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000052462_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two zebras standing side by side in dry grass, with the one on the left slightly in front of the other.\nObjects: [zebra, zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.219, 0.359, 0.453, 0.711]\nzebra: [0.625, 0.312, 0.820, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000052565",
    "conversations": [
      {
        "from": "human",
        "value": "The cow is standing at the center, facing slightly to the right."
      },
      {
        "from": "gpt",
        "value": "cow: [0.258, 0.422, 0.727, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000052565_key",
    "conversations": [
      {
        "from": "human",
        "value": "The cow is standing at the center, facing slightly to the right.\nObjects: [cow]"
      },
      {
        "from": "gpt",
        "value": "cow: [0.258, 0.422, 0.727, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000052565_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the brown cow is standing at the center, facing slightly to the right."
      },
      {
        "from": "gpt",
        "value": "brown cow: [0.258, 0.422, 0.727, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000052565_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the brown cow is standing at the center, facing slightly to the right.\nObjects: [brown cow]"
      },
      {
        "from": "gpt",
        "value": "brown cow: [0.258, 0.422, 0.727, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000052565_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cow: [0.258, 0.422, 0.727, 0.742]\nGiven the above layout, shift the cow upwards by 0.258."
      },
      {
        "from": "gpt",
        "value": "cow: [0.258, 0.164, 0.727, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000065288",
    "conversations": [
      {
        "from": "human",
        "value": "There is a chair in the foreground with a yellow floral pattern, another chair visible behind it to the left, and a potted plant on the far right in the background."
      },
      {
        "from": "gpt",
        "value": "chair: [0.336, 0.531, 0.969, 0.820]\nchair: [0.727, 0.344, 0.992, 0.508]\npotted plant: [0.070, 0.305, 0.305, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000065288_key",
    "conversations": [
      {
        "from": "human",
        "value": "There is a chair in the foreground with a yellow floral pattern, another chair visible behind it to the left, and a potted plant on the far right in the background.\nObjects: [chair, chair, potted plant]"
      },
      {
        "from": "gpt",
        "value": "chair: [0.336, 0.531, 0.969, 0.820]\nchair: [0.727, 0.344, 0.992, 0.508]\npotted plant: [0.070, 0.305, 0.305, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000071711",
    "conversations": [
      {
        "from": "human",
        "value": "Two airplanes in a hangar, one to the left and the other to the right of the image."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.086, 0.430, 0.508, 0.719]\nairplane: [0.594, 0.500, 0.992, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000071711_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two airplanes in a hangar, one to the left and the other to the right of the image.\nObjects: [airplane, airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.086, 0.430, 0.508, 0.719]\nairplane: [0.594, 0.500, 0.992, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000100489",
    "conversations": [
      {
        "from": "human",
        "value": "The bird is perched on a branch to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "bird: [0.250, 0.117, 0.602, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000100489_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bird is perched on a branch to the right side of the image.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.250, 0.117, 0.602, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000100489_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the blue and yellow macaw is perched on a branch to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "blue and yellow macaw: [0.250, 0.117, 0.602, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000100489_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the blue and yellow macaw is perched on a branch to the right side of the image.\nObjects: [blue and yellow macaw]"
      },
      {
        "from": "gpt",
        "value": "blue and yellow macaw: [0.250, 0.117, 0.602, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000100489_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.250, 0.117, 0.602, 0.562]\nGiven the above layout, shift the bird downwards by 0.414."
      },
      {
        "from": "gpt",
        "value": "bird: [0.250, 0.531, 0.602, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000146363",
    "conversations": [
      {
        "from": "human",
        "value": "An umbrella is open, providing shade over a chair to the right on a sandy beach. Another chair is partially visible to the left under the umbrella."
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.430, 0.289, 0.938, 0.578]\nchair: [0.422, 0.562, 0.828, 0.742]\nchair: [0.211, 0.742, 0.445, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000146363_key",
    "conversations": [
      {
        "from": "human",
        "value": "An umbrella is open, providing shade over a chair to the right on a sandy beach. Another chair is partially visible to the left under the umbrella.\nObjects: [umbrella, chair, chair]"
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.430, 0.289, 0.938, 0.578]\nchair: [0.422, 0.562, 0.828, 0.742]\nchair: [0.211, 0.742, 0.445, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000147745",
    "conversations": [
      {
        "from": "human",
        "value": "A white truck on the left facing the camera at an angle, and another white truck on the right facing right, partially hidden behind the first truck."
      },
      {
        "from": "gpt",
        "value": "truck: [0.047, 0.156, 0.586, 0.766]\ntruck: [0.547, 0.328, 0.898, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000147745_key",
    "conversations": [
      {
        "from": "human",
        "value": "A white truck on the left facing the camera at an angle, and another white truck on the right facing right, partially hidden behind the first truck.\nObjects: [truck, truck]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.047, 0.156, 0.586, 0.766]\ntruck: [0.547, 0.328, 0.898, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000149770",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center riding a surfboard on a wave."
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.289, 0.727, 0.672]\nsurfboard: [0.297, 0.617, 0.711, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000149770_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center riding a surfboard on a wave.\nObjects: [person, surfboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.289, 0.727, 0.672]\nsurfboard: [0.297, 0.617, 0.711, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000149770_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young surfer is at the center riding a sleek surfboard on a wave."
      },
      {
        "from": "gpt",
        "value": "young surfer: [0.320, 0.289, 0.727, 0.672]\nsleek surfboard: [0.297, 0.617, 0.711, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000149770_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young surfer is at the center riding a sleek surfboard on a wave.\nObjects: [young surfer, sleek surfboard]"
      },
      {
        "from": "gpt",
        "value": "young surfer: [0.320, 0.289, 0.727, 0.672]\nsleek surfboard: [0.297, 0.617, 0.711, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000149770_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.320, 0.289, 0.727, 0.672]\nsurfboard: [0.297, 0.617, 0.711, 0.680]\nGiven the above layout, shift the surfboard downwards by 0.148."
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.289, 0.727, 0.672]\nsurfboard: [0.297, 0.766, 0.711, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000151857",
    "conversations": [
      {
        "from": "human",
        "value": "The train is located on the right side of the image, parallel to the platform on the left."
      },
      {
        "from": "gpt",
        "value": "train: [0.078, 0.250, 0.992, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000151857_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is located on the right side of the image, parallel to the platform on the left.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.078, 0.250, 0.992, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000151857_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the high-speed bullet train is located on the right side of the image, parallel to the platform on the left."
      },
      {
        "from": "gpt",
        "value": "high-speed bullet train: [0.078, 0.250, 0.992, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000151857_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the high-speed bullet train is located on the right side of the image, parallel to the platform on the left.\nObjects: [high-speed bullet train]"
      },
      {
        "from": "gpt",
        "value": "high-speed bullet train: [0.078, 0.250, 0.992, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000151857_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.078, 0.250, 0.992, 0.758]\nGiven the above layout, shift the train upwards by 0.180."
      },
      {
        "from": "gpt",
        "value": "train: [0.078, 0.070, 0.992, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000166642",
    "conversations": [
      {
        "from": "human",
        "value": "The elephant is in the center of the image, standing behind a rocky outcrop."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.078, 0.211, 0.836, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000166642_key",
    "conversations": [
      {
        "from": "human",
        "value": "The elephant is in the center of the image, standing behind a rocky outcrop.\nObjects: [elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.078, 0.211, 0.836, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000166642_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the large mammoth is in the center of the image, standing behind a rocky outcrop."
      },
      {
        "from": "gpt",
        "value": "large mammoth: [0.078, 0.211, 0.836, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000166642_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the large mammoth is in the center of the image, standing behind a rocky outcrop.\nObjects: [large mammoth]"
      },
      {
        "from": "gpt",
        "value": "large mammoth: [0.078, 0.211, 0.836, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000166642_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: elephant: [0.078, 0.211, 0.836, 0.633]\nGiven the above layout, shift the elephant downwards by 0.336."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.078, 0.547, 0.836, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000171788",
    "conversations": [
      {
        "from": "human",
        "value": "A person is swinging a tennis racket to the right side."
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.172, 0.828, 0.969]\ntennis racket: [0.586, 0.562, 0.672, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000171788_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is swinging a tennis racket to the right side.\nObjects: [person, tennis racket]"
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.172, 0.828, 0.969]\ntennis racket: [0.586, 0.562, 0.672, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000171788_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a athletic woman is swinging a graphite tennis racket to the right side."
      },
      {
        "from": "gpt",
        "value": "athletic woman: [0.266, 0.172, 0.828, 0.969]\ngraphite tennis racket: [0.586, 0.562, 0.672, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000171788_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a athletic woman is swinging a graphite tennis racket to the right side.\nObjects: [athletic woman, graphite tennis racket]"
      },
      {
        "from": "gpt",
        "value": "athletic woman: [0.266, 0.172, 0.828, 0.969]\ngraphite tennis racket: [0.586, 0.562, 0.672, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000171788_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.266, 0.172, 0.828, 0.969]\ntennis racket: [0.586, 0.562, 0.672, 0.812]\nGiven the above layout, shift the person to the left by 0.141."
      },
      {
        "from": "gpt",
        "value": "person: [0.125, 0.172, 0.688, 0.969]\ntennis racket: [0.586, 0.562, 0.672, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000172977",
    "conversations": [
      {
        "from": "human",
        "value": "A zebra stands slightly to the right in the image."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.055, 0.164, 0.852, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000172977_key",
    "conversations": [
      {
        "from": "human",
        "value": "A zebra stands slightly to the right in the image.\nObjects: [zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.055, 0.164, 0.852, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000172977_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall giraffe stands slightly to the right in the image."
      },
      {
        "from": "gpt",
        "value": "tall giraffe: [0.055, 0.164, 0.852, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000172977_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall giraffe stands slightly to the right in the image.\nObjects: [tall giraffe]"
      },
      {
        "from": "gpt",
        "value": "tall giraffe: [0.055, 0.164, 0.852, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000172977_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: zebra: [0.055, 0.164, 0.852, 0.859]\nGiven the above layout, shift the zebra upwards by 0.016."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.055, 0.148, 0.852, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000174004",
    "conversations": [
      {
        "from": "human",
        "value": "An old yellow truck is centered in the image, surrounded by tall green grass."
      },
      {
        "from": "gpt",
        "value": "truck: [0.023, 0.297, 0.953, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000174004_key",
    "conversations": [
      {
        "from": "human",
        "value": "An old yellow truck is centered in the image, surrounded by tall green grass.\nObjects: [truck]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.023, 0.297, 0.953, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000174004_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an old yellow rusty pickup truck is centered in the image, surrounded by tall green grass."
      },
      {
        "from": "gpt",
        "value": "rusty pickup truck: [0.023, 0.297, 0.953, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000174004_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an old yellow rusty pickup truck is centered in the image, surrounded by tall green grass.\nObjects: [rusty pickup truck]"
      },
      {
        "from": "gpt",
        "value": "rusty pickup truck: [0.023, 0.297, 0.953, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000174004_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.023, 0.297, 0.953, 0.703]\nGiven the above layout, shift the truck upwards by 0.227."
      },
      {
        "from": "gpt",
        "value": "truck: [0.023, 0.070, 0.953, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000174482",
    "conversations": [
      {
        "from": "human",
        "value": "A bicycle is parked on the sidewalk in the foreground on the right, and a truck is passing by on the street in the background on the left."
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.289, 0.203, 0.773, 0.797]\ntruck: [0.781, 0.234, 0.992, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000174482_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bicycle is parked on the sidewalk in the foreground on the right, and a truck is passing by on the street in the background on the left.\nObjects: [bicycle, truck]"
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.289, 0.203, 0.773, 0.797]\ntruck: [0.781, 0.234, 0.992, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000174482_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red mountain bike is parked on the sidewalk in the foreground on the right, and a large delivery truck is passing by on the street in the background on the left."
      },
      {
        "from": "gpt",
        "value": "red mountain bike: [0.289, 0.203, 0.773, 0.797]\nlarge delivery truck: [0.781, 0.234, 0.992, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000174482_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red mountain bike is parked on the sidewalk in the foreground on the right, and a large delivery truck is passing by on the street in the background on the left.\nObjects: [red mountain bike, large delivery truck]"
      },
      {
        "from": "gpt",
        "value": "red mountain bike: [0.289, 0.203, 0.773, 0.797]\nlarge delivery truck: [0.781, 0.234, 0.992, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000174482_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bicycle: [0.289, 0.203, 0.773, 0.797]\ntruck: [0.781, 0.234, 0.992, 0.406]\nGiven the above layout, shift the bicycle to the left by 0.164."
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.125, 0.203, 0.609, 0.797]\ntruck: [0.781, 0.234, 0.992, 0.406]"
      }
    ]
  },
  {
    "id": "coco_000000177893",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is on the right side of the image, facing to the left."
      },
      {
        "from": "gpt",
        "value": "bus: [0.109, 0.391, 0.828, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000177893_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is on the right side of the image, facing to the left.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.109, 0.391, 0.828, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000177893_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker bus is on the right side of the image, facing to the left."
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.109, 0.391, 0.828, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000177893_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker bus is on the right side of the image, facing to the left.\nObjects: [double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.109, 0.391, 0.828, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000177893_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.109, 0.391, 0.828, 0.602]\nGiven the above layout, shift the bus upwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "bus: [0.109, 0.352, 0.828, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000235399",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is sitting on a bed at the back end of an open truck."
      },
      {
        "from": "gpt",
        "value": "truck: [0.172, 0.125, 0.992, 0.859]\nbed: [0.602, 0.523, 0.766, 0.719]\ndog: [0.320, 0.570, 0.461, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000235399_key",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is sitting on a bed at the back end of an open truck.\nObjects: [truck, bed, dog]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.172, 0.125, 0.992, 0.859]\nbed: [0.602, 0.523, 0.766, 0.719]\ndog: [0.320, 0.570, 0.461, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000235399_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a golden retriever is sitting on a queen-size bed at the back end of an open red pickup truck."
      },
      {
        "from": "gpt",
        "value": "red pickup truck: [0.172, 0.125, 0.992, 0.859]\nqueen-size bed: [0.602, 0.523, 0.766, 0.719]\ngolden retriever: [0.320, 0.570, 0.461, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000235399_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a golden retriever is sitting on a queen-size bed at the back end of an open red pickup truck.\nObjects: [red pickup truck, queen-size bed, golden retriever]"
      },
      {
        "from": "gpt",
        "value": "red pickup truck: [0.172, 0.125, 0.992, 0.859]\nqueen-size bed: [0.602, 0.523, 0.766, 0.719]\ngolden retriever: [0.320, 0.570, 0.461, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000235399_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.172, 0.125, 0.992, 0.859]\nbed: [0.602, 0.523, 0.766, 0.719]\ndog: [0.320, 0.570, 0.461, 0.758]\nGiven the above layout, shift the truck to the left by 0.047."
      },
      {
        "from": "gpt",
        "value": "truck: [0.125, 0.125, 0.945, 0.859]\nbed: [0.602, 0.523, 0.766, 0.719]\ndog: [0.320, 0.570, 0.461, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000237316",
    "conversations": [
      {
        "from": "human",
        "value": "A toilet is located to the left of the sink in a small bathroom."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.250, 0.516, 0.445, 0.953]\nsink: [0.453, 0.484, 0.648, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000237316_key",
    "conversations": [
      {
        "from": "human",
        "value": "A toilet is located to the left of the sink in a small bathroom.\nObjects: [toilet, sink]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.250, 0.516, 0.445, 0.953]\nsink: [0.453, 0.484, 0.648, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000237316_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a porcelain toilet is located to the left of the stainless steel sink in a small bathroom."
      },
      {
        "from": "gpt",
        "value": "porcelain toilet: [0.250, 0.516, 0.445, 0.953]\nstainless steel sink: [0.453, 0.484, 0.648, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000237316_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a porcelain toilet is located to the left of the stainless steel sink in a small bathroom.\nObjects: [porcelain toilet, stainless steel sink]"
      },
      {
        "from": "gpt",
        "value": "porcelain toilet: [0.250, 0.516, 0.445, 0.953]\nstainless steel sink: [0.453, 0.484, 0.648, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000237316_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.250, 0.516, 0.445, 0.953]\nsink: [0.453, 0.484, 0.648, 0.570]\nGiven the above layout, shift the sink upwards by 0.414."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.250, 0.516, 0.445, 0.953]\nsink: [0.453, 0.070, 0.648, 0.156]"
      }
    ]
  },
  {
    "id": "coco_000000251065",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center with a black seat and lid raised, against a wall with white tiles. There is a red object to the left of the toilet on the floor."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.328, 0.195, 0.672, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000251065_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center with a black seat and lid raised, against a wall with white tiles. There is a red object to the left of the toilet on the floor.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.328, 0.195, 0.672, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000251065_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the white porcelain toilet is at the center with a black seat and lid raised, against a wall with white tiles. there is a red object to the left of the white porcelain toilet on the floor."
      },
      {
        "from": "gpt",
        "value": "white porcelain toilet: [0.328, 0.195, 0.672, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000251065_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the white porcelain toilet is at the center with a black seat and lid raised, against a wall with white tiles. there is a red object to the left of the white porcelain toilet on the floor.\nObjects: [white porcelain toilet]"
      },
      {
        "from": "gpt",
        "value": "white porcelain toilet: [0.328, 0.195, 0.672, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000251065_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.328, 0.195, 0.672, 0.828]\nGiven the above layout, shift the toilet to the left by 0.227."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.102, 0.195, 0.445, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000252219",
    "conversations": [
      {
        "from": "human",
        "value": "From left to right: A person walking, a person standing in the center, and another person walking past the central figure."
      },
      {
        "from": "gpt",
        "value": "person: [0.016, 0.422, 0.203, 0.773]\nperson: [0.789, 0.430, 0.984, 0.766]\nperson: [0.508, 0.438, 0.617, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000252219_key",
    "conversations": [
      {
        "from": "human",
        "value": "From left to right: A person walking, a person standing in the center, and another person walking past the central figure.\nObjects: [person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.016, 0.422, 0.203, 0.773]\nperson: [0.789, 0.430, 0.984, 0.766]\nperson: [0.508, 0.438, 0.617, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000261161",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is standing on the left side of the image, in front of a pink bench to the right."
      },
      {
        "from": "gpt",
        "value": "dog: [0.500, 0.211, 0.922, 0.828]\nbench: [0.000, 0.344, 0.391, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000261161_key",
    "conversations": [
      {
        "from": "human",
        "value": "A dog is standing on the left side of the image, in front of a pink bench to the right.\nObjects: [dog, bench]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.500, 0.211, 0.922, 0.828]\nbench: [0.000, 0.344, 0.391, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000261161_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a golden retriever is standing on the left side of the image, in front of a pink red park bench to the right."
      },
      {
        "from": "gpt",
        "value": "golden retriever: [0.500, 0.211, 0.922, 0.828]\nred park bench: [0.000, 0.344, 0.391, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000261161_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a golden retriever is standing on the left side of the image, in front of a pink red park bench to the right.\nObjects: [golden retriever, red park bench]"
      },
      {
        "from": "gpt",
        "value": "golden retriever: [0.500, 0.211, 0.922, 0.828]\nred park bench: [0.000, 0.344, 0.391, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000261161_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.500, 0.211, 0.922, 0.828]\nbench: [0.000, 0.344, 0.391, 0.781]\nGiven the above layout, shift the dog upwards by 0.141."
      },
      {
        "from": "gpt",
        "value": "dog: [0.500, 0.070, 0.922, 0.688]\nbench: [0.000, 0.344, 0.391, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000271997",
    "conversations": [
      {
        "from": "human",
        "value": "A person wearing a dark suit with a tie at the center."
      },
      {
        "from": "gpt",
        "value": "person: [0.117, 0.008, 0.867, 0.977]\ntie: [0.344, 0.914, 0.586, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000271997_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person wearing a dark suit with a tie at the center.\nObjects: [person, tie]"
      },
      {
        "from": "gpt",
        "value": "person: [0.117, 0.008, 0.867, 0.977]\ntie: [0.344, 0.914, 0.586, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000271997_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a businessman in a fitted suit wearing a dark suit with a stylish navy blue tie at the center."
      },
      {
        "from": "gpt",
        "value": "businessman in a fitted suit: [0.117, 0.008, 0.867, 0.977]\nstylish navy blue tie: [0.344, 0.914, 0.586, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000271997_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a businessman in a fitted suit wearing a dark suit with a stylish navy blue tie at the center.\nObjects: [businessman in a fitted suit, stylish navy blue tie]"
      },
      {
        "from": "gpt",
        "value": "businessman in a fitted suit: [0.117, 0.008, 0.867, 0.977]\nstylish navy blue tie: [0.344, 0.914, 0.586, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000271997_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.117, 0.008, 0.867, 0.977]\ntie: [0.344, 0.914, 0.586, 0.992]\nGiven the above layout, shift the person to the right by 0.078."
      },
      {
        "from": "gpt",
        "value": "person: [0.195, 0.008, 0.945, 0.977]\ntie: [0.344, 0.914, 0.586, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000275727",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks centered in the image, moving from left to right."
      },
      {
        "from": "gpt",
        "value": "train: [0.039, 0.352, 0.867, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000275727_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks centered in the image, moving from left to right.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.039, 0.352, 0.867, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000275727_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the sleek bullet train is on the tracks centered in the image, moving from left to right."
      },
      {
        "from": "gpt",
        "value": "sleek bullet train: [0.039, 0.352, 0.867, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000275727_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the sleek bullet train is on the tracks centered in the image, moving from left to right.\nObjects: [sleek bullet train]"
      },
      {
        "from": "gpt",
        "value": "sleek bullet train: [0.039, 0.352, 0.867, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000275727_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.039, 0.352, 0.867, 0.727]\nGiven the above layout, shift the train upwards by 0.250."
      },
      {
        "from": "gpt",
        "value": "train: [0.039, 0.102, 0.867, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000281447",
    "conversations": [
      {
        "from": "human",
        "value": "The horse is in the foreground on the right side of the image facing left."
      },
      {
        "from": "gpt",
        "value": "horse: [0.383, 0.375, 0.891, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000281447_key",
    "conversations": [
      {
        "from": "human",
        "value": "The horse is in the foreground on the right side of the image facing left.\nObjects: [horse]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.383, 0.375, 0.891, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000281447_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the golden retriever is in the foreground on the right side of the image facing left."
      },
      {
        "from": "gpt",
        "value": "golden retriever: [0.383, 0.375, 0.891, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000281447_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the golden retriever is in the foreground on the right side of the image facing left.\nObjects: [golden retriever]"
      },
      {
        "from": "gpt",
        "value": "golden retriever: [0.383, 0.375, 0.891, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000281447_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: horse: [0.383, 0.375, 0.891, 0.812]\nGiven the above layout, shift the horse to the left by 0.320."
      },
      {
        "from": "gpt",
        "value": "horse: [0.062, 0.375, 0.570, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000289659",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe is standing in the center of the image, facing towards the left."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.312, 0.281, 0.820, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000289659_key",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe is standing in the center of the image, facing towards the left.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.312, 0.281, 0.820, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000289659_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the long-necked deer is standing in the center of the image, facing towards the left."
      },
      {
        "from": "gpt",
        "value": "long-necked deer: [0.312, 0.281, 0.820, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000289659_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the long-necked deer is standing in the center of the image, facing towards the left.\nObjects: [long-necked deer]"
      },
      {
        "from": "gpt",
        "value": "long-necked deer: [0.312, 0.281, 0.820, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000289659_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.312, 0.281, 0.820, 0.734]\nGiven the above layout, shift the giraffe to the left by 0.164."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.148, 0.281, 0.656, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000294695",
    "conversations": [
      {
        "from": "human",
        "value": "A person at the center holding a kite flying in the air to the right, with one person walking on the left and another person standing further right."
      },
      {
        "from": "gpt",
        "value": "kite: [0.180, 0.195, 0.578, 0.422]\nperson: [0.859, 0.453, 0.938, 0.664]\nperson: [0.344, 0.617, 0.414, 0.797]\nperson: [0.172, 0.594, 0.242, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000294695_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person at the center holding a kite flying in the air to the right, with one person walking on the left and another person standing further right.\nObjects: [kite, person, person, person]"
      },
      {
        "from": "gpt",
        "value": "kite: [0.180, 0.195, 0.578, 0.422]\nperson: [0.859, 0.453, 0.938, 0.664]\nperson: [0.344, 0.617, 0.414, 0.797]\nperson: [0.172, 0.594, 0.242, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000294855",
    "conversations": [
      {
        "from": "human",
        "value": "A suitcase rests on the floor to the right of a table with one of its wheels visible."
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.000, 0.125, 0.523, 0.461]"
      }
    ]
  },
  {
    "id": "coco_000000294855_key",
    "conversations": [
      {
        "from": "human",
        "value": "A suitcase rests on the floor to the right of a table with one of its wheels visible.\nObjects: [suitcase]"
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.000, 0.125, 0.523, 0.461]"
      }
    ]
  },
  {
    "id": "coco_000000294855_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a vintage leather suitcase rests on the floor to the right of a table with one of its wheels visible."
      },
      {
        "from": "gpt",
        "value": "vintage leather suitcase: [0.000, 0.125, 0.523, 0.461]"
      }
    ]
  },
  {
    "id": "coco_000000294855_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a vintage leather suitcase rests on the floor to the right of a table with one of its wheels visible.\nObjects: [vintage leather suitcase]"
      },
      {
        "from": "gpt",
        "value": "vintage leather suitcase: [0.000, 0.125, 0.523, 0.461]"
      }
    ]
  },
  {
    "id": "coco_000000294855_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: suitcase: [0.000, 0.125, 0.523, 0.461]\nGiven the above layout, shift the suitcase downwards by 0.055."
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.000, 0.180, 0.523, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000304545",
    "conversations": [
      {
        "from": "human",
        "value": "The suitcase is centered in the image with the handle extended upwards."
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.000, 0.094, 0.992, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000304545_key",
    "conversations": [
      {
        "from": "human",
        "value": "The suitcase is centered in the image with the handle extended upwards.\nObjects: [suitcase]"
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.000, 0.094, 0.992, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000304545_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the large travel luggage is centered in the image with the handle extended upwards."
      },
      {
        "from": "gpt",
        "value": "large travel luggage: [0.000, 0.094, 0.992, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000304545_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the large travel luggage is centered in the image with the handle extended upwards.\nObjects: [large travel luggage]"
      },
      {
        "from": "gpt",
        "value": "large travel luggage: [0.000, 0.094, 0.992, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000304545_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: suitcase: [0.000, 0.094, 0.992, 0.898]\nGiven the above layout, shift the suitcase upwards by 0.078."
      },
      {
        "from": "gpt",
        "value": "suitcase: [0.000, 0.016, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000333402",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing to the right of a bus at a bus stop."
      },
      {
        "from": "gpt",
        "value": "bus: [0.156, 0.242, 0.805, 0.734]\nperson: [0.734, 0.422, 0.875, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000333402_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing to the right of a bus at a bus stop.\nObjects: [bus, person]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.156, 0.242, 0.805, 0.734]\nperson: [0.734, 0.422, 0.875, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000333402_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a woman carrying a briefcase standing to the right of a city bus at a city bus stop."
      },
      {
        "from": "gpt",
        "value": "city bus: [0.156, 0.242, 0.805, 0.734]\na woman carrying a briefcase: [0.734, 0.422, 0.875, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000333402_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a woman carrying a briefcase standing to the right of a city bus at a city bus stop.\nObjects: [city bus, a woman carrying a briefcase]"
      },
      {
        "from": "gpt",
        "value": "city bus: [0.156, 0.242, 0.805, 0.734]\na woman carrying a briefcase: [0.734, 0.422, 0.875, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000333402_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.156, 0.242, 0.805, 0.734]\nperson: [0.734, 0.422, 0.875, 0.773]\nGiven the above layout, shift the bus upwards by 0.227."
      },
      {
        "from": "gpt",
        "value": "bus: [0.156, 0.016, 0.805, 0.508]\nperson: [0.734, 0.422, 0.875, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000360951",
    "conversations": [
      {
        "from": "human",
        "value": "A keyboard is on a table in the foreground, a laptop is on the right side of the table, and a TV is on the left side of the table in the background."
      },
      {
        "from": "gpt",
        "value": "tv: [0.203, 0.211, 0.578, 0.484]\nlaptop: [0.609, 0.398, 0.914, 0.633]\nkeyboard: [0.172, 0.641, 0.508, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000360951_key",
    "conversations": [
      {
        "from": "human",
        "value": "A keyboard is on a table in the foreground, a laptop is on the right side of the table, and a TV is on the left side of the table in the background.\nObjects: [tv, laptop, keyboard]"
      },
      {
        "from": "gpt",
        "value": "tv: [0.203, 0.211, 0.578, 0.484]\nlaptop: [0.609, 0.398, 0.914, 0.633]\nkeyboard: [0.172, 0.641, 0.508, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000360951_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a black mechanical keyboard is on a table in the foreground, a silver Macbook Pro is on the right side of the table, and a plasma TV is on the left side of the table in the background."
      },
      {
        "from": "gpt",
        "value": "plasma TV: [0.203, 0.211, 0.578, 0.484]\nsilver Macbook Pro: [0.609, 0.398, 0.914, 0.633]\nblack mechanical keyboard: [0.172, 0.641, 0.508, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000360951_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a black mechanical keyboard is on a table in the foreground, a silver Macbook Pro is on the right side of the table, and a plasma TV is on the left side of the table in the background.\nObjects: [plasma TV, silver Macbook Pro, black mechanical keyboard]"
      },
      {
        "from": "gpt",
        "value": "plasma TV: [0.203, 0.211, 0.578, 0.484]\nsilver Macbook Pro: [0.609, 0.398, 0.914, 0.633]\nblack mechanical keyboard: [0.172, 0.641, 0.508, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000360951_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: tv: [0.203, 0.211, 0.578, 0.484]\nlaptop: [0.609, 0.398, 0.914, 0.633]\nkeyboard: [0.172, 0.641, 0.508, 0.734]\nGiven the above layout, shift the keyboard downwards by 0.250."
      },
      {
        "from": "gpt",
        "value": "tv: [0.203, 0.211, 0.578, 0.484]\nlaptop: [0.609, 0.398, 0.914, 0.633]\nkeyboard: [0.172, 0.891, 0.508, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000386277",
    "conversations": [
      {
        "from": "human",
        "value": "The orange is hanging from a branch at the center of the image, surrounded by green leaves."
      },
      {
        "from": "gpt",
        "value": "orange: [0.328, 0.320, 0.734, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000386277_key",
    "conversations": [
      {
        "from": "human",
        "value": "The orange is hanging from a branch at the center of the image, surrounded by green leaves.\nObjects: [orange]"
      },
      {
        "from": "gpt",
        "value": "orange: [0.328, 0.320, 0.734, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000386277_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the ripe apple is hanging from a branch at the center of the image, surrounded by green leaves."
      },
      {
        "from": "gpt",
        "value": "ripe apple: [0.328, 0.320, 0.734, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000386277_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the ripe apple is hanging from a branch at the center of the image, surrounded by green leaves.\nObjects: [ripe apple]"
      },
      {
        "from": "gpt",
        "value": "ripe apple: [0.328, 0.320, 0.734, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000386277_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: orange: [0.328, 0.320, 0.734, 0.742]\nGiven the above layout, shift the orange to the left by 0.328."
      },
      {
        "from": "gpt",
        "value": "orange: [0.000, 0.320, 0.406, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000389684",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on the left side of the image, near the rear end of a bus on the right."
      },
      {
        "from": "gpt",
        "value": "bus: [0.555, 0.195, 0.992, 0.766]\nperson: [0.180, 0.453, 0.266, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000389684_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on the left side of the image, near the rear end of a bus on the right.\nObjects: [bus, person]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.555, 0.195, 0.992, 0.766]\nperson: [0.180, 0.453, 0.266, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000389684_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man in a blue shirt is standing on the left side of the image, near the rear end of a red city bus on the right."
      },
      {
        "from": "gpt",
        "value": "red city bus: [0.555, 0.195, 0.992, 0.766]\ntall man in a blue shirt: [0.180, 0.453, 0.266, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000389684_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man in a blue shirt is standing on the left side of the image, near the rear end of a red city bus on the right.\nObjects: [red city bus, tall man in a blue shirt]"
      },
      {
        "from": "gpt",
        "value": "red city bus: [0.555, 0.195, 0.992, 0.766]\ntall man in a blue shirt: [0.180, 0.453, 0.266, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000389684_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.555, 0.195, 0.992, 0.766]\nperson: [0.180, 0.453, 0.266, 0.648]\nGiven the above layout, shift the bus downwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "bus: [0.555, 0.234, 0.992, 0.805]\nperson: [0.180, 0.453, 0.266, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000392818",
    "conversations": [
      {
        "from": "human",
        "value": "The dog's face is at the center of the image, wearing a harness."
      },
      {
        "from": "gpt",
        "value": "dog: [0.000, 0.070, 0.992, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000392818_key",
    "conversations": [
      {
        "from": "human",
        "value": "The dogs face is at the center of the image, wearing a harness.\nObjects: [dog]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.000, 0.070, 0.992, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000392818_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the brown poodle's face is at the center of the image, wearing a harness."
      },
      {
        "from": "gpt",
        "value": "brown poodle: [0.000, 0.070, 0.992, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000392818_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the brown poodles face is at the center of the image, wearing a harness.\nObjects: [brown poodle]"
      },
      {
        "from": "gpt",
        "value": "brown poodle: [0.000, 0.070, 0.992, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000392818_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.000, 0.070, 0.992, 0.938]\nGiven the above layout, shift the dog upwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "dog: [0.000, 0.031, 0.992, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000395633",
    "conversations": [
      {
        "from": "human",
        "value": "A red and black boat is centered in the image, floating on the water."
      },
      {
        "from": "gpt",
        "value": "boat: [0.000, 0.188, 0.875, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000395633_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red and black boat is centered in the image, floating on the water.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.000, 0.188, 0.875, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000395633_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red and black sleek speedboat is centered in the image, floating on the water."
      },
      {
        "from": "gpt",
        "value": "sleek speedboat: [0.000, 0.188, 0.875, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000395633_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red and black sleek speedboat is centered in the image, floating on the water.\nObjects: [sleek speedboat]"
      },
      {
        "from": "gpt",
        "value": "sleek speedboat: [0.000, 0.188, 0.875, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000395633_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.000, 0.188, 0.875, 0.703]\nGiven the above layout, shift the boat downwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "boat: [0.000, 0.258, 0.875, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000400044",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the air, above a snowboard, with a snow-covered building in the background."
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.477, 0.797, 0.836]\nsnowboard: [0.508, 0.727, 0.867, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000400044_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the air, above a snowboard, with a snow-covered building in the background.\nObjects: [person, snowboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.477, 0.797, 0.836]\nsnowboard: [0.508, 0.727, 0.867, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000400044_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a thrill-seeking flashy yellow flashy yellow snowboarder is in the air, above a flashy yellow snowboard, with a snow-covered building in the background."
      },
      {
        "from": "gpt",
        "value": "thrill-seeking flashy yellow snowboarder: [0.406, 0.477, 0.797, 0.836]\nflashy yellow snowboard: [0.508, 0.727, 0.867, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000400044_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a thrill-seeking flashy yellow flashy yellow snowboarder is in the air, above a flashy yellow snowboard, with a snow-covered building in the background.\nObjects: [thrill-seeking flashy yellow snowboarder, flashy yellow snowboard]"
      },
      {
        "from": "gpt",
        "value": "thrill-seeking flashy yellow snowboarder: [0.406, 0.477, 0.797, 0.836]\nflashy yellow snowboard: [0.508, 0.727, 0.867, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000400044_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.406, 0.477, 0.797, 0.836]\nsnowboard: [0.508, 0.727, 0.867, 0.875]\nGiven the above layout, shift the person upwards by 0.172."
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.305, 0.797, 0.664]\nsnowboard: [0.508, 0.727, 0.867, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000404568",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is standing in the foreground on the right, with waves in the background."
      },
      {
        "from": "gpt",
        "value": "bird: [0.133, 0.391, 0.625, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000404568_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is standing in the foreground on the right, with waves in the background.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.133, 0.391, 0.625, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000404568_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a parrot perched in the scene is standing in the foreground on the right, with waves in the background."
      },
      {
        "from": "gpt",
        "value": "parrot perched in the scene: [0.133, 0.391, 0.625, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000404568_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a parrot perched in the scene is standing in the foreground on the right, with waves in the background.\nObjects: [parrot perched in the scene]"
      },
      {
        "from": "gpt",
        "value": "parrot perched in the scene: [0.133, 0.391, 0.625, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000404568_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.133, 0.391, 0.625, 0.828]\nGiven the above layout, shift the bird upwards by 0.195."
      },
      {
        "from": "gpt",
        "value": "bird: [0.133, 0.195, 0.625, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000412887",
    "conversations": [
      {
        "from": "human",
        "value": "The cow's face is at the center of the image, with chains visible to the left and right sides of its head."
      },
      {
        "from": "gpt",
        "value": "cow: [0.125, 0.156, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000412887_key",
    "conversations": [
      {
        "from": "human",
        "value": "The cows face is at the center of the image, with chains visible to the left and right sides of its head.\nObjects: [cow]"
      },
      {
        "from": "gpt",
        "value": "cow: [0.125, 0.156, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000412887_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the brown cow's face is at the center of the image, with chains visible to the left and right sides of its head."
      },
      {
        "from": "gpt",
        "value": "brown cow: [0.125, 0.156, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000412887_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the brown cows face is at the center of the image, with chains visible to the left and right sides of its head.\nObjects: [brown cow]"
      },
      {
        "from": "gpt",
        "value": "brown cow: [0.125, 0.156, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000412887_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cow: [0.125, 0.156, 0.867, 0.977]\nGiven the above layout, shift the cow upwards by 0.109."
      },
      {
        "from": "gpt",
        "value": "cow: [0.125, 0.047, 0.867, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000429011",
    "conversations": [
      {
        "from": "human",
        "value": "A green truck is on the left side of the image and a black car is to the right of the truck."
      },
      {
        "from": "gpt",
        "value": "truck: [0.070, 0.461, 0.398, 0.664]\ncar: [0.656, 0.547, 0.977, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000429011_key",
    "conversations": [
      {
        "from": "human",
        "value": "A green truck is on the left side of the image and a black car is to the right of the truck.\nObjects: [truck, car]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.070, 0.461, 0.398, 0.664]\ncar: [0.656, 0.547, 0.977, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000429011_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a green large green van is on the left side of the image and a black small black hatchback is to the right of the large green van."
      },
      {
        "from": "gpt",
        "value": "large green van: [0.070, 0.461, 0.398, 0.664]\nsmall black hatchback: [0.656, 0.547, 0.977, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000429011_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a green large green van is on the left side of the image and a black small black hatchback is to the right of the large green van.\nObjects: [large green van, small black hatchback]"
      },
      {
        "from": "gpt",
        "value": "large green van: [0.070, 0.461, 0.398, 0.664]\nsmall black hatchback: [0.656, 0.547, 0.977, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000429011_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.070, 0.461, 0.398, 0.664]\ncar: [0.656, 0.547, 0.977, 0.688]\nGiven the above layout, shift the truck upwards by 0.148."
      },
      {
        "from": "gpt",
        "value": "truck: [0.070, 0.312, 0.398, 0.516]\ncar: [0.656, 0.547, 0.977, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000431545",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the foreground running towards the left side of the image, and another person standing in the background to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.281, 0.328, 0.469, 0.742]\nperson: [0.555, 0.164, 0.648, 0.344]"
      }
    ]
  },
  {
    "id": "coco_000000431545_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the foreground running towards the left side of the image, and another person standing in the background to the right.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.281, 0.328, 0.469, 0.742]\nperson: [0.555, 0.164, 0.648, 0.344]"
      }
    ]
  },
  {
    "id": "coco_000000434297",
    "conversations": [
      {
        "from": "human",
        "value": "A sandwich is at the center of the plate, with slices of carrot to the right of the sandwich."
      },
      {
        "from": "gpt",
        "value": "sandwich: [0.133, 0.273, 0.820, 0.688]\ncarrot: [0.656, 0.562, 0.906, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000434297_key",
    "conversations": [
      {
        "from": "human",
        "value": "A sandwich is at the center of the plate, with slices of carrot to the right of the sandwich.\nObjects: [sandwich, carrot]"
      },
      {
        "from": "gpt",
        "value": "sandwich: [0.133, 0.273, 0.820, 0.688]\ncarrot: [0.656, 0.562, 0.906, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000434297_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a cheese and ham sandwich is at the center of the plate, with slices of diced carrot pieces to the right of the cheese and ham sandwich."
      },
      {
        "from": "gpt",
        "value": "cheese and ham sandwich: [0.133, 0.273, 0.820, 0.688]\ndiced carrot pieces: [0.656, 0.562, 0.906, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000434297_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a cheese and ham sandwich is at the center of the plate, with slices of diced carrot pieces to the right of the cheese and ham sandwich.\nObjects: [cheese and ham sandwich, diced carrot pieces]"
      },
      {
        "from": "gpt",
        "value": "cheese and ham sandwich: [0.133, 0.273, 0.820, 0.688]\ndiced carrot pieces: [0.656, 0.562, 0.906, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000434297_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sandwich: [0.133, 0.273, 0.820, 0.688]\ncarrot: [0.656, 0.562, 0.906, 0.734]\nGiven the above layout, shift the sandwich upwards by 0.250."
      },
      {
        "from": "gpt",
        "value": "sandwich: [0.133, 0.023, 0.820, 0.438]\ncarrot: [0.656, 0.562, 0.906, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000449406",
    "conversations": [
      {
        "from": "human",
        "value": "A zebra stands facing to the right in the center of the image, surrounded by a rocky landscape with sparse vegetation."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.211, 0.359, 0.617, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000449406_key",
    "conversations": [
      {
        "from": "human",
        "value": "A zebra stands facing to the right in the center of the image, surrounded by a rocky landscape with sparse vegetation.\nObjects: [zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.211, 0.359, 0.617, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000449406_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a monochrome donkey stands facing to the right in the center of the image, surrounded by a rocky landscape with sparse vegetation."
      },
      {
        "from": "gpt",
        "value": "monochrome donkey: [0.211, 0.359, 0.617, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000449406_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a monochrome donkey stands facing to the right in the center of the image, surrounded by a rocky landscape with sparse vegetation.\nObjects: [monochrome donkey]"
      },
      {
        "from": "gpt",
        "value": "monochrome donkey: [0.211, 0.359, 0.617, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000449406_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: zebra: [0.211, 0.359, 0.617, 0.711]\nGiven the above layout, shift the zebra to the right by 0.227."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.438, 0.359, 0.844, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000468124",
    "conversations": [
      {
        "from": "human",
        "value": "The image shows the rear three-quarter view of a double-decker bus with an open entrance at the center of the bus's right side."
      },
      {
        "from": "gpt",
        "value": "bus: [0.102, 0.352, 0.953, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000468124_key",
    "conversations": [
      {
        "from": "human",
        "value": "The image shows the rear three-quarter view of a double-decker bus with an open entrance at the center of the buss right side.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.102, 0.352, 0.953, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000468124_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the image shows the rear three-quarter view of a double-decker red double-decker bus with an open entrance at the center of the red double-decker bus's right side."
      },
      {
        "from": "gpt",
        "value": "red double-decker bus: [0.102, 0.352, 0.953, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000468124_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the image shows the rear three-quarter view of a double-decker red double-decker bus with an open entrance at the center of the red double-decker buss right side.\nObjects: [red double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "red double-decker bus: [0.102, 0.352, 0.953, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000468124_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.102, 0.352, 0.953, 0.719]\nGiven the above layout, shift the bus upwards by 0.078."
      },
      {
        "from": "gpt",
        "value": "bus: [0.102, 0.273, 0.953, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000511647",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the bottom left corner of the image, appearing to point upwards."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.125, 0.430, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000511647_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the bottom left corner of the image, appearing to point upwards.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.125, 0.430, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000511647_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman in a wool sweater is in the bottom left corner of the image, appearing to point upwards."
      },
      {
        "from": "gpt",
        "value": "young woman in a wool sweater: [0.000, 0.125, 0.430, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000511647_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman in a wool sweater is in the bottom left corner of the image, appearing to point upwards.\nObjects: [young woman in a wool sweater]"
      },
      {
        "from": "gpt",
        "value": "young woman in a wool sweater: [0.000, 0.125, 0.430, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000511647_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.000, 0.125, 0.430, 0.867]\nGiven the above layout, shift the person to the right by 0.484."
      },
      {
        "from": "gpt",
        "value": "person: [0.484, 0.125, 0.914, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000520301",
    "conversations": [
      {
        "from": "human",
        "value": "A dog in profile view, looking out of the car window to the right."
      },
      {
        "from": "gpt",
        "value": "dog: [0.297, 0.242, 0.867, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000520301_key",
    "conversations": [
      {
        "from": "human",
        "value": "A dog in profile view, looking out of the car window to the right.\nObjects: [dog]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.297, 0.242, 0.867, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000520301_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a Beagle puppy in profile view, looking out of the car window to the right."
      },
      {
        "from": "gpt",
        "value": "Beagle puppy: [0.297, 0.242, 0.867, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000520301_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a Beagle puppy in profile view, looking out of the car window to the right.\nObjects: [Beagle puppy]"
      },
      {
        "from": "gpt",
        "value": "Beagle puppy: [0.297, 0.242, 0.867, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000520301_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.297, 0.242, 0.867, 0.984]\nGiven the above layout, shift the dog to the left by 0.227."
      },
      {
        "from": "gpt",
        "value": "dog: [0.070, 0.242, 0.641, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000527960",
    "conversations": [
      {
        "from": "human",
        "value": "The bench is at the center, amidst a natural backdrop with trees."
      },
      {
        "from": "gpt",
        "value": "bench: [0.328, 0.500, 0.844, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000527960_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bench is at the center, amidst a natural backdrop with trees.\nObjects: [bench]"
      },
      {
        "from": "gpt",
        "value": "bench: [0.328, 0.500, 0.844, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000527960_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the rustic wooden bench is at the center, amidst a natural backdrop with trees."
      },
      {
        "from": "gpt",
        "value": "rustic wooden bench: [0.328, 0.500, 0.844, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000527960_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the rustic wooden bench is at the center, amidst a natural backdrop with trees.\nObjects: [rustic wooden bench]"
      },
      {
        "from": "gpt",
        "value": "rustic wooden bench: [0.328, 0.500, 0.844, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000527960_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bench: [0.328, 0.500, 0.844, 0.797]\nGiven the above layout, shift the bench upwards by 0.078."
      },
      {
        "from": "gpt",
        "value": "bench: [0.328, 0.422, 0.844, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000528980",
    "conversations": [
      {
        "from": "human",
        "value": "An umbrella is attached to a streetlamp post, and a car is parked on the street below it to the left."
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.367, 0.133, 0.727, 0.719]\ncar: [0.289, 0.938, 0.453, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000528980_key",
    "conversations": [
      {
        "from": "human",
        "value": "An umbrella is attached to a streetlamp post, and a car is parked on the street below it to the left.\nObjects: [umbrella, car]"
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.367, 0.133, 0.727, 0.719]\ncar: [0.289, 0.938, 0.453, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000528980_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an large rainbow-colored umbrella is attached to a streetlamp post, and a red hatchback car is parked on the street below it to the left."
      },
      {
        "from": "gpt",
        "value": "large rainbow-colored umbrella: [0.367, 0.133, 0.727, 0.719]\nred hatchback car: [0.289, 0.938, 0.453, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000528980_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an large rainbow-colored umbrella is attached to a streetlamp post, and a red hatchback car is parked on the street below it to the left.\nObjects: [large rainbow-colored umbrella, red hatchback car]"
      },
      {
        "from": "gpt",
        "value": "large rainbow-colored umbrella: [0.367, 0.133, 0.727, 0.719]\nred hatchback car: [0.289, 0.938, 0.453, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000528980_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: umbrella: [0.367, 0.133, 0.727, 0.719]\ncar: [0.289, 0.938, 0.453, 0.992]\nGiven the above layout, shift the car to the left by 0.039."
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.367, 0.133, 0.727, 0.719]\ncar: [0.250, 0.938, 0.414, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000532901",
    "conversations": [
      {
        "from": "human",
        "value": "The couch is at the center of the image, facing forward."
      },
      {
        "from": "gpt",
        "value": "couch: [0.141, 0.469, 0.867, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000532901_key",
    "conversations": [
      {
        "from": "human",
        "value": "The couch is at the center of the image, facing forward.\nObjects: [couch]"
      },
      {
        "from": "gpt",
        "value": "couch: [0.141, 0.469, 0.867, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000532901_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the vintage leather sofa is at the center of the image, facing forward."
      },
      {
        "from": "gpt",
        "value": "vintage leather sofa: [0.141, 0.469, 0.867, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000532901_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the vintage leather sofa is at the center of the image, facing forward.\nObjects: [vintage leather sofa]"
      },
      {
        "from": "gpt",
        "value": "vintage leather sofa: [0.141, 0.469, 0.867, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000532901_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: couch: [0.141, 0.469, 0.867, 0.781]\nGiven the above layout, shift the couch upwards by 0.258."
      },
      {
        "from": "gpt",
        "value": "couch: [0.141, 0.211, 0.867, 0.523]"
      }
    ]
  },
  {
    "id": "coco_000000539143",
    "conversations": [
      {
        "from": "human",
        "value": "The train is positioned horizontally across the image, on the train tracks at the bottom center."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.352, 0.922, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000539143_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is positioned horizontally across the image, on the train tracks at the bottom center.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.352, 0.922, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000539143_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the blue freight train is positioned horizontally across the image, on the blue freight train tracks at the bottom center."
      },
      {
        "from": "gpt",
        "value": "blue freight train: [0.000, 0.352, 0.922, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000539143_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the blue freight train is positioned horizontally across the image, on the blue freight train tracks at the bottom center.\nObjects: [blue freight train]"
      },
      {
        "from": "gpt",
        "value": "blue freight train: [0.000, 0.352, 0.922, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000539143_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.352, 0.922, 0.703]\nGiven the above layout, shift the train upwards by 0.227."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.125, 0.922, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000541291",
    "conversations": [
      {
        "from": "human",
        "value": "A sink is mounted on the wall beneath a window, on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "sink: [0.047, 0.594, 0.422, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000541291_key",
    "conversations": [
      {
        "from": "human",
        "value": "A sink is mounted on the wall beneath a window, on the left side of the image.\nObjects: [sink]"
      },
      {
        "from": "gpt",
        "value": "sink: [0.047, 0.594, 0.422, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000541291_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a porcelain sink is mounted on the wall beneath a window, on the left side of the image."
      },
      {
        "from": "gpt",
        "value": "porcelain sink: [0.047, 0.594, 0.422, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000541291_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a porcelain sink is mounted on the wall beneath a window, on the left side of the image.\nObjects: [porcelain sink]"
      },
      {
        "from": "gpt",
        "value": "porcelain sink: [0.047, 0.594, 0.422, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000541291_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sink: [0.047, 0.594, 0.422, 0.789]\nGiven the above layout, shift the sink upwards by 0.438."
      },
      {
        "from": "gpt",
        "value": "sink: [0.047, 0.156, 0.422, 0.352]"
      }
    ]
  },
  {
    "id": "coco_000000544519",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a toothbrush near their mouth."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.180, 0.992, 0.820]\ntoothbrush: [0.273, 0.555, 0.602, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000544519_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a toothbrush near their mouth.\nObjects: [person, toothbrush]"
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.180, 0.992, 0.820]\ntoothbrush: [0.273, 0.555, 0.602, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000544519_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a adult individual is holding a green toothbrush near their mouth."
      },
      {
        "from": "gpt",
        "value": "adult individual: [0.000, 0.180, 0.992, 0.820]\ngreen toothbrush: [0.273, 0.555, 0.602, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000544519_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a adult individual is holding a green toothbrush near their mouth.\nObjects: [adult individual, green toothbrush]"
      },
      {
        "from": "gpt",
        "value": "adult individual: [0.000, 0.180, 0.992, 0.820]\ngreen toothbrush: [0.273, 0.555, 0.602, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000544519_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.000, 0.180, 0.992, 0.820]\ntoothbrush: [0.273, 0.555, 0.602, 0.617]\nGiven the above layout, shift the person upwards by 0.180."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.000, 0.992, 0.641]\ntoothbrush: [0.273, 0.555, 0.602, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000549674",
    "conversations": [
      {
        "from": "human",
        "value": "Two TVs are side by side in the center, with a keyboard in front of them."
      },
      {
        "from": "gpt",
        "value": "tv: [0.508, 0.141, 0.969, 0.648]\ntv: [0.055, 0.172, 0.492, 0.539]\nkeyboard: [0.086, 0.664, 0.711, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000549674_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two TVs are side by side in the center, with a keyboard in front of them.\nObjects: [tv, tv, keyboard]"
      },
      {
        "from": "gpt",
        "value": "tv: [0.508, 0.141, 0.969, 0.648]\ntv: [0.055, 0.172, 0.492, 0.539]\nkeyboard: [0.086, 0.664, 0.711, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000551304",
    "conversations": [
      {
        "from": "human",
        "value": "A white and beige toilet is standing in the center of the image with the seat lid up, against a tiled wall, next to a small black trash can."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.320, 0.125, 0.695, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000551304_key",
    "conversations": [
      {
        "from": "human",
        "value": "A white and beige toilet is standing in the center of the image with the seat lid up, against a tiled wall, next to a small black trash can.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.320, 0.125, 0.695, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000551304_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a white and beige sleek porcelain toilet is standing in the center of the image with the seat lid up, against a tiled wall, next to a small black trash can."
      },
      {
        "from": "gpt",
        "value": "sleek porcelain toilet: [0.320, 0.125, 0.695, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000551304_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a white and beige sleek porcelain toilet is standing in the center of the image with the seat lid up, against a tiled wall, next to a small black trash can.\nObjects: [sleek porcelain toilet]"
      },
      {
        "from": "gpt",
        "value": "sleek porcelain toilet: [0.320, 0.125, 0.695, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000551304_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.320, 0.125, 0.695, 0.852]\nGiven the above layout, shift the toilet to the left by 0.055."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.266, 0.125, 0.641, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000552902",
    "conversations": [
      {
        "from": "human",
        "value": "A zebra stands at the center of the image, grazing on grass."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.203, 0.328, 0.719, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000552902_key",
    "conversations": [
      {
        "from": "human",
        "value": "A zebra stands at the center of the image, grazing on grass.\nObjects: [zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.203, 0.328, 0.719, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000552902_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall giraffe stands at the center of the image, grazing on grass."
      },
      {
        "from": "gpt",
        "value": "tall giraffe: [0.203, 0.328, 0.719, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000552902_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall giraffe stands at the center of the image, grazing on grass.\nObjects: [tall giraffe]"
      },
      {
        "from": "gpt",
        "value": "tall giraffe: [0.203, 0.328, 0.719, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000552902_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: zebra: [0.203, 0.328, 0.719, 0.648]\nGiven the above layout, shift the zebra downwards by 0.172."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.203, 0.500, 0.719, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000556158",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing in the center of the image on a snow-covered path, holding ski poles."
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.219, 0.570, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000556158_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing in the center of the image on a snow-covered path, holding ski poles.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.352, 0.219, 0.570, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000556158_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a ambitious hiker standing in the center of the image on a snow-covered path, holding ski poles."
      },
      {
        "from": "gpt",
        "value": "ambitious hiker: [0.352, 0.219, 0.570, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000556158_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a ambitious hiker standing in the center of the image on a snow-covered path, holding ski poles.\nObjects: [ambitious hiker]"
      },
      {
        "from": "gpt",
        "value": "ambitious hiker: [0.352, 0.219, 0.570, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000556158_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.352, 0.219, 0.570, 0.719]\nGiven the above layout, shift the person to the right by 0.352."
      },
      {
        "from": "gpt",
        "value": "person: [0.703, 0.219, 0.922, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000577735",
    "conversations": [
      {
        "from": "human",
        "value": "A vase with flowers is to the right of a potted plant."
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.094, 0.125, 0.898, 0.812]\nvase: [0.609, 0.516, 0.766, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000577735_key",
    "conversations": [
      {
        "from": "human",
        "value": "A vase with flowers is to the right of a potted plant.\nObjects: [potted plant, vase]"
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.094, 0.125, 0.898, 0.812]\nvase: [0.609, 0.516, 0.766, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000577735_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a porcelain vase with lilies with flowers is to the right of a succulent plant."
      },
      {
        "from": "gpt",
        "value": "succulent plant: [0.094, 0.125, 0.898, 0.812]\nporcelain vase with lilies: [0.609, 0.516, 0.766, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000577735_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a porcelain vase with lilies with flowers is to the right of a succulent plant.\nObjects: [succulent plant, porcelain vase with lilies]"
      },
      {
        "from": "gpt",
        "value": "succulent plant: [0.094, 0.125, 0.898, 0.812]\nporcelain vase with lilies: [0.609, 0.516, 0.766, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000577735_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: potted plant: [0.094, 0.125, 0.898, 0.812]\nvase: [0.609, 0.516, 0.766, 0.820]\nGiven the above layout, shift the vase downwards by 0.086."
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.094, 0.125, 0.898, 0.812]\nvase: [0.609, 0.602, 0.766, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000022623",
    "conversations": [
      {
        "from": "human",
        "value": "The cell phone is at the center of the image, tilted slightly to the left, with the focus on its circular navigation buttons."
      },
      {
        "from": "gpt",
        "value": "cell phone: [0.008, 0.125, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000022623_key",
    "conversations": [
      {
        "from": "human",
        "value": "The cell phone is at the center of the image, tilted slightly to the left, with the focus on its circular navigation buttons.\nObjects: [cell phone]"
      },
      {
        "from": "gpt",
        "value": "cell phone: [0.008, 0.125, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000022623_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the shiny new smartphone is at the center of the image, tilted slightly to the left, with the focus on its circular navigation buttons."
      },
      {
        "from": "gpt",
        "value": "shiny new smartphone: [0.008, 0.125, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000022623_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the shiny new smartphone is at the center of the image, tilted slightly to the left, with the focus on its circular navigation buttons.\nObjects: [shiny new smartphone]"
      },
      {
        "from": "gpt",
        "value": "shiny new smartphone: [0.008, 0.125, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000022623_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cell phone: [0.008, 0.125, 0.992, 0.820]\nGiven the above layout, shift the cell phone downwards by 0.062."
      },
      {
        "from": "gpt",
        "value": "cell phone: [0.008, 0.188, 0.992, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000098633",
    "conversations": [
      {
        "from": "human",
        "value": "The cake is in the center of the image, garnished with strawberries on top."
      },
      {
        "from": "gpt",
        "value": "cake: [0.203, 0.297, 0.781, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000098633_key",
    "conversations": [
      {
        "from": "human",
        "value": "The cake is in the center of the image, garnished with strawberries on top.\nObjects: [cake]"
      },
      {
        "from": "gpt",
        "value": "cake: [0.203, 0.297, 0.781, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000098633_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the heart-shaped cake with strawberries is in the center of the image, garnished with strawberries on top."
      },
      {
        "from": "gpt",
        "value": "heart-shaped cake with strawberries: [0.203, 0.297, 0.781, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000098633_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the heart-shaped cake with strawberries is in the center of the image, garnished with strawberries on top.\nObjects: [heart-shaped cake with strawberries]"
      },
      {
        "from": "gpt",
        "value": "heart-shaped cake with strawberries: [0.203, 0.297, 0.781, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000098633_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cake: [0.203, 0.297, 0.781, 0.914]\nGiven the above layout, shift the cake upwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "cake: [0.203, 0.258, 0.781, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000105923",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant is partly visible behind a glass window to the right of the frame."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.656, 0.266, 0.852, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000105923_key",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant is partly visible behind a glass window to the right of the frame.\nObjects: [elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.656, 0.266, 0.852, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000105923_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an mammoth is partly visible behind a glass window to the right of the frame."
      },
      {
        "from": "gpt",
        "value": "mammoth: [0.656, 0.266, 0.852, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000105923_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an mammoth is partly visible behind a glass window to the right of the frame.\nObjects: [mammoth]"
      },
      {
        "from": "gpt",
        "value": "mammoth: [0.656, 0.266, 0.852, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000105923_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: elephant: [0.656, 0.266, 0.852, 0.648]\nGiven the above layout, shift the elephant to the left by 0.547."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.109, 0.266, 0.305, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000108440",
    "conversations": [
      {
        "from": "human",
        "value": "A train is centered horizontally in the image, elevated on a track structure."
      },
      {
        "from": "gpt",
        "value": "train: [0.023, 0.422, 0.781, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000108440_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is centered horizontally in the image, elevated on a track structure.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.023, 0.422, 0.781, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000108440_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a fast moving bullet train is centered horizontally in the image, elevated on a track structure."
      },
      {
        "from": "gpt",
        "value": "fast moving bullet train: [0.023, 0.422, 0.781, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000108440_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a fast moving bullet train is centered horizontally in the image, elevated on a track structure.\nObjects: [fast moving bullet train]"
      },
      {
        "from": "gpt",
        "value": "fast moving bullet train: [0.023, 0.422, 0.781, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000108440_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.023, 0.422, 0.781, 0.516]\nGiven the above layout, shift the train downwards by 0.469."
      },
      {
        "from": "gpt",
        "value": "train: [0.023, 0.891, 0.781, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000110721",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is parked at the gate with the jet bridge connected to its side door."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.023, 0.172, 0.992, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000110721_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is parked at the gate with the jet bridge connected to its side door.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.023, 0.172, 0.992, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000110721_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an Boeing 777 is parked at the gate with the jet bridge connected to its side door."
      },
      {
        "from": "gpt",
        "value": "Boeing 777: [0.023, 0.172, 0.992, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000110721_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an Boeing 777 is parked at the gate with the jet bridge connected to its side door.\nObjects: [Boeing 777]"
      },
      {
        "from": "gpt",
        "value": "Boeing 777: [0.023, 0.172, 0.992, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000110721_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.023, 0.172, 0.992, 0.719]\nGiven the above layout, shift the airplane downwards by 0.078."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.023, 0.250, 0.992, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000136466",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is in the center of the image with its door open, revealing the inside."
      },
      {
        "from": "gpt",
        "value": "oven: [0.234, 0.188, 0.805, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000136466_key",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is in the center of the image with its door open, revealing the inside.\nObjects: [oven]"
      },
      {
        "from": "gpt",
        "value": "oven: [0.234, 0.188, 0.805, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000136466_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel oven is in the center of the image with its door open, revealing the inside."
      },
      {
        "from": "gpt",
        "value": "stainless steel oven: [0.234, 0.188, 0.805, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000136466_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel oven is in the center of the image with its door open, revealing the inside.\nObjects: [stainless steel oven]"
      },
      {
        "from": "gpt",
        "value": "stainless steel oven: [0.234, 0.188, 0.805, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000136466_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: oven: [0.234, 0.188, 0.805, 0.945]\nGiven the above layout, shift the oven to the left by 0.141."
      },
      {
        "from": "gpt",
        "value": "oven: [0.094, 0.188, 0.664, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000139871",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is positioned at the center of the image, on the ground facing to the right with the cockpit hatch open."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.023, 0.312, 0.969, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000139871_key",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is positioned at the center of the image, on the ground facing to the right with the cockpit hatch open.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.023, 0.312, 0.969, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000139871_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the jumbo jet is positioned at the center of the image, on the ground facing to the right with the cockpit hatch open."
      },
      {
        "from": "gpt",
        "value": "jumbo jet: [0.023, 0.312, 0.969, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000139871_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the jumbo jet is positioned at the center of the image, on the ground facing to the right with the cockpit hatch open.\nObjects: [jumbo jet]"
      },
      {
        "from": "gpt",
        "value": "jumbo jet: [0.023, 0.312, 0.969, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000139871_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.023, 0.312, 0.969, 0.656]\nGiven the above layout, shift the airplane downwards by 0.047."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.023, 0.359, 0.969, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000145591",
    "conversations": [
      {
        "from": "human",
        "value": "An outdoor clock is at the center against a clear sky, with palm trees and a building in the background."
      },
      {
        "from": "gpt",
        "value": "clock: [0.461, 0.203, 0.953, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000145591_key",
    "conversations": [
      {
        "from": "human",
        "value": "An outdoor clock is at the center against a clear sky, with palm trees and a building in the background.\nObjects: [clock]"
      },
      {
        "from": "gpt",
        "value": "clock: [0.461, 0.203, 0.953, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000145591_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an outdoor Roman numeral clock is at the center against a clear sky, with palm trees and a building in the background."
      },
      {
        "from": "gpt",
        "value": "Roman numeral clock: [0.461, 0.203, 0.953, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000145591_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an outdoor Roman numeral clock is at the center against a clear sky, with palm trees and a building in the background.\nObjects: [Roman numeral clock]"
      },
      {
        "from": "gpt",
        "value": "Roman numeral clock: [0.461, 0.203, 0.953, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000145591_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: clock: [0.461, 0.203, 0.953, 0.859]\nGiven the above layout, shift the clock to the left by 0.414."
      },
      {
        "from": "gpt",
        "value": "clock: [0.047, 0.203, 0.539, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000150930",
    "conversations": [
      {
        "from": "human",
        "value": "The clock is hanging above a street corner, extending out from a pole to the upper right."
      },
      {
        "from": "gpt",
        "value": "clock: [0.367, 0.266, 0.578, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000150930_key",
    "conversations": [
      {
        "from": "human",
        "value": "The clock is hanging above a street corner, extending out from a pole to the upper right.\nObjects: [clock]"
      },
      {
        "from": "gpt",
        "value": "clock: [0.367, 0.266, 0.578, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000150930_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the vintage wall clock is hanging above a street corner, extending out from a pole to the upper right."
      },
      {
        "from": "gpt",
        "value": "vintage wall clock: [0.367, 0.266, 0.578, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000150930_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the vintage wall clock is hanging above a street corner, extending out from a pole to the upper right.\nObjects: [vintage wall clock]"
      },
      {
        "from": "gpt",
        "value": "vintage wall clock: [0.367, 0.266, 0.578, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000150930_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: clock: [0.367, 0.266, 0.578, 0.617]\nGiven the above layout, shift the clock to the right by 0.227."
      },
      {
        "from": "gpt",
        "value": "clock: [0.594, 0.266, 0.805, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000152465",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is at the center, slightly to the right, with a tire encircling its base."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.641, 0.141, 0.844, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000152465_key",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is at the center, slightly to the right, with a tire encircling its base.\nObjects: [fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.641, 0.141, 0.844, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000152465_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red fire hydrant is at the center, slightly to the right, with a tire encircling its base."
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.641, 0.141, 0.844, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000152465_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red fire hydrant is at the center, slightly to the right, with a tire encircling its base.\nObjects: [red fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.641, 0.141, 0.844, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000152465_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: fire hydrant: [0.641, 0.141, 0.844, 0.781]\nGiven the above layout, shift the fire hydrant to the left by 0.086."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.555, 0.141, 0.758, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000164969",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza with various toppings is placed at the center of the image inside an open pizza box."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.125, 0.203, 0.781, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000164969_key",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza with various toppings is placed at the center of the image inside an open pizza box.\nObjects: [pizza]"
      },
      {
        "from": "gpt",
        "value": "pizza: [0.125, 0.203, 0.781, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000164969_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a Meat-loaded pizza with various toppings is placed at the center of the image inside an open Meat-loaded pizza box."
      },
      {
        "from": "gpt",
        "value": "Meat-loaded pizza: [0.125, 0.203, 0.781, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000164969_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a Meat-loaded pizza with various toppings is placed at the center of the image inside an open Meat-loaded pizza box.\nObjects: [Meat-loaded pizza]"
      },
      {
        "from": "gpt",
        "value": "Meat-loaded pizza: [0.125, 0.203, 0.781, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000164969_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: pizza: [0.125, 0.203, 0.781, 0.820]\nGiven the above layout, shift the pizza to the right by 0.086."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.211, 0.203, 0.867, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000167122",
    "conversations": [
      {
        "from": "human",
        "value": "The car is centered in the image under a night sky with lights flaring in the background."
      },
      {
        "from": "gpt",
        "value": "car: [0.047, 0.461, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000167122_key",
    "conversations": [
      {
        "from": "human",
        "value": "The car is centered in the image under a night sky with lights flaring in the background.\nObjects: [car]"
      },
      {
        "from": "gpt",
        "value": "car: [0.047, 0.461, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000167122_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the vintage red convertible is centered in the image under a night sky with lights flaring in the background."
      },
      {
        "from": "gpt",
        "value": "vintage red convertible: [0.047, 0.461, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000167122_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the vintage red convertible is centered in the image under a night sky with lights flaring in the background.\nObjects: [vintage red convertible]"
      },
      {
        "from": "gpt",
        "value": "vintage red convertible: [0.047, 0.461, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000167122_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: car: [0.047, 0.461, 0.992, 0.867]\nGiven the above layout, shift the car upwards by 0.141."
      },
      {
        "from": "gpt",
        "value": "car: [0.047, 0.320, 0.992, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000176847",
    "conversations": [
      {
        "from": "human",
        "value": "A black bird is perched on a branch surrounded by green leaves and blackberries at the center of the image."
      },
      {
        "from": "gpt",
        "value": "bird: [0.383, 0.461, 0.805, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000176847_key",
    "conversations": [
      {
        "from": "human",
        "value": "A black bird is perched on a branch surrounded by green leaves and blackberries at the center of the image.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.383, 0.461, 0.805, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000176847_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a black crow is perched on a branch surrounded by green leaves and blackberries at the center of the image."
      },
      {
        "from": "gpt",
        "value": "crow: [0.383, 0.461, 0.805, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000176847_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a black crow is perched on a branch surrounded by green leaves and blackberries at the center of the image.\nObjects: [crow]"
      },
      {
        "from": "gpt",
        "value": "crow: [0.383, 0.461, 0.805, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000176847_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.383, 0.461, 0.805, 0.680]\nGiven the above layout, shift the bird upwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "bird: [0.383, 0.438, 0.805, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000197528",
    "conversations": [
      {
        "from": "human",
        "value": "The cat is sitting behind a window screen, looking out."
      },
      {
        "from": "gpt",
        "value": "cat: [0.320, 0.180, 0.727, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000197528_key",
    "conversations": [
      {
        "from": "human",
        "value": "The cat is sitting behind a window screen, looking out.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.320, 0.180, 0.727, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000197528_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the striped feline is sitting behind a window screen, looking out."
      },
      {
        "from": "gpt",
        "value": "striped feline: [0.320, 0.180, 0.727, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000197528_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the striped feline is sitting behind a window screen, looking out.\nObjects: [striped feline]"
      },
      {
        "from": "gpt",
        "value": "striped feline: [0.320, 0.180, 0.727, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000197528_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.320, 0.180, 0.727, 0.984]\nGiven the above layout, shift the cat to the left by 0.031."
      },
      {
        "from": "gpt",
        "value": "cat: [0.289, 0.180, 0.695, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000234807",
    "conversations": [
      {
        "from": "human",
        "value": "One horse is facing the camera in the right foreground, and another horse is facing away from the camera on the left."
      },
      {
        "from": "gpt",
        "value": "horse: [0.789, 0.398, 0.992, 0.852]\nhorse: [0.203, 0.477, 0.336, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000234807_key",
    "conversations": [
      {
        "from": "human",
        "value": "One horse is facing the camera in the right foreground, and another horse is facing away from the camera on the left.\nObjects: [horse, horse]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.789, 0.398, 0.992, 0.852]\nhorse: [0.203, 0.477, 0.336, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000235064",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is standing in the center on a rocky surface."
      },
      {
        "from": "gpt",
        "value": "bear: [0.172, 0.328, 0.844, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000235064_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is standing in the center on a rocky surface.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.172, 0.328, 0.844, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000235064_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the large grizzly bear is standing in the center on a rocky surface."
      },
      {
        "from": "gpt",
        "value": "large grizzly bear: [0.172, 0.328, 0.844, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000235064_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the large grizzly bear is standing in the center on a rocky surface.\nObjects: [large grizzly bear]"
      },
      {
        "from": "gpt",
        "value": "large grizzly bear: [0.172, 0.328, 0.844, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000235064_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.172, 0.328, 0.844, 0.773]\nGiven the above layout, shift the bear upwards by 0.234."
      },
      {
        "from": "gpt",
        "value": "bear: [0.172, 0.094, 0.844, 0.539]"
      }
    ]
  },
  {
    "id": "coco_000000238039",
    "conversations": [
      {
        "from": "human",
        "value": "A sheep is on a dirt road to the right, with a leash leading off the edge of the image to the left."
      },
      {
        "from": "gpt",
        "value": "sheep: [0.320, 0.484, 0.633, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000238039_key",
    "conversations": [
      {
        "from": "human",
        "value": "A sheep is on a dirt road to the right, with a leash leading off the edge of the image to the left.\nObjects: [sheep]"
      },
      {
        "from": "gpt",
        "value": "sheep: [0.320, 0.484, 0.633, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000238039_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a fluffy white sheep is on a dirt road to the right, with a leash leading off the edge of the image to the left."
      },
      {
        "from": "gpt",
        "value": "fluffy white sheep: [0.320, 0.484, 0.633, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000238039_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a fluffy white sheep is on a dirt road to the right, with a leash leading off the edge of the image to the left.\nObjects: [fluffy white sheep]"
      },
      {
        "from": "gpt",
        "value": "fluffy white sheep: [0.320, 0.484, 0.633, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000238039_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: sheep: [0.320, 0.484, 0.633, 0.922]\nGiven the above layout, shift the sheep upwards by 0.484."
      },
      {
        "from": "gpt",
        "value": "sheep: [0.320, 0.000, 0.633, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000259625",
    "conversations": [
      {
        "from": "human",
        "value": "The elephant is in the center of the image, walking towards the left."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.219, 0.422, 0.586, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000259625_key",
    "conversations": [
      {
        "from": "human",
        "value": "The elephant is in the center of the image, walking towards the left.\nObjects: [elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.219, 0.422, 0.586, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000259625_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the large African elephant is in the center of the image, walking towards the left."
      },
      {
        "from": "gpt",
        "value": "large African elephant: [0.219, 0.422, 0.586, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000259625_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the large African elephant is in the center of the image, walking towards the left.\nObjects: [large African elephant]"
      },
      {
        "from": "gpt",
        "value": "large African elephant: [0.219, 0.422, 0.586, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000259625_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: elephant: [0.219, 0.422, 0.586, 0.641]\nGiven the above layout, shift the elephant upwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.219, 0.398, 0.586, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000269632",
    "conversations": [
      {
        "from": "human",
        "value": "A bus in the center of the image and a car to the right of the bus."
      },
      {
        "from": "gpt",
        "value": "bus: [0.156, 0.250, 0.766, 0.727]\ncar: [0.859, 0.531, 0.992, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000269632_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bus in the center of the image and a car to the right of the bus.\nObjects: [bus, car]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.156, 0.250, 0.766, 0.727]\ncar: [0.859, 0.531, 0.992, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000269632_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a double-decker bus in the center of the image and a red sedan to the right of the double-decker bus."
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.156, 0.250, 0.766, 0.727]\nred sedan: [0.859, 0.531, 0.992, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000269632_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a double-decker bus in the center of the image and a red sedan to the right of the double-decker bus.\nObjects: [double-decker bus, red sedan]"
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.156, 0.250, 0.766, 0.727]\nred sedan: [0.859, 0.531, 0.992, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000269632_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.156, 0.250, 0.766, 0.727]\ncar: [0.859, 0.531, 0.992, 0.703]\nGiven the above layout, shift the bus downwards by 0.242."
      },
      {
        "from": "gpt",
        "value": "bus: [0.156, 0.492, 0.766, 0.969]\ncar: [0.859, 0.531, 0.992, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000279278",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center with a leg on a bicycle to the left, while two other persons are partially visible, one on each side of the central person."
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.000, 0.562, 0.430, 0.820]\nperson: [0.531, 0.164, 0.742, 0.664]\nperson: [0.242, 0.164, 0.453, 0.617]\nperson: [0.875, 0.188, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000279278_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center with a leg on a bicycle to the left, while two other persons are partially visible, one on each side of the central person.\nObjects: [bicycle, person, person, person]"
      },
      {
        "from": "gpt",
        "value": "bicycle: [0.000, 0.562, 0.430, 0.820]\nperson: [0.531, 0.164, 0.742, 0.664]\nperson: [0.242, 0.164, 0.453, 0.617]\nperson: [0.875, 0.188, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000292155",
    "conversations": [
      {
        "from": "human",
        "value": "A striped umbrella is open in the center with the sky visible in the background."
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.000, 0.133, 0.727, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000292155_key",
    "conversations": [
      {
        "from": "human",
        "value": "A striped umbrella is open in the center with the sky visible in the background.\nObjects: [umbrella]"
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.000, 0.133, 0.727, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000292155_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a striped yellow and white striped umbrella is open in the center with the sky visible in the background."
      },
      {
        "from": "gpt",
        "value": "yellow and white striped umbrella: [0.000, 0.133, 0.727, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000292155_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a striped yellow and white striped umbrella is open in the center with the sky visible in the background.\nObjects: [yellow and white striped umbrella]"
      },
      {
        "from": "gpt",
        "value": "yellow and white striped umbrella: [0.000, 0.133, 0.727, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000292155_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: umbrella: [0.000, 0.133, 0.727, 0.859]\nGiven the above layout, shift the umbrella to the right by 0.023."
      },
      {
        "from": "gpt",
        "value": "umbrella: [0.023, 0.133, 0.750, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000296224",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is at the center of the image, facing slightly to the left."
      },
      {
        "from": "gpt",
        "value": "bus: [0.086, 0.172, 0.906, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000296224_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is at the center of the image, facing slightly to the left.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.086, 0.172, 0.906, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000296224_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the green double-decker bus is at the center of the image, facing slightly to the left."
      },
      {
        "from": "gpt",
        "value": "green double-decker bus: [0.086, 0.172, 0.906, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000296224_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the green double-decker bus is at the center of the image, facing slightly to the left.\nObjects: [green double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "green double-decker bus: [0.086, 0.172, 0.906, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000296224_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.086, 0.172, 0.906, 0.852]\nGiven the above layout, shift the bus upwards by 0.031."
      },
      {
        "from": "gpt",
        "value": "bus: [0.086, 0.141, 0.906, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000303713",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center, serving a tennis ball with a racquet above their head."
      },
      {
        "from": "gpt",
        "value": "person: [0.305, 0.508, 0.570, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000303713_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center, serving a tennis ball with a racquet above their head.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.305, 0.508, 0.570, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000303713_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a professional tennis player is at the center, serving a tennis ball with a racquet above their head."
      },
      {
        "from": "gpt",
        "value": "a professional tennis player: [0.305, 0.508, 0.570, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000303713_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a professional tennis player is at the center, serving a tennis ball with a racquet above their head.\nObjects: [a professional tennis player]"
      },
      {
        "from": "gpt",
        "value": "a professional tennis player: [0.305, 0.508, 0.570, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000303713_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.305, 0.508, 0.570, 0.984]\nGiven the above layout, shift the person upwards by 0.188."
      },
      {
        "from": "gpt",
        "value": "person: [0.305, 0.320, 0.570, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000304560",
    "conversations": [
      {
        "from": "human",
        "value": "A black cat is sitting on the grass looking towards the camera."
      },
      {
        "from": "gpt",
        "value": "cat: [0.000, 0.320, 0.703, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000304560_key",
    "conversations": [
      {
        "from": "human",
        "value": "A black cat is sitting on the grass looking towards the camera.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.000, 0.320, 0.703, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000304560_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a black Siamese cat is sitting on the grass looking towards the camera."
      },
      {
        "from": "gpt",
        "value": "Siamese cat: [0.000, 0.320, 0.703, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000304560_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a black Siamese cat is sitting on the grass looking towards the camera.\nObjects: [Siamese cat]"
      },
      {
        "from": "gpt",
        "value": "Siamese cat: [0.000, 0.320, 0.703, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000304560_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.000, 0.320, 0.703, 0.820]\nGiven the above layout, shift the cat upwards by 0.320."
      },
      {
        "from": "gpt",
        "value": "cat: [0.000, 0.000, 0.703, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000312340",
    "conversations": [
      {
        "from": "human",
        "value": "A black and white cat is sitting at the center, in front of a window pane with foliage around it."
      },
      {
        "from": "gpt",
        "value": "cat: [0.219, 0.336, 0.633, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000312340_key",
    "conversations": [
      {
        "from": "human",
        "value": "A black and white cat is sitting at the center, in front of a window pane with foliage around it.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.219, 0.336, 0.633, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000312340_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a black and white spotty tabby cat is sitting at the center, in front of a window pane with foliage around it."
      },
      {
        "from": "gpt",
        "value": "spotty tabby cat: [0.219, 0.336, 0.633, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000312340_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a black and white spotty tabby cat is sitting at the center, in front of a window pane with foliage around it.\nObjects: [spotty tabby cat]"
      },
      {
        "from": "gpt",
        "value": "spotty tabby cat: [0.219, 0.336, 0.633, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000312340_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.219, 0.336, 0.633, 0.703]\nGiven the above layout, shift the cat to the right by 0.078."
      },
      {
        "from": "gpt",
        "value": "cat: [0.297, 0.336, 0.711, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000321118",
    "conversations": [
      {
        "from": "human",
        "value": "The laptop is open at the center of the image on a table."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.133, 0.172, 0.852, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000321118_key",
    "conversations": [
      {
        "from": "human",
        "value": "The laptop is open at the center of the image on a table.\nObjects: [laptop]"
      },
      {
        "from": "gpt",
        "value": "laptop: [0.133, 0.172, 0.852, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000321118_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the sleek silver laptop is open at the center of the image on a table."
      },
      {
        "from": "gpt",
        "value": "sleek silver laptop: [0.133, 0.172, 0.852, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000321118_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the sleek silver laptop is open at the center of the image on a table.\nObjects: [sleek silver laptop]"
      },
      {
        "from": "gpt",
        "value": "sleek silver laptop: [0.133, 0.172, 0.852, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000321118_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: laptop: [0.133, 0.172, 0.852, 0.820]\nGiven the above layout, shift the laptop upwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.133, 0.102, 0.852, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000335529",
    "conversations": [
      {
        "from": "human",
        "value": "A red bench is positioned in the center of the image facing towards the water."
      },
      {
        "from": "gpt",
        "value": "bench: [0.047, 0.562, 0.672, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000335529_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red bench is positioned in the center of the image facing towards the water.\nObjects: [bench]"
      },
      {
        "from": "gpt",
        "value": "bench: [0.047, 0.562, 0.672, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000335529_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red a cherry red wooden garden bench is positioned in the center of the image facing towards the water."
      },
      {
        "from": "gpt",
        "value": "a cherry red wooden garden bench: [0.047, 0.562, 0.672, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000335529_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red a cherry red wooden garden bench is positioned in the center of the image facing towards the water.\nObjects: [a cherry red wooden garden bench]"
      },
      {
        "from": "gpt",
        "value": "a cherry red wooden garden bench: [0.047, 0.562, 0.672, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000335529_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bench: [0.047, 0.562, 0.672, 0.852]\nGiven the above layout, shift the bench upwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "bench: [0.047, 0.539, 0.672, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000357501",
    "conversations": [
      {
        "from": "human",
        "value": "The scissors are at the center with the handles pointing to the top left corner."
      },
      {
        "from": "gpt",
        "value": "scissors: [0.039, 0.156, 0.781, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000357501_key",
    "conversations": [
      {
        "from": "human",
        "value": "The scissors are at the center with the handles pointing to the top left corner.\nObjects: [scissors]"
      },
      {
        "from": "gpt",
        "value": "scissors: [0.039, 0.156, 0.781, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000357501_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the blue-handled scissors are at the center with the handles pointing to the top left corner."
      },
      {
        "from": "gpt",
        "value": "blue-handled scissors: [0.039, 0.156, 0.781, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000357501_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the blue-handled scissors are at the center with the handles pointing to the top left corner.\nObjects: [blue-handled scissors]"
      },
      {
        "from": "gpt",
        "value": "blue-handled scissors: [0.039, 0.156, 0.781, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000357501_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: scissors: [0.039, 0.156, 0.781, 0.852]\nGiven the above layout, shift the scissors to the right by 0.148."
      },
      {
        "from": "gpt",
        "value": "scissors: [0.188, 0.156, 0.930, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000429761",
    "conversations": [
      {
        "from": "human",
        "value": "One person is standing to the left facing and talking to another person standing to the right on a tennis court."
      },
      {
        "from": "gpt",
        "value": "person: [0.289, 0.281, 0.477, 0.766]\nperson: [0.469, 0.258, 0.633, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000429761_key",
    "conversations": [
      {
        "from": "human",
        "value": "One person is standing to the left facing and talking to another person standing to the right on a tennis court.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.289, 0.281, 0.477, 0.766]\nperson: [0.469, 0.258, 0.633, 0.719]"
      }
    ]
  },
  {
    "id": "coco_000000433374",
    "conversations": [
      {
        "from": "human",
        "value": "There is one elephant standing facing left in the center, and another elephant is on the right side with its back towards the viewer."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.180, 0.266, 0.461, 0.531]\nelephant: [0.781, 0.273, 0.906, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000433374_key",
    "conversations": [
      {
        "from": "human",
        "value": "There is one elephant standing facing left in the center, and another elephant is on the right side with its back towards the viewer.\nObjects: [elephant, elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.180, 0.266, 0.461, 0.531]\nelephant: [0.781, 0.273, 0.906, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000447200",
    "conversations": [
      {
        "from": "human",
        "value": "A dog on the right side of the image, leashed and walking on a brick path."
      },
      {
        "from": "gpt",
        "value": "dog: [0.016, 0.148, 0.820, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000447200_key",
    "conversations": [
      {
        "from": "human",
        "value": "A dog on the right side of the image, leashed and walking on a brick path.\nObjects: [dog]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.016, 0.148, 0.820, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000447200_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a golden retriever on the right side of the image, leashed and walking on a brick path."
      },
      {
        "from": "gpt",
        "value": "golden retriever: [0.016, 0.148, 0.820, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000447200_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a golden retriever on the right side of the image, leashed and walking on a brick path.\nObjects: [golden retriever]"
      },
      {
        "from": "gpt",
        "value": "golden retriever: [0.016, 0.148, 0.820, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000447200_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.016, 0.148, 0.820, 0.828]\nGiven the above layout, shift the dog to the right by 0.156."
      },
      {
        "from": "gpt",
        "value": "dog: [0.172, 0.148, 0.977, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000451150",
    "conversations": [
      {
        "from": "human",
        "value": "Four donuts are arranged in a two by two grid inside a box; two chocolate donuts positioned at the top, with one glazed and one plain donut below them."
      },
      {
        "from": "gpt",
        "value": "donut: [0.125, 0.023, 0.500, 0.375]\ndonut: [0.141, 0.680, 0.508, 0.977]\ndonut: [0.148, 0.367, 0.500, 0.664]\ndonut: [0.484, 0.094, 0.789, 0.422]"
      }
    ]
  },
  {
    "id": "coco_000000451150_key",
    "conversations": [
      {
        "from": "human",
        "value": "Four donuts are arranged in a two by two grid inside a box; two chocolate donuts positioned at the top, with one glazed and one plain donut below them.\nObjects: [donut, donut, donut, donut]"
      },
      {
        "from": "gpt",
        "value": "donut: [0.125, 0.023, 0.500, 0.375]\ndonut: [0.141, 0.680, 0.508, 0.977]\ndonut: [0.148, 0.367, 0.500, 0.664]\ndonut: [0.484, 0.094, 0.789, 0.422]"
      }
    ]
  },
  {
    "id": "coco_000000451714",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center wearing skis."
      },
      {
        "from": "gpt",
        "value": "person: [0.398, 0.164, 0.617, 0.875]\nskis: [0.312, 0.766, 0.867, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000451714_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center wearing skis.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.398, 0.164, 0.617, 0.875]\nskis: [0.312, 0.766, 0.867, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000451714_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a an adventurous teenager is standing in the center wearing large snow skis."
      },
      {
        "from": "gpt",
        "value": "an adventurous teenager: [0.398, 0.164, 0.617, 0.875]\nlarge snow skis: [0.312, 0.766, 0.867, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000451714_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a an adventurous teenager is standing in the center wearing large snow skis.\nObjects: [an adventurous teenager, large snow skis]"
      },
      {
        "from": "gpt",
        "value": "an adventurous teenager: [0.398, 0.164, 0.617, 0.875]\nlarge snow skis: [0.312, 0.766, 0.867, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000451714_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.398, 0.164, 0.617, 0.875]\nskis: [0.312, 0.766, 0.867, 0.984]\nGiven the above layout, shift the skis to the left by 0.070."
      },
      {
        "from": "gpt",
        "value": "person: [0.398, 0.164, 0.617, 0.875]\nskis: [0.242, 0.766, 0.797, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000462576",
    "conversations": [
      {
        "from": "human",
        "value": "There is no dining table, cup, or orange present in the image provided. Instead, there is a plate with food and an orange slice, a glass of orange juice, and a pastry on a smaller plate on a surface."
      },
      {
        "from": "gpt",
        "value": "dining table: [0.000, 0.125, 0.992, 0.844]\ncup: [0.719, 0.125, 0.969, 0.445]\norange: [0.375, 0.609, 0.586, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000462576_key",
    "conversations": [
      {
        "from": "human",
        "value": "There is no dining table, cup, or orange present in the image provided. Instead, there is a plate with food and an orange slice, a glass of orange juice, and a pastry on a smaller plate on a surface.\nObjects: [dining table, cup, orange]"
      },
      {
        "from": "gpt",
        "value": "dining table: [0.000, 0.125, 0.992, 0.844]\ncup: [0.719, 0.125, 0.969, 0.445]\norange: [0.375, 0.609, 0.586, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000462576_aug",
    "conversations": [
      {
        "from": "human",
        "value": "there is no mahogany coffee table, white porcelain mug, or ripe apple present in the image provided. instead, there is a plate with food and an ripe apple slice, a glass of ripe apple juice, and a pastry on a smaller plate on a surface."
      },
      {
        "from": "gpt",
        "value": "mahogany coffee table: [0.000, 0.125, 0.992, 0.844]\nwhite porcelain mug: [0.719, 0.125, 0.969, 0.445]\nripe apple: [0.375, 0.609, 0.586, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000462576_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "there is no mahogany coffee table, white porcelain mug, or ripe apple present in the image provided. instead, there is a plate with food and an ripe apple slice, a glass of ripe apple juice, and a pastry on a smaller plate on a surface.\nObjects: [mahogany coffee table, white porcelain mug, ripe apple]"
      },
      {
        "from": "gpt",
        "value": "mahogany coffee table: [0.000, 0.125, 0.992, 0.844]\nwhite porcelain mug: [0.719, 0.125, 0.969, 0.445]\nripe apple: [0.375, 0.609, 0.586, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000462576_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dining table: [0.000, 0.125, 0.992, 0.844]\ncup: [0.719, 0.125, 0.969, 0.445]\norange: [0.375, 0.609, 0.586, 0.742]\nGiven the above layout, shift the dining table downwards by 0.055."
      },
      {
        "from": "gpt",
        "value": "dining table: [0.000, 0.180, 0.992, 0.898]\ncup: [0.719, 0.125, 0.969, 0.445]\norange: [0.375, 0.609, 0.586, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000465129",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center fixing a light fixture, an oven is to their right, and a sink is located to their left."
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.273, 0.477, 0.859]\noven: [0.445, 0.758, 0.656, 0.859]\nsink: [0.648, 0.688, 0.945, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000465129_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center fixing a light fixture, an oven is to their right, and a sink is located to their left.\nObjects: [person, oven, sink]"
      },
      {
        "from": "gpt",
        "value": "person: [0.172, 0.273, 0.477, 0.859]\noven: [0.445, 0.758, 0.656, 0.859]\nsink: [0.648, 0.688, 0.945, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000469192",
    "conversations": [
      {
        "from": "human",
        "value": "A white truck parked on an open field with kites flying in the sky behind it."
      },
      {
        "from": "gpt",
        "value": "truck: [0.273, 0.477, 0.984, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000469192_key",
    "conversations": [
      {
        "from": "human",
        "value": "A white truck parked on an open field with kites flying in the sky behind it.\nObjects: [truck]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.273, 0.477, 0.984, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000469192_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a white shiny white van parked on an open field with kites flying in the sky behind it."
      },
      {
        "from": "gpt",
        "value": "shiny white van: [0.273, 0.477, 0.984, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000469192_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a white shiny white van parked on an open field with kites flying in the sky behind it.\nObjects: [shiny white van]"
      },
      {
        "from": "gpt",
        "value": "shiny white van: [0.273, 0.477, 0.984, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000469192_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.273, 0.477, 0.984, 0.758]\nGiven the above layout, shift the truck upwards by 0.195."
      },
      {
        "from": "gpt",
        "value": "truck: [0.273, 0.281, 0.984, 0.562]"
      }
    ]
  },
  {
    "id": "coco_000000471756",
    "conversations": [
      {
        "from": "human",
        "value": "A person is lying prone on a surfboard in the water."
      },
      {
        "from": "gpt",
        "value": "person: [0.430, 0.375, 0.984, 0.656]\nsurfboard: [0.406, 0.609, 0.836, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000471756_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is lying prone on a surfboard in the water.\nObjects: [person, surfboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.430, 0.375, 0.984, 0.656]\nsurfboard: [0.406, 0.609, 0.836, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000471756_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young surfer is lying prone on a red surfboard in the water."
      },
      {
        "from": "gpt",
        "value": "young surfer: [0.430, 0.375, 0.984, 0.656]\nred surfboard: [0.406, 0.609, 0.836, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000471756_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young surfer is lying prone on a red surfboard in the water.\nObjects: [young surfer, red surfboard]"
      },
      {
        "from": "gpt",
        "value": "young surfer: [0.430, 0.375, 0.984, 0.656]\nred surfboard: [0.406, 0.609, 0.836, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000471756_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.430, 0.375, 0.984, 0.656]\nsurfboard: [0.406, 0.609, 0.836, 0.672]\nGiven the above layout, shift the surfboard to the left by 0.391."
      },
      {
        "from": "gpt",
        "value": "person: [0.430, 0.375, 0.984, 0.656]\nsurfboard: [0.016, 0.609, 0.445, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000473869",
    "conversations": [
      {
        "from": "human",
        "value": "A person is pouring from a bottle into a wine glass on the left, with a spoon laying on the table in front of them."
      },
      {
        "from": "gpt",
        "value": "person: [0.078, 0.188, 0.508, 0.789]\nwine glass: [0.008, 0.648, 0.688, 0.828]\nbottle: [0.773, 0.383, 0.852, 0.609]\nspoon: [0.453, 0.523, 0.547, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000473869_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is pouring from a bottle into a wine glass on the left, with a spoon laying on the table in front of them.\nObjects: [person, wine glass, bottle, spoon]"
      },
      {
        "from": "gpt",
        "value": "person: [0.078, 0.188, 0.508, 0.789]\nwine glass: [0.008, 0.648, 0.688, 0.828]\nbottle: [0.773, 0.383, 0.852, 0.609]\nspoon: [0.453, 0.523, 0.547, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000473869_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in a red blouse is pouring from a vintage pinot noir bottle into a tall crystal wine glass on the left, with a shiny metal spoon laying on the table in front of them."
      },
      {
        "from": "gpt",
        "value": "woman in a red blouse: [0.078, 0.188, 0.508, 0.789]\ntall crystal wine glass: [0.008, 0.648, 0.688, 0.828]\nvintage pinot noir bottle: [0.773, 0.383, 0.852, 0.609]\nshiny metal spoon: [0.453, 0.523, 0.547, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000473869_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in a red blouse is pouring from a vintage pinot noir bottle into a tall crystal wine glass on the left, with a shiny metal spoon laying on the table in front of them.\nObjects: [woman in a red blouse, tall crystal wine glass, vintage pinot noir bottle, shiny metal spoon]"
      },
      {
        "from": "gpt",
        "value": "woman in a red blouse: [0.078, 0.188, 0.508, 0.789]\ntall crystal wine glass: [0.008, 0.648, 0.688, 0.828]\nvintage pinot noir bottle: [0.773, 0.383, 0.852, 0.609]\nshiny metal spoon: [0.453, 0.523, 0.547, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000473869_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.078, 0.188, 0.508, 0.789]\nwine glass: [0.008, 0.648, 0.688, 0.828]\nbottle: [0.773, 0.383, 0.852, 0.609]\nspoon: [0.453, 0.523, 0.547, 0.680]\nGiven the above layout, shift the person upwards by 0.094."
      },
      {
        "from": "gpt",
        "value": "person: [0.078, 0.094, 0.508, 0.695]\nwine glass: [0.008, 0.648, 0.688, 0.828]\nbottle: [0.773, 0.383, 0.852, 0.609]\nspoon: [0.453, 0.523, 0.547, 0.680]"
      }
    ]
  },
  {
    "id": "coco_000000475387",
    "conversations": [
      {
        "from": "human",
        "value": "The train is at the center of the image, positioned horizontally on the train tracks."
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.375, 0.859, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000475387_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is at the center of the image, positioned horizontally on the train tracks.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.375, 0.859, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000475387_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red locomotive is at the center of the image, positioned horizontally on the red locomotive tracks."
      },
      {
        "from": "gpt",
        "value": "red locomotive: [0.008, 0.375, 0.859, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000475387_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red locomotive is at the center of the image, positioned horizontally on the red locomotive tracks.\nObjects: [red locomotive]"
      },
      {
        "from": "gpt",
        "value": "red locomotive: [0.008, 0.375, 0.859, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000475387_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.008, 0.375, 0.859, 0.727]\nGiven the above layout, shift the train upwards by 0.133."
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.242, 0.859, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000482477",
    "conversations": [
      {
        "from": "human",
        "value": "The bird is perched atop a vertical branch in the center of the image."
      },
      {
        "from": "gpt",
        "value": "bird: [0.344, 0.133, 0.781, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000482477_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bird is perched atop a vertical branch in the center of the image.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.344, 0.133, 0.781, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000482477_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the small parakeet is perched atop a vertical branch in the center of the image."
      },
      {
        "from": "gpt",
        "value": "small parakeet: [0.344, 0.133, 0.781, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000482477_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the small parakeet is perched atop a vertical branch in the center of the image.\nObjects: [small parakeet]"
      },
      {
        "from": "gpt",
        "value": "small parakeet: [0.344, 0.133, 0.781, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000482477_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.344, 0.133, 0.781, 0.758]\nGiven the above layout, shift the bird to the left by 0.305."
      },
      {
        "from": "gpt",
        "value": "bird: [0.039, 0.133, 0.477, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000538458",
    "conversations": [
      {
        "from": "human",
        "value": "One person is skateboarding in the air towards the left, another person is crouching on the right holding a camera."
      },
      {
        "from": "gpt",
        "value": "person: [0.758, 0.328, 0.992, 0.648]\nperson: [0.461, 0.219, 0.617, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000538458_key",
    "conversations": [
      {
        "from": "human",
        "value": "One person is skateboarding in the air towards the left, another person is crouching on the right holding a camera.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.758, 0.328, 0.992, 0.648]\nperson: [0.461, 0.219, 0.617, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000015746",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is in the center of the image with grass surrounding it."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.273, 0.305, 0.711, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000015746_key",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is in the center of the image with grass surrounding it.\nObjects: [fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.273, 0.305, 0.711, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000015746_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red fire hydrant is in the center of the image with grass surrounding it."
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.273, 0.305, 0.711, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000015746_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red fire hydrant is in the center of the image with grass surrounding it.\nObjects: [red fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.273, 0.305, 0.711, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000015746_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: fire hydrant: [0.273, 0.305, 0.711, 0.891]\nGiven the above layout, shift the fire hydrant upwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.273, 0.234, 0.711, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000031620",
    "conversations": [
      {
        "from": "human",
        "value": "There is a person sitting on a chair in the foreground on the right, and another person standing in the background at the center."
      },
      {
        "from": "gpt",
        "value": "person: [0.414, 0.367, 0.711, 0.672]\nchair: [0.750, 0.680, 0.859, 0.992]\nperson: [0.172, 0.391, 0.258, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000031620_key",
    "conversations": [
      {
        "from": "human",
        "value": "There is a person sitting on a chair in the foreground on the right, and another person standing in the background at the center.\nObjects: [person, chair, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.414, 0.367, 0.711, 0.672]\nchair: [0.750, 0.680, 0.859, 0.992]\nperson: [0.172, 0.391, 0.258, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000037988",
    "conversations": [
      {
        "from": "human",
        "value": "One person is playing tennis in the foreground, and another person is standing in the background to the left, near the net."
      },
      {
        "from": "gpt",
        "value": "person: [0.477, 0.344, 0.633, 0.828]\nperson: [0.227, 0.125, 0.367, 0.305]"
      }
    ]
  },
  {
    "id": "coco_000000037988_key",
    "conversations": [
      {
        "from": "human",
        "value": "One person is playing tennis in the foreground, and another person is standing in the background to the left, near the net.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.477, 0.344, 0.633, 0.828]\nperson: [0.227, 0.125, 0.367, 0.305]"
      }
    ]
  },
  {
    "id": "coco_000000053624",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant is standing at the center facing forward, with water and rocks in the foreground."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.383, 0.336, 0.633, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000053624_key",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant is standing at the center facing forward, with water and rocks in the foreground.\nObjects: [elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.383, 0.336, 0.633, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000053624_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an towering giant giraffe is standing at the center facing forward, with water and rocks in the foreground."
      },
      {
        "from": "gpt",
        "value": "towering giant giraffe: [0.383, 0.336, 0.633, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000053624_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an towering giant giraffe is standing at the center facing forward, with water and rocks in the foreground.\nObjects: [towering giant giraffe]"
      },
      {
        "from": "gpt",
        "value": "towering giant giraffe: [0.383, 0.336, 0.633, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000053624_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: elephant: [0.383, 0.336, 0.633, 0.758]\nGiven the above layout, shift the elephant to the left by 0.133."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.250, 0.336, 0.500, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000066523",
    "conversations": [
      {
        "from": "human",
        "value": "A bed is positioned in the center, with white bedding and pillows."
      },
      {
        "from": "gpt",
        "value": "bed: [0.125, 0.461, 0.797, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000066523_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bed is positioned in the center, with white bedding and pillows.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.125, 0.461, 0.797, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000066523_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a fluffy queen-sized bed is positioned in the center, with white fluffy queen-sized bedding and pillows."
      },
      {
        "from": "gpt",
        "value": "fluffy queen-sized bed: [0.125, 0.461, 0.797, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000066523_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a fluffy queen-sized bed is positioned in the center, with white fluffy queen-sized bedding and pillows.\nObjects: [fluffy queen-sized bed]"
      },
      {
        "from": "gpt",
        "value": "fluffy queen-sized bed: [0.125, 0.461, 0.797, 0.969]"
      }
    ]
  },
  {
    "id": "coco_000000066523_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.125, 0.461, 0.797, 0.969]\nGiven the above layout, shift the bed upwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "bed: [0.125, 0.422, 0.797, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000068286",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is in the center of the image with pillows on top."
      },
      {
        "from": "gpt",
        "value": "bed: [0.039, 0.281, 0.852, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000068286_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is in the center of the image with pillows on top.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.039, 0.281, 0.852, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000068286_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the king-sized bed is in the center of the image with pillows on top."
      },
      {
        "from": "gpt",
        "value": "king-sized bed: [0.039, 0.281, 0.852, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000068286_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the king-sized bed is in the center of the image with pillows on top.\nObjects: [king-sized bed]"
      },
      {
        "from": "gpt",
        "value": "king-sized bed: [0.039, 0.281, 0.852, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000068286_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.039, 0.281, 0.852, 0.781]\nGiven the above layout, shift the bed upwards by 0.078."
      },
      {
        "from": "gpt",
        "value": "bed: [0.039, 0.203, 0.852, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000072281",
    "conversations": [
      {
        "from": "human",
        "value": "A person is on top of a skateboard in mid-air."
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.023, 0.711, 0.781]\nskateboard: [0.312, 0.680, 0.727, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000072281_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is on top of a skateboard in mid-air.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.023, 0.711, 0.781]\nskateboard: [0.312, 0.680, 0.727, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000072281_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young teenager is on top of a red skateboard in mid-air."
      },
      {
        "from": "gpt",
        "value": "young teenager: [0.312, 0.023, 0.711, 0.781]\nred skateboard: [0.312, 0.680, 0.727, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000072281_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young teenager is on top of a red skateboard in mid-air.\nObjects: [young teenager, red skateboard]"
      },
      {
        "from": "gpt",
        "value": "young teenager: [0.312, 0.023, 0.711, 0.781]\nred skateboard: [0.312, 0.680, 0.727, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000072281_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.312, 0.023, 0.711, 0.781]\nskateboard: [0.312, 0.680, 0.727, 0.836]\nGiven the above layout, shift the person to the left by 0.148."
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.023, 0.562, 0.781]\nskateboard: [0.312, 0.680, 0.727, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000079034",
    "conversations": [
      {
        "from": "human",
        "value": "A blue fire hydrant stands in the center of the image, with trees and grass in the background."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.328, 0.281, 0.508, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000079034_key",
    "conversations": [
      {
        "from": "human",
        "value": "A blue fire hydrant stands in the center of the image, with trees and grass in the background.\nObjects: [fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.328, 0.281, 0.508, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000079034_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a blue red fire hydrant stands in the center of the image, with trees and grass in the background."
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.328, 0.281, 0.508, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000079034_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a blue red fire hydrant stands in the center of the image, with trees and grass in the background.\nObjects: [red fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.328, 0.281, 0.508, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000079034_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: fire hydrant: [0.328, 0.281, 0.508, 0.758]\nGiven the above layout, shift the fire hydrant to the right by 0.188."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.516, 0.281, 0.695, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000098261",
    "conversations": [
      {
        "from": "human",
        "value": "One bird is perched on a branch facing left, and another bird is directly behind it, partially obscured, facing right."
      },
      {
        "from": "gpt",
        "value": "bird: [0.062, 0.250, 0.672, 0.609]\nbird: [0.602, 0.359, 0.992, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000098261_key",
    "conversations": [
      {
        "from": "human",
        "value": "One bird is perched on a branch facing left, and another bird is directly behind it, partially obscured, facing right.\nObjects: [bird, bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.062, 0.250, 0.672, 0.609]\nbird: [0.602, 0.359, 0.992, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000098520",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is in the center of the image, on the ground."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.133, 0.328, 0.953, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000098520_key",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is in the center of the image, on the ground.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.133, 0.328, 0.953, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000098520_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the commercial jetliner is in the center of the image, on the ground."
      },
      {
        "from": "gpt",
        "value": "commercial jetliner: [0.133, 0.328, 0.953, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000098520_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the commercial jetliner is in the center of the image, on the ground.\nObjects: [commercial jetliner]"
      },
      {
        "from": "gpt",
        "value": "commercial jetliner: [0.133, 0.328, 0.953, 0.570]"
      }
    ]
  },
  {
    "id": "coco_000000098520_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.133, 0.328, 0.953, 0.570]\nGiven the above layout, shift the airplane downwards by 0.250."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.133, 0.578, 0.953, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000106048",
    "conversations": [
      {
        "from": "human",
        "value": "A white bus is parked to the right side of the image facing left."
      },
      {
        "from": "gpt",
        "value": "bus: [0.227, 0.266, 0.812, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000106048_key",
    "conversations": [
      {
        "from": "human",
        "value": "A white bus is parked to the right side of the image facing left.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.227, 0.266, 0.812, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000106048_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a white red double-decker bus is parked to the right side of the image facing left."
      },
      {
        "from": "gpt",
        "value": "red double-decker bus: [0.227, 0.266, 0.812, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000106048_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a white red double-decker bus is parked to the right side of the image facing left.\nObjects: [red double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "red double-decker bus: [0.227, 0.266, 0.812, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000106048_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.227, 0.266, 0.812, 0.656]\nGiven the above layout, shift the bus downwards by 0.117."
      },
      {
        "from": "gpt",
        "value": "bus: [0.227, 0.383, 0.812, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000138856",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is in the center of the image with its door open."
      },
      {
        "from": "gpt",
        "value": "oven: [0.000, 0.125, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000138856_key",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is in the center of the image with its door open.\nObjects: [oven]"
      },
      {
        "from": "gpt",
        "value": "oven: [0.000, 0.125, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000138856_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the retro styled electric oven is in the center of the image with its door open."
      },
      {
        "from": "gpt",
        "value": "retro styled electric oven: [0.000, 0.125, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000138856_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the retro styled electric oven is in the center of the image with its door open.\nObjects: [retro styled electric oven]"
      },
      {
        "from": "gpt",
        "value": "retro styled electric oven: [0.000, 0.125, 0.992, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000138856_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: oven: [0.000, 0.125, 0.992, 0.859]\nGiven the above layout, shift the oven downwards by 0.102."
      },
      {
        "from": "gpt",
        "value": "oven: [0.000, 0.227, 0.992, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000184400",
    "conversations": [
      {
        "from": "human",
        "value": "A train is passing over a bridge at the center of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.445, 0.703, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000184400_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is passing over a bridge at the center of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.445, 0.703, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000184400_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a dark green steam engine is passing over a bridge at the center of the image."
      },
      {
        "from": "gpt",
        "value": "dark green steam engine: [0.008, 0.445, 0.703, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000184400_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a dark green steam engine is passing over a bridge at the center of the image.\nObjects: [dark green steam engine]"
      },
      {
        "from": "gpt",
        "value": "dark green steam engine: [0.008, 0.445, 0.703, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000184400_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.008, 0.445, 0.703, 0.617]\nGiven the above layout, shift the train upwards by 0.352."
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.094, 0.703, 0.266]"
      }
    ]
  },
  {
    "id": "coco_000000230450",
    "conversations": [
      {
        "from": "human",
        "value": "Two parking meters are positioned on the sidewalk, with one in the foreground on the right and another slightly behind it to the left."
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.648, 0.438, 0.992, 0.852]\nparking meter: [0.281, 0.477, 0.406, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000230450_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two parking meters are positioned on the sidewalk, with one in the foreground on the right and another slightly behind it to the left.\nObjects: [parking meter, parking meter]"
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.648, 0.438, 0.992, 0.852]\nparking meter: [0.281, 0.477, 0.406, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000231169",
    "conversations": [
      {
        "from": "human",
        "value": "A train on railway tracks, oriented horizontally across the image from the left to the right side."
      },
      {
        "from": "gpt",
        "value": "train: [0.227, 0.312, 0.664, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000231169_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train on railway tracks, oriented horizontally across the image from the left to the right side.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.227, 0.312, 0.664, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000231169_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a speeding bullet train on railway tracks, oriented horizontally across the image from the left to the right side."
      },
      {
        "from": "gpt",
        "value": "speeding bullet train: [0.227, 0.312, 0.664, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000231169_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a speeding bullet train on railway tracks, oriented horizontally across the image from the left to the right side.\nObjects: [speeding bullet train]"
      },
      {
        "from": "gpt",
        "value": "speeding bullet train: [0.227, 0.312, 0.664, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000231169_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.227, 0.312, 0.664, 0.828]\nGiven the above layout, shift the train to the right by 0.016."
      },
      {
        "from": "gpt",
        "value": "train: [0.242, 0.312, 0.680, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000233727",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is centered in the image, facing towards the right."
      },
      {
        "from": "gpt",
        "value": "bus: [0.125, 0.297, 0.711, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000233727_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is centered in the image, facing towards the right.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.125, 0.297, 0.711, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000233727_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a double-decker bus is centered in the image, facing towards the right."
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.125, 0.297, 0.711, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000233727_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a double-decker bus is centered in the image, facing towards the right.\nObjects: [double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.125, 0.297, 0.711, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000233727_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.125, 0.297, 0.711, 0.672]\nGiven the above layout, shift the bus downwards by 0.188."
      },
      {
        "from": "gpt",
        "value": "bus: [0.125, 0.484, 0.711, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000234526",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the left is feeding a giraffe, and another person is watching from the right side."
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.484, 0.852, 0.984]\ngiraffe: [0.000, 0.180, 0.414, 0.570]\nperson: [0.836, 0.430, 0.992, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000234526_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the left is feeding a giraffe, and another person is watching from the right side.\nObjects: [person, giraffe, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.406, 0.484, 0.852, 0.984]\ngiraffe: [0.000, 0.180, 0.414, 0.570]\nperson: [0.836, 0.430, 0.992, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000236412",
    "conversations": [
      {
        "from": "human",
        "value": "The pizza is at the center of the image on a white plate."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.148, 0.211, 0.898, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000236412_key",
    "conversations": [
      {
        "from": "human",
        "value": "The pizza is at the center of the image on a white plate.\nObjects: [pizza]"
      },
      {
        "from": "gpt",
        "value": "pizza: [0.148, 0.211, 0.898, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000236412_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the Hawaiian pizza is at the center of the image on a white plate."
      },
      {
        "from": "gpt",
        "value": "Hawaiian pizza: [0.148, 0.211, 0.898, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000236412_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the Hawaiian pizza is at the center of the image on a white plate.\nObjects: [Hawaiian pizza]"
      },
      {
        "from": "gpt",
        "value": "Hawaiian pizza: [0.148, 0.211, 0.898, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000236412_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: pizza: [0.148, 0.211, 0.898, 0.789]\nGiven the above layout, shift the pizza upwards by 0.211."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.148, 0.000, 0.898, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000265518",
    "conversations": [
      {
        "from": "human",
        "value": "A cup is to the top left of a sandwich in the center, with a fork to the bottom left of the sandwich."
      },
      {
        "from": "gpt",
        "value": "fork: [0.164, 0.656, 0.633, 0.906]\nsandwich: [0.406, 0.305, 0.750, 0.609]\ncup: [0.094, 0.070, 0.359, 0.320]"
      }
    ]
  },
  {
    "id": "coco_000000265518_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cup is to the top left of a sandwich in the center, with a fork to the bottom left of the sandwich.\nObjects: [fork, sandwich, cup]"
      },
      {
        "from": "gpt",
        "value": "fork: [0.164, 0.656, 0.633, 0.906]\nsandwich: [0.406, 0.305, 0.750, 0.609]\ncup: [0.094, 0.070, 0.359, 0.320]"
      }
    ]
  },
  {
    "id": "coco_000000273760",
    "conversations": [
      {
        "from": "human",
        "value": "The person is standing on a tennis court, dressed in a blue shirt and white shorts, holding a tennis racket in the left hand and a tennis ball in the right hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.055, 0.602, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000273760_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is standing on a tennis court, dressed in a blue shirt and white shorts, holding a tennis racket in the left hand and a tennis ball in the right hand.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.055, 0.602, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000273760_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the tennis player in a blue outfit is standing on a tennis court, dressed in a blue shirt and white shorts, holding a tennis racket in the left hand and a tennis ball in the right hand."
      },
      {
        "from": "gpt",
        "value": "tennis player in a blue outfit: [0.328, 0.055, 0.602, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000273760_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the tennis player in a blue outfit is standing on a tennis court, dressed in a blue shirt and white shorts, holding a tennis racket in the left hand and a tennis ball in the right hand.\nObjects: [tennis player in a blue outfit]"
      },
      {
        "from": "gpt",
        "value": "tennis player in a blue outfit: [0.328, 0.055, 0.602, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000273760_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.328, 0.055, 0.602, 0.844]\nGiven the above layout, shift the person to the right by 0.281."
      },
      {
        "from": "gpt",
        "value": "person: [0.609, 0.055, 0.883, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000279769",
    "conversations": [
      {
        "from": "human",
        "value": "A banana is placed on top of a dining table."
      },
      {
        "from": "gpt",
        "value": "dining table: [0.695, 0.266, 0.992, 0.758]\nbanana: [0.195, 0.242, 0.680, 0.383]"
      }
    ]
  },
  {
    "id": "coco_000000279769_key",
    "conversations": [
      {
        "from": "human",
        "value": "A banana is placed on top of a dining table.\nObjects: [dining table, banana]"
      },
      {
        "from": "gpt",
        "value": "dining table: [0.695, 0.266, 0.992, 0.758]\nbanana: [0.195, 0.242, 0.680, 0.383]"
      }
    ]
  },
  {
    "id": "coco_000000279769_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a ripe banana is placed on top of a mahogany dining table."
      },
      {
        "from": "gpt",
        "value": "mahogany dining table: [0.695, 0.266, 0.992, 0.758]\nripe banana: [0.195, 0.242, 0.680, 0.383]"
      }
    ]
  },
  {
    "id": "coco_000000279769_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a ripe banana is placed on top of a mahogany dining table.\nObjects: [mahogany dining table, ripe banana]"
      },
      {
        "from": "gpt",
        "value": "mahogany dining table: [0.695, 0.266, 0.992, 0.758]\nripe banana: [0.195, 0.242, 0.680, 0.383]"
      }
    ]
  },
  {
    "id": "coco_000000279769_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dining table: [0.695, 0.266, 0.992, 0.758]\nbanana: [0.195, 0.242, 0.680, 0.383]\nGiven the above layout, shift the banana upwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "dining table: [0.695, 0.266, 0.992, 0.758]\nbanana: [0.195, 0.203, 0.680, 0.344]"
      }
    ]
  },
  {
    "id": "coco_000000306136",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is on the right side of the image, with its front facing to the left."
      },
      {
        "from": "gpt",
        "value": "bus: [0.320, 0.500, 0.828, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000306136_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is on the right side of the image, with its front facing to the left.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.320, 0.500, 0.828, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000306136_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a green double-decker bus is on the right side of the image, with its front facing to the left."
      },
      {
        "from": "gpt",
        "value": "green double-decker bus: [0.320, 0.500, 0.828, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000306136_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a green double-decker bus is on the right side of the image, with its front facing to the left.\nObjects: [green double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "green double-decker bus: [0.320, 0.500, 0.828, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000306136_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.320, 0.500, 0.828, 0.953]\nGiven the above layout, shift the bus upwards by 0.453."
      },
      {
        "from": "gpt",
        "value": "bus: [0.320, 0.047, 0.828, 0.500]"
      }
    ]
  },
  {
    "id": "coco_000000314541",
    "conversations": [
      {
        "from": "human",
        "value": "The bench is at the bottom center of the image, facing slightly to the left."
      },
      {
        "from": "gpt",
        "value": "bench: [0.336, 0.578, 0.734, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000314541_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bench is at the bottom center of the image, facing slightly to the left.\nObjects: [bench]"
      },
      {
        "from": "gpt",
        "value": "bench: [0.336, 0.578, 0.734, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000314541_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the weathered park bench is at the bottom center of the image, facing slightly to the left."
      },
      {
        "from": "gpt",
        "value": "weathered park bench: [0.336, 0.578, 0.734, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000314541_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the weathered park bench is at the bottom center of the image, facing slightly to the left.\nObjects: [weathered park bench]"
      },
      {
        "from": "gpt",
        "value": "weathered park bench: [0.336, 0.578, 0.734, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000314541_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bench: [0.336, 0.578, 0.734, 0.820]\nGiven the above layout, shift the bench upwards by 0.430."
      },
      {
        "from": "gpt",
        "value": "bench: [0.336, 0.148, 0.734, 0.391]"
      }
    ]
  },
  {
    "id": "coco_000000321214",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on a chair at the center with a cake to their right side."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.133, 0.938, 0.844]\ncake: [0.430, 0.617, 0.836, 0.859]\nchair: [0.758, 0.156, 0.992, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000321214_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on a chair at the center with a cake to their right side.\nObjects: [person, cake, chair]"
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.133, 0.938, 0.844]\ncake: [0.430, 0.617, 0.836, 0.859]\nchair: [0.758, 0.156, 0.992, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000321214_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a elegantly dressed woman is sitting on a vintage wooden chair at the center with a strawberry cream cake to their right side."
      },
      {
        "from": "gpt",
        "value": "elegantly dressed woman: [0.000, 0.133, 0.938, 0.844]\nstrawberry cream cake: [0.430, 0.617, 0.836, 0.859]\nvintage wooden chair: [0.758, 0.156, 0.992, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000321214_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a elegantly dressed woman is sitting on a vintage wooden chair at the center with a strawberry cream cake to their right side.\nObjects: [elegantly dressed woman, strawberry cream cake, vintage wooden chair]"
      },
      {
        "from": "gpt",
        "value": "elegantly dressed woman: [0.000, 0.133, 0.938, 0.844]\nstrawberry cream cake: [0.430, 0.617, 0.836, 0.859]\nvintage wooden chair: [0.758, 0.156, 0.992, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000321214_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.000, 0.133, 0.938, 0.844]\ncake: [0.430, 0.617, 0.836, 0.859]\nchair: [0.758, 0.156, 0.992, 0.453]\nGiven the above layout, shift the person upwards by 0.055."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.078, 0.938, 0.789]\ncake: [0.430, 0.617, 0.836, 0.859]\nchair: [0.758, 0.156, 0.992, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000338325",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is in the center of the image, flying towards the right."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.180, 0.383, 0.703, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000338325_key",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is in the center of the image, flying towards the right.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.180, 0.383, 0.703, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000338325_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the large passenger jet is in the center of the image, flying towards the right."
      },
      {
        "from": "gpt",
        "value": "large passenger jet: [0.180, 0.383, 0.703, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000338325_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the large passenger jet is in the center of the image, flying towards the right.\nObjects: [large passenger jet]"
      },
      {
        "from": "gpt",
        "value": "large passenger jet: [0.180, 0.383, 0.703, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000338325_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.180, 0.383, 0.703, 0.633]\nGiven the above layout, shift the airplane upwards by 0.375."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.180, 0.008, 0.703, 0.258]"
      }
    ]
  },
  {
    "id": "coco_000000451084",
    "conversations": [
      {
        "from": "human",
        "value": "A person in mid-air above a skateboard, performing a trick at a skatepark."
      },
      {
        "from": "gpt",
        "value": "person: [0.422, 0.188, 0.656, 0.586]\nskateboard: [0.453, 0.469, 0.609, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000451084_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in mid-air above a skateboard, performing a trick at a skatepark.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.422, 0.188, 0.656, 0.586]\nskateboard: [0.453, 0.469, 0.609, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000451084_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young colorful colorful skateboarder in mid-air above a colorful skateboard, performing a trick at a skatepark."
      },
      {
        "from": "gpt",
        "value": "young colorful skateboarder: [0.422, 0.188, 0.656, 0.586]\ncolorful skateboard: [0.453, 0.469, 0.609, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000451084_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young colorful colorful skateboarder in mid-air above a colorful skateboard, performing a trick at a skatepark.\nObjects: [young colorful skateboarder, colorful skateboard]"
      },
      {
        "from": "gpt",
        "value": "young colorful skateboarder: [0.422, 0.188, 0.656, 0.586]\ncolorful skateboard: [0.453, 0.469, 0.609, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000451084_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.422, 0.188, 0.656, 0.586]\nskateboard: [0.453, 0.469, 0.609, 0.656]\nGiven the above layout, shift the person to the left by 0.195."
      },
      {
        "from": "gpt",
        "value": "person: [0.227, 0.188, 0.461, 0.586]\nskateboard: [0.453, 0.469, 0.609, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000452793",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is on the right side of the image."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.578, 0.242, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000452793_key",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is on the right side of the image.\nObjects: [refrigerator]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.578, 0.242, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000452793_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel refrigerator is on the right side of the image."
      },
      {
        "from": "gpt",
        "value": "stainless steel refrigerator: [0.578, 0.242, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000452793_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel refrigerator is on the right side of the image.\nObjects: [stainless steel refrigerator]"
      },
      {
        "from": "gpt",
        "value": "stainless steel refrigerator: [0.578, 0.242, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000452793_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: refrigerator: [0.578, 0.242, 0.992, 0.820]\nGiven the above layout, shift the refrigerator to the left by 0.516."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.062, 0.242, 0.477, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000475365",
    "conversations": [
      {
        "from": "human",
        "value": "The front part of the train is at the center, with the train facing towards the right of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.164, 0.703, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000475365_key",
    "conversations": [
      {
        "from": "human",
        "value": "The front part of the train is at the center, with the train facing towards the right of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.164, 0.703, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000475365_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the front part of the speeding locomotive is at the center, with the speeding locomotive facing towards the right of the image."
      },
      {
        "from": "gpt",
        "value": "speeding locomotive: [0.008, 0.164, 0.703, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000475365_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the front part of the speeding locomotive is at the center, with the speeding locomotive facing towards the right of the image.\nObjects: [speeding locomotive]"
      },
      {
        "from": "gpt",
        "value": "speeding locomotive: [0.008, 0.164, 0.703, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000475365_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.008, 0.164, 0.703, 0.828]\nGiven the above layout, shift the train to the right by 0.281."
      },
      {
        "from": "gpt",
        "value": "train: [0.289, 0.164, 0.984, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000475732",
    "conversations": [
      {
        "from": "human",
        "value": "A cat with a blue hat on its head near the center of the image."
      },
      {
        "from": "gpt",
        "value": "cat: [0.000, 0.312, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000475732_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat with a blue hat on its head near the center of the image.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.000, 0.312, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000475732_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a long-haired Persian cat with a blue hat on its head near the center of the image."
      },
      {
        "from": "gpt",
        "value": "long-haired Persian cat: [0.000, 0.312, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000475732_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a long-haired Persian cat with a blue hat on its head near the center of the image.\nObjects: [long-haired Persian cat]"
      },
      {
        "from": "gpt",
        "value": "long-haired Persian cat: [0.000, 0.312, 0.992, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000475732_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.000, 0.312, 0.992, 0.867]\nGiven the above layout, shift the cat upwards by 0.086."
      },
      {
        "from": "gpt",
        "value": "cat: [0.000, 0.227, 0.992, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000476258",
    "conversations": [
      {
        "from": "human",
        "value": "A person is riding a skateboard, crouched low and centered in the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.398, 0.266, 0.797, 0.688]\nskateboard: [0.422, 0.602, 0.789, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000476258_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is riding a skateboard, crouched low and centered in the image.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.398, 0.266, 0.797, 0.688]\nskateboard: [0.422, 0.602, 0.789, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000476258_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a athletic teenager is riding a lime-green skateboard, crouched low and centered in the image."
      },
      {
        "from": "gpt",
        "value": "athletic teenager: [0.398, 0.266, 0.797, 0.688]\nlime-green skateboard: [0.422, 0.602, 0.789, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000476258_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a athletic teenager is riding a lime-green skateboard, crouched low and centered in the image.\nObjects: [athletic teenager, lime-green skateboard]"
      },
      {
        "from": "gpt",
        "value": "athletic teenager: [0.398, 0.266, 0.797, 0.688]\nlime-green skateboard: [0.422, 0.602, 0.789, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000476258_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.398, 0.266, 0.797, 0.688]\nskateboard: [0.422, 0.602, 0.789, 0.750]\nGiven the above layout, shift the person to the left by 0.234."
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.266, 0.562, 0.688]\nskateboard: [0.422, 0.602, 0.789, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000482585",
    "conversations": [
      {
        "from": "human",
        "value": "Two trains are facing each other on adjacent tracks; the train on the left is closer to the foreground, and the train on the right is slightly further away in the background."
      },
      {
        "from": "gpt",
        "value": "train: [0.031, 0.242, 0.688, 0.727]\ntrain: [0.688, 0.367, 0.875, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000482585_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two trains are facing each other on adjacent tracks; the train on the left is closer to the foreground, and the train on the right is slightly further away in the background.\nObjects: [train, train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.031, 0.242, 0.688, 0.727]\ntrain: [0.688, 0.367, 0.875, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000494863",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks located to the right of the image, parallel to a road in the foreground."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.320, 0.992, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000494863_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks located to the right of the image, parallel to a road in the foreground.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.320, 0.992, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000494863_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the vintage steam locomotive is on the tracks located to the right of the image, parallel to a road in the foreground."
      },
      {
        "from": "gpt",
        "value": "vintage steam locomotive: [0.000, 0.320, 0.992, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000494863_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the vintage steam locomotive is on the tracks located to the right of the image, parallel to a road in the foreground.\nObjects: [vintage steam locomotive]"
      },
      {
        "from": "gpt",
        "value": "vintage steam locomotive: [0.000, 0.320, 0.992, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000494863_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.320, 0.992, 0.695]\nGiven the above layout, shift the train upwards by 0.250."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.070, 0.992, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000507473",
    "conversations": [
      {
        "from": "human",
        "value": "The person is in the center of the image taking a photo with a camera covering where the face would be."
      },
      {
        "from": "gpt",
        "value": "person: [0.047, 0.141, 0.664, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000507473_key",
    "conversations": [
      {
        "from": "human",
        "value": "The person is in the center of the image taking a photo with a camera covering where the face would be.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.047, 0.141, 0.664, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000507473_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the young woman with a camera is in the center of the image taking a photo with a camera covering where the face would be."
      },
      {
        "from": "gpt",
        "value": "young woman with a camera: [0.047, 0.141, 0.664, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000507473_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the young woman with a camera is in the center of the image taking a photo with a camera covering where the face would be.\nObjects: [young woman with a camera]"
      },
      {
        "from": "gpt",
        "value": "young woman with a camera: [0.047, 0.141, 0.664, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000507473_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.047, 0.141, 0.664, 0.859]\nGiven the above layout, shift the person to the right by 0.047."
      },
      {
        "from": "gpt",
        "value": "person: [0.094, 0.141, 0.711, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000522007",
    "conversations": [
      {
        "from": "human",
        "value": "A potted plant is on the left, an oven is at the center, and a microwave is to the right of the oven."
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.062, 0.125, 0.320, 0.641]\noven: [0.617, 0.641, 0.836, 0.859]\nmicrowave: [0.836, 0.586, 0.992, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000522007_key",
    "conversations": [
      {
        "from": "human",
        "value": "A potted plant is on the left, an oven is at the center, and a microwave is to the right of the oven.\nObjects: [potted plant, oven, microwave]"
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.062, 0.125, 0.320, 0.641]\noven: [0.617, 0.641, 0.836, 0.859]\nmicrowave: [0.836, 0.586, 0.992, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000522007_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a leafy green houseplant is on the left, an stainless steel oven is at the center, and a compact countertop microwave is to the right of the stainless steel oven."
      },
      {
        "from": "gpt",
        "value": "leafy green houseplant: [0.062, 0.125, 0.320, 0.641]\nstainless steel oven: [0.617, 0.641, 0.836, 0.859]\ncompact countertop microwave: [0.836, 0.586, 0.992, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000522007_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a leafy green houseplant is on the left, an stainless steel oven is at the center, and a compact countertop microwave is to the right of the stainless steel oven.\nObjects: [leafy green houseplant, stainless steel oven, compact countertop microwave]"
      },
      {
        "from": "gpt",
        "value": "leafy green houseplant: [0.062, 0.125, 0.320, 0.641]\nstainless steel oven: [0.617, 0.641, 0.836, 0.859]\ncompact countertop microwave: [0.836, 0.586, 0.992, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000522007_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: potted plant: [0.062, 0.125, 0.320, 0.641]\noven: [0.617, 0.641, 0.836, 0.859]\nmicrowave: [0.836, 0.586, 0.992, 0.781]\nGiven the above layout, shift the oven downwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "potted plant: [0.062, 0.125, 0.320, 0.641]\noven: [0.617, 0.664, 0.836, 0.883]\nmicrowave: [0.836, 0.586, 0.992, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000528705",
    "conversations": [
      {
        "from": "human",
        "value": "A person is facing away from the viewer with a teddy bear attached to their backpack."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.242, 0.328, 0.609, 0.797]\nperson: [0.648, 0.742, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000528705_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is facing away from the viewer with a teddy bear attached to their backpack.\nObjects: [teddy bear, person]"
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.242, 0.328, 0.609, 0.797]\nperson: [0.648, 0.742, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000528705_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young tourist is facing away from the viewer with a small panda plush attached to their backpack."
      },
      {
        "from": "gpt",
        "value": "small panda plush: [0.242, 0.328, 0.609, 0.797]\nyoung tourist: [0.648, 0.742, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000528705_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young tourist is facing away from the viewer with a small panda plush attached to their backpack.\nObjects: [small panda plush, young tourist]"
      },
      {
        "from": "gpt",
        "value": "small panda plush: [0.242, 0.328, 0.609, 0.797]\nyoung tourist: [0.648, 0.742, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000528705_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: teddy bear: [0.242, 0.328, 0.609, 0.797]\nperson: [0.648, 0.742, 0.828, 0.992]\nGiven the above layout, shift the teddy bear upwards by 0.242."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.242, 0.086, 0.609, 0.555]\nperson: [0.648, 0.742, 0.828, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000534601",
    "conversations": [
      {
        "from": "human",
        "value": "A white teddy bear is at the center of the image, facing forward."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.172, 0.172, 0.766, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000534601_key",
    "conversations": [
      {
        "from": "human",
        "value": "A white teddy bear is at the center of the image, facing forward.\nObjects: [teddy bear]"
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.172, 0.172, 0.766, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000534601_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a white large plush teddy bear is at the center of the image, facing forward."
      },
      {
        "from": "gpt",
        "value": "large plush teddy bear: [0.172, 0.172, 0.766, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000534601_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a white large plush teddy bear is at the center of the image, facing forward.\nObjects: [large plush teddy bear]"
      },
      {
        "from": "gpt",
        "value": "large plush teddy bear: [0.172, 0.172, 0.766, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000534601_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: teddy bear: [0.172, 0.172, 0.766, 0.820]\nGiven the above layout, shift the teddy bear to the right by 0.141."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.312, 0.172, 0.906, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000540962",
    "conversations": [
      {
        "from": "human",
        "value": "There are two couches facing each other; one is in the foreground and the other is in the background of the image."
      },
      {
        "from": "gpt",
        "value": "couch: [0.016, 0.531, 0.578, 0.852]\ncouch: [0.656, 0.547, 0.938, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000540962_key",
    "conversations": [
      {
        "from": "human",
        "value": "There are two couches facing each other; one is in the foreground and the other is in the background of the image.\nObjects: [couch, couch]"
      },
      {
        "from": "gpt",
        "value": "couch: [0.016, 0.531, 0.578, 0.852]\ncouch: [0.656, 0.547, 0.938, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000558073",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is sitting at the center of a bathtub, looking upwards."
      },
      {
        "from": "gpt",
        "value": "cat: [0.242, 0.344, 0.727, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000558073_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat is sitting at the center of a bathtub, looking upwards.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.242, 0.344, 0.727, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000558073_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a white kitten is sitting at the center of a bathtub, looking upwards."
      },
      {
        "from": "gpt",
        "value": "white kitten: [0.242, 0.344, 0.727, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000558073_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a white kitten is sitting at the center of a bathtub, looking upwards.\nObjects: [white kitten]"
      },
      {
        "from": "gpt",
        "value": "white kitten: [0.242, 0.344, 0.727, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000558073_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.242, 0.344, 0.727, 0.734]\nGiven the above layout, shift the cat upwards by 0.227."
      },
      {
        "from": "gpt",
        "value": "cat: [0.242, 0.117, 0.727, 0.508]"
      }
    ]
  },
  {
    "id": "coco_000000018737",
    "conversations": [
      {
        "from": "human",
        "value": "The motorcycle is parked in the center of the image on a paved area with palm trees in the background."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.391, 0.414, 0.914, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000018737_key",
    "conversations": [
      {
        "from": "human",
        "value": "The motorcycle is parked in the center of the image on a paved area with palm trees in the background.\nObjects: [motorcycle]"
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.391, 0.414, 0.914, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000018737_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red sportsbike is parked in the center of the image on a paved area with palm trees in the background."
      },
      {
        "from": "gpt",
        "value": "red sportsbike: [0.391, 0.414, 0.914, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000018737_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red sportsbike is parked in the center of the image on a paved area with palm trees in the background.\nObjects: [red sportsbike]"
      },
      {
        "from": "gpt",
        "value": "red sportsbike: [0.391, 0.414, 0.914, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000018737_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: motorcycle: [0.391, 0.414, 0.914, 0.797]\nGiven the above layout, shift the motorcycle upwards by 0.203."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.391, 0.211, 0.914, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000140439",
    "conversations": [
      {
        "from": "human",
        "value": "A vase with flowers on top of a dining table at the center."
      },
      {
        "from": "gpt",
        "value": "vase: [0.422, 0.492, 0.609, 0.977]\ndining table: [0.211, 0.859, 0.781, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000140439_key",
    "conversations": [
      {
        "from": "human",
        "value": "A vase with flowers on top of a dining table at the center.\nObjects: [vase, dining table]"
      },
      {
        "from": "gpt",
        "value": "vase: [0.422, 0.492, 0.609, 0.977]\ndining table: [0.211, 0.859, 0.781, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000140439_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a crystal vase with colorful tulips with flowers on top of a antique wooden dining table at the center."
      },
      {
        "from": "gpt",
        "value": "crystal vase with colorful tulips: [0.422, 0.492, 0.609, 0.977]\nantique wooden dining table: [0.211, 0.859, 0.781, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000140439_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a crystal vase with colorful tulips with flowers on top of a antique wooden dining table at the center.\nObjects: [crystal vase with colorful tulips, antique wooden dining table]"
      },
      {
        "from": "gpt",
        "value": "crystal vase with colorful tulips: [0.422, 0.492, 0.609, 0.977]\nantique wooden dining table: [0.211, 0.859, 0.781, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000140439_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: vase: [0.422, 0.492, 0.609, 0.977]\ndining table: [0.211, 0.859, 0.781, 0.977]\nGiven the above layout, shift the vase upwards by 0.453."
      },
      {
        "from": "gpt",
        "value": "vase: [0.422, 0.039, 0.609, 0.523]\ndining table: [0.211, 0.859, 0.781, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000148730",
    "conversations": [
      {
        "from": "human",
        "value": "The boat is docked to the right side of the image, parallel to the wooden pier."
      },
      {
        "from": "gpt",
        "value": "boat: [0.336, 0.320, 0.766, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000148730_key",
    "conversations": [
      {
        "from": "human",
        "value": "The boat is docked to the right side of the image, parallel to the wooden pier.\nObjects: [boat]"
      },
      {
        "from": "gpt",
        "value": "boat: [0.336, 0.320, 0.766, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000148730_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the sleek white yacht is docked to the right side of the image, parallel to the wooden pier."
      },
      {
        "from": "gpt",
        "value": "sleek white yacht: [0.336, 0.320, 0.766, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000148730_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the sleek white yacht is docked to the right side of the image, parallel to the wooden pier.\nObjects: [sleek white yacht]"
      },
      {
        "from": "gpt",
        "value": "sleek white yacht: [0.336, 0.320, 0.766, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000148730_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: boat: [0.336, 0.320, 0.766, 0.617]\nGiven the above layout, shift the boat downwards by 0.266."
      },
      {
        "from": "gpt",
        "value": "boat: [0.336, 0.586, 0.766, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000171740",
    "conversations": [
      {
        "from": "human",
        "value": "A couch is positioned in the foreground facing the right side of the image."
      },
      {
        "from": "gpt",
        "value": "couch: [0.000, 0.508, 0.672, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000171740_key",
    "conversations": [
      {
        "from": "human",
        "value": "A couch is positioned in the foreground facing the right side of the image.\nObjects: [couch]"
      },
      {
        "from": "gpt",
        "value": "couch: [0.000, 0.508, 0.672, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000171740_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a plush black leather couch is positioned in the foreground facing the right side of the image."
      },
      {
        "from": "gpt",
        "value": "plush black leather couch: [0.000, 0.508, 0.672, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000171740_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a plush black leather couch is positioned in the foreground facing the right side of the image.\nObjects: [plush black leather couch]"
      },
      {
        "from": "gpt",
        "value": "plush black leather couch: [0.000, 0.508, 0.672, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000171740_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: couch: [0.000, 0.508, 0.672, 0.867]\nGiven the above layout, shift the couch upwards by 0.062."
      },
      {
        "from": "gpt",
        "value": "couch: [0.000, 0.445, 0.672, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000176037",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is on the right side of the image, facing forward on the street."
      },
      {
        "from": "gpt",
        "value": "bus: [0.422, 0.359, 0.836, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000176037_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is on the right side of the image, facing forward on the street.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.422, 0.359, 0.836, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000176037_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker bus is on the right side of the image, facing forward on the street."
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.422, 0.359, 0.836, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000176037_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker bus is on the right side of the image, facing forward on the street.\nObjects: [double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "double-decker bus: [0.422, 0.359, 0.836, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000176037_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.422, 0.359, 0.836, 0.672]\nGiven the above layout, shift the bus to the left by 0.055."
      },
      {
        "from": "gpt",
        "value": "bus: [0.367, 0.359, 0.781, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000185950",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center of the image, skateboarding and performing a trick in the air."
      },
      {
        "from": "gpt",
        "value": "person: [0.297, 0.125, 0.680, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000185950_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the center of the image, skateboarding and performing a trick in the air.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.297, 0.125, 0.680, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000185950_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage skater is in the center of the image, skateboarding and performing a trick in the air."
      },
      {
        "from": "gpt",
        "value": "teenage skater: [0.297, 0.125, 0.680, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000185950_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage skater is in the center of the image, skateboarding and performing a trick in the air.\nObjects: [teenage skater]"
      },
      {
        "from": "gpt",
        "value": "teenage skater: [0.297, 0.125, 0.680, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000185950_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.297, 0.125, 0.680, 0.633]\nGiven the above layout, shift the person downwards by 0.078."
      },
      {
        "from": "gpt",
        "value": "person: [0.297, 0.203, 0.680, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000187990",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding on a ramp to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.227, 0.734, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000187990_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding on a ramp to the right side of the image.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.227, 0.734, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000187990_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage skater is skateboarding on a ramp to the right side of the image."
      },
      {
        "from": "gpt",
        "value": "teenage skater: [0.367, 0.227, 0.734, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000187990_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage skater is skateboarding on a ramp to the right side of the image.\nObjects: [teenage skater]"
      },
      {
        "from": "gpt",
        "value": "teenage skater: [0.367, 0.227, 0.734, 0.531]"
      }
    ]
  },
  {
    "id": "coco_000000187990_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.367, 0.227, 0.734, 0.531]\nGiven the above layout, shift the person downwards by 0.266."
      },
      {
        "from": "gpt",
        "value": "person: [0.367, 0.492, 0.734, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000192964",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding in the air to the left above a bench."
      },
      {
        "from": "gpt",
        "value": "person: [0.305, 0.094, 0.609, 0.547]\nskateboard: [0.289, 0.516, 0.453, 0.602]\nbench: [0.688, 0.781, 0.828, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000192964_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding in the air to the left above a bench.\nObjects: [person, skateboard, bench]"
      },
      {
        "from": "gpt",
        "value": "person: [0.305, 0.094, 0.609, 0.547]\nskateboard: [0.289, 0.516, 0.453, 0.602]\nbench: [0.688, 0.781, 0.828, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000192964_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a athletic skater is graffiti-covered skateboarding in the air to the left above a wooden park bench."
      },
      {
        "from": "gpt",
        "value": "athletic skater: [0.305, 0.094, 0.609, 0.547]\ngraffiti-covered skateboard: [0.289, 0.516, 0.453, 0.602]\nwooden park bench: [0.688, 0.781, 0.828, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000192964_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a athletic skater is graffiti-covered skateboarding in the air to the left above a wooden park bench.\nObjects: [athletic skater, graffiti-covered skateboard, wooden park bench]"
      },
      {
        "from": "gpt",
        "value": "athletic skater: [0.305, 0.094, 0.609, 0.547]\ngraffiti-covered skateboard: [0.289, 0.516, 0.453, 0.602]\nwooden park bench: [0.688, 0.781, 0.828, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000192964_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.305, 0.094, 0.609, 0.547]\nskateboard: [0.289, 0.516, 0.453, 0.602]\nbench: [0.688, 0.781, 0.828, 0.867]\nGiven the above layout, shift the skateboard to the left by 0.070."
      },
      {
        "from": "gpt",
        "value": "person: [0.305, 0.094, 0.609, 0.547]\nskateboard: [0.219, 0.516, 0.383, 0.602]\nbench: [0.688, 0.781, 0.828, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000194506",
    "conversations": [
      {
        "from": "human",
        "value": "Two bears facing each other in water, one slightly to the left of the other."
      },
      {
        "from": "gpt",
        "value": "bear: [0.125, 0.297, 0.469, 0.539]\nbear: [0.438, 0.336, 0.641, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000194506_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two bears facing each other in water, one slightly to the left of the other.\nObjects: [bear, bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.125, 0.297, 0.469, 0.539]\nbear: [0.438, 0.336, 0.641, 0.484]"
      }
    ]
  },
  {
    "id": "coco_000000211674",
    "conversations": [
      {
        "from": "human",
        "value": "A red double-decker bus is centered in the image."
      },
      {
        "from": "gpt",
        "value": "bus: [0.320, 0.242, 0.844, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000211674_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red double-decker bus is centered in the image.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.320, 0.242, 0.844, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000211674_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red double-decker vintage yellow school bus is centered in the image."
      },
      {
        "from": "gpt",
        "value": "vintage yellow school bus: [0.320, 0.242, 0.844, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000211674_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red double-decker vintage yellow school bus is centered in the image.\nObjects: [vintage yellow school bus]"
      },
      {
        "from": "gpt",
        "value": "vintage yellow school bus: [0.320, 0.242, 0.844, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000211674_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.320, 0.242, 0.844, 0.789]\nGiven the above layout, shift the bus to the left by 0.305."
      },
      {
        "from": "gpt",
        "value": "bus: [0.016, 0.242, 0.539, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000227482",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the left side of the image is throwing a frisbee to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.109, 0.320, 0.641, 0.867]\nfrisbee: [0.156, 0.641, 0.383, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000227482_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the left side of the image is throwing a frisbee to the right.\nObjects: [person, frisbee]"
      },
      {
        "from": "gpt",
        "value": "person: [0.109, 0.320, 0.641, 0.867]\nfrisbee: [0.156, 0.641, 0.383, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000227482_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man wearing a red shirt on the left side of the image is throwing a blue flying disc to the right."
      },
      {
        "from": "gpt",
        "value": "tall man wearing a red shirt: [0.109, 0.320, 0.641, 0.867]\nblue flying disc: [0.156, 0.641, 0.383, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000227482_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tall man wearing a red shirt on the left side of the image is throwing a blue flying disc to the right.\nObjects: [tall man wearing a red shirt, blue flying disc]"
      },
      {
        "from": "gpt",
        "value": "tall man wearing a red shirt: [0.109, 0.320, 0.641, 0.867]\nblue flying disc: [0.156, 0.641, 0.383, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000227482_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.109, 0.320, 0.641, 0.867]\nfrisbee: [0.156, 0.641, 0.383, 0.758]\nGiven the above layout, shift the person to the right by 0.227."
      },
      {
        "from": "gpt",
        "value": "person: [0.336, 0.320, 0.867, 0.867]\nfrisbee: [0.156, 0.641, 0.383, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000227898",
    "conversations": [
      {
        "from": "human",
        "value": "A horse harnessed to a carriage is at the center, with a person sitting on the carriage to the right, and a car directly behind them."
      },
      {
        "from": "gpt",
        "value": "horse: [0.070, 0.477, 0.406, 0.703]\nperson: [0.500, 0.383, 0.617, 0.547]\ncar: [0.898, 0.461, 0.992, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000227898_key",
    "conversations": [
      {
        "from": "human",
        "value": "A horse harnessed to a carriage is at the center, with a person sitting on the carriage to the right, and a car directly behind them.\nObjects: [horse, person, car]"
      },
      {
        "from": "gpt",
        "value": "horse: [0.070, 0.477, 0.406, 0.703]\nperson: [0.500, 0.383, 0.617, 0.547]\ncar: [0.898, 0.461, 0.992, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000227898_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a mature white stallion harnessed to a blue sedanriage is at the center, with a hat-wearing man sitting on the blue sedanriage to the right, and a blue sedan directly behind them."
      },
      {
        "from": "gpt",
        "value": "mature white stallion: [0.070, 0.477, 0.406, 0.703]\nhat-wearing man: [0.500, 0.383, 0.617, 0.547]\nblue sedan: [0.898, 0.461, 0.992, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000227898_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a mature white stallion harnessed to a blue sedanriage is at the center, with a hat-wearing man sitting on the blue sedanriage to the right, and a blue sedan directly behind them.\nObjects: [mature white stallion, hat-wearing man, blue sedan]"
      },
      {
        "from": "gpt",
        "value": "mature white stallion: [0.070, 0.477, 0.406, 0.703]\nhat-wearing man: [0.500, 0.383, 0.617, 0.547]\nblue sedan: [0.898, 0.461, 0.992, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000227898_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: horse: [0.070, 0.477, 0.406, 0.703]\nperson: [0.500, 0.383, 0.617, 0.547]\ncar: [0.898, 0.461, 0.992, 0.641]\nGiven the above layout, shift the person upwards by 0.312."
      },
      {
        "from": "gpt",
        "value": "horse: [0.070, 0.477, 0.406, 0.703]\nperson: [0.500, 0.070, 0.617, 0.234]\ncar: [0.898, 0.461, 0.992, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000238013",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the center of the image playing tennis."
      },
      {
        "from": "gpt",
        "value": "person: [0.086, 0.289, 0.586, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000238013_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the center of the image playing tennis.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.086, 0.289, 0.586, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000238013_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a professional tennis player in the center of the image playing tennis."
      },
      {
        "from": "gpt",
        "value": "professional tennis player: [0.086, 0.289, 0.586, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000238013_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a professional tennis player in the center of the image playing tennis.\nObjects: [professional tennis player]"
      },
      {
        "from": "gpt",
        "value": "professional tennis player: [0.086, 0.289, 0.586, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000238013_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.086, 0.289, 0.586, 0.820]\nGiven the above layout, shift the person to the right by 0.047."
      },
      {
        "from": "gpt",
        "value": "person: [0.133, 0.289, 0.633, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000335658",
    "conversations": [
      {
        "from": "human",
        "value": "A keyboard is to the left and a mouse is to the right on a table."
      },
      {
        "from": "gpt",
        "value": "keyboard: [0.000, 0.289, 0.508, 0.547]\nmouse: [0.594, 0.523, 0.742, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000335658_key",
    "conversations": [
      {
        "from": "human",
        "value": "A keyboard is to the left and a mouse is to the right on a table.\nObjects: [keyboard, mouse]"
      },
      {
        "from": "gpt",
        "value": "keyboard: [0.000, 0.289, 0.508, 0.547]\nmouse: [0.594, 0.523, 0.742, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000335658_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a wireless keyboard is to the left and a ergonomic mouse is to the right on a table."
      },
      {
        "from": "gpt",
        "value": "wireless keyboard: [0.000, 0.289, 0.508, 0.547]\nergonomic mouse: [0.594, 0.523, 0.742, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000335658_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a wireless keyboard is to the left and a ergonomic mouse is to the right on a table.\nObjects: [wireless keyboard, ergonomic mouse]"
      },
      {
        "from": "gpt",
        "value": "wireless keyboard: [0.000, 0.289, 0.508, 0.547]\nergonomic mouse: [0.594, 0.523, 0.742, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000335658_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: keyboard: [0.000, 0.289, 0.508, 0.547]\nmouse: [0.594, 0.523, 0.742, 0.773]\nGiven the above layout, shift the keyboard upwards by 0.172."
      },
      {
        "from": "gpt",
        "value": "keyboard: [0.000, 0.117, 0.508, 0.375]\nmouse: [0.594, 0.523, 0.742, 0.773]"
      }
    ]
  },
  {
    "id": "coco_000000390902",
    "conversations": [
      {
        "from": "human",
        "value": "A person in a red shirt stands in the foreground, while another person is visible in the background to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.148, 0.695, 0.992]\nperson: [0.523, 0.117, 0.617, 0.359]"
      }
    ]
  },
  {
    "id": "coco_000000390902_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in a red shirt stands in the foreground, while another person is visible in the background to the right.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.266, 0.148, 0.695, 0.992]\nperson: [0.523, 0.117, 0.617, 0.359]"
      }
    ]
  },
  {
    "id": "coco_000000393093",
    "conversations": [
      {
        "from": "human",
        "value": "A train is crossing a bridge over a road, parallel to the bridge's railing, at the upper section of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.398, 0.992, 0.508]"
      }
    ]
  },
  {
    "id": "coco_000000393093_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is crossing a bridge over a road, parallel to the bridges railing, at the upper section of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.398, 0.992, 0.508]"
      }
    ]
  },
  {
    "id": "coco_000000393093_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a steam locomotive is crossing a bridge over a road, parallel to the bridge's railing, at the upper section of the image."
      },
      {
        "from": "gpt",
        "value": "steam locomotive: [0.008, 0.398, 0.992, 0.508]"
      }
    ]
  },
  {
    "id": "coco_000000393093_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a steam locomotive is crossing a bridge over a road, parallel to the bridges railing, at the upper section of the image.\nObjects: [steam locomotive]"
      },
      {
        "from": "gpt",
        "value": "steam locomotive: [0.008, 0.398, 0.992, 0.508]"
      }
    ]
  },
  {
    "id": "coco_000000393093_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.008, 0.398, 0.992, 0.508]\nGiven the above layout, shift the train downwards by 0.367."
      },
      {
        "from": "gpt",
        "value": "train: [0.008, 0.766, 0.992, 0.875]"
      }
    ]
  },
  {
    "id": "coco_000000404191",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is at the center of the image with its door partially covered in text and pictures."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.180, 0.094, 0.836, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000404191_key",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is at the center of the image with its door partially covered in text and pictures.\nObjects: [refrigerator]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.180, 0.094, 0.836, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000404191_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the large silver fridge is at the center of the image with its door partially covered in text and pictures."
      },
      {
        "from": "gpt",
        "value": "large silver fridge: [0.180, 0.094, 0.836, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000404191_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the large silver fridge is at the center of the image with its door partially covered in text and pictures.\nObjects: [large silver fridge]"
      },
      {
        "from": "gpt",
        "value": "large silver fridge: [0.180, 0.094, 0.836, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000404191_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: refrigerator: [0.180, 0.094, 0.836, 0.977]\nGiven the above layout, shift the refrigerator to the left by 0.117."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.062, 0.094, 0.719, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000440617",
    "conversations": [
      {
        "from": "human",
        "value": "A train on the tracks at the center of the image, facing to the right."
      },
      {
        "from": "gpt",
        "value": "train: [0.094, 0.422, 0.648, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000440617_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train on the tracks at the center of the image, facing to the right.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.094, 0.422, 0.648, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000440617_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red freight train on the tracks at the center of the image, facing to the right."
      },
      {
        "from": "gpt",
        "value": "red freight train: [0.094, 0.422, 0.648, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000440617_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red freight train on the tracks at the center of the image, facing to the right.\nObjects: [red freight train]"
      },
      {
        "from": "gpt",
        "value": "red freight train: [0.094, 0.422, 0.648, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000440617_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.094, 0.422, 0.648, 0.625]\nGiven the above layout, shift the train upwards by 0.359."
      },
      {
        "from": "gpt",
        "value": "train: [0.094, 0.062, 0.648, 0.266]"
      }
    ]
  },
  {
    "id": "coco_000000447169",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is to the left of the image, near the center."
      },
      {
        "from": "gpt",
        "value": "oven: [0.000, 0.500, 0.375, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000447169_key",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is to the left of the image, near the center.\nObjects: [oven]"
      },
      {
        "from": "gpt",
        "value": "oven: [0.000, 0.500, 0.375, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000447169_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel oven is to the left of the image, near the center."
      },
      {
        "from": "gpt",
        "value": "stainless steel oven: [0.000, 0.500, 0.375, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000447169_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel oven is to the left of the image, near the center.\nObjects: [stainless steel oven]"
      },
      {
        "from": "gpt",
        "value": "stainless steel oven: [0.000, 0.500, 0.375, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000447169_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: oven: [0.000, 0.500, 0.375, 0.852]\nGiven the above layout, shift the oven to the right by 0.359."
      },
      {
        "from": "gpt",
        "value": "oven: [0.359, 0.500, 0.734, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000466835",
    "conversations": [
      {
        "from": "human",
        "value": "A bunch of bananas is hanging from a tree at the center of the image."
      },
      {
        "from": "gpt",
        "value": "banana: [0.391, 0.086, 0.672, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000466835_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bunch of bananas is hanging from a tree at the center of the image.\nObjects: [banana]"
      },
      {
        "from": "gpt",
        "value": "banana: [0.391, 0.086, 0.672, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000466835_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a bunch of large bunch of ripe bananass is hanging from a tree at the center of the image."
      },
      {
        "from": "gpt",
        "value": "large bunch of ripe bananas: [0.391, 0.086, 0.672, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000466835_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a bunch of large bunch of ripe bananass is hanging from a tree at the center of the image.\nObjects: [large bunch of ripe bananas]"
      },
      {
        "from": "gpt",
        "value": "large bunch of ripe bananas: [0.391, 0.086, 0.672, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000466835_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: banana: [0.391, 0.086, 0.672, 0.664]\nGiven the above layout, shift the banana to the left by 0.289."
      },
      {
        "from": "gpt",
        "value": "banana: [0.102, 0.086, 0.383, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000475779",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant is at the center of the image with trees in the background."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.000, 0.312, 0.727, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000475779_key",
    "conversations": [
      {
        "from": "human",
        "value": "An elephant is at the center of the image with trees in the background.\nObjects: [elephant]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.000, 0.312, 0.727, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000475779_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an gigantic mammoth with tusks is at the center of the image with trees in the background."
      },
      {
        "from": "gpt",
        "value": "gigantic mammoth with tusks: [0.000, 0.312, 0.727, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000475779_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an gigantic mammoth with tusks is at the center of the image with trees in the background.\nObjects: [gigantic mammoth with tusks]"
      },
      {
        "from": "gpt",
        "value": "gigantic mammoth with tusks: [0.000, 0.312, 0.727, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000475779_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: elephant: [0.000, 0.312, 0.727, 0.867]\nGiven the above layout, shift the elephant upwards by 0.125."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.000, 0.188, 0.727, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000478420",
    "conversations": [
      {
        "from": "human",
        "value": "Two people standing side by side against a white wall."
      },
      {
        "from": "gpt",
        "value": "person: [0.523, 0.148, 0.852, 0.953]\nperson: [0.164, 0.211, 0.375, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000478420_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two people standing side by side against a white wall.\nObjects: [person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.523, 0.148, 0.852, 0.953]\nperson: [0.164, 0.211, 0.375, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000534639",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks facing towards the left of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.023, 0.172, 0.820, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000534639_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is on the tracks facing towards the left of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.023, 0.172, 0.820, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000534639_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the green diesel train is on the tracks facing towards the left of the image."
      },
      {
        "from": "gpt",
        "value": "green diesel train: [0.023, 0.172, 0.820, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000534639_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the green diesel train is on the tracks facing towards the left of the image.\nObjects: [green diesel train]"
      },
      {
        "from": "gpt",
        "value": "green diesel train: [0.023, 0.172, 0.820, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000534639_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.023, 0.172, 0.820, 0.828]\nGiven the above layout, shift the train upwards by 0.023."
      },
      {
        "from": "gpt",
        "value": "train: [0.023, 0.148, 0.820, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000539445",
    "conversations": [
      {
        "from": "human",
        "value": "The train is approaching on the tracks from the center-right side of the image."
      },
      {
        "from": "gpt",
        "value": "train: [0.414, 0.398, 0.766, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000539445_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is approaching on the tracks from the center-right side of the image.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.414, 0.398, 0.766, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000539445_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the freight train is approaching on the tracks from the center-right side of the image."
      },
      {
        "from": "gpt",
        "value": "freight train: [0.414, 0.398, 0.766, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000539445_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the freight train is approaching on the tracks from the center-right side of the image.\nObjects: [freight train]"
      },
      {
        "from": "gpt",
        "value": "freight train: [0.414, 0.398, 0.766, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000539445_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.414, 0.398, 0.766, 0.766]\nGiven the above layout, shift the train to the left by 0.125."
      },
      {
        "from": "gpt",
        "value": "train: [0.289, 0.398, 0.641, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000545007",
    "conversations": [
      {
        "from": "human",
        "value": "The statue of a person is on top of a clock tower that has two clock faces, one on the left and one on the right side of the tower."
      },
      {
        "from": "gpt",
        "value": "person: [0.398, 0.047, 0.602, 0.414]\nclock: [0.469, 0.461, 0.711, 0.719]\nclock: [0.281, 0.492, 0.414, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000545007_key",
    "conversations": [
      {
        "from": "human",
        "value": "The statue of a person is on top of a clock tower that has two clock faces, one on the left and one on the right side of the tower.\nObjects: [person, clock, clock]"
      },
      {
        "from": "gpt",
        "value": "person: [0.398, 0.047, 0.602, 0.414]\nclock: [0.469, 0.461, 0.711, 0.719]\nclock: [0.281, 0.492, 0.414, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000064495",
    "conversations": [
      {
        "from": "human",
        "value": "The parking meter is at the center, in front of a wall with graffiti."
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.359, 0.188, 0.641, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000064495_key",
    "conversations": [
      {
        "from": "human",
        "value": "The parking meter is at the center, in front of a wall with graffiti.\nObjects: [parking meter]"
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.359, 0.188, 0.641, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000064495_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the green parking meter is at the center, in front of a wall with graffiti."
      },
      {
        "from": "gpt",
        "value": "green parking meter: [0.359, 0.188, 0.641, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000064495_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the green parking meter is at the center, in front of a wall with graffiti.\nObjects: [green parking meter]"
      },
      {
        "from": "gpt",
        "value": "green parking meter: [0.359, 0.188, 0.641, 0.477]"
      }
    ]
  },
  {
    "id": "coco_000000064495_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: parking meter: [0.359, 0.188, 0.641, 0.477]\nGiven the above layout, shift the parking meter downwards by 0.273."
      },
      {
        "from": "gpt",
        "value": "parking meter: [0.359, 0.461, 0.641, 0.750]"
      }
    ]
  },
  {
    "id": "coco_000000176634",
    "conversations": [
      {
        "from": "human",
        "value": "The zebra is upside down with its head facing the ground and legs in the air."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.117, 0.125, 0.992, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000176634_key",
    "conversations": [
      {
        "from": "human",
        "value": "The zebra is upside down with its head facing the ground and legs in the air.\nObjects: [zebra]"
      },
      {
        "from": "gpt",
        "value": "zebra: [0.117, 0.125, 0.992, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000176634_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the playful giraffe is upside down with its head facing the ground and legs in the air."
      },
      {
        "from": "gpt",
        "value": "playful giraffe: [0.117, 0.125, 0.992, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000176634_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the playful giraffe is upside down with its head facing the ground and legs in the air.\nObjects: [playful giraffe]"
      },
      {
        "from": "gpt",
        "value": "playful giraffe: [0.117, 0.125, 0.992, 0.852]"
      }
    ]
  },
  {
    "id": "coco_000000176634_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: zebra: [0.117, 0.125, 0.992, 0.852]\nGiven the above layout, shift the zebra downwards by 0.078."
      },
      {
        "from": "gpt",
        "value": "zebra: [0.117, 0.203, 0.992, 0.930]"
      }
    ]
  },
  {
    "id": "coco_000000186282",
    "conversations": [
      {
        "from": "human",
        "value": "A television to the left and a keyboard in front of it, slightly to the right."
      },
      {
        "from": "gpt",
        "value": "tv: [0.422, 0.164, 0.797, 0.648]\nkeyboard: [0.266, 0.586, 0.516, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000186282_key",
    "conversations": [
      {
        "from": "human",
        "value": "A television to the left and a keyboard in front of it, slightly to the right.\nObjects: [tv, keyboard]"
      },
      {
        "from": "gpt",
        "value": "tv: [0.422, 0.164, 0.797, 0.648]\nkeyboard: [0.266, 0.586, 0.516, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000186282_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a television to the left and a wireless computer keyboard in front of it, slightly to the right."
      },
      {
        "from": "gpt",
        "value": "large plasma television: [0.422, 0.164, 0.797, 0.648]\nwireless computer keyboard: [0.266, 0.586, 0.516, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000186282_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a television to the left and a wireless computer keyboard in front of it, slightly to the right.\nObjects: [large plasma television, wireless computer keyboard]"
      },
      {
        "from": "gpt",
        "value": "large plasma television: [0.422, 0.164, 0.797, 0.648]\nwireless computer keyboard: [0.266, 0.586, 0.516, 0.688]"
      }
    ]
  },
  {
    "id": "coco_000000186282_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: tv: [0.422, 0.164, 0.797, 0.648]\nkeyboard: [0.266, 0.586, 0.516, 0.688]\nGiven the above layout, shift the keyboard downwards by 0.156."
      },
      {
        "from": "gpt",
        "value": "tv: [0.422, 0.164, 0.797, 0.648]\nkeyboard: [0.266, 0.742, 0.516, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000188592",
    "conversations": [
      {
        "from": "human",
        "value": "A person sitting in the center of the image, holding an object with both hands."
      },
      {
        "from": "gpt",
        "value": "person: [0.234, 0.195, 0.656, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000188592_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person sitting in the center of the image, holding an object with both hands.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.234, 0.195, 0.656, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000188592_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young man in a hat sitting in the center of the image, holding an object with both hands."
      },
      {
        "from": "gpt",
        "value": "young man in a hat: [0.234, 0.195, 0.656, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000188592_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young man in a hat sitting in the center of the image, holding an object with both hands.\nObjects: [young man in a hat]"
      },
      {
        "from": "gpt",
        "value": "young man in a hat: [0.234, 0.195, 0.656, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000188592_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.234, 0.195, 0.656, 0.992]\nGiven the above layout, shift the person to the right by 0.250."
      },
      {
        "from": "gpt",
        "value": "person: [0.484, 0.195, 0.906, 0.992]"
      }
    ]
  },
  {
    "id": "coco_000000210394",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is at the center, a person is to the left of the bus walking towards it, and another person is to the right of the bus walking away."
      },
      {
        "from": "gpt",
        "value": "bus: [0.391, 0.328, 0.680, 0.633]\nperson: [0.648, 0.477, 0.719, 0.641]\nperson: [0.773, 0.477, 0.836, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000210394_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is at the center, a person is to the left of the bus walking towards it, and another person is to the right of the bus walking away.\nObjects: [bus, person, person]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.391, 0.328, 0.680, 0.633]\nperson: [0.648, 0.477, 0.719, 0.641]\nperson: [0.773, 0.477, 0.836, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000213422",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is at the center, with white bedding and a brown throw at the foot of the bed, flanked by two pillows and a cylindrical cushion in the middle."
      },
      {
        "from": "gpt",
        "value": "bed: [0.000, 0.414, 0.859, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000213422_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is at the center, with white bedding and a brown throw at the foot of the bed, flanked by two pillows and a cylindrical cushion in the middle.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.000, 0.414, 0.859, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000213422_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the king-sized bed with white and beige bedding is at the center, with white king-sized bed with white and beige beddingding and a brown throw at the foot of the king-sized bed with white and beige bedding, flanked by two pillows and a cylindrical cushion in the middle."
      },
      {
        "from": "gpt",
        "value": "king-sized bed with white and beige bedding: [0.000, 0.414, 0.859, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000213422_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the king-sized bed with white and beige bedding is at the center, with white king-sized bed with white and beige beddingding and a brown throw at the foot of the king-sized bed with white and beige bedding, flanked by two pillows and a cylindrical cushion in the middle.\nObjects: [king-sized bed with white and beige bedding]"
      },
      {
        "from": "gpt",
        "value": "king-sized bed with white and beige bedding: [0.000, 0.414, 0.859, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000213422_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.000, 0.414, 0.859, 0.820]\nGiven the above layout, shift the bed upwards by 0.383."
      },
      {
        "from": "gpt",
        "value": "bed: [0.000, 0.031, 0.859, 0.438]"
      }
    ]
  },
  {
    "id": "coco_000000232348",
    "conversations": [
      {
        "from": "human",
        "value": "The toaster is on the right side of the counter."
      },
      {
        "from": "gpt",
        "value": "toaster: [0.195, 0.328, 0.633, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000232348_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toaster is on the right side of the counter.\nObjects: [toaster]"
      },
      {
        "from": "gpt",
        "value": "toaster: [0.195, 0.328, 0.633, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000232348_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel toaster is on the right side of the counter."
      },
      {
        "from": "gpt",
        "value": "stainless steel toaster: [0.195, 0.328, 0.633, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000232348_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the stainless steel toaster is on the right side of the counter.\nObjects: [stainless steel toaster]"
      },
      {
        "from": "gpt",
        "value": "stainless steel toaster: [0.195, 0.328, 0.633, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000232348_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toaster: [0.195, 0.328, 0.633, 0.836]\nGiven the above layout, shift the toaster to the right by 0.016."
      },
      {
        "from": "gpt",
        "value": "toaster: [0.211, 0.328, 0.648, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000234413",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is in the center of the image with the lid up."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.234, 0.195, 0.688, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000234413_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is in the center of the image with the lid up.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.234, 0.195, 0.688, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000234413_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain throne is in the center of the image with the lid up."
      },
      {
        "from": "gpt",
        "value": "porcelain throne: [0.234, 0.195, 0.688, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000234413_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain throne is in the center of the image with the lid up.\nObjects: [porcelain throne]"
      },
      {
        "from": "gpt",
        "value": "porcelain throne: [0.234, 0.195, 0.688, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000234413_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.234, 0.195, 0.688, 0.828]\nGiven the above layout, shift the toilet to the right by 0.156."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.391, 0.195, 0.844, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000262631",
    "conversations": [
      {
        "from": "human",
        "value": "In the foreground, there is a large vase on the left; in the background to the right, there is a smaller vase."
      },
      {
        "from": "gpt",
        "value": "vase: [0.234, 0.133, 0.688, 0.867]\nvase: [0.648, 0.508, 0.812, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000262631_key",
    "conversations": [
      {
        "from": "human",
        "value": "In the foreground, there is a large vase on the left; in the background to the right, there is a smaller vase.\nObjects: [vase, vase]"
      },
      {
        "from": "gpt",
        "value": "vase: [0.234, 0.133, 0.688, 0.867]\nvase: [0.648, 0.508, 0.812, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000293245",
    "conversations": [
      {
        "from": "human",
        "value": "A motorcycle is positioned on the right side of the image, parked outside a building with the number 500 on it."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.266, 0.336, 0.906, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000293245_key",
    "conversations": [
      {
        "from": "human",
        "value": "A motorcycle is positioned on the right side of the image, parked outside a building with the number 500 on it.\nObjects: [motorcycle]"
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.266, 0.336, 0.906, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000293245_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek sports bike is positioned on the right side of the image, parked outside a building with the number 500 on it."
      },
      {
        "from": "gpt",
        "value": "sleek sports bike: [0.266, 0.336, 0.906, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000293245_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a sleek sports bike is positioned on the right side of the image, parked outside a building with the number 500 on it.\nObjects: [sleek sports bike]"
      },
      {
        "from": "gpt",
        "value": "sleek sports bike: [0.266, 0.336, 0.906, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000293245_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: motorcycle: [0.266, 0.336, 0.906, 0.820]\nGiven the above layout, shift the motorcycle upwards by 0.328."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.266, 0.008, 0.906, 0.492]"
      }
    ]
  },
  {
    "id": "coco_000000298738",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is at the center, partially obscured by greenery in the foreground."
      },
      {
        "from": "gpt",
        "value": "bear: [0.164, 0.195, 0.828, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000298738_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bear is at the center, partially obscured by greenery in the foreground.\nObjects: [bear]"
      },
      {
        "from": "gpt",
        "value": "bear: [0.164, 0.195, 0.828, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000298738_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the big brown bear is at the center, partially obscured by greenery in the foreground."
      },
      {
        "from": "gpt",
        "value": "big brown bear: [0.164, 0.195, 0.828, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000298738_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the big brown bear is at the center, partially obscured by greenery in the foreground.\nObjects: [big brown bear]"
      },
      {
        "from": "gpt",
        "value": "big brown bear: [0.164, 0.195, 0.828, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000298738_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bear: [0.164, 0.195, 0.828, 0.977]\nGiven the above layout, shift the bear upwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "bear: [0.164, 0.156, 0.828, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000338560",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is on the right side of the image near the bottom edge, placed on a sidewalk next to a street."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.328, 0.258, 0.617, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000338560_key",
    "conversations": [
      {
        "from": "human",
        "value": "The fire hydrant is on the right side of the image near the bottom edge, placed on a sidewalk next to a street.\nObjects: [fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.328, 0.258, 0.617, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000338560_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red fire hydrant is on the right side of the image near the bottom edge, placed on a sidewalk next to a street."
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.328, 0.258, 0.617, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000338560_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red fire hydrant is on the right side of the image near the bottom edge, placed on a sidewalk next to a street.\nObjects: [red fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "red fire hydrant: [0.328, 0.258, 0.617, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000338560_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: fire hydrant: [0.328, 0.258, 0.617, 0.953]\nGiven the above layout, shift the fire hydrant to the right by 0.031."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.359, 0.258, 0.648, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000554156",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the left holding a tennis racket with both hands at chest level."
      },
      {
        "from": "gpt",
        "value": "person: [0.180, 0.305, 0.711, 0.820]\ntennis racket: [0.648, 0.164, 0.805, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000554156_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the left holding a tennis racket with both hands at chest level.\nObjects: [person, tennis racket]"
      },
      {
        "from": "gpt",
        "value": "person: [0.180, 0.305, 0.711, 0.820]\ntennis racket: [0.648, 0.164, 0.805, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000554156_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a tennis player on the left holding a professional tennis racket with both hands at chest level."
      },
      {
        "from": "gpt",
        "value": "tennis player: [0.180, 0.305, 0.711, 0.820]\nprofessional tennis racket: [0.648, 0.164, 0.805, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000554156_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a tennis player on the left holding a professional tennis racket with both hands at chest level.\nObjects: [tennis player, professional tennis racket]"
      },
      {
        "from": "gpt",
        "value": "tennis player: [0.180, 0.305, 0.711, 0.820]\nprofessional tennis racket: [0.648, 0.164, 0.805, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000554156_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.180, 0.305, 0.711, 0.820]\ntennis racket: [0.648, 0.164, 0.805, 0.453]\nGiven the above layout, shift the tennis racket to the right by 0.062."
      },
      {
        "from": "gpt",
        "value": "person: [0.180, 0.305, 0.711, 0.820]\ntennis racket: [0.711, 0.164, 0.867, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000554838",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is at the center bottom of the image with various items on top of it."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.234, 0.586, 0.797, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000554838_key",
    "conversations": [
      {
        "from": "human",
        "value": "The refrigerator is at the center bottom of the image with various items on top of it.\nObjects: [refrigerator]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.234, 0.586, 0.797, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000554838_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the silver double door refrigerator is at the center bottom of the image with various items on top of it."
      },
      {
        "from": "gpt",
        "value": "silver double door refrigerator: [0.234, 0.586, 0.797, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000554838_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the silver double door refrigerator is at the center bottom of the image with various items on top of it.\nObjects: [silver double door refrigerator]"
      },
      {
        "from": "gpt",
        "value": "silver double door refrigerator: [0.234, 0.586, 0.797, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000554838_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: refrigerator: [0.234, 0.586, 0.797, 0.984]\nGiven the above layout, shift the refrigerator upwards by 0.195."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.234, 0.391, 0.797, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000576654",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the right holding a kite flying in the air to the left."
      },
      {
        "from": "gpt",
        "value": "kite: [0.375, 0.219, 0.766, 0.414]\nperson: [0.781, 0.523, 0.906, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000576654_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person on the right holding a kite flying in the air to the left.\nObjects: [kite, person]"
      },
      {
        "from": "gpt",
        "value": "kite: [0.375, 0.219, 0.766, 0.414]\nperson: [0.781, 0.523, 0.906, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000576654_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a person on the right holding a kite flying in the air to the left."
      },
      {
        "from": "gpt",
        "value": "kite: [0.375, 0.219, 0.766, 0.414]\nperson: [0.781, 0.523, 0.906, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000576654_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a person on the right holding a kite flying in the air to the left.\nObjects: [kite, person]"
      },
      {
        "from": "gpt",
        "value": "kite: [0.375, 0.219, 0.766, 0.414]\nperson: [0.781, 0.523, 0.906, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000576654_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: kite: [0.375, 0.219, 0.766, 0.414]\nperson: [0.781, 0.523, 0.906, 0.758]\nGiven the above layout, shift the kite to the left by 0.047."
      },
      {
        "from": "gpt",
        "value": "kite: [0.328, 0.219, 0.719, 0.414]\nperson: [0.781, 0.523, 0.906, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000581357",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in mid-air above a skateboard at the center of the image."
      },
      {
        "from": "gpt",
        "value": "person: [0.430, 0.148, 0.781, 0.555]\nskateboard: [0.375, 0.492, 0.609, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000581357_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in mid-air above a skateboard at the center of the image.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.430, 0.148, 0.781, 0.555]\nskateboard: [0.375, 0.492, 0.609, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000581357_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager in mid-jump is in mid-air above a vintage wooden skateboard at the center of the image."
      },
      {
        "from": "gpt",
        "value": "teenager in mid-jump: [0.430, 0.148, 0.781, 0.555]\nvintage wooden skateboard: [0.375, 0.492, 0.609, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000581357_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager in mid-jump is in mid-air above a vintage wooden skateboard at the center of the image.\nObjects: [teenager in mid-jump, vintage wooden skateboard]"
      },
      {
        "from": "gpt",
        "value": "teenager in mid-jump: [0.430, 0.148, 0.781, 0.555]\nvintage wooden skateboard: [0.375, 0.492, 0.609, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000581357_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.430, 0.148, 0.781, 0.555]\nskateboard: [0.375, 0.492, 0.609, 0.594]\nGiven the above layout, shift the skateboard downwards by 0.047."
      },
      {
        "from": "gpt",
        "value": "person: [0.430, 0.148, 0.781, 0.555]\nskateboard: [0.375, 0.539, 0.609, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000016439",
    "conversations": [
      {
        "from": "human",
        "value": "An open laptop is on the left side of a wooden desk."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.211, 0.383, 0.570, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000016439_key",
    "conversations": [
      {
        "from": "human",
        "value": "An open laptop is on the left side of a wooden desk.\nObjects: [laptop]"
      },
      {
        "from": "gpt",
        "value": "laptop: [0.211, 0.383, 0.570, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000016439_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an open MacBook Pro is on the left side of a wooden desk."
      },
      {
        "from": "gpt",
        "value": "MacBook Pro: [0.211, 0.383, 0.570, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000016439_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an open MacBook Pro is on the left side of a wooden desk.\nObjects: [MacBook Pro]"
      },
      {
        "from": "gpt",
        "value": "MacBook Pro: [0.211, 0.383, 0.570, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000016439_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: laptop: [0.211, 0.383, 0.570, 0.672]\nGiven the above layout, shift the laptop to the right by 0.016."
      },
      {
        "from": "gpt",
        "value": "laptop: [0.227, 0.383, 0.586, 0.672]"
      }
    ]
  },
  {
    "id": "coco_000000045472",
    "conversations": [
      {
        "from": "human",
        "value": "Three oranges are grouped together on a white plate to the right of the image."
      },
      {
        "from": "gpt",
        "value": "orange: [0.641, 0.430, 0.977, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000045472_key",
    "conversations": [
      {
        "from": "human",
        "value": "Three oranges are grouped together on a white plate to the right of the image.\nObjects: [orange]"
      },
      {
        "from": "gpt",
        "value": "orange: [0.641, 0.430, 0.977, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000045472_aug",
    "conversations": [
      {
        "from": "human",
        "value": "three tangerines are grouped together on a white plate to the right of the image."
      },
      {
        "from": "gpt",
        "value": "tangerine: [0.641, 0.430, 0.977, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000045472_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "three tangerines are grouped together on a white plate to the right of the image.\nObjects: [tangerine]"
      },
      {
        "from": "gpt",
        "value": "tangerine: [0.641, 0.430, 0.977, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000045472_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: orange: [0.641, 0.430, 0.977, 0.703]\nGiven the above layout, shift the orange to the left by 0.266."
      },
      {
        "from": "gpt",
        "value": "orange: [0.375, 0.430, 0.711, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000066635",
    "conversations": [
      {
        "from": "human",
        "value": "A keyboard is placed in front of the TV at the center of the table."
      },
      {
        "from": "gpt",
        "value": "tv: [0.164, 0.188, 0.617, 0.609]\nkeyboard: [0.359, 0.656, 0.773, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000066635_key",
    "conversations": [
      {
        "from": "human",
        "value": "A keyboard is placed in front of the TV at the center of the table.\nObjects: [tv, keyboard]"
      },
      {
        "from": "gpt",
        "value": "tv: [0.164, 0.188, 0.617, 0.609]\nkeyboard: [0.359, 0.656, 0.773, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000066635_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a ergonomic gaming keyboard is placed in front of the large flat screen TV at the center of the table."
      },
      {
        "from": "gpt",
        "value": "large flat screen TV: [0.164, 0.188, 0.617, 0.609]\nergonomic gaming keyboard: [0.359, 0.656, 0.773, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000066635_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a ergonomic gaming keyboard is placed in front of the large flat screen TV at the center of the table.\nObjects: [large flat screen TV, ergonomic gaming keyboard]"
      },
      {
        "from": "gpt",
        "value": "large flat screen TV: [0.164, 0.188, 0.617, 0.609]\nergonomic gaming keyboard: [0.359, 0.656, 0.773, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000066635_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: tv: [0.164, 0.188, 0.617, 0.609]\nkeyboard: [0.359, 0.656, 0.773, 0.836]\nGiven the above layout, shift the keyboard to the right by 0.047."
      },
      {
        "from": "gpt",
        "value": "tv: [0.164, 0.188, 0.617, 0.609]\nkeyboard: [0.406, 0.656, 0.820, 0.836]"
      }
    ]
  },
  {
    "id": "coco_000000074092",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center, serving a tennis ball with a raised arm."
      },
      {
        "from": "gpt",
        "value": "person: [0.453, 0.328, 0.633, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000074092_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center, serving a tennis ball with a raised arm.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.453, 0.328, 0.633, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000074092_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a tennis player is standing at the center, serving a tennis ball with a raised arm."
      },
      {
        "from": "gpt",
        "value": "a tennis player: [0.453, 0.328, 0.633, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000074092_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a tennis player is standing at the center, serving a tennis ball with a raised arm.\nObjects: [a tennis player]"
      },
      {
        "from": "gpt",
        "value": "a tennis player: [0.453, 0.328, 0.633, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000074092_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.453, 0.328, 0.633, 0.859]\nGiven the above layout, shift the person to the left by 0.344."
      },
      {
        "from": "gpt",
        "value": "person: [0.109, 0.328, 0.289, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000104803",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center with the lid open."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.258, 0.117, 0.641, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000104803_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center with the lid open.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.258, 0.117, 0.641, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000104803_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain sink is at the center with the lid open."
      },
      {
        "from": "gpt",
        "value": "porcelain sink: [0.258, 0.117, 0.641, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000104803_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the porcelain sink is at the center with the lid open.\nObjects: [porcelain sink]"
      },
      {
        "from": "gpt",
        "value": "porcelain sink: [0.258, 0.117, 0.641, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000104803_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.258, 0.117, 0.641, 0.906]\nGiven the above layout, shift the toilet to the right by 0.117."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.375, 0.117, 0.758, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000109827",
    "conversations": [
      {
        "from": "human",
        "value": "A teddy bear is leaning against a tree on the sidewalk."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.242, 0.367, 0.633, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000109827_key",
    "conversations": [
      {
        "from": "human",
        "value": "A teddy bear is leaning against a tree on the sidewalk.\nObjects: [teddy bear]"
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.242, 0.367, 0.633, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000109827_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a fluffy soft pink teddy bear is leaning against a tree on the sidewalk."
      },
      {
        "from": "gpt",
        "value": "fluffy soft pink teddy bear: [0.242, 0.367, 0.633, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000109827_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a fluffy soft pink teddy bear is leaning against a tree on the sidewalk.\nObjects: [fluffy soft pink teddy bear]"
      },
      {
        "from": "gpt",
        "value": "fluffy soft pink teddy bear: [0.242, 0.367, 0.633, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000109827_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: teddy bear: [0.242, 0.367, 0.633, 0.742]\nGiven the above layout, shift the teddy bear upwards by 0.047."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.242, 0.320, 0.633, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000110784",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is parked on the right side of the image, while a truck is visible in the background to the left of the bus."
      },
      {
        "from": "gpt",
        "value": "truck: [0.164, 0.359, 0.586, 0.648]\nbus: [0.469, 0.422, 0.609, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000110784_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bus is parked on the right side of the image, while a truck is visible in the background to the left of the bus.\nObjects: [truck, bus]"
      },
      {
        "from": "gpt",
        "value": "truck: [0.164, 0.359, 0.586, 0.648]\nbus: [0.469, 0.422, 0.609, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000110784_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a city bus is parked on the right side of the image, while a delivery truck is visible in the background to the left of the city bus."
      },
      {
        "from": "gpt",
        "value": "delivery truck: [0.164, 0.359, 0.586, 0.648]\ncity bus: [0.469, 0.422, 0.609, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000110784_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a city bus is parked on the right side of the image, while a delivery truck is visible in the background to the left of the city bus.\nObjects: [delivery truck, city bus]"
      },
      {
        "from": "gpt",
        "value": "delivery truck: [0.164, 0.359, 0.586, 0.648]\ncity bus: [0.469, 0.422, 0.609, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000110784_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: truck: [0.164, 0.359, 0.586, 0.648]\nbus: [0.469, 0.422, 0.609, 0.602]\nGiven the above layout, shift the bus to the right by 0.289."
      },
      {
        "from": "gpt",
        "value": "truck: [0.164, 0.359, 0.586, 0.648]\nbus: [0.758, 0.422, 0.898, 0.602]"
      }
    ]
  },
  {
    "id": "coco_000000137950",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying in the center of the image, above the trees and buildings below."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.008, 0.227, 0.828, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000137950_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying in the center of the image, above the trees and buildings below.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.008, 0.227, 0.828, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000137950_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an commercial jetliner is flying in the center of the image, above the trees and buildings below."
      },
      {
        "from": "gpt",
        "value": "commercial jetliner: [0.008, 0.227, 0.828, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000137950_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an commercial jetliner is flying in the center of the image, above the trees and buildings below.\nObjects: [commercial jetliner]"
      },
      {
        "from": "gpt",
        "value": "commercial jetliner: [0.008, 0.227, 0.828, 0.445]"
      }
    ]
  },
  {
    "id": "coco_000000137950_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.008, 0.227, 0.828, 0.445]\nGiven the above layout, shift the airplane downwards by 0.141."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.008, 0.367, 0.828, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000187271",
    "conversations": [
      {
        "from": "human",
        "value": "A pale yellow refrigerator stands in the center, between wooden cabinetry."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.273, 0.234, 0.664, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000187271_key",
    "conversations": [
      {
        "from": "human",
        "value": "A pale yellow refrigerator stands in the center, between wooden cabinetry.\nObjects: [refrigerator]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.273, 0.234, 0.664, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000187271_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a pale yellow antiquated cream-colored refrigerator stands in the center, between wooden cabinetry."
      },
      {
        "from": "gpt",
        "value": "antiquated cream-colored refrigerator: [0.273, 0.234, 0.664, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000187271_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a pale yellow antiquated cream-colored refrigerator stands in the center, between wooden cabinetry.\nObjects: [antiquated cream-colored refrigerator]"
      },
      {
        "from": "gpt",
        "value": "antiquated cream-colored refrigerator: [0.273, 0.234, 0.664, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000187271_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: refrigerator: [0.273, 0.234, 0.664, 0.953]\nGiven the above layout, shift the refrigerator to the right by 0.086."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.359, 0.234, 0.750, 0.953]"
      }
    ]
  },
  {
    "id": "coco_000000334417",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing and holding a white plate in their left hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.156, 0.266, 0.930, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000334417_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing and holding a white plate in their left hand.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.156, 0.266, 0.930, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000334417_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young lady in a blue dress is standing and holding a white plate in their left hand."
      },
      {
        "from": "gpt",
        "value": "young lady in a blue dress: [0.156, 0.266, 0.930, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000334417_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young lady in a blue dress is standing and holding a white plate in their left hand.\nObjects: [young lady in a blue dress]"
      },
      {
        "from": "gpt",
        "value": "young lady in a blue dress: [0.156, 0.266, 0.930, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000334417_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.156, 0.266, 0.930, 0.812]\nGiven the above layout, shift the person upwards by 0.078."
      },
      {
        "from": "gpt",
        "value": "person: [0.156, 0.188, 0.930, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000394275",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is centered in the image, facing to the right."
      },
      {
        "from": "gpt",
        "value": "bus: [0.141, 0.320, 0.945, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000394275_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is centered in the image, facing to the right.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.141, 0.320, 0.945, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000394275_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the green double-decker bus is centered in the image, facing to the right."
      },
      {
        "from": "gpt",
        "value": "green double-decker bus: [0.141, 0.320, 0.945, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000394275_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the green double-decker bus is centered in the image, facing to the right.\nObjects: [green double-decker bus]"
      },
      {
        "from": "gpt",
        "value": "green double-decker bus: [0.141, 0.320, 0.945, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000394275_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.141, 0.320, 0.945, 0.766]\nGiven the above layout, shift the bus upwards by 0.172."
      },
      {
        "from": "gpt",
        "value": "bus: [0.141, 0.148, 0.945, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000407646",
    "conversations": [
      {
        "from": "human",
        "value": "A person in a green shirt is swinging a tennis racket to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.148, 0.180, 0.820, 0.883]\ntennis racket: [0.000, 0.586, 0.211, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000407646_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in a green shirt is swinging a tennis racket to the right.\nObjects: [person, tennis racket]"
      },
      {
        "from": "gpt",
        "value": "person: [0.148, 0.180, 0.820, 0.883]\ntennis racket: [0.000, 0.586, 0.211, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000450439",
    "conversations": [
      {
        "from": "human",
        "value": "Two kites flying in the sky, with one positioned slightly higher and to the left of the other."
      },
      {
        "from": "gpt",
        "value": "kite: [0.516, 0.305, 0.953, 0.641]\nkite: [0.039, 0.570, 0.305, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000450439_key",
    "conversations": [
      {
        "from": "human",
        "value": "Two kites flying in the sky, with one positioned slightly higher and to the left of the other.\nObjects: [kite, kite]"
      },
      {
        "from": "gpt",
        "value": "kite: [0.516, 0.305, 0.953, 0.641]\nkite: [0.039, 0.570, 0.305, 0.695]"
      }
    ]
  },
  {
    "id": "coco_000000478862",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is at the center with a person standing in front of it and another person standing to the left of the airplane."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.023, 0.211, 0.992, 0.695]\nperson: [0.633, 0.555, 0.719, 0.750]\nperson: [0.125, 0.562, 0.180, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000478862_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is at the center with a person standing in front of it and another person standing to the left of the airplane.\nObjects: [airplane, person, person]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.023, 0.211, 0.992, 0.695]\nperson: [0.633, 0.555, 0.719, 0.750]\nperson: [0.125, 0.562, 0.180, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000498807",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a surfboard in the water."
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.219, 0.656, 0.703]\nsurfboard: [0.398, 0.609, 0.703, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000498807_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a surfboard in the water.\nObjects: [person, surfboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.219, 0.656, 0.703]\nsurfboard: [0.398, 0.609, 0.703, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000498807_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a person is standing on a surfboard in the water."
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.219, 0.656, 0.703]\nsurfboard: [0.398, 0.609, 0.703, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000498807_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a person is standing on a surfboard in the water.\nObjects: [person, surfboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.219, 0.656, 0.703]\nsurfboard: [0.398, 0.609, 0.703, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000498807_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.164, 0.219, 0.656, 0.703]\nsurfboard: [0.398, 0.609, 0.703, 0.734]\nGiven the above layout, shift the surfboard to the right by 0.227."
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.219, 0.656, 0.703]\nsurfboard: [0.625, 0.609, 0.930, 0.734]"
      }
    ]
  },
  {
    "id": "coco_000000544444",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skiing with skis on their feet, sliding down a snowy slope."
      },
      {
        "from": "gpt",
        "value": "person: [0.359, 0.406, 0.727, 0.805]\nskis: [0.305, 0.789, 0.516, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000544444_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skiing with skis on their feet, sliding down a snowy slope.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.359, 0.406, 0.727, 0.805]\nskis: [0.305, 0.789, 0.516, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000544444_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a snowboarder is skiing with snowboard on their feet, sliding down a snowy slope."
      },
      {
        "from": "gpt",
        "value": "snowboarder: [0.359, 0.406, 0.727, 0.805]\nsnowboard: [0.305, 0.789, 0.516, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000544444_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a snowboarder is skiing with snowboard on their feet, sliding down a snowy slope.\nObjects: [snowboarder, snowboard]"
      },
      {
        "from": "gpt",
        "value": "snowboarder: [0.359, 0.406, 0.727, 0.805]\nsnowboard: [0.305, 0.789, 0.516, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000544444_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.359, 0.406, 0.727, 0.805]\nskis: [0.305, 0.789, 0.516, 0.844]\nGiven the above layout, shift the person upwards by 0.359."
      },
      {
        "from": "gpt",
        "value": "person: [0.359, 0.047, 0.727, 0.445]\nskis: [0.305, 0.789, 0.516, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000018519",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding in the center of the image, leaning forward with arms outstretched."
      },
      {
        "from": "gpt",
        "value": "person: [0.289, 0.352, 0.648, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000018519_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding in the center of the image, leaning forward with arms outstretched.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.289, 0.352, 0.648, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000018519_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage boy is skateboarding in the center of the image, leaning forward with arms outstretched."
      },
      {
        "from": "gpt",
        "value": "teenage boy: [0.289, 0.352, 0.648, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000018519_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage boy is skateboarding in the center of the image, leaning forward with arms outstretched.\nObjects: [teenage boy]"
      },
      {
        "from": "gpt",
        "value": "teenage boy: [0.289, 0.352, 0.648, 0.617]"
      }
    ]
  },
  {
    "id": "coco_000000018519_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.289, 0.352, 0.648, 0.617]\nGiven the above layout, shift the person downwards by 0.195."
      },
      {
        "from": "gpt",
        "value": "person: [0.289, 0.547, 0.648, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000055002",
    "conversations": [
      {
        "from": "human",
        "value": "No person is visible, only a toilet is centered in the image."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.258, 0.133, 0.656, 0.867]\nperson: [0.305, 0.766, 0.625, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000055002_key",
    "conversations": [
      {
        "from": "human",
        "value": "No person is visible, only a toilet is centered in the image.\nObjects: [toilet, person]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.258, 0.133, 0.656, 0.867]\nperson: [0.305, 0.766, 0.625, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000055002_aug",
    "conversations": [
      {
        "from": "human",
        "value": "no absent individual is visible, only a white porcelain toilet is centered in the image."
      },
      {
        "from": "gpt",
        "value": "white porcelain toilet: [0.258, 0.133, 0.656, 0.867]\nabsent individual: [0.305, 0.766, 0.625, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000055002_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "no absent individual is visible, only a white porcelain toilet is centered in the image.\nObjects: [white porcelain toilet, absent individual]"
      },
      {
        "from": "gpt",
        "value": "white porcelain toilet: [0.258, 0.133, 0.656, 0.867]\nabsent individual: [0.305, 0.766, 0.625, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000055002_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.258, 0.133, 0.656, 0.867]\nperson: [0.305, 0.766, 0.625, 0.867]\nGiven the above layout, shift the toilet to the right by 0.047."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.305, 0.133, 0.703, 0.867]\nperson: [0.305, 0.766, 0.625, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000067310",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the air above a skateboard, performing a trick in a skate park."
      },
      {
        "from": "gpt",
        "value": "person: [0.141, 0.188, 0.492, 0.570]\nskateboard: [0.305, 0.445, 0.477, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000067310_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is in the air above a skateboard, performing a trick in a skate park.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.141, 0.188, 0.492, 0.570]\nskateboard: [0.305, 0.445, 0.477, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000067310_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage scratched scratched skateboarder is in the air above a scratched skateboard, performing a trick in a skate park."
      },
      {
        "from": "gpt",
        "value": "teenage scratched skateboarder: [0.141, 0.188, 0.492, 0.570]\nscratched skateboard: [0.305, 0.445, 0.477, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000067310_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenage scratched scratched skateboarder is in the air above a scratched skateboard, performing a trick in a skate park.\nObjects: [teenage scratched skateboarder, scratched skateboard]"
      },
      {
        "from": "gpt",
        "value": "teenage scratched skateboarder: [0.141, 0.188, 0.492, 0.570]\nscratched skateboard: [0.305, 0.445, 0.477, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000067310_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.141, 0.188, 0.492, 0.570]\nskateboard: [0.305, 0.445, 0.477, 0.594]\nGiven the above layout, shift the person to the right by 0.156."
      },
      {
        "from": "gpt",
        "value": "person: [0.297, 0.188, 0.648, 0.570]\nskateboard: [0.305, 0.445, 0.477, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000073326",
    "conversations": [
      {
        "from": "human",
        "value": "A bottle is inside the door of the open refrigerator."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.086, 0.125, 0.992, 0.859]\nbottle: [0.875, 0.508, 0.961, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000073326_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bottle is inside the door of the open refrigerator.\nObjects: [refrigerator, bottle]"
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.086, 0.125, 0.992, 0.859]\nbottle: [0.875, 0.508, 0.961, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000073326_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a litre water bottle is inside the door of the open two-door stainless steel refrigerator."
      },
      {
        "from": "gpt",
        "value": "two-door stainless steel refrigerator: [0.086, 0.125, 0.992, 0.859]\nlitre water bottle: [0.875, 0.508, 0.961, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000073326_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a litre water bottle is inside the door of the open two-door stainless steel refrigerator.\nObjects: [two-door stainless steel refrigerator, litre water bottle]"
      },
      {
        "from": "gpt",
        "value": "two-door stainless steel refrigerator: [0.086, 0.125, 0.992, 0.859]\nlitre water bottle: [0.875, 0.508, 0.961, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000073326_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: refrigerator: [0.086, 0.125, 0.992, 0.859]\nbottle: [0.875, 0.508, 0.961, 0.656]\nGiven the above layout, shift the refrigerator downwards by 0.070."
      },
      {
        "from": "gpt",
        "value": "refrigerator: [0.086, 0.195, 0.992, 0.930]\nbottle: [0.875, 0.508, 0.961, 0.656]"
      }
    ]
  },
  {
    "id": "coco_000000166664",
    "conversations": [
      {
        "from": "human",
        "value": "A car is behind an elephant on a road; both are facing away."
      },
      {
        "from": "gpt",
        "value": "elephant: [0.594, 0.242, 0.867, 0.617]\ncar: [0.000, 0.391, 0.211, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000166664_key",
    "conversations": [
      {
        "from": "human",
        "value": "A car is behind an elephant on a road; both are facing away.\nObjects: [elephant, car]"
      },
      {
        "from": "gpt",
        "value": "elephant: [0.594, 0.242, 0.867, 0.617]\ncar: [0.000, 0.391, 0.211, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000298904",
    "conversations": [
      {
        "from": "human",
        "value": "A vase at the center of the image with plants and stones inside it."
      },
      {
        "from": "gpt",
        "value": "vase: [0.211, 0.023, 0.742, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000298904_key",
    "conversations": [
      {
        "from": "human",
        "value": "A vase at the center of the image with plants and stones inside it.\nObjects: [vase]"
      },
      {
        "from": "gpt",
        "value": "vase: [0.211, 0.023, 0.742, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000298904_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a ornamental glass bowl at the center of the image with plants and stones inside it."
      },
      {
        "from": "gpt",
        "value": "ornamental glass bowl: [0.211, 0.023, 0.742, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000298904_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a ornamental glass bowl at the center of the image with plants and stones inside it.\nObjects: [ornamental glass bowl]"
      },
      {
        "from": "gpt",
        "value": "ornamental glass bowl: [0.211, 0.023, 0.742, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000298904_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: vase: [0.211, 0.023, 0.742, 0.961]\nGiven the above layout, shift the vase to the right by 0.164."
      },
      {
        "from": "gpt",
        "value": "vase: [0.375, 0.023, 0.906, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000383621",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying in the center of the image towards the right, with a part of a vertical pole visible on the far right edge."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.055, 0.484, 0.695, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000383621_key",
    "conversations": [
      {
        "from": "human",
        "value": "An airplane is flying in the center of the image towards the right, with a part of a vertical pole visible on the far right edge.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.055, 0.484, 0.695, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000383621_aug",
    "conversations": [
      {
        "from": "human",
        "value": "an shiny silver jet plane is flying in the center of the image towards the right, with a part of a vertical pole visible on the far right edge."
      },
      {
        "from": "gpt",
        "value": "shiny silver jet plane: [0.055, 0.484, 0.695, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000383621_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "an shiny silver jet plane is flying in the center of the image towards the right, with a part of a vertical pole visible on the far right edge.\nObjects: [shiny silver jet plane]"
      },
      {
        "from": "gpt",
        "value": "shiny silver jet plane: [0.055, 0.484, 0.695, 0.625]"
      }
    ]
  },
  {
    "id": "coco_000000383621_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.055, 0.484, 0.695, 0.625]\nGiven the above layout, shift the airplane upwards by 0.336."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.055, 0.148, 0.695, 0.289]"
      }
    ]
  },
  {
    "id": "coco_000000388215",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center of the image, preparing to hit a tennis ball with a raised racket."
      },
      {
        "from": "gpt",
        "value": "person: [0.383, 0.305, 0.648, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000388215_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing at the center of the image, preparing to hit a tennis ball with a raised racket.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.383, 0.305, 0.648, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000388215_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young athlete is standing at the center of the image, preparing to hit a tennis ball with a raised racket."
      },
      {
        "from": "gpt",
        "value": "young athlete: [0.383, 0.305, 0.648, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000388215_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young athlete is standing at the center of the image, preparing to hit a tennis ball with a raised racket.\nObjects: [young athlete]"
      },
      {
        "from": "gpt",
        "value": "young athlete: [0.383, 0.305, 0.648, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000388215_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.383, 0.305, 0.648, 0.805]\nGiven the above layout, shift the person to the left by 0.148."
      },
      {
        "from": "gpt",
        "value": "person: [0.234, 0.305, 0.500, 0.805]"
      }
    ]
  },
  {
    "id": "coco_000000396903",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is at the center of the image, on the ground, in front of a building with the sign \"BAE SYSTEMS\"."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.039, 0.594, 0.633, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000396903_key",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is at the center of the image, on the ground, in front of a building with the sign \"BAE SYSTEMS\".\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.039, 0.594, 0.633, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000396903_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the large commercial jet is at the center of the image, on the ground, in front of a building with the sign \"bae systems\"."
      },
      {
        "from": "gpt",
        "value": "large commercial jet: [0.039, 0.594, 0.633, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000396903_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the large commercial jet is at the center of the image, on the ground, in front of a building with the sign \"bae systems\".\nObjects: [large commercial jet]"
      },
      {
        "from": "gpt",
        "value": "large commercial jet: [0.039, 0.594, 0.633, 0.789]"
      }
    ]
  },
  {
    "id": "coco_000000396903_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.039, 0.594, 0.633, 0.789]\nGiven the above layout, shift the airplane upwards by 0.508."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.039, 0.086, 0.633, 0.281]"
      }
    ]
  },
  {
    "id": "coco_000000467776",
    "conversations": [
      {
        "from": "human",
        "value": "A large cow stands in the center, while a smaller cow is to its left, both facing forward."
      },
      {
        "from": "gpt",
        "value": "cow: [0.414, 0.289, 0.680, 0.758]\ncow: [0.188, 0.500, 0.352, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000467776_key",
    "conversations": [
      {
        "from": "human",
        "value": "A large cow stands in the center, while a smaller cow is to its left, both facing forward.\nObjects: [cow, cow]"
      },
      {
        "from": "gpt",
        "value": "cow: [0.414, 0.289, 0.680, 0.758]\ncow: [0.188, 0.500, 0.352, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000477441",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is outside, centered in view, seen through a large window."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.156, 0.367, 0.773, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000477441_key",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is outside, centered in view, seen through a large window.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.156, 0.367, 0.773, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000477441_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the large commercial jet is outside, centered in view, seen through a large window."
      },
      {
        "from": "gpt",
        "value": "large commercial jet: [0.156, 0.367, 0.773, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000477441_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the large commercial jet is outside, centered in view, seen through a large window.\nObjects: [large commercial jet]"
      },
      {
        "from": "gpt",
        "value": "large commercial jet: [0.156, 0.367, 0.773, 0.578]"
      }
    ]
  },
  {
    "id": "coco_000000477441_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.156, 0.367, 0.773, 0.578]\nGiven the above layout, shift the airplane downwards by 0.383."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.156, 0.750, 0.773, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000520077",
    "conversations": [
      {
        "from": "human",
        "value": "Several books are stacked on top of each other in a slightly tilted pile."
      },
      {
        "from": "gpt",
        "value": "book: [0.656, 0.164, 0.844, 0.711]\nbook: [0.125, 0.492, 0.664, 0.609]\nbook: [0.664, 0.562, 0.914, 0.805]\nbook: [0.266, 0.312, 0.719, 0.422]"
      }
    ]
  },
  {
    "id": "coco_000000520077_key",
    "conversations": [
      {
        "from": "human",
        "value": "Several books are stacked on top of each other in a slightly tilted pile.\nObjects: [book, book, book, book]"
      },
      {
        "from": "gpt",
        "value": "book: [0.656, 0.164, 0.844, 0.711]\nbook: [0.125, 0.492, 0.664, 0.609]\nbook: [0.664, 0.562, 0.914, 0.805]\nbook: [0.266, 0.312, 0.719, 0.422]"
      }
    ]
  },
  {
    "id": "coco_000000574810",
    "conversations": [
      {
        "from": "human",
        "value": "A cat sitting on the left side, facing a window with its profile to the viewer."
      },
      {
        "from": "gpt",
        "value": "cat: [0.250, 0.188, 0.680, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000574810_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cat sitting on the left side, facing a window with its profile to the viewer.\nObjects: [cat]"
      },
      {
        "from": "gpt",
        "value": "cat: [0.250, 0.188, 0.680, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000574810_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a black and white cat sitting on the left side, facing a window with its profile to the viewer."
      },
      {
        "from": "gpt",
        "value": "black and white cat: [0.250, 0.188, 0.680, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000574810_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a black and white cat sitting on the left side, facing a window with its profile to the viewer.\nObjects: [black and white cat]"
      },
      {
        "from": "gpt",
        "value": "black and white cat: [0.250, 0.188, 0.680, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000574810_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: cat: [0.250, 0.188, 0.680, 0.914]\nGiven the above layout, shift the cat to the right by 0.125."
      },
      {
        "from": "gpt",
        "value": "cat: [0.375, 0.188, 0.805, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000580757",
    "conversations": [
      {
        "from": "human",
        "value": "A red and white striped fire hydrant stands on the sidewalk to the right, against a tan brick wall."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.523, 0.273, 0.883, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000580757_key",
    "conversations": [
      {
        "from": "human",
        "value": "A red and white striped fire hydrant stands on the sidewalk to the right, against a tan brick wall.\nObjects: [fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.523, 0.273, 0.883, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000580757_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red and white striped blue and yellow striped fire hydrant stands on the sidewalk to the right, against a tan brick wall."
      },
      {
        "from": "gpt",
        "value": "blue and yellow striped fire hydrant: [0.523, 0.273, 0.883, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000580757_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red and white striped blue and yellow striped fire hydrant stands on the sidewalk to the right, against a tan brick wall.\nObjects: [blue and yellow striped fire hydrant]"
      },
      {
        "from": "gpt",
        "value": "blue and yellow striped fire hydrant: [0.523, 0.273, 0.883, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000580757_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: fire hydrant: [0.523, 0.273, 0.883, 0.812]\nGiven the above layout, shift the fire hydrant to the left by 0.242."
      },
      {
        "from": "gpt",
        "value": "fire hydrant: [0.281, 0.273, 0.641, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000071451",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is at the center with white bedding and a folded towel on top of it."
      },
      {
        "from": "gpt",
        "value": "bed: [0.203, 0.258, 0.797, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000071451_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is at the center with white bedding and a folded towel on top of it.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.203, 0.258, 0.797, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000071451_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the cosy queen-sized bed is at the center with white cosy queen-sized bedding and a folded towel on top of it."
      },
      {
        "from": "gpt",
        "value": "cosy queen-sized bed: [0.203, 0.258, 0.797, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000071451_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the cosy queen-sized bed is at the center with white cosy queen-sized bedding and a folded towel on top of it.\nObjects: [cosy queen-sized bed]"
      },
      {
        "from": "gpt",
        "value": "cosy queen-sized bed: [0.203, 0.258, 0.797, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000071451_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.203, 0.258, 0.797, 0.984]\nGiven the above layout, shift the bed upwards by 0.039."
      },
      {
        "from": "gpt",
        "value": "bed: [0.203, 0.219, 0.797, 0.945]"
      }
    ]
  },
  {
    "id": "coco_000000076416",
    "conversations": [
      {
        "from": "human",
        "value": "A bus with advertisements on its side is parked to the right of a metal fence, with a building in the background."
      },
      {
        "from": "gpt",
        "value": "bus: [0.180, 0.328, 0.875, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000076416_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bus with advertisements on its side is parked to the right of a metal fence, with a building in the background.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.180, 0.328, 0.875, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000076416_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red double-decker bus with ads with advertisements on its side is parked to the right of a metal fence, with a building in the background."
      },
      {
        "from": "gpt",
        "value": "red double-decker bus with ads: [0.180, 0.328, 0.875, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000076416_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red double-decker bus with ads with advertisements on its side is parked to the right of a metal fence, with a building in the background.\nObjects: [red double-decker bus with ads]"
      },
      {
        "from": "gpt",
        "value": "red double-decker bus with ads: [0.180, 0.328, 0.875, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000076416_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.180, 0.328, 0.875, 0.711]\nGiven the above layout, shift the bus upwards by 0.062."
      },
      {
        "from": "gpt",
        "value": "bus: [0.180, 0.266, 0.875, 0.648]"
      }
    ]
  },
  {
    "id": "coco_000000102820",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting with a cake placed in front on a surface."
      },
      {
        "from": "gpt",
        "value": "person: [0.203, 0.023, 0.805, 0.828]\ncake: [0.234, 0.750, 0.555, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000102820_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting with a cake placed in front on a surface.\nObjects: [person, cake]"
      },
      {
        "from": "gpt",
        "value": "person: [0.203, 0.023, 0.805, 0.828]\ncake: [0.234, 0.750, 0.555, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000102820_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young individual is sitting with a delicious looking chocolate cake placed in front on a surface."
      },
      {
        "from": "gpt",
        "value": "young individual: [0.203, 0.023, 0.805, 0.828]\ndelicious looking chocolate cake: [0.234, 0.750, 0.555, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000102820_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young individual is sitting with a delicious looking chocolate cake placed in front on a surface.\nObjects: [young individual, delicious looking chocolate cake]"
      },
      {
        "from": "gpt",
        "value": "young individual: [0.203, 0.023, 0.805, 0.828]\ndelicious looking chocolate cake: [0.234, 0.750, 0.555, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000102820_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.203, 0.023, 0.805, 0.828]\ncake: [0.234, 0.750, 0.555, 0.883]\nGiven the above layout, shift the person to the left by 0.125."
      },
      {
        "from": "gpt",
        "value": "person: [0.078, 0.023, 0.680, 0.828]\ncake: [0.234, 0.750, 0.555, 0.883]"
      }
    ]
  },
  {
    "id": "coco_000000355610",
    "conversations": [
      {
        "from": "human",
        "value": "A teddy bear on the left, slightly behind a sheep plush toy."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.000, 0.227, 0.555, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000355610_key",
    "conversations": [
      {
        "from": "human",
        "value": "A teddy bear on the left, slightly behind a sheep plush toy.\nObjects: [teddy bear]"
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.000, 0.227, 0.555, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000355610_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a brown teddy bear on the left, slightly behind a sheep plush toy."
      },
      {
        "from": "gpt",
        "value": "brown teddy bear: [0.000, 0.227, 0.555, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000355610_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a brown teddy bear on the left, slightly behind a sheep plush toy.\nObjects: [brown teddy bear]"
      },
      {
        "from": "gpt",
        "value": "brown teddy bear: [0.000, 0.227, 0.555, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000355610_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: teddy bear: [0.000, 0.227, 0.555, 0.820]\nGiven the above layout, shift the teddy bear to the right by 0.227."
      },
      {
        "from": "gpt",
        "value": "teddy bear: [0.227, 0.227, 0.781, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000578093",
    "conversations": [
      {
        "from": "human",
        "value": "A train is on the right track under a large curved station roof."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.484, 0.461, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000578093_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is on the right track under a large curved station roof.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.484, 0.461, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000578093_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a green freight train is on the right track under a large curved station roof."
      },
      {
        "from": "gpt",
        "value": "a green freight train: [0.000, 0.484, 0.461, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000578093_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a green freight train is on the right track under a large curved station roof.\nObjects: [a green freight train]"
      },
      {
        "from": "gpt",
        "value": "a green freight train: [0.000, 0.484, 0.461, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000578093_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.484, 0.461, 0.727]\nGiven the above layout, shift the train to the right by 0.391."
      },
      {
        "from": "gpt",
        "value": "train: [0.391, 0.484, 0.852, 0.727]"
      }
    ]
  },
  {
    "id": "coco_000000073153",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the right of a tree trunk, partially obscured by it."
      },
      {
        "from": "gpt",
        "value": "person: [0.484, 0.023, 0.781, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000073153_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the right of a tree trunk, partially obscured by it.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.484, 0.023, 0.781, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000073153_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a hiker wearing a backpack is standing to the right of a tree trunk, partially obscured by it."
      },
      {
        "from": "gpt",
        "value": "hiker wearing a backpack: [0.484, 0.023, 0.781, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000073153_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a hiker wearing a backpack is standing to the right of a tree trunk, partially obscured by it.\nObjects: [hiker wearing a backpack]"
      },
      {
        "from": "gpt",
        "value": "hiker wearing a backpack: [0.484, 0.023, 0.781, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000073153_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.484, 0.023, 0.781, 0.984]\nGiven the above layout, shift the person to the left by 0.125."
      },
      {
        "from": "gpt",
        "value": "person: [0.359, 0.023, 0.656, 0.984]"
      }
    ]
  },
  {
    "id": "coco_000000173830",
    "conversations": [
      {
        "from": "human",
        "value": "A person is leaning forward while standing on skis."
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.289, 0.688, 0.883]\nskis: [0.227, 0.859, 0.820, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000173830_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is leaning forward while standing on skis.\nObjects: [person, skis]"
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.289, 0.688, 0.883]\nskis: [0.227, 0.859, 0.820, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000173830_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a man in red ski suit is leaning forward while standing on thin blue skis."
      },
      {
        "from": "gpt",
        "value": "man in red ski suit: [0.328, 0.289, 0.688, 0.883]\nthin blue skis: [0.227, 0.859, 0.820, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000173830_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a man in red ski suit is leaning forward while standing on thin blue skis.\nObjects: [man in red ski suit, thin blue skis]"
      },
      {
        "from": "gpt",
        "value": "man in red ski suit: [0.328, 0.289, 0.688, 0.883]\nthin blue skis: [0.227, 0.859, 0.820, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000173830_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.328, 0.289, 0.688, 0.883]\nskis: [0.227, 0.859, 0.820, 0.906]\nGiven the above layout, shift the person upwards by 0.266."
      },
      {
        "from": "gpt",
        "value": "person: [0.328, 0.023, 0.688, 0.617]\nskis: [0.227, 0.859, 0.820, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000235057",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe is bending its neck down towards the water at the center of the image."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.172, 0.000, 0.648, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000235057_key",
    "conversations": [
      {
        "from": "human",
        "value": "The giraffe is bending its neck down towards the water at the center of the image.\nObjects: [giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.172, 0.000, 0.648, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000235057_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the tall ostrich is bending its neck down towards the water at the center of the image."
      },
      {
        "from": "gpt",
        "value": "tall ostrich: [0.172, 0.000, 0.648, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000235057_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the tall ostrich is bending its neck down towards the water at the center of the image.\nObjects: [tall ostrich]"
      },
      {
        "from": "gpt",
        "value": "tall ostrich: [0.172, 0.000, 0.648, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000235057_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: giraffe: [0.172, 0.000, 0.648, 0.766]\nGiven the above layout, shift the giraffe to the right by 0.156."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.328, 0.000, 0.805, 0.766]"
      }
    ]
  },
  {
    "id": "coco_000000328430",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center, serving a tennis ball with a racket overhead."
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.500, 0.531, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000328430_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is at the center, serving a tennis ball with a racket overhead.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.500, 0.531, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000328430_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young man is at the center, serving a tennis ball with a racket overhead."
      },
      {
        "from": "gpt",
        "value": "young man: [0.312, 0.500, 0.531, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000328430_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young man is at the center, serving a tennis ball with a racket overhead.\nObjects: [young man]"
      },
      {
        "from": "gpt",
        "value": "young man: [0.312, 0.500, 0.531, 0.938]"
      }
    ]
  },
  {
    "id": "coco_000000328430_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.312, 0.500, 0.531, 0.938]\nGiven the above layout, shift the person upwards by 0.195."
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.305, 0.531, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000332455",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center of the image with the seat cover raised."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.234, 0.000, 0.828, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000332455_key",
    "conversations": [
      {
        "from": "human",
        "value": "The toilet is at the center of the image with the seat cover raised.\nObjects: [toilet]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.234, 0.000, 0.828, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000332455_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the white porcelain toilet is at the center of the image with the seat cover raised."
      },
      {
        "from": "gpt",
        "value": "white porcelain toilet: [0.234, 0.000, 0.828, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000332455_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the white porcelain toilet is at the center of the image with the seat cover raised.\nObjects: [white porcelain toilet]"
      },
      {
        "from": "gpt",
        "value": "white porcelain toilet: [0.234, 0.000, 0.828, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000332455_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.234, 0.000, 0.828, 0.977]\nGiven the above layout, shift the toilet to the left by 0.234."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.000, 0.000, 0.594, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000363072",
    "conversations": [
      {
        "from": "human",
        "value": "A train is on the tracks at the center, curving towards the right."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.484, 0.688, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000363072_key",
    "conversations": [
      {
        "from": "human",
        "value": "A train is on the tracks at the center, curving towards the right.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.484, 0.688, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000363072_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a red freight train is on the tracks at the center, curving towards the right."
      },
      {
        "from": "gpt",
        "value": "red freight train: [0.000, 0.484, 0.688, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000363072_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a red freight train is on the tracks at the center, curving towards the right.\nObjects: [red freight train]"
      },
      {
        "from": "gpt",
        "value": "red freight train: [0.000, 0.484, 0.688, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000363072_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.000, 0.484, 0.688, 0.758]\nGiven the above layout, shift the train upwards by 0.289."
      },
      {
        "from": "gpt",
        "value": "train: [0.000, 0.195, 0.688, 0.469]"
      }
    ]
  },
  {
    "id": "coco_000000409211",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the foreground playing tennis, with two people observing in the background."
      },
      {
        "from": "gpt",
        "value": "person: [0.414, 0.172, 0.594, 0.828]\nperson: [0.047, 0.367, 0.188, 0.523]\nperson: [0.570, 0.383, 0.641, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000409211_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the foreground playing tennis, with two people observing in the background.\nObjects: [person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.414, 0.172, 0.594, 0.828]\nperson: [0.047, 0.367, 0.188, 0.523]\nperson: [0.570, 0.383, 0.641, 0.641]"
      }
    ]
  },
  {
    "id": "coco_000000438269",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is standing on the right side of the image near the water's edge."
      },
      {
        "from": "gpt",
        "value": "bird: [0.242, 0.445, 0.578, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000438269_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is standing on the right side of the image near the waters edge.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.242, 0.445, 0.578, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000438269_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a elegant egret is standing on the right side of the image near the water's edge."
      },
      {
        "from": "gpt",
        "value": "elegant egret: [0.242, 0.445, 0.578, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000438269_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a elegant egret is standing on the right side of the image near the waters edge.\nObjects: [elegant egret]"
      },
      {
        "from": "gpt",
        "value": "elegant egret: [0.242, 0.445, 0.578, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000438269_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.242, 0.445, 0.578, 0.922]\nGiven the above layout, shift the bird upwards by 0.328."
      },
      {
        "from": "gpt",
        "value": "bird: [0.242, 0.117, 0.578, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000020992",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a hot dog in front of them."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.164, 0.992, 0.828]\nhot dog: [0.008, 0.594, 0.438, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000020992_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a hot dog in front of them.\nObjects: [person, hot dog]"
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.164, 0.992, 0.828]\nhot dog: [0.008, 0.594, 0.438, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000020992_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young man is holding a ketchup-topped hot dog in front of them."
      },
      {
        "from": "gpt",
        "value": "young man: [0.000, 0.164, 0.992, 0.828]\nketchup-topped hot dog: [0.008, 0.594, 0.438, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000020992_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young man is holding a ketchup-topped hot dog in front of them.\nObjects: [young man, ketchup-topped hot dog]"
      },
      {
        "from": "gpt",
        "value": "young man: [0.000, 0.164, 0.992, 0.828]\nketchup-topped hot dog: [0.008, 0.594, 0.438, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000020992_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.000, 0.164, 0.992, 0.828]\nhot dog: [0.008, 0.594, 0.438, 0.812]\nGiven the above layout, shift the person upwards by 0.102."
      },
      {
        "from": "gpt",
        "value": "person: [0.000, 0.062, 0.992, 0.727]\nhot dog: [0.008, 0.594, 0.438, 0.812]"
      }
    ]
  },
  {
    "id": "coco_000000331352",
    "conversations": [
      {
        "from": "human",
        "value": "A sink is mounted on the back of a toilet, which is at the center of the image."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.203, 0.500, 0.789, 0.977]\nsink: [0.250, 0.125, 0.742, 0.289]"
      }
    ]
  },
  {
    "id": "coco_000000331352_key",
    "conversations": [
      {
        "from": "human",
        "value": "A sink is mounted on the back of a toilet, which is at the center of the image.\nObjects: [toilet, sink]"
      },
      {
        "from": "gpt",
        "value": "toilet: [0.203, 0.500, 0.789, 0.977]\nsink: [0.250, 0.125, 0.742, 0.289]"
      }
    ]
  },
  {
    "id": "coco_000000331352_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a small stainless steel sink is mounted on the back of a contemporary porcelain toilet, which is at the center of the image."
      },
      {
        "from": "gpt",
        "value": "contemporary porcelain toilet: [0.203, 0.500, 0.789, 0.977]\nsmall stainless steel sink: [0.250, 0.125, 0.742, 0.289]"
      }
    ]
  },
  {
    "id": "coco_000000331352_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a small stainless steel sink is mounted on the back of a contemporary porcelain toilet, which is at the center of the image.\nObjects: [contemporary porcelain toilet, small stainless steel sink]"
      },
      {
        "from": "gpt",
        "value": "contemporary porcelain toilet: [0.203, 0.500, 0.789, 0.977]\nsmall stainless steel sink: [0.250, 0.125, 0.742, 0.289]"
      }
    ]
  },
  {
    "id": "coco_000000331352_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: toilet: [0.203, 0.500, 0.789, 0.977]\nsink: [0.250, 0.125, 0.742, 0.289]\nGiven the above layout, shift the toilet to the left by 0.070."
      },
      {
        "from": "gpt",
        "value": "toilet: [0.133, 0.500, 0.719, 0.977]\nsink: [0.250, 0.125, 0.742, 0.289]"
      }
    ]
  },
  {
    "id": "coco_000000577182",
    "conversations": [
      {
        "from": "human",
        "value": "Three benches are aligned next to each other, with the one on the leftmost side being the closest to the viewer, the center bench slightly farther away, and the rightmost bench being the farthest."
      },
      {
        "from": "gpt",
        "value": "bench: [0.008, 0.484, 0.992, 0.820]\nbench: [0.773, 0.445, 0.992, 0.734]\nbench: [0.000, 0.180, 0.070, 0.430]"
      }
    ]
  },
  {
    "id": "coco_000000577182_key",
    "conversations": [
      {
        "from": "human",
        "value": "Three benches are aligned next to each other, with the one on the leftmost side being the closest to the viewer, the center bench slightly farther away, and the rightmost bench being the farthest.\nObjects: [bench, bench, bench]"
      },
      {
        "from": "gpt",
        "value": "bench: [0.008, 0.484, 0.992, 0.820]\nbench: [0.773, 0.445, 0.992, 0.734]\nbench: [0.000, 0.180, 0.070, 0.430]"
      }
    ]
  },
  {
    "id": "coco_000000581100",
    "conversations": [
      {
        "from": "human",
        "value": "One giraffe stands slightly to the left and in front of another giraffe facing it."
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.367, 0.344, 0.602, 0.742]\ngiraffe: [0.578, 0.391, 0.711, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000581100_key",
    "conversations": [
      {
        "from": "human",
        "value": "One giraffe stands slightly to the left and in front of another giraffe facing it.\nObjects: [giraffe, giraffe]"
      },
      {
        "from": "gpt",
        "value": "giraffe: [0.367, 0.344, 0.602, 0.742]\ngiraffe: [0.578, 0.391, 0.711, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000108495",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on a bench with a skateboard positioned horizontally on the ground in front of them."
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.008, 0.828, 0.984]\nskateboard: [0.352, 0.625, 0.750, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000108495_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting on a bench with a skateboard positioned horizontally on the ground in front of them.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.312, 0.008, 0.828, 0.984]\nskateboard: [0.352, 0.625, 0.750, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000108495_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young teenager is sitting on a bench with a blue skateboard positioned horizontally on the ground in front of them."
      },
      {
        "from": "gpt",
        "value": "young teenager: [0.312, 0.008, 0.828, 0.984]\nblue skateboard: [0.352, 0.625, 0.750, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000108495_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young teenager is sitting on a bench with a blue skateboard positioned horizontally on the ground in front of them.\nObjects: [young teenager, blue skateboard]"
      },
      {
        "from": "gpt",
        "value": "young teenager: [0.312, 0.008, 0.828, 0.984]\nblue skateboard: [0.352, 0.625, 0.750, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000108495_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.312, 0.008, 0.828, 0.984]\nskateboard: [0.352, 0.625, 0.750, 0.891]\nGiven the above layout, shift the person to the left by 0.156."
      },
      {
        "from": "gpt",
        "value": "person: [0.156, 0.008, 0.672, 0.984]\nskateboard: [0.352, 0.625, 0.750, 0.891]"
      }
    ]
  },
  {
    "id": "coco_000000228214",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the foreground holding a bottle, another person partly visible to the right under an umbrella."
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.031, 0.766, 0.969]\nperson: [0.609, 0.734, 0.797, 0.992]\numbrella: [0.695, 0.500, 0.828, 0.719]\nbottle: [0.359, 0.594, 0.453, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000228214_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in the foreground holding a bottle, another person partly visible to the right under an umbrella.\nObjects: [person, person, umbrella, bottle]"
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.031, 0.766, 0.969]\nperson: [0.609, 0.734, 0.797, 0.992]\numbrella: [0.695, 0.500, 0.828, 0.719]\nbottle: [0.359, 0.594, 0.453, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000297147",
    "conversations": [
      {
        "from": "human",
        "value": "The motorcycle is parked in the center of the image, angled slightly to the right."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.023, 0.148, 0.953, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000297147_key",
    "conversations": [
      {
        "from": "human",
        "value": "The motorcycle is parked in the center of the image, angled slightly to the right.\nObjects: [motorcycle]"
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.023, 0.148, 0.953, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000297147_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red Harley-Davidson is parked in the center of the image, angled slightly to the right."
      },
      {
        "from": "gpt",
        "value": "red Harley-Davidson: [0.023, 0.148, 0.953, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000297147_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red Harley-Davidson is parked in the center of the image, angled slightly to the right.\nObjects: [red Harley-Davidson]"
      },
      {
        "from": "gpt",
        "value": "red Harley-Davidson: [0.023, 0.148, 0.953, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000297147_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: motorcycle: [0.023, 0.148, 0.953, 0.820]\nGiven the above layout, shift the motorcycle downwards by 0.094."
      },
      {
        "from": "gpt",
        "value": "motorcycle: [0.023, 0.242, 0.953, 0.914]"
      }
    ]
  },
  {
    "id": "coco_000000337055",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting to the left of a suitcase."
      },
      {
        "from": "gpt",
        "value": "person: [0.203, 0.172, 0.969, 0.820]\nsuitcase: [0.672, 0.586, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000337055_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is sitting to the left of a suitcase.\nObjects: [person, suitcase]"
      },
      {
        "from": "gpt",
        "value": "person: [0.203, 0.172, 0.969, 0.820]\nsuitcase: [0.672, 0.586, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000337055_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman is sitting to the left of a large travel bag."
      },
      {
        "from": "gpt",
        "value": "young woman: [0.203, 0.172, 0.969, 0.820]\nlarge travel bag: [0.672, 0.586, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000337055_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman is sitting to the left of a large travel bag.\nObjects: [young woman, large travel bag]"
      },
      {
        "from": "gpt",
        "value": "young woman: [0.203, 0.172, 0.969, 0.820]\nlarge travel bag: [0.672, 0.586, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000337055_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.203, 0.172, 0.969, 0.820]\nsuitcase: [0.672, 0.586, 0.992, 0.820]\nGiven the above layout, shift the person to the left by 0.141."
      },
      {
        "from": "gpt",
        "value": "person: [0.062, 0.172, 0.828, 0.820]\nsuitcase: [0.672, 0.586, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000356505",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a surfboard while surfing a wave."
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.297, 0.617, 0.719]\nsurfboard: [0.516, 0.695, 0.750, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000356505_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing on a surfboard while surfing a wave.\nObjects: [person, surfboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.344, 0.297, 0.617, 0.719]\nsurfboard: [0.516, 0.695, 0.750, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000356505_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a adventurous surfer is standing on a red surfboard while surfing a wave."
      },
      {
        "from": "gpt",
        "value": "adventurous surfer: [0.344, 0.297, 0.617, 0.719]\nred surfboard: [0.516, 0.695, 0.750, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000356505_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a adventurous surfer is standing on a red surfboard while surfing a wave.\nObjects: [adventurous surfer, red surfboard]"
      },
      {
        "from": "gpt",
        "value": "adventurous surfer: [0.344, 0.297, 0.617, 0.719]\nred surfboard: [0.516, 0.695, 0.750, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000356505_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.344, 0.297, 0.617, 0.719]\nsurfboard: [0.516, 0.695, 0.750, 0.742]\nGiven the above layout, shift the person to the left by 0.320."
      },
      {
        "from": "gpt",
        "value": "person: [0.023, 0.297, 0.297, 0.719]\nsurfboard: [0.516, 0.695, 0.750, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000357430",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza with a few slices missing, placed on a wooden round board at the center of the image."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.000, 0.188, 0.984, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000357430_key",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza with a few slices missing, placed on a wooden round board at the center of the image.\nObjects: [pizza]"
      },
      {
        "from": "gpt",
        "value": "pizza: [0.000, 0.188, 0.984, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000357430_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a fresh margherita pie with a few slices missing, placed on a wooden round board at the center of the image."
      },
      {
        "from": "gpt",
        "value": "fresh margherita pie: [0.000, 0.188, 0.984, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000357430_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a fresh margherita pie with a few slices missing, placed on a wooden round board at the center of the image.\nObjects: [fresh margherita pie]"
      },
      {
        "from": "gpt",
        "value": "fresh margherita pie: [0.000, 0.188, 0.984, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000357430_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: pizza: [0.000, 0.188, 0.984, 0.742]\nGiven the above layout, shift the pizza downwards by 0.102."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.000, 0.289, 0.984, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000357748",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is at the center of the image, angled to the right."
      },
      {
        "from": "gpt",
        "value": "bus: [0.086, 0.125, 0.992, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000357748_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bus is at the center of the image, angled to the right.\nObjects: [bus]"
      },
      {
        "from": "gpt",
        "value": "bus: [0.086, 0.125, 0.992, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000357748_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker red bus is at the center of the image, angled to the right."
      },
      {
        "from": "gpt",
        "value": "double-decker red bus: [0.086, 0.125, 0.992, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000357748_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the double-decker red bus is at the center of the image, angled to the right.\nObjects: [double-decker red bus]"
      },
      {
        "from": "gpt",
        "value": "double-decker red bus: [0.086, 0.125, 0.992, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000357748_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bus: [0.086, 0.125, 0.992, 0.781]\nGiven the above layout, shift the bus downwards by 0.062."
      },
      {
        "from": "gpt",
        "value": "bus: [0.086, 0.188, 0.992, 0.844]"
      }
    ]
  },
  {
    "id": "coco_000000365766",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is located to the left of the image, between a microwave and a sink."
      },
      {
        "from": "gpt",
        "value": "oven: [0.117, 0.500, 0.375, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000365766_key",
    "conversations": [
      {
        "from": "human",
        "value": "The oven is located to the left of the image, between a microwave and a sink.\nObjects: [oven]"
      },
      {
        "from": "gpt",
        "value": "oven: [0.117, 0.500, 0.375, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000365766_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the four-burner stove is located to the left of the image, between a microwave and a sink."
      },
      {
        "from": "gpt",
        "value": "four-burner stove: [0.117, 0.500, 0.375, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000365766_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the four-burner stove is located to the left of the image, between a microwave and a sink.\nObjects: [four-burner stove]"
      },
      {
        "from": "gpt",
        "value": "four-burner stove: [0.117, 0.500, 0.375, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000365766_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: oven: [0.117, 0.500, 0.375, 0.820]\nGiven the above layout, shift the oven to the right by 0.617."
      },
      {
        "from": "gpt",
        "value": "oven: [0.734, 0.500, 0.992, 0.820]"
      }
    ]
  },
  {
    "id": "coco_000000515982",
    "conversations": [
      {
        "from": "human",
        "value": "A person in red sliding into base to the left, a person in white crouching and catching a ball at the center, and a person in black standing as a referee to the right."
      },
      {
        "from": "gpt",
        "value": "person: [0.531, 0.172, 0.914, 0.812]\nperson: [0.250, 0.586, 0.641, 0.773]\nperson: [0.945, 0.164, 0.992, 0.312]"
      }
    ]
  },
  {
    "id": "coco_000000515982_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person in red sliding into base to the left, a person in white crouching and catching a ball at the center, and a person in black standing as a referee to the right.\nObjects: [person, person, person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.531, 0.172, 0.914, 0.812]\nperson: [0.250, 0.586, 0.641, 0.773]\nperson: [0.945, 0.164, 0.992, 0.312]"
      }
    ]
  },
  {
    "id": "coco_000000545407",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is in the center of the image flying from left to right against a clear sky."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.273, 0.438, 0.734, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000545407_key",
    "conversations": [
      {
        "from": "human",
        "value": "The airplane is in the center of the image flying from left to right against a clear sky.\nObjects: [airplane]"
      },
      {
        "from": "gpt",
        "value": "airplane: [0.273, 0.438, 0.734, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000545407_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the single-engine propeller plane is in the center of the image flying from left to right against a clear sky."
      },
      {
        "from": "gpt",
        "value": "single-engine propeller plane: [0.273, 0.438, 0.734, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000545407_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the single-engine propeller plane is in the center of the image flying from left to right against a clear sky.\nObjects: [single-engine propeller plane]"
      },
      {
        "from": "gpt",
        "value": "single-engine propeller plane: [0.273, 0.438, 0.734, 0.633]"
      }
    ]
  },
  {
    "id": "coco_000000545407_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: airplane: [0.273, 0.438, 0.734, 0.633]\nGiven the above layout, shift the airplane upwards by 0.172."
      },
      {
        "from": "gpt",
        "value": "airplane: [0.273, 0.266, 0.734, 0.461]"
      }
    ]
  },
  {
    "id": "coco_000000175251",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a toothbrush in their right hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.148, 0.031, 0.992, 0.984]\ntoothbrush: [0.484, 0.570, 0.836, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000175251_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a toothbrush in their right hand.\nObjects: [person, toothbrush]"
      },
      {
        "from": "gpt",
        "value": "person: [0.148, 0.031, 0.992, 0.984]\ntoothbrush: [0.484, 0.570, 0.836, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000175251_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a a lady with glasses is holding a blue toothbrush in their right hand."
      },
      {
        "from": "gpt",
        "value": "a lady with glasses: [0.148, 0.031, 0.992, 0.984]\nblue toothbrush: [0.484, 0.570, 0.836, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000175251_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a a lady with glasses is holding a blue toothbrush in their right hand.\nObjects: [a lady with glasses, blue toothbrush]"
      },
      {
        "from": "gpt",
        "value": "a lady with glasses: [0.148, 0.031, 0.992, 0.984]\nblue toothbrush: [0.484, 0.570, 0.836, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000175251_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.148, 0.031, 0.992, 0.984]\ntoothbrush: [0.484, 0.570, 0.836, 0.664]\nGiven the above layout, shift the person to the left by 0.141."
      },
      {
        "from": "gpt",
        "value": "person: [0.008, 0.031, 0.852, 0.984]\ntoothbrush: [0.484, 0.570, 0.836, 0.664]"
      }
    ]
  },
  {
    "id": "coco_000000193348",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a toothbrush in their right hand."
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.117, 0.828, 0.977]\ntoothbrush: [0.570, 0.609, 0.828, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000193348_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is holding a toothbrush in their right hand.\nObjects: [person, toothbrush]"
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.117, 0.828, 0.977]\ntoothbrush: [0.570, 0.609, 0.828, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000193348_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a middle-aged man is holding a blue toothbrush in their right hand."
      },
      {
        "from": "gpt",
        "value": "middle-aged man: [0.164, 0.117, 0.828, 0.977]\nblue toothbrush: [0.570, 0.609, 0.828, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000193348_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a middle-aged man is holding a blue toothbrush in their right hand.\nObjects: [middle-aged man, blue toothbrush]"
      },
      {
        "from": "gpt",
        "value": "middle-aged man: [0.164, 0.117, 0.828, 0.977]\nblue toothbrush: [0.570, 0.609, 0.828, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000193348_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.164, 0.117, 0.828, 0.977]\ntoothbrush: [0.570, 0.609, 0.828, 0.898]\nGiven the above layout, shift the person to the left by 0.125."
      },
      {
        "from": "gpt",
        "value": "person: [0.039, 0.117, 0.703, 0.977]\ntoothbrush: [0.570, 0.609, 0.828, 0.898]"
      }
    ]
  },
  {
    "id": "coco_000000236690",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is flying at the center over the water."
      },
      {
        "from": "gpt",
        "value": "bird: [0.484, 0.234, 0.758, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000236690_key",
    "conversations": [
      {
        "from": "human",
        "value": "A bird is flying at the center over the water.\nObjects: [bird]"
      },
      {
        "from": "gpt",
        "value": "bird: [0.484, 0.234, 0.758, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000236690_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a soaring hawk is flying at the center over the water."
      },
      {
        "from": "gpt",
        "value": "soaring hawk: [0.484, 0.234, 0.758, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000236690_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a soaring hawk is flying at the center over the water.\nObjects: [soaring hawk]"
      },
      {
        "from": "gpt",
        "value": "soaring hawk: [0.484, 0.234, 0.758, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000236690_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bird: [0.484, 0.234, 0.758, 0.711]\nGiven the above layout, shift the bird to the left by 0.250."
      },
      {
        "from": "gpt",
        "value": "bird: [0.234, 0.234, 0.508, 0.711]"
      }
    ]
  },
  {
    "id": "coco_000000351823",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing on the right side of the image, wearing a blue and white outfit with a red cap, looking towards the left."
      },
      {
        "from": "gpt",
        "value": "person: [0.258, 0.133, 0.586, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000351823_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing on the right side of the image, wearing a blue and white outfit with a red cap, looking towards the left.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.258, 0.133, 0.586, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000351823_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman wearing a red beret and striped blue-and-white dress standing on the right side of the image, wearing a blue and white outfit with a red cap, looking towards the left."
      },
      {
        "from": "gpt",
        "value": "young woman wearing a red beret and striped blue-and-white dress: [0.258, 0.133, 0.586, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000351823_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a young woman wearing a red beret and striped blue-and-white dress standing on the right side of the image, wearing a blue and white outfit with a red cap, looking towards the left.\nObjects: [young woman wearing a red beret and striped blue-and-white dress]"
      },
      {
        "from": "gpt",
        "value": "young woman wearing a red beret and striped blue-and-white dress: [0.258, 0.133, 0.586, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000351823_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.258, 0.133, 0.586, 0.922]\nGiven the above layout, shift the person to the right by 0.211."
      },
      {
        "from": "gpt",
        "value": "person: [0.469, 0.133, 0.797, 0.922]"
      }
    ]
  },
  {
    "id": "coco_000000358195",
    "conversations": [
      {
        "from": "human",
        "value": "A person stands at the center on a skateboard."
      },
      {
        "from": "gpt",
        "value": "person: [0.438, 0.164, 0.648, 0.844]\nskateboard: [0.531, 0.727, 0.688, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000358195_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person stands at the center on a skateboard.\nObjects: [person, skateboard]"
      },
      {
        "from": "gpt",
        "value": "person: [0.438, 0.164, 0.648, 0.844]\nskateboard: [0.531, 0.727, 0.688, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000358195_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a hipster in a beanie stands at the center on a neon-bright skateboard."
      },
      {
        "from": "gpt",
        "value": "hipster in a beanie: [0.438, 0.164, 0.648, 0.844]\nneon-bright skateboard: [0.531, 0.727, 0.688, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000358195_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a hipster in a beanie stands at the center on a neon-bright skateboard.\nObjects: [hipster in a beanie, neon-bright skateboard]"
      },
      {
        "from": "gpt",
        "value": "hipster in a beanie: [0.438, 0.164, 0.648, 0.844]\nneon-bright skateboard: [0.531, 0.727, 0.688, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000358195_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.438, 0.164, 0.648, 0.844]\nskateboard: [0.531, 0.727, 0.688, 0.859]\nGiven the above layout, shift the person to the left by 0.273."
      },
      {
        "from": "gpt",
        "value": "person: [0.164, 0.164, 0.375, 0.844]\nskateboard: [0.531, 0.727, 0.688, 0.859]"
      }
    ]
  },
  {
    "id": "coco_000000384651",
    "conversations": [
      {
        "from": "human",
        "value": "A cup is centered on a surface in the foreground with a disheveled bed in the background."
      },
      {
        "from": "gpt",
        "value": "bed: [0.000, 0.375, 0.500, 0.695]\ncup: [0.391, 0.594, 0.500, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000384651_key",
    "conversations": [
      {
        "from": "human",
        "value": "A cup is centered on a surface in the foreground with a disheveled bed in the background.\nObjects: [bed, cup]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.000, 0.375, 0.500, 0.695]\ncup: [0.391, 0.594, 0.500, 0.758]"
      }
    ]
  },
  {
    "id": "coco_000000465179",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center of the image with one arm raised and the other on the hip."
      },
      {
        "from": "gpt",
        "value": "person: [0.125, 0.195, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000465179_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing in the center of the image with one arm raised and the other on the hip.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.125, 0.195, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000465179_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a an intellectual-looking lady is standing in the center of the image with one arm raised and the other on the hip."
      },
      {
        "from": "gpt",
        "value": "an intellectual-looking lady: [0.125, 0.195, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000465179_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a an intellectual-looking lady is standing in the center of the image with one arm raised and the other on the hip.\nObjects: [an intellectual-looking lady]"
      },
      {
        "from": "gpt",
        "value": "an intellectual-looking lady: [0.125, 0.195, 0.867, 0.977]"
      }
    ]
  },
  {
    "id": "coco_000000465179_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.125, 0.195, 0.867, 0.977]\nGiven the above layout, shift the person upwards by 0.016."
      },
      {
        "from": "gpt",
        "value": "person: [0.125, 0.180, 0.867, 0.961]"
      }
    ]
  },
  {
    "id": "coco_000000575815",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza is at the center of the image on a sheet of parchment paper."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.156, 0.219, 0.797, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000575815_key",
    "conversations": [
      {
        "from": "human",
        "value": "A pizza is at the center of the image on a sheet of parchment paper.\nObjects: [pizza]"
      },
      {
        "from": "gpt",
        "value": "pizza: [0.156, 0.219, 0.797, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000575815_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a margherita pizza is at the center of the image on a sheet of parchment paper."
      },
      {
        "from": "gpt",
        "value": "margherita pizza: [0.156, 0.219, 0.797, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000575815_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a margherita pizza is at the center of the image on a sheet of parchment paper.\nObjects: [margherita pizza]"
      },
      {
        "from": "gpt",
        "value": "margherita pizza: [0.156, 0.219, 0.797, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000575815_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: pizza: [0.156, 0.219, 0.797, 0.742]\nGiven the above layout, shift the pizza downwards by 0.164."
      },
      {
        "from": "gpt",
        "value": "pizza: [0.156, 0.383, 0.797, 0.906]"
      }
    ]
  },
  {
    "id": "coco_000000352491",
    "conversations": [
      {
        "from": "human",
        "value": "The train is positioned on the tracks to the right under a platform canopy."
      },
      {
        "from": "gpt",
        "value": "train: [0.195, 0.352, 0.992, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000352491_key",
    "conversations": [
      {
        "from": "human",
        "value": "The train is positioned on the tracks to the right under a platform canopy.\nObjects: [train]"
      },
      {
        "from": "gpt",
        "value": "train: [0.195, 0.352, 0.992, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000352491_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the red locomotive is positioned on the tracks to the right under a platform canopy."
      },
      {
        "from": "gpt",
        "value": "red locomotive: [0.195, 0.352, 0.992, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000352491_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the red locomotive is positioned on the tracks to the right under a platform canopy.\nObjects: [red locomotive]"
      },
      {
        "from": "gpt",
        "value": "red locomotive: [0.195, 0.352, 0.992, 0.781]"
      }
    ]
  },
  {
    "id": "coco_000000352491_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: train: [0.195, 0.352, 0.992, 0.781]\nGiven the above layout, shift the train upwards by 0.266."
      },
      {
        "from": "gpt",
        "value": "train: [0.195, 0.086, 0.992, 0.516]"
      }
    ]
  },
  {
    "id": "coco_000000371552",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing in the center of the image on a soccer field, with a soccer ball at their feet."
      },
      {
        "from": "gpt",
        "value": "person: [0.281, 0.250, 0.445, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000371552_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person standing in the center of the image on a soccer field, with a soccer ball at their feet.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.281, 0.250, 0.445, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000371552_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager in football attire standing in the center of the image on a soccer field, with a soccer ball at their feet."
      },
      {
        "from": "gpt",
        "value": "teenager in football attire: [0.281, 0.250, 0.445, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000371552_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a teenager in football attire standing in the center of the image on a soccer field, with a soccer ball at their feet.\nObjects: [teenager in football attire]"
      },
      {
        "from": "gpt",
        "value": "teenager in football attire: [0.281, 0.250, 0.445, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000371552_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.281, 0.250, 0.445, 0.742]\nGiven the above layout, shift the person to the right by 0.398."
      },
      {
        "from": "gpt",
        "value": "person: [0.680, 0.250, 0.844, 0.742]"
      }
    ]
  },
  {
    "id": "coco_000000149375",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding at the center of the image, slightly to the left, performing a trick on a ramp."
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.188, 0.609, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000149375_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is skateboarding at the center of the image, slightly to the left, performing a trick on a ramp.\nObjects: [person]"
      },
      {
        "from": "gpt",
        "value": "person: [0.320, 0.188, 0.609, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000149375_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a skater with red hoodie is skateboarding at the center of the image, slightly to the left, performing a trick on a ramp."
      },
      {
        "from": "gpt",
        "value": "skater with red hoodie: [0.320, 0.188, 0.609, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000149375_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a skater with red hoodie is skateboarding at the center of the image, slightly to the left, performing a trick on a ramp.\nObjects: [skater with red hoodie]"
      },
      {
        "from": "gpt",
        "value": "skater with red hoodie: [0.320, 0.188, 0.609, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000149375_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.320, 0.188, 0.609, 0.703]\nGiven the above layout, shift the person to the right by 0.320."
      },
      {
        "from": "gpt",
        "value": "person: [0.641, 0.188, 0.930, 0.703]"
      }
    ]
  },
  {
    "id": "coco_000000206831",
    "conversations": [
      {
        "from": "human",
        "value": "The dog is lying on the grass, positioned diagonally from the bottom left to the top right of the image, with a green toy in its mouth."
      },
      {
        "from": "gpt",
        "value": "dog: [0.031, 0.242, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000206831_key",
    "conversations": [
      {
        "from": "human",
        "value": "The dog is lying on the grass, positioned diagonally from the bottom left to the top right of the image, with a green toy in its mouth.\nObjects: [dog]"
      },
      {
        "from": "gpt",
        "value": "dog: [0.031, 0.242, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000206831_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the small-sized brown dog is lying on the grass, positioned diagonally from the bottom left to the top right of the image, with a green toy in its mouth."
      },
      {
        "from": "gpt",
        "value": "small-sized brown dog: [0.031, 0.242, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000206831_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the small-sized brown dog is lying on the grass, positioned diagonally from the bottom left to the top right of the image, with a green toy in its mouth.\nObjects: [small-sized brown dog]"
      },
      {
        "from": "gpt",
        "value": "small-sized brown dog: [0.031, 0.242, 0.992, 0.828]"
      }
    ]
  },
  {
    "id": "coco_000000206831_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: dog: [0.031, 0.242, 0.992, 0.828]\nGiven the above layout, shift the dog upwards by 0.242."
      },
      {
        "from": "gpt",
        "value": "dog: [0.031, 0.000, 0.992, 0.586]"
      }
    ]
  },
  {
    "id": "coco_000000231549",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is centered in the image, with two lamps on either side mounted on the wall."
      },
      {
        "from": "gpt",
        "value": "bed: [0.188, 0.664, 0.789, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000231549_key",
    "conversations": [
      {
        "from": "human",
        "value": "The bed is centered in the image, with two lamps on either side mounted on the wall.\nObjects: [bed]"
      },
      {
        "from": "gpt",
        "value": "bed: [0.188, 0.664, 0.789, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000231549_aug",
    "conversations": [
      {
        "from": "human",
        "value": "the king sized bed is centered in the image, with two lamps on either side mounted on the wall."
      },
      {
        "from": "gpt",
        "value": "king sized bed: [0.188, 0.664, 0.789, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000231549_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "the king sized bed is centered in the image, with two lamps on either side mounted on the wall.\nObjects: [king sized bed]"
      },
      {
        "from": "gpt",
        "value": "king sized bed: [0.188, 0.664, 0.789, 0.867]"
      }
    ]
  },
  {
    "id": "coco_000000231549_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: bed: [0.188, 0.664, 0.789, 0.867]\nGiven the above layout, shift the bed upwards by 0.555."
      },
      {
        "from": "gpt",
        "value": "bed: [0.188, 0.109, 0.789, 0.312]"
      }
    ]
  },
  {
    "id": "coco_000000155051",
    "conversations": [
      {
        "from": "human",
        "value": "A clock is positioned at the upper right in the image."
      },
      {
        "from": "gpt",
        "value": "clock: [0.578, 0.133, 0.984, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000155051_key",
    "conversations": [
      {
        "from": "human",
        "value": "A clock is positioned at the upper right in the image.\nObjects: [clock]"
      },
      {
        "from": "gpt",
        "value": "clock: [0.578, 0.133, 0.984, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000155051_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a vintage wall clock is positioned at the upper right in the image."
      },
      {
        "from": "gpt",
        "value": "vintage wall clock: [0.578, 0.133, 0.984, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000155051_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a vintage wall clock is positioned at the upper right in the image.\nObjects: [vintage wall clock]"
      },
      {
        "from": "gpt",
        "value": "vintage wall clock: [0.578, 0.133, 0.984, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000155051_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: clock: [0.578, 0.133, 0.984, 0.594]\nGiven the above layout, shift the clock to the left by 0.312."
      },
      {
        "from": "gpt",
        "value": "clock: [0.266, 0.133, 0.672, 0.594]"
      }
    ]
  },
  {
    "id": "coco_000000353096",
    "conversations": [
      {
        "from": "human",
        "value": "A keyboard is placed in front of the TV which is centered on a desk."
      },
      {
        "from": "gpt",
        "value": "tv: [0.211, 0.203, 0.789, 0.703]\nkeyboard: [0.195, 0.703, 0.789, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000353096_key",
    "conversations": [
      {
        "from": "human",
        "value": "A keyboard is placed in front of the TV which is centered on a desk.\nObjects: [tv, keyboard]"
      },
      {
        "from": "gpt",
        "value": "tv: [0.211, 0.203, 0.789, 0.703]\nkeyboard: [0.195, 0.703, 0.789, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000353096_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a wireless gaming keyboard is placed in front of the cinematic plasma screen which is centered on a desk."
      },
      {
        "from": "gpt",
        "value": "cinematic plasma screen: [0.211, 0.203, 0.789, 0.703]\nwireless gaming keyboard: [0.195, 0.703, 0.789, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000353096_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a wireless gaming keyboard is placed in front of the cinematic plasma screen which is centered on a desk.\nObjects: [cinematic plasma screen, wireless gaming keyboard]"
      },
      {
        "from": "gpt",
        "value": "cinematic plasma screen: [0.211, 0.203, 0.789, 0.703]\nwireless gaming keyboard: [0.195, 0.703, 0.789, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000353096_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: tv: [0.211, 0.203, 0.789, 0.703]\nkeyboard: [0.195, 0.703, 0.789, 0.797]\nGiven the above layout, shift the tv upwards by 0.195."
      },
      {
        "from": "gpt",
        "value": "tv: [0.211, 0.008, 0.789, 0.508]\nkeyboard: [0.195, 0.703, 0.789, 0.797]"
      }
    ]
  },
  {
    "id": "coco_000000369503",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the right with a sink to the left in the kitchen area."
      },
      {
        "from": "gpt",
        "value": "person: [0.781, 0.125, 0.992, 0.867]\nsink: [0.523, 0.422, 0.789, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000369503_key",
    "conversations": [
      {
        "from": "human",
        "value": "A person is standing to the right with a sink to the left in the kitchen area.\nObjects: [person, sink]"
      },
      {
        "from": "gpt",
        "value": "person: [0.781, 0.125, 0.992, 0.867]\nsink: [0.523, 0.422, 0.789, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000369503_aug",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in a red dress is standing to the right with a double-basin stainless steel sink to the left in the kitchen area."
      },
      {
        "from": "gpt",
        "value": "woman in a red dress: [0.781, 0.125, 0.992, 0.867]\ndouble-basin stainless steel sink: [0.523, 0.422, 0.789, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000369503_aug_key",
    "conversations": [
      {
        "from": "human",
        "value": "a woman in a red dress is standing to the right with a double-basin stainless steel sink to the left in the kitchen area.\nObjects: [woman in a red dress, double-basin stainless steel sink]"
      },
      {
        "from": "gpt",
        "value": "woman in a red dress: [0.781, 0.125, 0.992, 0.867]\ndouble-basin stainless steel sink: [0.523, 0.422, 0.789, 0.453]"
      }
    ]
  },
  {
    "id": "coco_000000369503_shift",
    "conversations": [
      {
        "from": "human",
        "value": "Layout: person: [0.781, 0.125, 0.992, 0.867]\nsink: [0.523, 0.422, 0.789, 0.453]\nGiven the above layout, shift the sink to the left by 0.250."
      },
      {
        "from": "gpt",
        "value": "person: [0.781, 0.125, 0.992, 0.867]\nsink: [0.273, 0.422, 0.539, 0.453]"
      }
    ]
  }
]